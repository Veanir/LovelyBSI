[
    {
        "questionId": 1,
        "title": "Sieci VPN mozna zbudowac wykorzystujac: ",
        "answers": [
            {
                "text": "IDS",
                "isCorrect": false
            },
            {
                "text": "Wireguard",
                "isCorrect": true
            },
            {
                "text": "TLS",
                "isCorrect": true
            },
            {
                "text": "SIEM",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Sieć VPN (Virtual Private Network) to technologia tworząca bezpieczne, szyfrowane połączenie w mniej bezpiecznej sieci, takiej jak internet. VPN-y wykorzystują różne protokoły i narzędzia, aby zapewnić poufność, integralność oraz autentyczność przesyłanych danych.\n\n**\"IDS\" (Intrusion Detection System)** jest **niepoprawną** odpowiedzią, ponieważ IDS to system wykrywania intruzów. Systemy IDS nie tworzą bezpiecznych połączeń, tylko monitorują ruch sieciowy w poszukiwaniu złośliwej aktywności. Przykładowo, Snort to popularny system IDS analizujący ruch sieciowy, ale nie tworzy połączeń VPN. Użyteczność systemów IDS jest duża z uwagi na analizę ruchu sieciowego, jednak nie są one wykorzystywane w procesie tworzenia tuneli VPN.\n\n**\"Wireguard\"** jest **poprawną** odpowiedzią. WireGuard to nowoczesny, otwarty protokół VPN, znany z prostoty, szybkości i bezpieczeństwa. Jest zaprojektowany z myślą o łatwości konfiguracji i wysokiej wydajności. Wykorzystuje zaawansowaną kryptografię, w tym Curve25519 dla wymiany kluczy, ChaCha20 dla szyfrowania symetrycznego i Poly1305 dla uwierzytelniania. WireGuard jest szeroko stosowany na różnych platformach, od smartfonów po serwery. Przykładowo można za jego pomocą zestawić tunel między telefonem z systemem Android a serwerem w firmie.\n\n**\"TLS\" (Transport Layer Security)** jest **poprawną** odpowiedzią. TLS to protokół kryptograficzny zapewniający bezpieczeństwo komunikacji w sieci. Często używany w połączeniu z protokołem HTTP w celu utworzenia bezpiecznego połączenia HTTPS, TLS również może być używany do tworzenia tuneli VPN. OpenVPN na przykład, jest popularnym oprogramowaniem VPN, które wykorzystuje protokół TLS. Zabezpieczenie poczty elektronicznej szyfrowaniem lub podpisem również opiera się o TLS. TLS jest szeroko wykorzystywane, ponieważ może być stosowane w oparciu o zróżnicowane algorytmy kryptograficzne w połączeniu z uwierzytelnieniem za pomocą certyfikatów cyfrowych.\n\n**\"SIEM\" (Security Information and Event Management)** jest **niepoprawną** odpowiedzią, ponieważ SIEM to system zarządzania informacjami i zdarzeniami bezpieczeństwa. Systemy SIEM to narzędzia analityczne służące do zbierania logów z wielu źródeł i analizowania ich pod kątem zagrożeń. Logi z systemów IDS mogą zostać wykorzystane do zasilenia systemu SIEM. Chociaż istotne w bezpieczeństwie, systemy SIEM nie tworzą szyfrowanych połączeń, a jedynie wspomagają proces analizy bezpieczeństwa systemu."
    },
    {
        "questionId": 2,
        "title": "Uzytkownik Windows, bedacy administratorem, po zalogowaniu sie do systemu: ",
        "answers": [
            {
                "text": "otrzyma pelny token uprawnien i zawsze bedzie korzystal z pelnego tokenu",
                "isCorrect": false
            },
            {
                "text": "otrzyma token pelny i ograniczony, zawsze bedzie korzystal z pelnego tokenu",
                "isCorrect": false
            },
            {
                "text": "otrzyma token pelny i ograniczony, bedzie mogl korzystac z jednego lub drugiego",
                "isCorrect": true
            },
            {
                "text": "otrzyma tylko token ograniczony, ale bedzie mogl wykorzystac pelny token przy uzyciu mechanizmu impersonation",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "W systemie Windows, użytkownik będący administratorem po zalogowaniu otrzymuje dwa tokeny: token pełny i token ograniczony. Token w systemie Windows reprezentuje kontekst zabezpieczeń, zawierający informacje o użytkowniku, jego przynależności do grup i jego uprawnieniach. Token pełny zawiera wszystkie możliwe uprawnienia administracyjne, podczas gdy token ograniczony daje dostęp tylko do uprawnień typowego użytkownika.\n\n**Odpowiedź 1:**\n„otrzyma pelny token uprawnien i zawsze bedzie korzystal z pelnego tokenu” - **Niepoprawna**.\n Administrator po zalogowaniu nie korzysta _zawsze_ z pełnego tokenu. System Windows domyślnie uruchamia procesy w kontekście użytkownika standardowego, nawet jeśli użytkownik zalogował się jako administrator. Zastosowanie pełnego tokenu wymaga podjęcia specjalnych akcji (np. uruchomienia programu z podwyższonymi uprawnieniami poprzez menu kontekstowe). Ta odpowiedź ignoruje ważny mechanizm bezpieczeństwa jakim jest dualizm tokenów.\n\n**Odpowiedź 2:**\n„otrzyma token pelny i ograniczony, zawsze bedzie korzystal z pelnego tokenu” - **Niepoprawna.**\nUżytkownik otrzymuje oba tokeny, ale jak już wspomniano, system domyślnie nie używa tokenu pełnego, a ograniczonego. Ta odpowiedź błędnie zakłada, że uprawnienia administratora są stale aktywne, co przeczy idei bezpieczeństwa.\n\n**Odpowiedź 3:**\n„otrzyma token pelny i ograniczony, bedzie mogl korzystac z jednego lub drugiego” - **Poprawna**.\nTa odpowiedź jest prawdziwa. Administrator otrzymuje oba tokeny i może, w zależności od wykonywanej akcji, używać tokenu standardowego (ograniczonego) lub tokenu z podwyższonymi uprawnieniami (pełnego). Typowym przykładem wykorzystania tokenu pełnego jest uruchomienie programu \"jako administrator\" (wywołanie z menu kontekstowego). Domyślne uruchomienie programu z graficznego interfejsu (GUI) spowoduje wykorzystanie tokena ograniczonego. Token pełny jest również wykorzystywany podczas pracy z konsolą (cmd) i innych narzędzi administracyjnych, jeśli są one wywoływane bezpośrednio z graficznego interfejsu(GUI) z wykorzystaniem menu kontekstowego \"Uruchom jako administrator\". \n\n**Odpowiedź 4:**\n„otrzyma tylko token ograniczony, ale bedzie mogl wykorzystac pelny token przy uzyciu mechanizmu impersonation” - **Niepoprawna.**\nChociaż mechanizm impersonation, czyli podszywania się pod innego użytkownika, jest w Windows używany, to nie jest jedyną drogą do uzyskania pełnego tokena. A administrator, jak to zostało już wyjaśnione, otrzymuje oba tokeny.  Prawdziwym powodem istnienia dualnego tokenu jest mechanizm separacji uprawnień, dzięki czemu nawet jeśli dojdzie do niepowołanej ingerencji w system operacyjny to jej negatywne skutki są w znacznym stopniu ograniczone poprzez wymóg aktywnego zażądania podwyższenia uprawnień do pełnego tokena. \n\n**Praktyczne implikacje:** Załóżmy, że użytkownik, który jest administratorem w systemie Windows, otwiera plik tekstowy ze złośliwym kodem. Jeśli uruchomienie takiego pliku z prawami administratora nie było by wymagane do działania pliku(nie jest to domyślna akcja użytkownika) to kod ten mógłby potencjalnie spowodować poważne problemy w systemie operacyjnym. Wykorzystanie mechanizmu separacji uprawnień powoduje, że kod tego pliku uruchomiony z poziomu standardowego użytkownika nie powoduje większych szkód dla systemu operacyjnego. \n\n**Podsumowanie:**\nKoncepcja dualnych tokenów w Windows to mechanizm bezpieczeństwa, który uniemożliwia domyślne działanie wszystkich programów z uprawnieniami administratora, co drastycznie ogranicza potencjalne zagrożenia wynikające z błędnego działania użytkownika lub niepożądanych działań złośliwego oprogramowania."
    },
    {
        "questionId": 3,
        "title": "Metoda Diffiego-Hellmana: ",
        "answers": [
            {
                "text": "pozwala bezpiecznie skladowac klucze prywatne uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "jest odporna na ataki pasywne",
                "isCorrect": true
            },
            {
                "text": "jest odporna na ataki aktywne",
                "isCorrect": false
            },
            {
                "text": "pozwala bezpiecznie dystrybuowac klucze publiczne uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "wykorzystuje idee asymetrycznej pary kluczy (prywatny-publiczny)",
                "isCorrect": true
            },
            {
                "text": "generuje programowo hasla SSO",
                "isCorrect": false
            },
            {
                "text": "pozwala wygenerowac symetryczny klucz sesji",
                "isCorrect": true
            },
            {
                "text": "realizuje uwierzytelnianie metoda hasel jednorazowych",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Metoda Diffiego-Hellmana jest protokołem wymiany kluczy, a nie algorytmem szyfrowania samym w sobie. Służy ona do bezpiecznego uzgodnienia tajnego, wspólnego klucza symetrycznego pomiędzy dwoma stronami komunikacji, które nie mają żadnych wcześniejszych ustaleń ani tajnych informacji. Klucz ten jest później używany do symetrycznego szyfrowania wiadomości między komunikującymi się stronami. Klucz publiczny, będący wynikiem obliczeń w procedurze Diffiego-Hellmana, nie jest w ogólności certyfikowany. Klucze prywatne są tajne i nie są przez tą metodę przechowywane ani udostępniane.\n\n*   **\"pozwala bezpiecznie skladowac klucze prywatne uzytkownikow\"**\n    *   **Incorrect.** Metoda Diffiego-Hellmana *nie* służy do przechowywania kluczy. Klucze prywatne są tajne i muszą być przechowywane w bezpieczny sposób po stronie użytkowników.  Diffie-Hellman  wykorzystywane jest jedynie do uzgodnienia klucza symetrycznego.\n*   **\"jest odporna na ataki pasywne\"**\n    *   **Correct.**  Atak pasywny to sytuacja, w której atakujący jedynie podsłuchuje komunikację, nie modyfikując jej.  Diffie-Hellman  zapewnia, że nawet jeśli atakujący przechwyci wymieniane dane publiczne, nie będzie w stanie obliczyć wspólnego tajnego klucza. Jest to możliwe dzięki matematycznym właściwościom tej metody, opartej na problemie logarytmu dyskretnego.\n*   **\"jest odporna na ataki aktywne\"**\n    *   **Incorrect.** Diffie-Hellman jest podatny na ataki aktywne, takie jak atak typu \"man-in-the-middle\" (człowiek w środku). Atakujący może przechwycić wymieniane dane publiczne i zastąpić je swoimi danymi, niepostrzeżenie dla obu stron wymiany. W efekcie atakujący uzyskuje wspólny tajny klucz z każdą ze stron i w ten sposób uzyskuje dostęp do zaszyfrowanej komunikacji. Protokół Diffiego-Hellmana sam w sobie nie posiada mechanizmu uwierzytelniania stron komunikacji.\n*   **\"pozwala bezpiecznie dystrybuowac klucze publiczne uzytkownikow\"**\n    *   **Incorrect.** Diffie-Hellman nie jest używany do dystrybucji kluczy publicznych. Uczestnicy wymieniają dane publiczne potrzebne do uzgodnienia klucza symetrycznego. Klucze publiczne w sensie certyfikatów cyfrowych nie są dystrybuowane.\n*   **\"wykorzystuje idee asymetrycznej pary kluczy (prywatny-publiczny)\"**\n    *    **Correct.** Algorytm Diffiego-Hellmana opiera się na koncepcji, w której obie strony mają dane publiczne i prywatne, które biorą udział w obliczeniu wspólnego sekretu symetrycznego. Chociaż nie są one używane do szyfrowania danych jak w kryptografii asymetrycznej (np. RSA), to mechanizm Diffie-Hellmana wykorzystuje operacje matematyczne analogiczne do używanych przy kryptografii asymetrycznej.\n*  **\"generuje programowo hasla SSO\"**\n    *  **Incorrect**. Diffie-Hellman nie generuje haseł dla mechanizmów SSO. SSO(ang. Single sign-on) to protokół umożliwiający wykorzystanie jednego hasła do wielu usług/aplikacji.  Diffie-Hellman jest protokołem wymiany kluczy, nie uwierzytelniania.\n*   **\"pozwala wygenerowac symetryczny klucz sesji\"**\n    *   **Correct.**  Głównym zadaniem protokołu Diffiego-Hellmana jest uzgodnienie wspólnego tajnego klucza, który jest kluczem symetrycznym. Klucz ten jest używany do szyfrowania komunikacji między stronami po zakończeniu protokołu Diffiego-Hellmana. Klucz ten jest określany mianem klucza sesyjnego ponieważ jest generowany dla jednej konkretnej sesji.\n*   **\"realizuje uwierzytelnianie metoda hasel jednorazowych\"**\n     *    **Incorrect.** Diffie-Hellman nie ma nic wspólnego z hasłami jednorazowymi OTP. OTP to metoda uwierzytelniania wymagająca użycia specjalnych, często fizycznych tokenów, które zmieniają hasło co pewien okres czasu. Diffie-Hellman to metoda wymiany kluczy.\n\nW praktyce Diffie-Hellman jest wykorzystywany w protokołach HTTPS (w połączeniu z RSA w celu uwierzytelniania serwera) czy SSH, gdzie pozwala na uzgodnienie wspólnego klucza sesyjnego do szyfrowania komunikacji. Na przykład, gdy przeglądarka łączy się z serwerem banku, Diffie-Hellman może być wykorzystane do wygenerowania klucza sesyjnego potrzebnego do odszyfrowania danych transmitowanych po SSL/TLS."
    },
    {
        "questionId": 4,
        "title": "Usluga DNSsec:",
        "answers": [
            {
                "text": "wykorzystuje IPsec do tunelowania zapytan i odpowiedzi DNS",
                "isCorrect": false
            },
            {
                "text": "wykorzystuje SSL do tunelowania zapytan i odpowiedzi DNS",
                "isCorrect": false
            },
            {
                "text": "wymaga podpisanych cyfrowo zapytan DNS",
                "isCorrect": false
            },
            {
                "text": "stosuje podpisy cyfrowe odpowiedzi DNS",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "DNSSEC (Domain Name System Security Extensions) to zestaw rozszerzeń protokołu DNS, którego celem jest zwiększenie bezpieczeństwa systemu DNS. DNSSEC skupia się na zapewnieniu autentyczności i integralności odpowiedzi DNS, a nie na ochronie poufności zapytań. Wykorzystuje do tego podpisy cyfrowe tworzone przy użyciu kryptografii klucza publicznego. Serwery DNS podpisują swoje odpowiedzi kluczem prywatnym, a klienci weryfikują ten podpis kluczem publicznym, powiązanym z daną strefą DNS, w celu sprawdzenia autentyczności i integralności danych.\n\n**Odpowiedź: \"wykorzystuje IPsec do tunelowania zapytan i odpowiedzi DNS\" jest niepoprawna.** IPsec to protokół służący do tworzenia bezpiecznych połączeń VPN (Virtual Private Network) na poziomie warstwy sieciowej (IP). Protokół ten zapewnia poufność i integralność pakietów IP. IPsec nie jest bezpośrednio używany do ochrony odpowiedzi DNS przed manipulacją, ale może chronić dane przekazywane tunelami VPN, które mogą w pewnych przypadkach przesyłać zapytania i odpowiedzi DNS. Na przykład sieć korporacyjna może wykorzystywać IPsec do zapewnienia poufności i autentyczności pakietów przesyłanych między oddziałami, gdzie zapytania DNS i odpowiedzi mogą być transmitowane w bezpiecznym tunelu, ale sam DNSSEC tego tunelowania nie zapewnia.\n\n**Odpowiedź: \"wykorzystuje SSL do tunelowania zapytan i odpowiedzi DNS\" jest niepoprawna.** SSL (Secure Sockets Layer) / TLS (Transport Layer Security) to protokoły zapewniające bezpieczeństwo komunikacji na poziomie warstwy transportowej (TCP) poprzez szyfrowanie i uwierzytelnianie. SSL chroni komunikację pomiędzy klientem a serwerem, natomiast nie chroni bezpośrednio zapytań DNS, które często są przesyłane protokołem UDP bez nawiązywania połączenia. Choć SSL można użyć do przesyłania zapytań DNS (np. DNS over HTTPS), nie jest to typowa metoda ochrony samego DNS-a. Zastosowanie SSL ma za zadanie zabezpieczyć połączenie HTTP z serwerem WWW, na przykład gdy klient odwołuje się do danej strony o adresie www.przyklad.pl. Najpierw wykonywane jest zapytanie DNS do serwera w celu uzyskania adresu IP serwera a następnie, jeśli serwer wspiera SSL połączenie HTTP jest szyfrowane za pomocą protokołu SSL.\n\n**Odpowiedź: \"wymaga podpisanych cyfrowo zapytan DNS\" jest niepoprawna.** Chociaż DNSSEC *może* być używany do weryfikacji zapytań, to standardowo skupia się on na weryfikacji odpowiedzi. Zapytania są przesyłane w niezmienionej postaci, natomiast odpowiedzi są podpisywane przez zaufane serwery DNS. Oznacza to, że DNSSEC chroni przed podmianą odpowiedzi i gwarantuje, że odpowiedź pochodzi z zaufanego serwera, ale niekoniecznie zapewnia ochronę zapytań przed podsłuchem. Implementacja DNSSEC skupia się na ochronie integralności odpowiedzi. \nNa przykład w sytuacji kiedy ktoś złośliwie podszyje się pod serwer DNS i zwróci fałszywą odpowiedź dla strony www.przyklad.pl zamiast prawdziwego adresu IP, klient z DNSSEC rozpozna, że podpis cyfrowy dla odpowiedzi jest niepoprawny, co oznacza ingerencję osób trzecich i klient odrzuci taką fałszywą odpowiedź.\n\n**Odpowiedź: \"stosuje podpisy cyfrowe odpowiedzi DNS\" jest poprawna.** Istotą DNSSEC jest dodawanie podpisów cyfrowych do odpowiedzi DNS. Podpis jest tworzony przez serwer, który jest autorytatywny dla danej domeny, i weryfikowany przez klienta. Klient używa klucza publicznego zaufanej trzeciej strony, urzędu certyfikacji (CA), aby zweryfikować, czy klucz publiczny serwera DNS jest autentyczny oraz zweryfikować podpis cyfrowy w odpowiedzi. Jeżeli weryfikacja podpisów przebiegnie pomyślnie, klient DNS może mieć pewność, że dana odpowiedź DNS jest autentyczna i nie została sfałszowana podczas transmisji. Zabezpieczenie to chroni przed atakami typu _man-in-the-middle_, polegającymi na przechwyceniu i modyfikacji odpowiedzi DNS.\nNa przykład podczas nawiązywania połączenia z serwerem pocztowym z domeny poczta.przyklad.pl, odpowiedź DNS z serwera, która wskazuje na adres IP serwera poczty jest podpisana cyfrowo. Klient poczty po otrzymaniu odpowiedzi DNS i jej pozytywnej weryfikacji wie że ten adres IP na pewno wskazuje na serwer poczty z domeny poczta.przyklad.pl."
    },
    {
        "questionId": 5,
        "title": "Ktore metody uwierzytelniania stosuje protokol HTTP/1.1",
        "answers": [
            {
                "text": "tylko uzycie jednokierunkowej funkcji skrotu",
                "isCorrect": false
            },
            {
                "text": "tylko username-password",
                "isCorrect": false
            },
            {
                "text": "zarowno username-password jak i uzycie funkcji skrotu, ale nie certyfikaty X.509",
                "isCorrect": true
            },
            {
                "text": "zarowno username-password, funkcja skrotu, jak i certyfikaty X.509",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół HTTP/1.1, sam w sobie, wykorzystuje głównie dwie metody uwierzytelniania: \"basic\" (podstawowe, _username-password_) i \"digest\" (z użyciem funkcji skrótu).  Uwierzytelnianie to proces weryfikacji tożsamości użytkownika, aplikacji lub urządzenia.\n\nOpcja podstawowa _username-password_ polega na przesłaniu przez klienta (np. przeglądarkę internetową) do serwera (np. serwera www) zakodowanej metodą base64 nazwy użytkownika i hasła. Zastosowanie kodowania Base64 powoduje , że hasło nie jest transmitowane tekstem jawnym, jednak jest bardzo proste do odkodowania, dlatego też uważa się za metodę mało bezpieczną.  Przykład: jeśli nazwa użytkownika to \"user\" i hasło \"pass\", to zakodowana wersja w polu nagłówka HTTP wygląda mniej więcej tak _Authorization: Basic dXNlcjpwYXNz_. Hasło przekazywane jest bez żadnego dodatkowego zabezpieczenia.\n\nOpcja _digest_  jest bardziej zaawansowana.  Zamiast przesyłać hasło, klient i serwer posługują się jednokierunkową funkcją skrótu.  Serwer wysyła do klienta wyzwanie (ang. _nonce_) - losowy ciąg znaków. Klient, mając hasło użytkownika, oraz znając tajny klucz z serwera,  łączy to hasło, _nonce_  i  inne dane ze znanego sobie algorytmu  i generuje skrót (np. MD5, SHA1, SHA256). Ten skrót jest przesyłany do serwera. Serwer powtarza tą samą operację i porównuje wynik ze skrótem otrzymanym od klienta. Jeśli skróty są identyczne, uwierzytelnianie jest zakończone sukcesem.  Funkcja skrótu jest jednokierunkowa, tzn nie jest możliwe z odzyskanie informacji(hasła) z jego postaci skróconej. Podstawową wadą tego rozwiązania jest konieczność posiadania wspólnego tajnego klucza. \n\nWażne jest aby zauważyć że HTTP/1.1 **samodzielnie** nie wspiera uwierzytelniania z użyciem certyfikatów X.509. Certyfikaty X.509 są wykorzystywane głównie w protokole HTTPS, który to jest kombinacją protokołu HTTP oraz protokołu SSL/TLS. Protokoły SSL/TLS to odrębne mechanizmy ochrony komunikacji działające niżej w hierarchii sieciowej i niezależne od protokołu warstwy aplikacji HTTP.\n\n* **\"tylko uzycie jednokierunkowej funkcji skrotu\"** -  **Niepoprawna**. Chociaż HTTP/1.1 umożliwia uwierzytelnianie typu _digest_, to nie jest to jedyna możliwość, ponieważ nadal wspierane jest uwierzytelnienie podstawowe. Brak wiedzy o podstawowym typie uwierzytelniania może skutkować poważnymi dziurami bezpieczeństwa.\n* **\"tylko username-password\"** - **Niepoprawna**. Brak wiedzy o uwierzytelnieniu z wykorzystaniem funkcji skrótu może być szkodliwe z uwagi na większe bezpieczeństwo tego podejścia. Brak wykorzystywania tego mechanizmu świadczy o słabej konfiguracji systemu.\n* **\"zarowno username-password jak i uzycie funkcji skrotu, ale nie certyfikaty X.509\"** -  **Poprawna**.  HTTP/1.1 (bez SSL/TLS) wspiera te dwie metody.  Zarówno basic authentication jak i digest, ale samo HTTP/1.1 nie posiada mechanizmów weryfikacji certyfikatów X.509.\n* **\"zarowno username-password, funkcja skrotu, jak i certyfikaty X.509\"** -  **Niepoprawna**.  Protokół HTTP/1.1 nie posiada mechanizmów weryfikacji certyfikatów X.509. Certyfikaty wykorzystywane są w protokole HTTPS, który to jest rozszerzeniem HTTP o możliwości szyfrowania oraz identyfikacji certyfikatami standardu X.509.\n\nPraktyczne implikacje: Tworząc aplikację WWW z użyciem protokołu HTTP/1.1 musimy pamiętać o jego ograniczeniach, w szczególności o możliwości wykorzystania jedynie podstawowego uwierzytelnienia oraz uwierzytelnienia z wykorzystaniem funkcji skrótu. Jeżeli zależy nam na większym bezpieczeństwie należy pamiętać o skorzystaniu z HTTPS.\n\nPodsumowanie: Poprawne uwierzytelnianie w protokole HTTP/1.1 jest ważne, gdyż nieumiejętne konfiguracje mogą narazić użytkowników na potencjalne nadużycia lub przejęcie hasła. Niestety w protokole HTTP/1.1 nie ma wbudowanych mechanizmów uwierzytelniania certyfikatami. Natomiast wykorzystywanie szyfrowania w komunikacji z użyciem HTTPS stanowi najistotniejszy krok do bezpiecznego i poufnego przesyłania danych."
    },
    {
        "questionId": 6,
        "title": "Ktore komponenty systemu operacyjnego Windows moga korzystac ze sprzetowej wirtualizacji celem podniesienia bezpieczenstwa systemu:",
        "answers": [
            {
                "text": "Alpine docker containers",
                "isCorrect": false
            },
            {
                "text": "Defender Application Guard",
                "isCorrect": true
            },
            {
                "text": "AppContainer",
                "isCorrect": true
            },
            {
                "text": "Ring - 1 compartmentalization",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm wirtualizacji sprzętowej (hardware virtualization) umożliwia tworzenie izolowanych środowisk w ramach jednego fizycznego komputera. Te środowiska, zwane maszynami wirtualnymi (VM), posiadają własne, wirtualne zasoby sprzętowe takie jak procesor, pamięć, dysk, czy karta sieciowa. Kluczową cechą tej technologii, w kontekście bezpieczeństwa, jest to, że każdy VM działa odizolowany od pozostałych środowisk.  Dzięki temu, atak na jeden VM nie ma bezpośredniego wpływu na pozostałe VM. W systemie Windows, pewne mechanizmy zabezpieczeń są oparte właśnie na tej technologii.\n\n*   **Defender Application Guard:** Ta funkcja systemu Windows wykorzystuje wirtualizację sprzętową do uruchamiania niezaufanej treści w odizolowanym środowisku. Jeśli użytkownik otworzy dokument lub stronę internetową, która może być niebezpieczna, Application Guard uruchomi przeglądarkę internetową lub edytor wewnątrz wirtualnej maszyny. W przypadku wykrycia złośliwego kodu, jego działanie ograniczone jest wyłącznie do wirtualnego środowiska, a nie całego systemu operacyjnego.  To oznacza, że nawet jeśli złośliwy kod podejmie próbę ataku na pliki użytkownika, zmodyfikowania konfiguracji,  czy próbę rozprzestrzenienia się na sieć lokalną, nie będzie to możliwe. Ta wtyczka, to nie jest po prostu dodatkowa przeglądarka ale wirtualny komputer, o ograniczonych prawach, dzięki czemu potencjalny kod złośliwy który się uruchomi w przeglądarce nie wydostanie się poza ten ograniczony obszar.\n\n*   **AppContainer:** Jest to technologia, wykorzystywana głównie w systemach z rodziny Windows (aplikacje typu ModernUI) . AppContainer, nazywany również piaskownicą (sandboxing), jest mechanizmem izolacji aplikacji. AppContainer, co ciekawe wykorzystuje elementy wirtualizacji sprzętowej do ograniczania uprawnień aplikacji, które są uruchamiane w takim środowisku. Działanie tego mechanizmu polega na ograniczeniu uprawnień do zasobów systemu operacyjnego, do których ma dostęp dana aplikacja, ale nie tylko. AppContainer pozwala również separować aplikacje od siebie, dzięki czemu ich ewentualne działanie jest ograniczone do konkretnej piaskownicy. AppContainer w systemie Windows jest uważany za jeden z bardziej bezpiecznych mechanizmów ochronnych dla aplikacji uruchamianych przez użytkownika.  Przykładem zastosowania AppContainer są choćby aplikacje pobrane ze Sklepu Microsoft.\n\n*   **Alpine docker containers**: Kontenery Docker w systemie Windows również korzystają z wirtualizacji sprzętowej. Jednakże kontenery Docker to nie jest wbudowana funkcjonalność systemu MS Windows, tylko dodatkowe narzędzie, które wykorzystuje mechanizmy wirtualizacji w systemie operacyjnym Windows. Na platformie Windows Docker kontenery najczęściej korzystają z wirtualizacji Hyper-V lub WSL2 (Windows Subsystem for Linux 2), które same wykorzystują hardware virtualization.  Zatem, kontenery Docker to nie jest specyficzna funkcjonalność systemu MS Windows, w związku z tym wybór tej odpowiedzi nie jest do końca właściwy. Dodatkowo kontenery Docker są najczęściej wykorzystywane do uruchamiania obrazów systemów operacyjnych typu Linux, a nie Windows. Użytkownik musi sam zadbać o konfigurację i bezpieczeństwo Docker i działających w nich aplikacji.\n\n*   **Ring -1 compartmentalization**: System operacyjny, a dokładnie jądro systemu (kernel) realizuje swoje zadania w tzw. _ringach_ (ang. privilege ring).  Są to poziomy dostępu do procesora (ang. protection rings) a ich ideą jest ochrona kluczowych struktur systemu operacyjnego przed aplikacjami działającymi w _ringu_ użytkownika. _Ringi_ numerowane są od najmniej uprzywilejowanego do najbardziej uprzywilejowanego. Aplikacje działają w _ringu_ 3, jądro w _ringu_ 0 a hypervisor w _ringu_ -1. Próba działania aplikacji poza przydzielonym jej poziomem uprawnień zakończy się błędem systemowym.  Mechanizm _ringów_ jest ważny w systemach operacyjnych ale nie polega na mechanizmach wirtualizacji sprzętowej, a na mechanizmach kontroli dostępu w samym systemie operacyjnym. W związku z tym odpowiedź ta nie jest poprawna."
    },
    {
        "questionId": 7,
        "title": "Wskaz mechanizmy chroniace m.in. przed atakami przepelnienia bufora:",
        "answers": [
            {
                "text": "wykorzystanie Structured Exception Handling i Vectored Exception Handling",
                "isCorrect": false
            },
            {
                "text": "zapewnienie by segment pamieci z prawem zapisu nie posiadal jednoczesnie prawa wykonywania",
                "isCorrect": true
            },
            {
                "text": "randomizacja alokacji wirtualnej przestrzeni adresowej procesu",
                "isCorrect": true
            },
            {
                "text": "alokowanie na stosie dodatkowego elementu ramki funkcji wykrywajacego modyfikacje adresu powrotu - stack cookie (kanarek)",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Ataki przepełnienia bufora (ang. buffer overflow attacks) wykorzystują błędy w oprogramowaniu, które pozwalają na zapisanie większej ilości danych w buforze (obszarze pamięci) niż ten bufor jest w stanie pomieścić. Nadmiarowe dane \"wylewają się\" poza bufor, nadpisując sąsiadujące obszary pamięci. W ten sposób napastnik może przejąć kontrolę nad programem. W celu ochrony przed atakami przepełnienia bufora stosuje się różnorodne mechanizmy, które utrudniają lub uniemożliwiają wykorzystanie luki. \n\n*   **zapewnienie by segment pamięci z prawem zapisu nie posiadał jednocześnie prawa wykonywania** - jest to poprawna odpowiedź, a mechanizm nazywany jest DEP (Data Execution Prevention) lub NX (No eXecute). Polega on na tym, że obszary pamięci przeznaczone do przechowywania danych, np. sterta (heap) lub stos (stack), są oznaczone jako niewykonywalne. W ten sposób, nawet jeśli atakujący zdoła umieścić swój kod w obszarze danych, to procesor nie pozwoli na jego wykonanie, gdyż nie jest to obszar pamięci przeznaczony dla kodu wykonywalnego. Przykładowo, jeżeli kod ataku zostanie umieszczony na stosie poprzez nadpisanie adresu powrotu funkcji, to po powrocie na ten adres program zderzy się z ograniczeniem, które nie pozwala na wykonanie danych. Jest to bardzo efektywna metoda obrony w przypadku nadpisywania adresu powrotu funkcji na stosie.\n\n*   **randomizacja alokacji wirtualnej przestrzeni adresowej procesu** - jest to również poprawna odpowiedź, a mechanizm ten nazywany jest ASLR (Address Space Layout Randomization). Polega on na tym, że przy każdym uruchomieniu programu adresy obszarów pamięci (sterty, stosu, bibliotek) są losowo rozmieszczane w przestrzeni adresowej procesu. W ten sposób atakujący nie może przewidzieć adresów w pamięci, które będzie musiał nadpisać, aby np. uruchomić własny kod, więc musi opierać się na metodzie prób i błędów, przez co atak staje się trudniejszy, a często nieekonomiczny. Przykładowo, po każdej kolejnej próbie ataku, adres stosu i sterty będzie inny i atakujący nie będzie w stanie skutecznie wykorzystać poprzednio zdobytej wiedzy o rozmieszczeniu pamięci.\n\n*   **alokowanie na stosie dodatkowego elementu ramki funkcji wykrywającego modyfikacje adresu powrotu - stack cookie (kanarek)** - jest to również poprawna odpowiedź, a mechanizm ten opiera się na ochronie stosu, a dokładniej adresu powrotu funkcji. Przed umieszczeniem adresu powrotu na stosie, na stosie umieszczana jest dodatkowa wartość nazywana kanarkiem. Tuż przed powrotem z funkcji, program sprawdza, czy kanarek nie został zmodyfikowany. Jeśli kanarek został zmodyfikowany oznacza to, że doszło do przepełnienia bufora i nadpisania kanarka, i w takiej sytuacji program ma szansę wykrycia ataku i nie dopuszczenia do jego realizacji. Przykładowo, wywołując funkcję `strcpy` program umieszcza przed adresem powrotu na stosie kanarka. Jeżeli funkcja ta spowoduje przepełnienie bufora, to dojdzie do nadpisania wartości kanarka, a w konsekwencji wykrycia próby przepełnienia bufora.\n\n*   **wykorzystanie Structured Exception Handling i Vectored Exception Handling** - jest to niepoprawna odpowiedź. Te mechanizmy służą do obsługi wyjątków i błędów w programie, umożliwiając kontrolowane przejęcie sterowania w przypadku awarii, ale same w sobie nie chronią przed atakami przepełnienia bufora. Co prawda napastnik może wykorzystać te mechanizmy w celu przejęcia kontroli nad działaniem procesu poprzez zmodyfikowanie tablicy wyjątków, ale użycie tych mechanizmów nie zapobiega pojawieniu się błędu przepełnienia bufora. Przykładowo, zmodyfikowanie tablicy wyjątków pozwoli zadeklarować, że po wykryciu błędu ma być wykonany kod napastnika.\n\nPodsumowując, mechanizmy takie jak DEP/NX, ASLR i ochrona stosu za pomocą kanarków są konkretnymi, praktycznymi technikami obrony przed atakami przepełnienia bufora. Natomiast mechanizmy obsługi wyjątków mogą być wykorzystane w atakach, ale same w sobie nie stanowią ochrony przed atakami przepełnienia bufora."
    },
    {
        "questionId": 8,
        "title": "Mechanizm two-factor authentication (2FA):",
        "answers": [
            {
                "text": "wymaga uzycia 2 oddzielnych operacji (oraz danych) uwierzytelniajacych",
                "isCorrect": true
            },
            {
                "text": "dotyczy zlozonosci hasla i wymaga by nowe haslo roznilo sie od dotychczasowego na 2 pozycjach",
                "isCorrect": false
            },
            {
                "text": "to uwierzytelnianie z zaufana strona trzecia",
                "isCorrect": false
            },
            {
                "text": "to uwierzytelnianie metoda zawolanie-odzew",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Uwierzytelnianie dwuskładnikowe (2FA), zwane również uwierzytelnianiem wieloskładnikowym, wymaga użycia dwóch różnych rodzajów danych uwierzytelniających, pochodzących z odmiennych kategorii. Te kategorie, znane jako „czynniki uwierzytelniania\", to:\n*   **Coś, co wiesz:**  Na przykład hasło, PIN, odpowiedź na pytanie pomocnicze, lub wzór.\n*   **Coś, co posiadasz:** Na przykład karta chipowa, telefon komórkowy, token USB, lub klucz sprzętowy.\n*   **Coś, czym jesteś:**  Na przykład dane biometryczne, takie jak odcisk palca, skan tęczówki oka, lub rozpoznawanie głosu.\n\nPoprawne uwierzytelnianie dwuskładnikowe wymaga spełnienia dwóch z trzech wymienionych czynników.\n\n**Odpowiedź pierwsza (\"wymaga użycia 2 oddzielnych operacji (oraz danych) uwierzytelniających\"):** Jest to **poprawna** odpowiedź.  Uwierzytelnianie dwuskładnikowe  dokładnie na tym polega, czyli na zastosowaniu dwóch różnych  metod weryfikacji, aby potwierdzić tożsamość użytkownika. Na przykład, oprócz standardowego hasła, użytkownik musi wprowadzić kod z tokena lub jednorazowe hasło z telefonu komórkowego.\n\n**Odpowiedź druga (\"dotyczy złożoności hasła i wymaga by nowe hasło różniło się od dotychczasowego na 2 pozycjach\"):** Jest to odpowiedź **niepoprawna**. Złożoność hasła i zasady jego zmiany są związane z polityką haseł i nie wchodzą w zakres definicji 2FA. Chociaż silne hasło jest ważne dla bezpieczeństwa, to jednak nie jest drugim czynnikiem uwierzytelniania. 2FA dotyczy dwóch *oddzielnych* metod weryfikacji, a nie *jednej*, skomplikowanej.\n\n**Odpowiedź trzecia (\"to uwierzytelnianie z zaufaną stroną trzecią\"):** Jest to odpowiedź **niepoprawna**. Chociaż zaufane strony trzecie (np. systemy SSO) są ważne w uwierzytelnianiu, to jednak uwierzytelnianie dwuskładnikowe nie jest z nimi związane. Zaufana strona trzecia może pełnić funkcję brokera tożsamości, jednak ostatecznie weryfikacja tożsamości odbywa się na podstawie dwóch *odrębnych* czynników uwierzytelniających.\n\n**Odpowiedź czwarta (\"to uwierzytelnianie metodą zawołanie-odzew\"):** Jest to odpowiedź **niepoprawna**. Metoda zawołanie-odzew (ang. *challenge-response*) jest specyficzną formą uwierzytelniania, ale sama w sobie nie definiuje uwierzytelniania dwuskładnikowego. Metoda zawołanie-odzew może być *jednym* z czynników uwierzytelniających w 2FA, na przykład, jeśli uwierzytelnienie odbywa się przez token sprzętowy. \n\n**Przykład praktyczny:**\nUżytkownik chce zalogować się do poczty internetowej (np. Gmail). Oprócz podania hasła, musi wpisać kod, który został wysłany SMS-em na jego telefon. Hasło stanowi *„coś, co wiesz”*, a kod SMS jest *„coś, co posiadasz”*. To jest przykład 2FA. \n\nInny przykład:  \nUżytkownik loguje się do bankowości elektronicznej. Podaje login i hasło (*\"coś co wie\"*) oraz podłącza czytnik kart chipowych i podaje PIN karty (*\"coś co ma\"*). To też jest przykład 2FA.\n\nWażne jest to, że weryfikacja jest dokonywana dwoma różnymi sposobami, a nie jednym (np. skomplikowanym hasłem) w dwóch krokach."
    },
    {
        "questionId": 9,
        "title": "System Kerberos oferuje (wybierz wszystkie poprawne mozliwosci):",
        "answers": [
            {
                "text": "kryptograficzne uwierzytelnianie uzytkownikow w ramach domeny",
                "isCorrect": true
            },
            {
                "text": "delegowanie uprawnien jednego podmiotu innym podmiotom",
                "isCorrect": true
            },
            {
                "text": "zastosowanie kryptograficznego weryfikatora w celu ochrony przed atakiem Golden Ticket",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie uzytkownikow pomiedzy domenami",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Kerberos to protokół uwierzytelniania sieciowego, który umożliwia bezpieczne uwierzytelnianie użytkowników i usług w środowisku rozproszonym. Opiera się na koncepcji biletów (ang. _tickets_), które są wydawane przez Centralny Ośrodek Dystrybucji Kluczy (ang. _Key Distribution Center_, KDC). KDC jest zaufaną stroną, która przechowuje klucze wszystkich użytkowników i usług w ramach danej domeny Kerberos (ang. _realm_). \n\n**Odpowiedź 1: \"kryptograficzne uwierzytelnianie uzytkownikow w ramach domeny\" - POPRAWNA.**\nKerberos zapewnia silne kryptograficzne uwierzytelnianie użytkowników w obrębie domeny, które jest oparte o algorytmy symetryczne. KDC wydaje bilety (ang. _tickets_) dla użytkowników, które są podpisane jego kluczem prywatnym. Użytkownik uwierzytelnia się, przedstawiając bilet serwerowi usługowemu, który wie jak zweryfikować poprawność biletu używając do tego klucza publicznego KDC. W praktyce, logując się do domeny Windows, używamy właśnie tego mechanizmu: po podaniu hasła na stacji roboczej następuje komunikacja z KDC i uzyskanie odpowiedniego biletu (TGT – Ticket Granting Ticket). Bilet ten umożliwia dostęp do zasobów w domenie. \n\n**Odpowiedź 2: \"delegowanie uprawnien jednego podmiotu innym podmiotom\" - POPRAWNA.**\nKerberos umożliwia delegowanie (ang. _delegation_) uprawnień, co oznacza, że usługa lub użytkownik może działać w imieniu innego użytkownika lub usługi. Ma to zastosowanie np. w sytuacjach, gdy aplikacja webowa musi uzyskać dostęp do bazy danych w imieniu zalogowanego użytkownika. Wówczas usługa webowa deleguje swoje uprawnienia do dostępu do bazy danych w imieniu użytkownika. Bez delegacji serwer webowy musiałby logować się do bazy przy użyciu własnego konta, przez co nie mógłby dostarczać konkretnemu użytkownikowi danych, do których ma dostęp. Kerberos umożliwia przesyłanie poświadczeń, które potwierdzają uprawnienia wydelegowane do serwera lub usługi. \n\n**Odpowiedź 3: \"zastosowanie kryptograficznego weryfikatora w celu ochrony przed atakiem Golden Ticket\" - NIEPOPRAWNA.**\nAtak Golden Ticket polega na uzyskaniu dostępu do klucza KDC, a następnie stworzeniu fałszywego biletu TGT (Ticket Granting Ticket), który daje uprawnienia do dowolnej usługi w domenie, bez potrzeby ponownego uwierzytelniania. System Kerberos nie chroni przed tym atakiem samym w sobie. Atak ten omija bowiem zabezpieczenia samego protokołu, a opiera się o wyciek klucza KDC. Ochrona przed takimi atakami opiera się o zabezpieczenie KDC przed nieautoryzowanym dostępem, regularne zmiany kluczy KDC oraz monitorowanie aktywności, a nie poprzez kryptograficzny weryfikator w ramach protokołu Kerberos. Kerberos nie oferuje wbudowanego mechanizmu który by wykrywał fałszywe bilety TGT. \n\n**Odpowiedź 4: \"uwierzytelnianie uzytkownikow pomiedzy domenami\" - POPRAWNA.**\nKerberos umożliwia uwierzytelnianie użytkowników pomiędzy różnymi domenami, poprzez konfigurację tzw. zaufania między domenami. W takim przypadku KDC jednej domeny wydaje bilety dla użytkowników zaufanej domeny. Użytkownik z zaufanej domeny uzyskuje dostęp do usług innej domeny na zasadzie wzajemnego zaufania. Ta funkcjonalność jest bardzo ważna w dużych organizacjach, które posiadają wiele oddziałów zlokalizowanych w różnych lokalizacjach. Oznacza to, że użytkownik np. z oddziału w Warszawie, może mieć dostęp do usług w oddziale np. w Poznaniu pod warunkiem, że obie domeny sobie ufają. W takim przypadku loguje się tylko w domenie swojego oddziału, a do domeny oddziału w Poznaniu uzyskuje dostęp bez dodatkowego logowania, a wszystko to dzięki mechanizmom uwierzytelniania międzydomenowego."
    },
    {
        "questionId": 10,
        "title": "Komputer-Twierdza:",
        "answers": [
            {
                "text": "dopuszcza komunikacje przechodzaca tylko przez uslugi proxy",
                "isCorrect": true
            },
            {
                "text": "to rodzaj zapory sieciowej z filtracja pakietow i modulem IDS",
                "isCorrect": false
            },
            {
                "text": "jest implementacja zapory typu Application Layer Gateway",
                "isCorrect": true
            },
            {
                "text": "pelni role zaufanej strony trzeciej w domenie Kerberos",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Komputer-Twierdza, znany również jako Bastion Host, to specjalnie skonfigurowany komputer w sieci, który pełni rolę pośrednika między siecią wewnętrzną (chronioną) a siecią zewnętrzną (np. Internetem). Jego kluczowym zadaniem jest kontrolowanie dostępu do zasobów sieci wewnętrznej poprzez ścisłe egzekwowanie zasad bezpieczeństwa. W przeciwieństwie do zapór sieciowych działających na niższych warstwach modelu OSI, Komputer-Twierdza działa na warstwie aplikacji, co pozwala na bardziej szczegółową kontrolę ruchu sieciowego.\n\n**Odpowiedź 1:** \"dopuszcza komunikacje przechodzaca tylko przez uslugi proxy\" jest **poprawna**. Komputer-Twierdza nie pozwala na bezpośrednie połączenia między sieciami wewnętrzną i zewnętrzną. Wszelka komunikacja przechodzi przez serwery proxy uruchomione na Twierdzy. Te serwery proxy działają jako pośrednicy, analizując ruch i podejmując decyzję, czy dopuścić go dalej, czy zablokować. Przykładowo, jeśli klient z sieci zewnętrznej chce uzyskać dostęp do serwera WWW w sieci wewnętrznej, nie łączy się bezpośrednio z tym serwerem. Zamiast tego łączy się z serwerem proxy HTTP uruchomionym na Komputerze-Twierdzy, a serwer proxy następnie przekazuje żądanie do serwera WWW w sieci wewnętrznej, po czym odebrane dane przesyła zwrotnie do klienta z sieci zewnętrznej. Takie podejście utrudnia bezpośrednie ataki na wewnętrzne zasoby.\n\n**Odpowiedź 2:** \"to rodzaj zapory sieciowej z filtracja pakietow i modulem IDS\" jest **niepoprawna**. Chociaż Komputer-Twierdza może zawierać zaporę sieciową (firewall) do filtrowania pakietów, to jego podstawowa funkcja wykracza poza filtrację. Zapory działają na niższych warstwach modelu OSI (warstwa sieciowa lub transportowa), filtrując pakiety na podstawie adresów IP, portów itp. Moduł IDS(_ang. Intrusion Detection System_) nie jest integralną częścią Komputera-Twierdzy, to dodatkowe narzędzie do wykrywania prób włamań do systemu. Komputer-Twierdza może współpracować z systemem IDS, ale ich funkcje są oddzielne. Przykładowo, gdy atakujący próbuje skanować porty, Komputer-Twierdza (współpracując z modułem IDS) może te próby rejestrować, jednak to nie jest jego głównym zadaniem.  Komputer-Twierdza przede wszystkim pośredniczy w komunikacji w warstwie aplikacji, analizując i kontrolując treść ruchu sieciowego na wyższym poziomie abstrakcji niż standardowa zapora sieciowa.\n\n**Odpowiedź 3:** \"jest implementacja zapory typu Application Layer Gateway\" jest **poprawna**. Application Layer Gateway (ALG), to zapora działająca na warstwie aplikacji, która analizuje komunikację na tym poziomie (warstwie 7). Komputer-Twierdza jest właśnie takim rodzajem zapory, kontrolującym i pośredniczącym w komunikacji przez aplikacje działające na nim, takie jak serwery proxy. Działa ona na wyższym poziomie niż tradycyjna zapora sieciowa filtrująca jedynie pakiety IP. Na przykład, ALG dla protokołu FTP może analizować komendy przesyłane w strumieniu TCP i dynamicznie otwierać porty dla transferu danych (a tradycyjna zapora może mieć problem z dynamicznym otwieraniem portów) . Używając ALG, Komputer Twierdza zapewnia kontrolę na poziomie treści przesyłanych danych, a nie tylko na poziomie adresu i portu.\n\n**Odpowiedź 4:** \"pełni role zaufanej strony trzeciej w domenie Kerberos\" jest **niepoprawna**. Kerberos to protokół uwierzytelniania wykorzystujący klucze symetryczne i zaufaną stronę trzecią, którą jest serwer Kerberos. Zaufana strona trzecia, w tym przypadku serwer Kerberos, wydaje bilety umożliwiające dostęp do usług w domenie Kerberos.  Komputer-Twierdza nie jest związany z mechanizmami Kerberosa i działa na innym poziomie. Komputer-Twierdza nie zarządza procesem uwierzytelniania Kerberosa.  Komputer-Twierdza dba o to aby nikt z zewnątrz nie dostał się do usług serwerów wewnętrznej sieci, wykorzystuje do tego serwery proxy. Kerberos z kolei pomaga użytkownikom w uzyskaniu dostępu do usług udostępnionych w sieci."
    },
    {
        "questionId": 11,
        "title": "Ktore komponenty sprzetowe sluza (miedzy innymi) do bezpiecznego przechowywania materialu kryptograficznego:",
        "answers": [
            {
                "text": "IEEE 1609.2",
                "isCorrect": false
            },
            {
                "text": "X.509",
                "isCorrect": false
            },
            {
                "text": "EFS",
                "isCorrect": false
            },
            {
                "text": "Trusted Platform Module",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "**Trusted Platform Module (TPM)** jest wyspecjalizowanym układem scalonym, czyli fizycznym komponentem, który został zaprojektowany w celu bezpiecznego przechowywania kluczy kryptograficznych. Układ TPM jest często implementowany jako osobny układ scalony wbudowany w płytę główną komputera, ale może być też zaimplementowany jako wirtualny TPM w oprogramowaniu. Jego podstawową funkcją jest ochrona danych kryptograficznych, takich jak klucze prywatne, hasła i certyfikaty. TPM zapewnia mechanizmy do bezpiecznego generowania kluczy, ich przechowywania i wykonywania operacji kryptograficznych z ich użyciem, a także do pomiaru integralności oprogramowania startowego, co ma na celu zapobieganie uruchomienia złośliwego oprogramowania.\n\nOpcja **IEEE 1609.2** odnosi się do standardu, a nie do fizycznego komponentu. IEEE 1609.2 jest standardem definiującym usługi bezpieczeństwa w komunikacji bezprzewodowej systemów transportowych. Obejmuje on m.in. formaty wiadomości, podpisy cyfrowe oraz mechanizmy szyfrowania. Standard ten nie zajmuje się przechowywaniem danych kryptograficznych, ale określa, jak te dane powinny być wykorzystywane w kontekście komunikacji między pojazdami, infrastrukturą drogową itp.\n\n**X.509** jest standardem definiującym format certyfikatów klucza publicznego. Certyfikaty X.509 zawierają klucz publiczny, dane identyfikujące podmiot (np. właściciela klucza), podpis cyfrowy wystawcy certyfikatu (urzędu certyfikacji - CA) i inne metadane. Certyfikaty X.509 nie są fizycznymi komponentami, a raczej cyfrowymi dokumentami służącymi do weryfikacji tożsamości w środowiskach opartych na kryptografii klucza publicznego. Klucze prywatne powiązane z certyfikatami mogą być przechowywane na różnych nośnikach, w tym np. w TPM.\n\n**EFS** (Encrypting File System) jest funkcją systemu plików NTFS w systemie operacyjnym MS Windows umożliwiającą szyfrowanie plików i katalogów. EFS jest mechanizmem software'owym, który wykorzystuje klucze kryptograficzne do szyfrowania danych na dysku, jednak sama funkcja EFS nie jest komponentem sprzętowym, a klucze wykorzystywane w EFS mogą być przechowywane w TPM (jeśli jest on dostępny). W systemach, które nie posiadają układu TPM klucze prywatne są przechowywane na dysku twardym w postaci zaszyfrowanej, co może być potencjalnie niebezpieczne.\n\nZatem prawidłową odpowiedzią jest **Trusted Platform Module (TPM)** ponieważ jest to fizyczny komponent, który został zaprojektowany w celu bezpiecznego przechowywania materiału kryptograficznego, w przeciwieństwie do pozostałych odpowiedzi, które określają standardy, formaty certyfikatów czy mechanizmy szyfrowania."
    },
    {
        "questionId": 12,
        "title": "Model CAP kontroli dostepu:",
        "answers": [
            {
                "text": "jest stosowany w systemach MIC (Mandatory Integrity Control)",
                "isCorrect": false
            },
            {
                "text": "jest stosowany w systemach RBAC (Role-Based Access Control)",
                "isCorrect": true
            },
            {
                "text": "uprawnienia dostepu wiaze z podmiotami",
                "isCorrect": true
            },
            {
                "text": "uprawnienia dostepu wiaze z zasobami",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Model kontroli dostępu CAP (Capability-based access control) to mechanizm kontroli, w którym uprawnienia do zasobów nie są wiązane bezpośrednio z użytkownikami (podmiotami), lecz są przekazywane za pomocą specjalnych znaczników zwanych możliwościami (ang. _capabilities_). Każdy proces lub użytkownik (podmiot) musi posiadać odpowiednie „możliwości”, aby uzyskać dostęp do danego zasobu. System operacyjny sprawdza, czy dany podmiot (użytkownik, proces) posiada taką „możliwość”, a nie czy ma ogólne uprawnienie do zasobu. Można to porównać do fizycznego klucza - posiadanie klucza daje możliwość otwarcia drzwi, a nie przypisane jest bezpośrednio do użytkownika.\n\n**Odpowiedź \"jest stosowany w systemach MIC (Mandatory Integrity Control)\" jest niepoprawna.** Systemy MIC (Mandatory Integrity Control) to systemy zaimplementowane w systemach operacyjnych, które określają dostęp do zasobów na podstawie etykiet bezpieczeństwa lub poziomów zaufania zasobów oraz podmiotów w systemie. W systemach MIC uprawnienia są narzucane przez system i użytkownik nie ma możliwości zdefiniowania uprawnień dla poszczególnych zasobów. MIC skupia się na ochronie integralności danych i zapobieganiu nieuprawnionym modyfikacjom, a nie tak jak CAP na uprawnieniach danego podmiotu do zasobu.\n\n**Odpowiedź \"jest stosowany w systemach RBAC (Role-Based Access Control)\" jest poprawna.** Model CAP ma wiele wspólnego z modelem RBAC (Role-Based Access Control) chociażby w sposobie zarządzania uprawnieniami w systemie. RBAC przypisuje uprawnienia do ról, a następnie przydziela role do podmiotów (użytkowników, procesów). Podmioty posiadają tak jak w modelu CAP możliwość wykonania akcji w obrębie systemu poprzez wcześniej zdefiniowane uprawnienia. Jednak, o ile model RBAC operuje na rolach, które są zbiorem uprawnień, tak w modelu CAP każda możliwość uprawnia do wykonania konkretnej operacji na danym zasobie. W efekcie w RBAC mamy do czynienia z pewnym zbiorem uprawnień do zasobów, a w CAP uprawnienia są bardziej atomowe i bezpośrednio przypisane do podmiotu a nie do roli. Należy pamiętać, że w systemach z polityką RBAC nadal działa kontrola dostępu do zasobów, gdzie rola jest pośrednikiem przyznającym te prawa, w przypadku CAP uprawnienia do zasobów są przyznawane poprzez posiadanie możliwości przez podmiot, bez pośredników.\n\n**Odpowiedź \"uprawnienia dostepu wiaze z podmiotami\" jest poprawna**. W modelu CAP to podmioty (użytkownicy, procesy) posiadają możliwości. Posiadanie danej możliwości implikuje prawo dostępu do zasobu i wykonywania na nim określonych akcji. A zatem, uprawnienia do zasobów są skorelowane z możliwościami jakie posiadają podmioty, a nie do samych zasobów. Pomyślmy, że posiadanie klucza pozwala nam wejść do budynku (zasób) - posiadanie klucza jest przypisane do nas (podmiot), a nie jest jakąś właściwością drzwi (zasób).\n\n**Odpowiedź \"uprawnienia dostepu wiaze z zasobami\" jest niepoprawna.** W modelu CAP uprawnienia nie są przypisywane do zasobów. W tym modelu to podmioty posiadają prawa (możliwości). W klasycznych modelach opartych o listy kontroli dostępu ACL (Access Control Lists) to zasoby określają kto ma do nich dostęp. CAP działa na zasadzie _capability_ – podmiot musi przedstawić _capability_, aby uzyskać dostęp do zasobu."
    },
    {
        "questionId": 13,
        "title": "Model kontroli dostepu MAC zabrania podmiotowi o etykiecie P:",
        "answers": [
            {
                "text": "odczytu obiektu o nizszej etykiecie niz P",
                "isCorrect": false
            },
            {
                "text": "zapisu obiektu o wyzszej etykiecie niz P",
                "isCorrect": false
            },
            {
                "text": "odczytu obiektu o wyzszej etykiecie niz P",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to model kontroli dostępu, który nakłada sztywne ograniczenia na dostęp do zasobów systemowych, w przeciwieństwie do Uznaniowej Kontroli Dostępu (DAC), w której właściciel zasobu decyduje o prawach dostępu innych użytkowników. W systemie MAC każdy podmiot (np. użytkownik, proces) i obiekt (np. plik, dane) ma przypisaną etykietę bezpieczeństwa, która reprezentuje poziom zaufania lub poufności. Dostęp jest dozwolony lub zabroniony w oparciu o porównanie etykiet podmiotu i obiektu, zgodnie z polityką bezpieczeństwa. Jedną z podstawowych reguł w systemie MAC jest zasada \"no read up\", która zabrania podmiotowi odczytywania obiektów o etykietach wyższych niż jego własna etykieta, niezależnie od tego, czy dany podmiot jest właścicielem obiektu, czy też nie.\n\n**Odpowiedź 1: \"odczytu obiektu o nizszej etykiecie niz P\"** -  Jest to odpowiedź niepoprawna. Model MAC _nie zabrania_ podmiotowi odczytu obiektów o niższej etykiecie niż jego własna etykieta, wręcz przeciwnie takie działanie jest dozwolone. Podmiot o etykiecie P może swobodnie czytać dane, które są na poziomie lub niższym niż P, np. gdy ma dane z poziomem *poufne*, to może zobaczyć dane *jawne*.\n\n**Odpowiedź 2: \"zapisu obiektu o wyzszej etykiecie niz P\"** - Jest to odpowiedź niepoprawna. Model MAC zabrania podmiotowi o danej etykiecie zapisywania obiektów o etykiecie niższej niż P(tzw. *no write down*). Zatem podmiot o etykiecie P nie może zapisać żadnej informacji do obiektu z niższą etykietą. Odpowiedź podaje sytuacje odwrotną. Przykład: użytkownik z etykietą *poufne* nie ma prawa pisać danych w pliku z etykietą *jawne*, gdyż taki zapis mógłby nieświadomie zdegradować informację *poufne*.\n\n**Odpowiedź 3: \"odczytu obiektu o wyzszej etykiecie niz P\"** - Jest to odpowiedź poprawna. Zgodnie z regułą \"no read up\" systemu MAC, podmiot nie może odczytać obiektu o wyższej etykiecie niż jego własna.  Na przykład, jeśli użytkownik posiada etykietę *poufne*, to nie może on odczytać danych z obiektu o etykiecie *tajne*. Takie działanie ma na celu zapobiec nieuprawnionemu dostępowi do danych, które są wyżej w hierarchii poufności.\n\nPraktyczny przykład: w systemie wojskowym, użytkownik o uprawnieniach \"poufne\" nie może czytać dokumentów oznaczonych jako \"ściśle tajne,\" ale może bez problemu czytać te z etykietą *poufne* lub *jawne*."
    },
    {
        "questionId": 14,
        "title": "Wskaz protokoly i standardy dokonujace uwierzytelniania dostepu do sieci, dzialajace miedzy klientem sieci (komputerem) a punktem (serwerem) dostepowym:",
        "answers": [
            {
                "text": "IEEE 802.1X",
                "isCorrect": true
            },
            {
                "text": "TACACS",
                "isCorrect": false
            },
            {
                "text": "RADIUS",
                "isCorrect": false
            },
            {
                "text": "EAP",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół IEEE 802.1X jest standardem do uwierzytelniania dostępu do sieci, często używanym w sieciach Ethernet i Wi-Fi. Umożliwia kontrolę dostępu na poziomie portu, gdzie urządzenie klienckie (np. komputer, smartfon) musi się uwierzytelnić, zanim zostanie mu przyznany dostęp do sieci. Uwierzytelnienie odbywa się w oparciu o protokół EAP (Extensible Authentication Protocol), który jest „nośnikiem” danych uwierzytelniających. Zatem w połączeniu protokoły IEEE 802.1X i EAP działają między klientem a punktem dostępowym (authenticator) w sieci.\n\n*   **IEEE 802.1X** jest protokołem warstwy łącza danych, który zarządza dostępem do sieci na poziomie portu. Określa ramy dla uwierzytelniania, ale sam nie realizuje uwierzytelniania. W praktyce, na przykład w sieci Wi-Fi,  802.1X działa na połączeniach między urządzeniem (klientem) a punktem dostępowym (serwerem dostępowym). Użytkownik  (klient) próbując połączyć się z siecią, trafia  na logowanie, gdzie musi podać nazwę użytkownika i hasło, lub certyfikat, w zależności od konfiguracji. Próba logowania jest przekazywana przy pomocy ramki 802.1x.  Zastosowanie tego protokołu ma na celu uniemożliwienie nieautoryzowanemu klientowi na swobodne przesyłanie ramek w sieci, np. podsłuchiwanie ruchu sieciowego. Prawidłowa konfiguracja umożliwia też kontrolę zaufania hostów.\n    \n    *   **Poprawna odpowiedź**. Bez protokołu IEEE 802.1X protokół EAP nie ma zastosowania,  nie tworzy on ram dla uwierzytelniania pomiędzy klientem a serwerem, jest on jedynie środkiem transportowym dla mechanizmów uwierzytelniania.\n\n*   **TACACS (Terminal Access Controller Access-Control System)** jest protokołem centralnego uwierzytelniania, autoryzacji i accountingu (AAA). Został pierwotnie opracowany przez firmę Cisco, ale jest rozszerzany i implementowany również przez innych dostawców. Protokół TACACS  jest wykorzystywany, do scentralizowanej kontroli dostępu do urządzeń sieciowych (np. routerów, przełączników). Nie bierze on udziału bezpośrednio w uwierzytelnianiu pomiędzy klientem a punktem dostępowym (serwerem). Zamiast tego, serwer dostępowy (autentykator) przekazuje żądanie uwierzytelnienia do serwera TACACS, który w oparciu o zdefiniowaną bazę użytkowników podejmuje decyzję czy użytkownik ma dostęp do danego zasobu. W przeciwieństwie do 802.1X (gdzie protokół EAP jest pośrednikiem), TACACS nie jest używany bezpośrednio między klientem a punktem dostępowym, ale między punktem dostępowym a serwerem AAA.\n    \n    *   **Niepoprawna odpowiedź**. TACACS nie jest protokołem działającym bezpośrednio między klientem a punktem dostępowym, lecz protokołem działającym między urządzeniem sieciowym a scentralizowanym serwerem AAA. Protokół TACACS jest często używany do autentykacji administratorów urządzeń sieciowych.\n\n*   **RADIUS (Remote Authentication Dial-In User Service)** jest również protokołem centralnego AAA.  W ten sam sposób co TACACS nie bierze udziału bezpośrednio w uwierzytelnianiu pomiędzy klientem a punktem dostępowym (serwerem). Zamiast tego, punkt dostępowy (autentykator) przekazuje żądanie uwierzytelnienia do serwera RADIUS. Protokół ten jest szeroko wykorzystywany w połączeniach bezprzewodowych, ale nie przeprowadza bezpośrednio uwierzytelniania pomiędzy klientem a punktem dostępowym. Zamiast tego punkt dostępowy deleguje funkcję uwierzytelniania do serwera RADIUS.\n    \n    *  **Niepoprawna odpowiedź**. RADIUS podobnie jak TACACS nie jest protokołem działającym bezpośrednio pomiędzy klientem a punktem dostępowym, tylko mechanizmem centralnego uwierzytelniania.\n\n*   **EAP (Extensible Authentication Protocol)**, jak sama nazwa wskazuje jest rozszerzalnym protokołem uwierzytelniania, pozwalającym na różnorodne metody uwierzytelniania w połączeniach sieciowych np. poprzez certyfikaty, hasła, tokeny. Jest często stosowany w połączeniach z wykorzystaniem protokołu IEEE 802.1X, służąc jako „nośnik” dla danych uwierzytelniających. Protokół EAP nie jest w stanie pracować bez protokołu, który określi sposób przesyłania ramek uwierzytelniających, takim protokołem jest właśnie IEEE 802.1X. EAP jest wykorzystywany w wielu różnych protokołach, chociaż pierwotnie został zaprojektowany na potrzeby protokołu PPP (Point-to-Point Protocol). W istocie EAP jest sposobem komunikacji, dzięki któremu klient i serwer mogą się porozumieć odnośnie wyboru metody uwierzytelniania i przekazać informacje potrzebne do tego uwierzytelniania, protokół nie narzuca z góry metody, tak jak ma to miejsce w przypadku protokołów PAP czy CHAP.\n    \n    *   **Poprawna odpowiedź**. EAP działa pomiędzy klientem a punktem dostępowym, zazwyczaj w oparciu o protokół IEEE 802.1X. Protokół ten zapewnia ramy dla różnych metod uwierzytelniania, np. EAP-TLS (z wykorzystaniem certyfikatów) czy EAP-TTLS (z wykorzystaniem tunelowania).\n\nPodsumowując, IEEE 802.1X i EAP wspólnie realizują uwierzytelnianie dostępu do sieci, działając bezpośrednio między klientem a punktem dostępowym. Protokóły RADIUS i TACACS zapewniają z kolei scentralizowane uwierzytelnianie dla większych środowisk sieciowych, ale nie biorą udziału bezpośrednio w wymianie danych między klientem a serwerem dostępowym."
    },
    {
        "questionId": 15,
        "title": "Protokol Kerberos:",
        "answers": [
            {
                "text": "pozwala osiagnac obustronne uwierzytelnienie klienta uslugi sieciowej i serwera tej uslugi",
                "isCorrect": true
            },
            {
                "text": "realizuje uwierzytelnianie w modelu z zaufana strona trzecia",
                "isCorrect": true
            },
            {
                "text": "realizuje uwierzytelnianie kryptograficzne z wykorzystaniem kluczy symetrycznych",
                "isCorrect": true
            },
            {
                "text": "realizuje uwierzytelnianie SSO w srodowisku domenowym",
                "isCorrect": true
            },
            {
                "text": "realizuje uwierzytelnianie SSO w środowisku między-domenowym",
                "isCorrect": false
            },
            {
                "text": "umożliwia uwierzytelnianie i autoryzację klientów usług sieciowych przez scentralizowany mechanizm (serwer KDC)",
                "isCorrect": true
            },
            {
                "text": "nie wymaga znajomości po stronie uwierzytelniającej żadnych danych wrażliwych klienta (Zero-Proof Knowledge)",
                "isCorrect": true
            }
        ],
        "clue": 6,
        "isStarred": false,
        "explanation": "Protokół Kerberos to protokół uwierzytelniania, który umożliwia bezpieczne potwierdzenie tożsamości użytkowników i usług w sieci komputerowej. Jest on oparty na kryptografii symetrycznej i wykorzystuje zaufaną stronę trzecią, tzw. Centrum Dystrybucji Kluczy (KDC, _ang. Key Distribution Center_).\n\n**Poprawne odpowiedzi:**\n\n*   **\"pozwala osiagnac obustronne uwierzytelnienie klienta uslugi sieciowej i serwera tej uslugi\"**: Kerberos jest zaprojektowany do zapewnienia _wzajemnego_ uwierzytelnienia. Klient, żądając dostępu do usługi, musi udowodnić swoją tożsamość serwerowi, a serwer musi udowodnić swoją tożsamość klientowi. Proces ten jest niezbędny do zapewnienia, że ​​obie strony komunikują się z wiarygodnym podmiotem i ma praktyczne znaczenie na przykład gdy chcemy używać bezpiecznej komunikacji z serwerem WWW.\n\n*   **\"realizuje uwierzytelnianie w modelu z zaufana strona trzecia\"**:  W modelu Kerberosa występuje KDC, które pośredniczy w procesie uwierzytelniania. Klient nie kontaktuje się bezpośrednio z serwerem usługi w celu uwierzytelnienia, lecz najpierw kontaktuje się z KDC, aby uzyskać _bilet_ (_ang. ticket_), który następnie prezentuje serwerowi. W praktyce KDC pełni rolę zaufanego urzędu poświadczającego, co upraszcza zarządzanie bezpieczeństwem w rozległych środowiskach sieciowych.\n\n*    **\"realizuje uwierzytelnianie kryptograficzne z wykorzystaniem kluczy symetrycznych\"**: Kerberos intensywnie używa kryptografii symetrycznej. Zarówno klient jak i KDC oraz KDC i serwer posiadają klucze symetryczne, które umożliwiają wymianę informacji potrzebnych do uwierzytelniania i tworzenia _biletów_. Klucze te są używane do szyfrowania i deszyfrowania komunikatów, dzięki czemu nie są one dostępne dla podsłuchujących. Klucze sesyjne są dynamiczne i zmieniane w ustalonym odstępie czasu, co czyni protokół bardziej odporny na ataki.\n\n*   **\"realizuje uwierzytelnianie SSO w srodowisku domenowym\"**: Kerberos jest wykorzystywany w systemach operacyjnych, szczególnie w środowiskach domenowych, do realizacji _SSO_ (ang. _Single Sign-On_). Użytkownik loguje się do systemu tylko raz, a następnie może bez dodatkowej autoryzacji korzystać z wielu usług w ramach tej domeny. Po pierwszym uwierzytelnieniu w systemie operacyjnym, użytkownik może bez dodatkowego podawania hasła logować się na zdalnych serwerach wykorzystujących mechanizmy Kerberosa.\n\n*    **\"umożliwia uwierzytelnianie i autoryzację klientów usług sieciowych przez scentralizowany mechanizm (serwer KDC)\"**: Rzeczywiście, KDC jest centralnym elementem Kerberosa, który poświadcza tożsamość klientów i przyznaje bilety dostępu do usług. Zatem to KDC wykonuje uwierzytelnianie i autoryzację użytkowników w systemie. W ten sposób zarządzanie użytkownikami jest scentralizowane. KDC nie tylko udostępnia bilety, ale również umożliwia odwołanie biletów i zarządza czasem życia biletów.\n\n*   **\"nie wymaga znajomości po stronie uwierzytelniającej żadnych danych wrażliwych klienta (Zero-Proof Knowledge)\"**: Choć mechanizm jest oparty o przekazywanie \"sekretów\" to de facto strona uwierzytelniająca (serwer lub KDC) nigdy nie dowiaduje się o haśle użytkownika. KDC w celu ustalenia czy klient jest tym za kogo się podaje nie musi znać hasła użytkownika. Ta własność jest bardzo ważna w systemach bezpieczeństwa, gdyż minimalizuje ryzyko wycieku danych użytkownika. Klient przekazuje do serwera unikalny bilet, którego ważność jest ograniczona w czasie.\n\n**Niepoprawna odpowiedź:**\n\n*   **\"realizuje uwierzytelnianie SSO w środowisku między-domenowym\"**:  Tradycyjny protokół Kerberos jest przeznaczony do pracy w obrębie jednej domeny, a w przypadku istnienia wielu domen potrzebna jest konfiguracja _relacji zaufania_ (_ang. trust relationship_) między domenami. Uwierzytelnienie _między-domenowe_ w tradycyjnym protokole Kerberos wymaga dodatkowej konfiguracji i nie jest częścią podstawowej funkcjonalności. Istnieją wprawdzie rozszerzenia, które umożliwiają przekraczanie granic domen, ale nie jest to podstawowa cecha tego protokołu. Przykładowo Kerberos w Active Directory wymaga tworzenia relacji zaufania między domenami."
    },
    {
        "questionId": 16,
        "title": "Wskaz mozliwe prawidlowe reakcje na wykrycie faktu przepelnienia bufora (w segmencie stosu) umozliwiajace zachowanie bezpieczenstwa systemu:",
        "answers": [
            {
                "text": "ponowne zainicjowanie bufora domyslna wartoscia",
                "isCorrect": false
            },
            {
                "text": "usuniecie danych wykraczajacych poza bufor, zanim zostana odczytane",
                "isCorrect": false
            },
            {
                "text": "natychmiastowe przerwanie dzialania procesu",
                "isCorrect": true
            },
            {
                "text": "zapisanie zaraz za nadmiernymi danymi \"kanarka\" ostrzegajacego o wystapieniu przepelniania przy probie odczytu bufora",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Przepelnienie bufora, zwłaszcza w segmencie stosu, to błąd programistyczny, który polega na zapisaniu danych poza obszarem pamięci wyznaczonym na dany bufor. W przypadku stosu, który jest strukturą danych zarządzającą wywołaniami funkcji, przepelnienie bufora może spowodować nadpisanie adresów powrotnych funkcji lub innych istotnych danych, umożliwiając atakującemu przejęcie kontroli nad działaniem programu. Kluczowe jest zrozumienie, że skuteczne przepelnienie bufora jest zazwyczaj wynikiem świadomej próby ataku.\n\n**Ponowne zainicjowanie bufora domyślna wartością:** Ta odpowiedź jest **nieprawidłowa**. Po wykryciu przepelnienia bufora, dane już zostały zapisane w obszarze pamięci, do którego program nie powinien mieć dostępu. Samo \"zerowanie\" bufora nie usuwa tego faktu, a co więcej potencjalnie nie usuwa już nielegalnych danych, które mogły być np. kodem wykonywalnym przez atakującego.  Atakujący mógł już nadpisać adres powrotu funkcji lub inne ważne dane na stosie. W związku z tym ponowne zainicjowanie bufora nie naprawia szkody i nie chroni przed złośliwymi działaniami, a wręcz przeciwnie w niektórych przypadkach może ułatwić ataki. \n\n**Usunięcie danych wykraczających poza bufor, zanim zostaną odczytane:** Ta odpowiedź jest **nieprawidłowa**. Ta opcja zakłada, że system jest w stanie na bieżąco wykryć i usunąć nadmiarowe dane. Jednak mechanizm przepełnienia bufora polega na tym, że to program - a nie jakiś zewnętrzny mechanizm - zapisuje dane bezpośrednio do pamięci, poza wyznaczony dla bufora obszar. Po wykryciu nadmiarowych danych system nie wie, gdzie kończy się bufor, gdzie zaczynają się ważne dane, a gdzie kończy się nadmiar danych. Te informacje są już dawno utracone. A samo usunięcie nadmiaru danych w dalszej kolejności nie ma sensu bo dane zostały already zapisane w nieprawidłowym miejscu, nadpisując inne ważne dane dla programu (np. adres powrotu funkcji).\n\n**Natychmiastowe przerwanie działania procesu:** Ta odpowiedź jest **prawidłowa**.  Po wykryciu przepełnienia bufora, jedyną bezpieczną reakcją jest natychmiastowe przerwanie działania procesu. Ponieważ przepelnienie bufora sygnalizuje naruszenie integralności pamięci, a nadpisane dane mogą zawierać kod sterujący procesem, dalsze wykonywanie kodu programu jest potencjalnie bardzo niebezpieczne. Nagłe przerwanie procesu minimalizuje szkody, zapobiega wykonaniu potencjalnie złośliwego kodu. W praktyce system operacyjny monitoruje próby zapisu poza zakres pamięci do której ma dostęp proces i w przypadku naruszenia generuje sygnał SIGSEGV, który ma domyślnie działanie terminujące proces.\n\n**Zapisanie zaraz za nadmiernymi danymi \"kanarka\" ostrzegającego o wystąpieniu przepełniania przy próbie odczytu bufora:** Ta odpowiedź jest **nieprawidłowa**. \"Kanarek\" (ang. *canary*) to specjalna wartość umieszczana w pamięci obok bufora, która ma być nie zmieniona podczas zapisu do bufora. Próba odczytu bufora jest poprzedzona sprawdzeniem czy \"kanarek\" jest nadal nienaruszony, a tym samym informuje o nadpisaniu zawartości stosu.  Jednak system nie może być pewny że po przepelnieniu bufora atakujący nie wyzeruje \"kanarka\", a w tym przypadku ochrona jest nieskuteczna. Sam \"kanarek\" nie chroni przed atakiem a jedynie informuje o nadpisaniu pamięci po przepełnieniu bufora. Nie jest to więc rozwiązanie problemu przepełnienia bufora a jedynie metoda wykrycia nadpisania danych w pamięci."
    },
    {
        "questionId": 17,
        "title": "Systemy nadzoru NAC (Network Access Control):",
        "answers": [
            {
                "text": "dokonuja uwierzytelniania stanowisk sieciowych przed dopuszczeniem ich do sieci lokalnej",
                "isCorrect": true
            },
            {
                "text": "wykrywaja pakiety na podstawie analizy behawioralnej i uczenia maszynowego",
                "isCorrect": false
            },
            {
                "text": "dopuszczaja stanowiska do sieci lokalnej po weryfikacji zgodnosci ich konfiguracji z polityka bezpieczenstwa",
                "isCorrect": true
            },
            {
                "text": "wykrywaja podejrzane pakiety na podstawie sygnatur atakow sieciowych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Systemy Network Access Control (NAC) są rozwiązaniami, które mają na celu kontrolę dostępu do sieci, zapewniając, że tylko autoryzowane urządzenia i użytkownicy mogą uzyskać połączenie, a ich konfiguracja spełnia określone standardy bezpieczeństwa. NAC działa na poziomie dostępu do sieci, a nie na poziomie pakietów czy danych przesyłanych po nawiązaniu połączenia, jak firewalle lub systemy wykrywania intruzów (IDS). NAC realizuje kontrolę dostępu w oparciu o identyfikację urządzeń i użytkowników, a także weryfikację ich zgodności z polityką bezpieczeństwa danej sieci.\n\n**Odpowiedź 1: \"dokonuja uwierzytelniania stanowisk sieciowych przed dopuszczeniem ich do sieci lokalnej\"** - Jest to **poprawna** odpowiedź. Uwierzytelnianie jest podstawową funkcją NAC, aby dopuścić do sieci tylko znane i autoryzowane urządzenia oraz użytkowników. NAC sprawdza tożsamość użytkownika lub urządzenia, najczęściej poprzez zestawienie z predefiniowanymi kontami lub bazami tożsamości. Na przykład w przedsiębiorstwie pracownik logując się z laptopa do firmowej sieci musi przejść proces uwierzytelnienia, gdzie system NAC upewnia się czy ten pracownik ma prawo dostępu do danej sieci.\n\n**Odpowiedź 2: \"wykrywaja pakiety na podstawie analizy behawioralnej i uczenia maszynowego\"** - Jest to **niepoprawna** odpowiedź. Analiza behawioralna i uczenie maszynowe są charakterystyczne dla systemów wykrywania intruzów (IDS) lub systemów zapobiegania intruzom (IPS). System NAC koncentruje się na weryfikacji tożsamości i zgodności z polityką bezpieczeństwa. System IDS analizuje wzorce ruchu w celu wykrycia anomalii. System IPS dodatkowo może blokować podejrzane zachowania. Na przykład, system IDS monitoruje nietypowe wzorce ruchu, co sugeruje próbę włamania, ale to nie jest zadanie systemu NAC.\n\n**Odpowiedź 3: \"dopuszczaja stanowiska do sieci lokalnej po weryfikacji zgodnosci ich konfiguracji z polityka bezpieczenstwa\"** - Jest to **poprawna** odpowiedź. Oprócz uwierzytelnienia, NAC weryfikuje również czy konfiguracja urządzenia lub użytkownika (np. stan antywirusa, włączone firewalle, aktualność systemu operacyjnego) jest zgodna z polityką bezpieczeństwa. Jeśli urządzenie nie spełnia wymogów, dostęp do sieci może być zablokowany, a dostęp zostaje przyznany po naprawieniu problemu. Na przykład, aby dopuścić laptopa pracownika do sieci, system NAC może sprawdzać, czy ma on zainstalowany aktualny program antywirusowy oraz czy system operacyjny jest w najnowszej wersji.\n\n**Odpowiedź 4: \"wykrywaja podejrzane pakiety na podstawie sygnatur atakow sieciowych\"** - Jest to **niepoprawna** odpowiedź. Wykrywanie podejrzanych pakietów na podstawie sygnatur ataków jest charakterystyczne dla systemów IDS/IPS. Systemy IDS/IPS monitorują pakiety w poszukiwaniu wzorców znanych ataków. System NAC skupia się na kontroli dostępu. Na przykład system IPS monitoruje ruch w sieci w poszukiwaniu wzorców zgodnych z sygnaturami konkretnych ataków."
    },
    {
        "questionId": 18,
        "title": "Protokol SSL/TLS:",
        "answers": [
            {
                "text": "pozwala uwierzytelniac kryptograficznie zarowno klienta, jak i serwer",
                "isCorrect": true
            },
            {
                "text": "nigdy nie uwierzytelnia klienta, to zadanie wylacznie protokolu aplikacyjnego, np. HTTP",
                "isCorrect": false
            },
            {
                "text": "nigdy nie dokonuje uwierzytelniania, zostawiajac to zadanie innym protokolom, np. ISAKMP",
                "isCorrect": false
            },
            {
                "text": "kryptograficznie uwierzytelnia tylko serwer, klienta tylko haslem",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół SSL/TLS (Secure Sockets Layer/Transport Layer Security) to protokół kryptograficzny, który zapewnia poufność, integralność i autentyczność komunikacji w sieci komputerowej. Jednym z kluczowych aspektów bezpieczeństwa, które oferuje SSL/TLS, jest kryptograficzne uwierzytelnianie, w którym tożsamość zarówno serwera, jak i, opcjonalnie, klienta jest weryfikowana za pomocą kluczy kryptograficznych i certyfikatów cyfrowych. Uwierzytelnianie to proces, w którym każda ze stron upewnia się, że komunikuje się z właściwym partnerem. W przeciwieństwie do protokołów warstwy aplikacji, które często używają haseł, SSL/TLS do uwierzytelniania wykorzystuje metody kryptograficzne. W trakcie uzgadniania połączenia SSL/TLS, serwer przedstawia swój certyfikat, zawierający jego klucz publiczny, który to certyfikat jest podpisany przez zaufany urząd certyfikacji. Klient używa tego klucza publicznego do odszyfrowania danych wysłanych przez serwer, i zweryfikowania jego tożsamości poprzez certyfikat. Dodatkowo (opcjonalnie) klient może przedstawić swój certyfikat, umożliwiając serwerowi zweryfikowanie tożsamości klienta.\n\n**Pierwsza odpowiedź: \"pozwala uwierzytelniac kryptograficznie zarowno klienta, jak i serwer\"** jest poprawna. Protokół SSL/TLS umożliwia wzajemne kryptograficzne uwierzytelnienie. Serwer używa swojego klucza prywatnego do podpisania informacji, a następnie klient weryfikuje ten podpis za pomocą klucza publicznego zawartego w certyfikacie serwera. W trybie dwustronnego uwierzytelniania klient również prezentuje certyfikat, który serwer weryfikuje. To dwustronne uwierzytelnianie zapewnia, że obie strony sesji SSL/TLS są tymi, za które się podają. Na przykład, podczas łączenia się ze stroną banku, przeglądarka weryfikuje certyfikat serwera aby potwierdzić że jest to właściwa strona banku a nie strona utworzona przez potencjalnego włamywacza, próbującego pozyskać informacje o użytkownikach tego banku. Podobnie można skonfigurować serwer aby żądał weryfikacji tożsamości klienta poprzez jego certyfikat. \n\n**Druga odpowiedź: \"nigdy nie uwierzytelnia klienta, to zadanie wylacznie protokolu aplikacyjnego, np. HTTP\"** jest niepoprawna. Chociaż protokoły warstwy aplikacyjnej (jak HTTP) mogą stosować mechanizmy uwierzytelniania (np. hasła), SSL/TLS *również* udostępnia kryptograficzne uwierzytelnianie klienta. Ta opcja, w której serwer żąda certyfikatu od klienta jest używana np. w korporacyjnych VPN, gdy serwer wymaga uwierzytelnienia klienta przed udostępnieniem zasobów wewnętrznych.\n\n**Trzecia odpowiedź: \"nigdy nie dokonuje uwierzytelniania, zostawiajac to zadanie innym protokolom, np. ISAKMP\"** jest niepoprawna. Chociaż istnieje protokół ISAKMP(Internet Security Association and Key Management Protocol), który jest wykorzystywany w protokole IPsec, to nie jest on zamiennikiem dla mechanizmów uwierzytelniania w protokole SSL/TLS. Protokół ISAKMP wykorzystywany jest w protokole IPsec do negocjacji parametrów połączenia VPN. \n\n**Czwarta odpowiedź: \"kryptograficznie uwierzytelnia tylko serwer, klienta tylko haslem\"** jest niepoprawna. SSL/TLS potrafi uwierzytelnić kryptograficznie klienta, nie wymuszając przy tym stosowania haseł. W takim przypadku tożsamość klienta potwierdzana jest poprzez certyfikat klienta i podpis cyfrowy generowany przy użyciu klucza prywatnego tego klienta. Jest to znacznie bezpieczniejsza metoda uwierzytelniania niż zwykłe hasło."
    },
    {
        "questionId": 19,
        "title": "Wskaz prawdziwe stwierdzenia dotyczace bramy aplikacyjnej Application Layer Gateway:",
        "answers": [
            {
                "text": "posredniczy w komunikacji wylacznie na poziomie warstwy aplikacyjnej",
                "isCorrect": true
            },
            {
                "text": "optymalizuje ruch stosujac filtracje kontekstowa na podstawie tablicy aktywnych polaczen",
                "isCorrect": false
            },
            {
                "text": "wymaga dzialajacego poprawnie routingu miedzy interfejsami sieciowymi",
                "isCorrect": false
            },
            {
                "text": "filtruje pakiety na poziomie wszystkich 3 warstw: sieciowej, transportowej i aplikacyjnej",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Brama aplikacyjna (ang. Application Layer Gateway, ALG) to element systemu bezpieczeństwa działający na poziomie warstwy aplikacji (warstwa 7 modelu OSI).  Jej głównym zadaniem jest pośredniczenie w komunikacji pomiędzy aplikacjami działającymi w sieci wewnętrznej i aplikacjami działającymi w sieci zewnętrznej. ALG działa jak pośrednik (ang. proxy), który nie tylko przekazuje dane, ale również je analizuje, interpretuje i modyfikuje, zapewniając dodatkową kontrolę nad ruchem sieciowym. W kontekście bezpieczeństwa ALGi są używane do wzmocnienia ochrony systemu i kontroli nad specyficznymi protokołami aplikacyjnymi. W przeciwieństwie do tradycyjnych zapór ogniowych, które operują na niższych warstwach (sieciowej i transportowej), ALG skupia się na zrozumieniu i filtrowaniu danych na poziomie samej aplikacji. \n\n**Odpowiedź 1: \"posredniczy w komunikacji wylacznie na poziomie warstwy aplikacyjnej\"** - **PRAWDA**.\nBrama aplikacyjna działa na warstwie aplikacji. To kluczowe zrozumienie.  ALG rozumie logikę protokołu, którym się posługuje, np. HTTP, FTP czy SIP. ALG ma za zadanie analizować dane przesyłane między klientem a serwerem na poziomie semantyki aplikacji. Przykładowo, dla protokołu FTP, ALG rozpozna komendy `PORT` i `PASV` oraz przeanalizuje adres IP i port przesyłane w komendach by odpowiednio zablokować nieprawidłowy ruch. Inaczej niż zapory sieciowe, które działają na poziomie IP czy portów, ALG rozumie strukturę przesyłanych danych aplikacji. Przykładowo zapora może odblokować port 21 dla ftp, jednak nadal bez wsparcia ALG nie może zablokować ruchu typu ftp-data w trybie aktywnym z uwagi na to, że port docelowy nie może być predefiniowany dla tego ruchu.\n\n**Odpowiedź 2: \"optymalizuje ruch stosujac filtracje kontekstowa na podstawie tablicy aktywnych polaczen\"** - **FAŁSZ**.\nChociaż ALG pośredniczy w komunikacji na poziomie aplikacji, to nie działa jak typowa zapora sieciowa, która stosuje filtrację kontekstową (ang. stateful inspection) bazującą na tablicy aktywnych połączeń. Filtracja kontekstowa opiera się na śledzeniu stanów połączeń TCP/UDP na warstwach niższych niż warstwa aplikacji i wywiera wpływ na pakiet tylko w oparciu o ten stan i nie ingeruje w przesyłane dane. ALG działa inaczej, jego praca jest związana z każdorazową analizą danych, bez względu na połączenia. W praktyce np. dla protokołu SIP analiza ta polega na sprawdzeniu, czy wszystkie komunikaty w sesji SIP zachowują właściwą kolejność oraz czy adresy IP oraz porty w nagłówkach protokołu są poprawne. Tablica aktywnych połączeń (ang. state table) nie jest używana bezpośrednio przez ALG do filtrowania danych. \n\n**Odpowiedź 3: \"wymaga dzialajacego poprawnie routingu miedzy interfejsami sieciowymi\"** - **FAŁSZ**.\nALG działa na poziomie warstwy aplikacji. Nie wymaga istnienia warstwy sieciowej lub transportowej. Aplikacja ALG jest odpowiedzialna za odbiór danych w warstwie aplikacyjnej a następnie przesyłanie ich dalej po uprzedniej analizie i ewentualnej modyfikacji. Tym samym ALG może być swobodnie stosowana tam gdzie ruch nie jest bezpośrednio kierowany po ścieżkach wyznaczonych protokołem IP. Typowym przykładem użycia ALG jest serwer proxy, który może działać w oparciu o dowolną architekturę i może realizować całkowicie autonomiczny routing swoich połączeń.\n.\n**Odpowiedź 4: \"filtruje pakiety na poziomie wszystkich 3 warstw: sieciowej, transportowej i aplikacyjnej\"** - **FAŁSZ**.\nBramy aplikacyjne filtrują ruch *wyłącznie* na warstwie aplikacji, czyli warstwie 7 modelu OSI. W przeciwieństwie do tradycyjnych zapór ogniowych (firewalli), które operują na warstwach 3 (sieciowej) i 4 (transportowej) filtrując ruch w oparciu o adres IP i porty, ALG skupiają się na analizie i interpretacji danych na poziomie samej aplikacji. Przykładowo, zapora ogniowa może blokować ruch na porcie 80 (HTTP), natomiast ALG może analizować treść żądania HTTP, blokując te, które zawierają potencjalnie złośliwy kod. ALG analizuje to, co *aplikacja* komunikuje, a nie tylko *jak* komunikuje (np. na jakim porcie). Przykładowo, ALG dla protokołu HTTP może filtrować żądania przesyłane w standardzie HTTP (żądania GET, PUT, POST), a nie pakiety IP czy TCP na porcie 80."
    },
    {
        "questionId": 20,
        "title": "Ktore z ponizszych algorytmow kryptograficznych moga w praktyce zostac wykorzystane do zaszyfrowania tresci listu e-mail:",
        "answers": [
            {
                "text": "AES",
                "isCorrect": true
            },
            {
                "text": "RSA",
                "isCorrect": false
            },
            {
                "text": "Twofish",
                "isCorrect": true
            },
            {
                "text": "Blowfish",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "W kryptografii rozróżniamy dwa główne podejścia do szyfrowania: symetryczne i asymetryczne. Algorytmy symetryczne, takie jak AES, Twofish i Blowfish, wykorzystują ten sam klucz zarówno do szyfrowania, jak i deszyfrowania danych. Algorytmy asymetryczne, jak RSA, wykorzystują parę kluczy - publiczny do szyfrowania i prywatny do deszyfrowania. Zastosowanie tych algorytmów różni się ze względu na ich wydajność i funkcjonalność.\n\n**AES (Advanced Encryption Standard)** jest algorytmem symetrycznym, co oznacza, że do szyfrowania i deszyfrowania danych używa tego samego klucza. AES jest powszechnie uważany za bardzo bezpieczny i wydajny algorytm, dlatego jest często używany do szyfrowania dużych ilości danych, takich jak treść wiadomości e-mail. W praktyce, w procesie ochrony korespondencji email, po uzgodnieniu tajnego klucza dla szyfrowania symetrycznego, to nim szyfrowana jest treść wiadomości.\n\n**RSA (Rivest-Shamir-Adleman)** to algorytm asymetryczny. W tym przypadku klucz publiczny służy do szyfrowania danych, a klucz prywatny do ich deszyfrowania. RSA jest algorytmem wolniejszym od symetrycznych, dlatego nie nadaje się do szyfrowania dużych objętości danych, takich jak treść całego listu e-mail. Jest on natomiast często używany do szyfrowania mniejszych danych, takich jak klucze sesyjne (klucze używane w algorytmach symetrycznych). Protokół SSL, wykorzystywany w https, używa RSA do szyfrowania klucza sesyjnego, a następnie klucz ten używany jest do symetrycznego szyfrowania połączenia. RSA jest również powszechnie wykorzystywane do cyfrowego podpisywania danych, gdzie podpis jest tworzony z użyciem klucza prywatnego i weryfikowany za pomocą klucza publicznego.\n\n**Twofish** to symetryczny algorytm szyfrowania blokowego, który jest bardzo szybki i wydajny. Ze względu na swoją wydajność i bezpieczeństwo jest on jak najbardziej odpowiedni do szyfrowania treści listów e-mail. Algorytm Twofish jest jednym z kandydatów do standardu AES, z którym ostatecznie przegrał, ale jest nadal szeroko używany.\n\n**Blowfish** to kolejny algorytm symetryczny który również można użyć do szyfrowania treści listów email. Jest to algorytm o zróżnicowanej długości klucza, który można zdefiniować od 32 aż do 448 bitów. Ponadto charakteryzuje się on prostotą implementacji i dużą wydajnością. Blowfish jest algorytmem szyfrowania, który w implementacjach programowych nie jest chroniony patentem. Jest to algorytm, który w obecnych czasach jest bardzo często spotykany.\n\nPodsumowując, algorytmy AES, Twofish i Blowfish to algorytmy symetryczne, które można efektywnie używać do szyfrowania dużych objętości danych, takich jak zawartość wiadomości e-mail. RSA to algorytm asymetryczny, który nie nadaje się do bezpośredniego szyfrowania całej treści listu e-mail, ale jest niezbędny w procesie wymiany kluczy sesyjnych dla szyfrowania symetrycznego oraz cyfrowego podpisywania wiadomości. W praktyce do szyfrowania listów e-mail nie stosuje się szyfrowania asymetrycznego gdyż jest to operacja wymagająca większej mocy obliczeniowej i jest wolniejsza od symetrycznego szyfrowania. Dlatego do samej treści listów powszechnie używa się szyfrowania symetrycznego, a algorytmy asymetryczne wykorzystuje się do wymiany kluczy sesyjnych, którymi zaszyfrowano treść listu."
    },
    {
        "questionId": 21,
        "title": "Technologie umozliwiajace ochrone integralnosci transmitowanych danych to m.in:",
        "answers": [
            {
                "text": "protokol TLS",
                "isCorrect": true
            },
            {
                "text": "protokol AH",
                "isCorrect": true
            },
            {
                "text": "protokol ESP",
                "isCorrect": true
            },
            {
                "text": "SYN cookies",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Integralność danych w kontekście transmisji oznacza ochronę informacji przed nieautoryzowaną modyfikacją podczas przesyłania. Mechanizmy zapewniające integralność umożliwiają odbiorcy wykrycie, czy dane zostały zmienione w trakcie transferu, nawet nieumyślnie. Najczęściej używa się do tego celu funkcji skrótu kryptograficznego (hash), która generuje unikalny odcisk danych, oraz kryptografii klucza publicznego (podpisu cyfrowego) w celu zweryfikowania, czy skrót i podpis nie zostały podrobione. \n\n*   **protokół TLS** (Transport Layer Security) jest następcą protokołu SSL i  zapewnia poufność oraz integralność komunikacji w warstwie transportowej. TLS wykorzystuje kryptograficzne sumy kontrolne (MAC - Message Authentication Code) oparte na funkcjach skrótu, aby gwarantować, że dane nie zostały zmienione w trakcie przesyłania. Dodatkowo, TLS może wykorzystywać algorytmy szyfrowania symetrycznego (np. AES) i asymetrycznego (np. RSA) w celu zapewnienia poufności przesyłanych danych. Certyfikaty cyfrowe (X.509) pozwalają uwierzytelnić strony komunikacji, zapewniając, że połączenie jest nawiązywane z zamierzonym odbiorcą. W praktyce TLS jest powszechnie wykorzystywany w protokole HTTPS, zapewniając bezpieczne przeglądanie stron WWW i ochronę danych przesyłanych przez formularze internetowe, np. formularze logowania.\n*   **protokół AH** (Authentication Header) to element zestawu protokołów IPsec, który zapewnia integralność i autentyczność pakietów IP. AH wykorzystuje funkcję skrótu kryptograficznego i klucz tajny (który musi być znany obu stronom komunikacji), aby stworzyć skrót pakietu. Skrót ten, dołączony do pakietu, pozwala odbiorcy zweryfikować, czy pakiet nie został zmodyfikowany w trakcie transferu. AH nie zapewnia szyfrowania danych, skupiając się wyłącznie na ochronie integralności i autentyczności przesyłanej informacji. Przykładem użycia AH może być weryfikacja, czy nie doszło do próby manipulacji pakietami przesyłanymi między dwoma ruterami w sieci VPN.\n*   **protokół ESP** (Encapsulating Security Payload) to drugi protokół wchodzący w skład IPsec, który zapewnia zarówno poufność jak i integralność danych. ESP wykorzystuje szyfrowanie symetryczne do zapewnienia poufności (np. AES, 3DES) i funkcje skrótu kryptograficznego do zapewnienia integralności (np. SHA1, SHA256). Podobnie jak AH, ESP dołącza do pakietu sumę kontrolną(MAC), która jest obliczana na podstawie danych i tajnego klucza. Przy czym w tym przypadku cała zawartość pakietu (w tym adresy IP oraz dane użytkownika) jest szyfrowana i tylko strona docelowa jest w stanie je rozszyfrować. ESP jest często używane w sieciach VPN, aby zabezpieczyć cały ruch sieciowy między zdalnymi lokacjami.\n*   **SYN cookies** to mechanizm obrony przed atakami typu SYN flood. Atak SYN flood polega na wysyłaniu dużej liczby segmentów TCP SYN do serwera, przy czym nie następuje zakończenie procesu uzgadniania połączenia TCP. Celem jest wyczerpanie zasobów serwera. W odpowiedzi na segment SYN, serwer zazwyczaj odpowiada segmentem SYN/ACK. W przypadku ataku SYN flood serwer rezerwuje zasoby dla każdego odebranego pakietu SYN, co szybko może doprowadzić do przeciążenia serwera. Mechanizm SYN cookies pozwala na zmniejszenie zużycia zasobów po stronie serwera w ten sposób, że po otrzymaniu segmentu SYN nie przydziela się zasobów dla danego połączenia tylko serwer generuje specjalny kod (_cookie_), który jest odsyłany do nadawcy i w przyszłości posłuży do weryfikacji czy to rzeczywiście ta sama strona wysyła do serwera segment ACK. Zatem SYN cookies jest technologią zabezpieczającą dostępność, a nie integralność danych. Przykładowo serwer www może wykorzystywać SYN cookies do ochrony przed potencjalnym atakiem DoS.\n\nPodsumowując, protokoły TLS, AH i ESP są mechanizmami zapewniającymi integralność danych w trakcie transmisji. Różnią się one swoim przeznaczeniem (protokół transportowy, warstwa sieciowa), ale ich celem jest ochrona przed modyfikacją danych. Natomiast SYN cookies służy do ochrony dostępności i jest mechanizmem odmiennym od pozostałych."
    },
    {
        "questionId": 22,
        "title": "Szyfrowanie asymetryczne zapewnia:",
        "answers": [
            {
                "text": "autentycznosc pod warunkiem zachowania tajnosci klucza prywatnego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "poufnosc pod warunkiem zachowania tajnosci klucza prywatnego nadawcy",
                "isCorrect": false
            },
            {
                "text": "poufnosc pod warunkiem zachowania tajnosci klucza prywatnego odbiorcy",
                "isCorrect": true
            },
            {
                "text": "autentycznosc pod warunkiem zachowania tajnosci klucza prywatnego nadawcy",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Szyfrowanie asymetryczne, znane również jako kryptografia klucza publicznego, wykorzystuje parę kluczy - klucz publiczny i klucz prywatny, które są powiązane matematycznie, ale nie można na podstawie jednego wyznaczyć drugiego. Klucz publiczny jest szeroko dostępny, natomiast klucz prywatny musi być znany tylko właścicielowi. W kryptografii asymetrycznej klucze te wykorzystuje się na dwa sposoby: szyfrowanie i podpisywanie. Szyfrowanie asymetryczne gwarantuje **poufność**, a podpisywanie, **autentyczność**.\n\n**Opcja pierwsza jest niepoprawna**, ponieważ autentyczność, czyli pewność, że wiadomość pochodzi od faktycznego nadawcy, a nie osoby podszywającej się, jest osiągana poprzez **podpisanie** wiadomości kluczem prywatnym nadawcy. Odbiorca weryfikuje podpis za pomocą klucza publicznego nadawcy. Tajność klucza prywatnego odbiorcy jest istotna, ale dla zapewnienia poufności, nie autentyczności. Praktycznie, użytkownik X chce podpisać dokument dla użytkownika Y, w tym celu użytkownik X bierze klucz prywatny do podpisu dokumentu, a weryfikacji tego podpisu dokona każdy posiadający publiczny klucz użytkownika X, ponieważ publiczny klucz jest powiązany z kluczem prywatnym.\n\n**Opcja druga jest niepoprawna**, ponieważ poufność, czyli pewność, że wiadomość może być odczytana tylko przez adresata, jest osiągana poprzez **zaszyfrowanie** wiadomości kluczem publicznym odbiorcy. Klucz prywatny nadawcy jest wykorzystywany do podpisania wiadomości w celu osiągnięcia autentyczności, a nie poufności.  Na przykład: użytkownik X chce wysłać poufną wiadomość do użytkownika Y, w tym celu użytkownik X bierze klucz publiczny użytkownika Y i szyfruje nim wiadomość, a odszyfrowanie nastąpi po stronie Y z użyciem klucza prywatnego.\n\n**Opcja trzecia jest poprawna**, ponieważ poufność jest zapewniana poprzez zaszyfrowanie wiadomości **kluczem publicznym odbiorcy**. Tylko odbiorca posiadający odpowiedni klucz prywatny może odszyfrować wiadomość. To zapewnia, że nikt inny nie ma dostępu do treści wiadomości, nawet jeśli przechwyci dane. Na przykład podczas połączenia z serwisem bankowym to serwer bankowy ma klucz prywatny, a przeglądarka klienta korzysta z klucza publicznego serwera do zaszyfrowania danych. W praktyce połączenie z bankiem wykorzystuje mechanizm kryptografii klucza publicznego podczas fazy zestawienia sesji SSL, po tym kroku dochodzi do wymiany tajnych kluczy wykorzystywanych w mechanizmie kryptografii symetrycznej.\n\n**Opcja czwarta jest poprawna**, ponieważ autentyczność osiągana jest poprzez podpisanie wiadomości **kluczem prywatnym nadawcy**. Każdy kto posiada klucz publiczny nadawcy może zweryfikować autentyczność wiadomości, czyli czy na pewno wiadomość została wysłana przez tego nadawcę, którego identyfikuje użyty klucz publiczny. Ma to bardzo duże znaczenie, gdyż certyfikaty (które zawierają klucze publiczne) są potwierdzane przez zaufane centrum certyfikacji(CA). W praktyce podpis elektroniczny używany do podpisywania dokumentów lub wiadomości, służy do weryfikacji autentyczności, gdyż w podpisie tym zawarta jest wartość skrótu wiadomości. Odbiorca wiadomości posiadając publiczny klucz nadawcy, w łatwy sposób może zweryfikować czy ta wiadomość na pewno pochodzi od nadawcy podpisanego na liście."
    },
    {
        "questionId": 23,
        "title": "Algorytm Lamporta, lezacy u podstaw koncepcji programowej generacji hasel jednorazowych:",
        "answers": [
            {
                "text": "wymaga uzycia funkcji jednokierunkowej",
                "isCorrect": true
            },
            {
                "text": "wymaga rozwiazania problemu rozproszonego konsensusu",
                "isCorrect": false
            },
            {
                "text": "wymaga wykorzystania kryptografii asymetrycznej",
                "isCorrect": false
            },
            {
                "text": "wymaga rozwiazania problemu rozproszonego wzajemnego wykluczania",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Algorytm Lamporta, w kontekście generowania haseł jednorazowych, opiera się na koncepcji funkcji jednokierunkowej. Funkcja jednokierunkowa to funkcja, którą łatwo obliczyć w jedną stronę, ale bardzo trudno obliczyć w odwrotną, czyli z uzyskanego wyniku odtworzyć wejściową wartość. Ta właściwość funkcji jednokierunkowej jest kluczowa dla bezpieczeństwa jednorazowych haseł.\n\n*   **\"wymaga uzycia funkcji jednokierunkowej\"** - **Prawidłowa odpowiedź.** Algorytm Lamporta wykorzystuje funkcję jednokierunkową, aby wygenerować ciąg haseł jednorazowych.  Zaczynając od tajnego hasła początkowego, które jest tajne tylko dla użytkownika, iteracyjnie oblicza się kolejne hasła, aplikując do poprzedniego hasła funkcję jednokierunkową. Na przykład, jeśli tajne hasło początkowe to H0, to pierwsze hasło jednorazowe H1 to f(H0), drugie to H2 = f(H1) = f(f(H0)) i tak dalej, gdzie f jest funkcją jednokierunkową. Hasła jednorazowe są generowane \"w przód\" i używane w kolejności. Ponieważ odwrócenie f jest bardzo trudne, nie można odtworzyć poprzednich haseł mając tylko obecne, ani tym bardziej odtworzyć tajnego hasła początkowego. Ma to kluczowe znaczenie dla bezpieczeństwa schematu, gdyż nawet jeśli atakujący pozna hasło H2 z transmisji, nie będzie w stanie wyliczyć z niego hasła H1 (ani H0).\n*   **\"wymaga rozwiazania problemu rozproszonego konsensusu\"** - **Nieprawidłowa odpowiedź.** Rozproszony konsensus to problem, który dotyczy uzgodnienia jednej wartości danych między wieloma węzłami, gdzie pojedyncze węzły mogą ulec awarii. Algorytm Lamporta do generowania haseł jednorazowych nie porusza tego problemu, ponieważ dotyczy to sytuacji, gdy mamy wiele systemów które mają te same hasła, a w tej sytuacji to jeden użytkownik generuje i używa hasła jednorazowe.\n*   **\"wymaga wykorzystania kryptografii asymetrycznej\"** - **Nieprawidłowa odpowiedź.** Kryptografia asymetryczna wykorzystuje pary kluczy: publiczny i prywatny. Algorytm Lamporta nie wykorzystuje szyfrowania asymetrycznego, ale opiera się jedynie na wykorzystaniu funkcji jednokierunkowej. Kryptografia asymetryczna może być wykorzystana przy dystrybucji wygenerowanej listy haseł ale to jest inny problem niż sam mechanizm algorytmu Lamporta.\n*   **\"wymaga rozwiazania problemu rozproszonego wzajemnego wykluczania\"** - **Nieprawidłowa odpowiedź.** Rozproszone wzajemne wykluczanie to problem zabezpieczenia dostępu do współdzielonego zasobu przez wiele procesów tak aby uniknąć konfliktów lub wyścigu. Algorytm Lamporta dla haseł jednorazowych nie ma problemu wzajemnego wykluczania, ponieważ nie ma współdzielonych zasobów które trzeba chronić.\n\n**Przykład praktyczny:** Użytkownik ma tajne hasło H0 i chce używać haseł jednorazowych do logowania do aplikacji bankowej. Aplikacja bankowa zna proces generacji hasła (zna funkcję jednokierunkową). Użytkownik oblicza: H1 = f(H0), H2 = f(H1), H3 = f(H2), itd. Logując się za pierwszym razem podaje H1. Potem bank zna f(H1) = H2, więc za drugim razem, aby się zalogować, użytkownik musi podać H2."
    },
    {
        "questionId": 24,
        "title": "Wskaz mechanizmy systemu operacyjnego bedace realizacja (chocby czesciowa) koncepcji piaskownicy:",
        "answers": [
            {
                "text": "Windows AppContainer",
                "isCorrect": true
            },
            {
                "text": "SSL/TLS",
                "isCorrect": false
            },
            {
                "text": "click-jacking",
                "isCorrect": false
            },
            {
                "text": "wirtualizacja systemu operacyjnego",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Piaskownica, w kontekście bezpieczeństwa systemów komputerowych, to mechanizm izolacji, który ogranicza dostęp aplikacji lub procesu do zasobów systemowych, takich jak pliki, katalogi, pamięć i inne.  Piaskownica ma na celu zapobieganie szkodliwym działaniom złośliwego oprogramowania. Oprogramowanie działające w piaskownicy nie może oddziaływać na system operacyjny poza ograniczonym środowiskiem.\n\n**Windows AppContainer** to mechanizm piaskownicy wykorzystywany w systemie Windows. Jest to technologia izolacji aplikacji, która zapewnia, że aplikacje działające w trybie \"AppContainer\" mają ograniczony dostęp do systemu i zasobów innych aplikacji. Windows AppContainer zapobiega między innymi uzyskaniu dostępu do plików i katalogów, które nie zostały jawnie udostępnione przez system operacyjny dla aplikacji działającej w piaskownicy. Aplikacja działająca w piaskownicy ma wydzielone tylko i wyłącznie do swojej dyspozycji: katalogi z danymi i plikami konfiguracyjnymi, porty sieciowe, pamięć operacyjna, zasoby systemowe. Aplikacje działające w trybie AppContainer stosowane są przykładowo do izolacji aplikacji pobieranych ze sklepu Windows oraz aplikacje takie jak przeglądarka Edge. Wirtualne katalogi używane przez aplikacje w systemie Windows nie muszą istnieć fizycznie na dysku. Aplikacja w trybie AppContainer myśli, że wykorzystuje zasoby jak w systemie operacyjnym, jednakże w rzeczywistości ma ona przydzielone odseparowane i niezależne fragmenty systemu operacyjnego.\n\n**SSL/TLS**, czyli Secure Sockets Layer/Transport Layer Security to protokoły kryptograficzne zapewniające poufność, integralność i uwierzytelnianie komunikacji w sieci komputerowej. Protokół SSL/TLS nie ma na celu zapewnienia izolacji aplikacji, a jedynie ochronę danych przesyłanych w sieci. Przykładowo, połączenie z bezpieczną stroną internetową (https) wykorzystuje protokół SSL/TLS. Podłączając się do serwera www przesyłamy dane w postaci zaszyfrowanej, chronimy je przed podsłuchem. Protokół SSL/TLS sam w sobie nie ogranicza możliwości systemu czy aplikacji.\n\n**Click-jacking** to atak, który manipuluje interfejsem użytkownika strony internetowej, aby podsunąć użytkownikowi interaktywne elementy udające standardową zawartość strony, a w rzeczywistości wywołuje interakcję z innymi zasobami, np.: wysłanie niechcianej wiadomości, polubienia jakiegoś profilu. Click-jacking nie jest mechanizmem izolacji. To atak, który wykorzystuje błędy w implementacji stron internetowych, a nie błędy w systemie operacyjnym. Click-jacking opiera się o możliwość \"nakładania\" elementów interaktywnych i manipulowanie nimi w kontekście strony www.\n\n**Wirtualizacja systemu operacyjnego** to technologia, która umożliwia uruchomienie jednego lub wielu systemów operacyjnych (gości) na platformie fizycznej (hoście). Wirtualizacja jest mechanizmem izolacji, ale odnosi się do izolacji całych systemów, a nie poszczególnych aplikacji. Mechanizm ten nie oferuje opcji ograniczeń dla danej aplikacji w ramach systemu operacyjnego. Każdy wirtualizowany system operacyjny pracuje niezależnie, posiada swój własny zestaw usług systemowych, sterowników oraz zasobów. Aplikacje działające w ramach wirtualizowanego systemu operacyjnego mają do dyspozycji całą moc obliczeniową jak i pełen dostęp do zasobów systemu operacyjnego, tak samo jak w przypadku rzeczywistych(fizycznych) komputerów. Przykładowo, mechanizm wirtualizacji może być wykorzystany do uruchomienia wielu serwerów www na jednym komputerze fizycznym."
    },
    {
        "questionId": 25,
        "title": "Pewna zapora sieciowa filtrujaca pakiety realizuje jednoczesnie funkcje NAT. Ktore opisy pasuja do takiej zapory:",
        "answers": [
            {
                "text": "filtracja DNAT moze byc dokonywana dla pakietow przechodzacych przez zapore niezaleznie od kierunku",
                "isCorrect": false
            },
            {
                "text": "translacja DNAT musi byc dokonana przed routingiem pakietu aby pozycje tablicy routingu mogly byc prawidlowo dopasowane",
                "isCorrect": true
            },
            {
                "text": "translacja DNAT musi byc dokonana przed filtracja pakietu na interfejsie wejsciowym, aby reguly lancucha wejsciowego mogly byc prawidlowo dopasowane",
                "isCorrect": false
            },
            {
                "text": "translacja SNAT musi byc dokonana przed filtracja kontekstowa na interfejsie wyjsciowym, aby pakiet znalazl prawidlowe dopasowanie do tablicy aktywnych polaczen",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Translacja Adresów Sieciowych (NAT) to technika modyfikacji adresów IP w nagłówkach pakietów przechodzących przez ruter lub zaporę sieciową. Jest używana głównie do umożliwienia wielu komputerom w sieci prywatnej korzystania z jednego publicznego adresu IP lub do zmiany adresów docelowych. Wyróżniamy dwa główne typy translacji: SNAT (Source NAT), gdzie modyfikowany jest adres źródłowy, oraz DNAT (Destination NAT), gdzie modyfikowany jest adres docelowy. Zapory sieciowe, które filtrują pakiety i jednocześnie realizują NAT, wymagają starannej konfiguracji, ponieważ kolejność tych operacji ma kluczowe znaczenie dla prawidłowego działania.\n\n*   **\"filtracja DNAT moze byc dokonywana dla pakietow przechodzacych przez zapore niezaleznie od kierunku\"** -  To stwierdzenie jest **nieprawidłowe**.  Filtracja pakietów, zwłaszcza w kontekście DNAT, jest ściśle związana z kierunkiem przepływu pakietów. DNAT, czyli translacja adresu docelowego, jest wykonywana dla pakietów przychodzących do zapory sieciowej, a więc w kierunku do sieci wewnętrznej. Zapora sieciowa musi dokonać translacji adresu docelowego aby móc przekierować ruch do właściwego serwera. Filracji pakietów dokonujemy na interfejsie wejściowym i wyjściowym. Nie ma więc sytuacji w której filtracja DNAT jest niezależna od kierunku. Pakiet, który jest adresowany do sieci publicznej i jest przepuszczany przez zaporę, nie jest translacją DNAT, tylko SNAT.\n\n*   **\"translacja DNAT musi byc dokonana przed routingiem pakietu aby pozycje tablicy routingu mogly byc prawidlowo dopasowane\"** - To stwierdzenie jest **prawidłowe**.  Routing, czyli wybór ścieżki, którą pakiet ma podążyć, odbywa się na podstawie adresu docelowego. W przypadku pakietu przychodzącego do zapory, adres docelowy jest adres publiczny interfejsu tej zapory i jest on nieprawidłowy, gdy serwer do którego ma dotrzeć ten pakiet jest w sieci wewnętrznej z prywatnym adresem. Dlatego translacja DNAT musi być dokonana *przed* procesem routingu, aby ruter wiedział, do jakiej sieci wewnętrznej i do jakiego serwera wewnątrz sieci prywatnej ma wysłać ten pakiet. Inaczej, tablica routingu zawierałaby wpisy wskazujące na nieosiągalne adresy. W praktyce oznacza to, że w konfiguracji zapory, reguły DNAT muszą być umieszczone we właściwym łańcuchu przetwarzania pakietów (np. w łańcuchu PREROUTING dla *iptables*).\n\n*   **\"translacja DNAT musi byc dokonana przed filtracja pakietu na interfejsie wejsciowym, aby reguly lancucha wejsciowego mogly byc prawidlowo dopasowane\"** -  To stwierdzenie jest **nieprawidłowe**. Filtracja pakietów na interfejsie wejściowym w większości zapór jest wykonywana przed translacją DNAT. Pakiet przychodząc do zapory jest najpierw filtrowany na podstawie adresu docelowego i portu (jeśli filtracja ich dotyczy), następnie dokonywana jest translacja docelowego adresu IP (DNAT) oraz portu. Oznacza to, że zapora podejmuje decyzję odnośnie przepuszczania pakietu w oparciu o adres IP publiczny(interfejsu zapory), a po podjęciu decyzji o akceptacji takiego ruchu, jest dokonywana translacja docelowego adresu IP na prywatny adres serwera w sieci wewnętrznej.\n\n*   **\"translacja SNAT musi byc dokonana przed filtracja kontekstowa na interfejsie wyjsciowym, aby pakiet znalazl prawidlowe dopasowanie do tablicy aktywnych polaczen\"** - To stwierdzenie jest **nieprawidłowe**. Translacja SNAT (Source NAT) odbywa się przed filtrowaniem kontekstowym na interfejsie *wyjściowym*, ale nie po to, by pakiet znalazł dopasowanie do tablicy aktywnych połączeń. Filtracja kontekstowa, taka jak _stateful firewall_,  działa na podstawie połączeń, które zostały wcześniej ustanowione i zarejestrowane. Pakiety z danego, wcześniej znanego połączenia są dopasowywane do tablicy stanu, niezależnie od tego, jaki adres źródłowy mają. SNAT jest dokonywana po filtracji kontekstowej, ponieważ filtry kontekstowe wymagają dostępu do adresu źródłowego i portu przed ich zmianą przez SNAT. Gdyby tak nie było filtry nie potrafiły by dopasować danego pakietu do istniejących połączeń. Dodatkowo SNAT jest używane w przypadku pakietów wychodzących, czyli z sieci prywatnej do publicznej, dlatego translacja SNAT nie może być na interfejsie wejściowym."
    },
    {
        "questionId": 26,
        "title": "Jakie cechy wirtualizacji sa istotne dla bezpieczenstwa systemu?",
        "answers": [
            {
                "text": "procesor utrudnia ucieczke ze srodowiska zwirtualizowanego poprzez ochrone komend hipervisora na poziomie Ring -1",
                "isCorrect": true
            },
            {
                "text": "wirtualizacja systemu operacyjnego daje efekt piaskownicy dla uruchomionych w tym systemie aplikacji",
                "isCorrect": true
            },
            {
                "text": "hypervisor posredniczy w wywolaniach funkcji jada systemu operacyjnego, wiec moze wychwytywac potencjalnie niebezpieczne zachowania",
                "isCorrect": true
            },
            {
                "text": "w systemie wirtualnym bezposredni dostep do pamieci fizycznej (w tym pamieci urzadzen I/O) nie jest mozliwy nawet dla rozkazow Ring 0, co ulatwia izolacje maszyn wirtualnych nawet w przypadku przejecia uprawnien administracyjnych wewnatrz dowolnej z nich",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Wirtualizacja systemów komputerowych, szczególnie z wykorzystaniem hiperwizora, wprowadza szereg cech, które istotnie wpływają na bezpieczeństwo systemu. Hiperwizor, działając na poziomie uprzywilejowanym (często Ring -1), a więc poniżej jądra systemu operacyjnego (Ring 0), jest odpowiedzialny za zarządzanie i przydzielanie zasobów maszynom wirtualnym (VM). To rozwarstwienie wprowadza istotne bariery ochronne.\n\nPierwsza poprawna odpowiedź podkreśla, że procesor utrudnia ucieczkę z środowiska zwirtualizowanego, chroniąc polecenia hiperwizora na poziomie Ring -1. W architekturach procesorów z mechanizmami wirtualizacji, poziom Ring -1, poniżej Ring 0, jest wykorzystywany do uruchomienia hiperwizora. To hierarchiczne rozdzielenie uprawnień oznacza, że kod działający w maszynie wirtualnej (na Ring 0) nie ma możliwości bezpośredniego dostępu do sprzętu i zasobów kontrolowanych przez hiperwizor, co utrudnia potencjalne ataki mające na celu ucieczkę ze zwirtualizowanego środowiska, czyli przejęcie kontroli nad fizycznym hostem. Procesor celowo separuje te poziomy by kontrola hiperwizora była nienaruszalna.\n\nDruga poprawna odpowiedź trafnie wskazuje, że wirtualizacja systemu operacyjnego tworzy efekt piaskownicy dla aplikacji uruchomionych w tym systemie. Maszyna wirtualna, będąc odizolowanym środowiskiem, uniemożliwia aplikacjom działającym wewnątrz VM bezpośredni dostęp do zasobów hosta. Dzięki temu, złośliwe oprogramowanie uruchomione w wirtualizowanym systemie operacyjnym jest ograniczone tylko do tego środowiska i nie stanowi zagrożenia dla systemów działających poza maszyną wirtualną. W ten sposób awaria czy przejęcie systemu wirtualnego nie pociąga za sobą negatywnych konsekwencji w postaci kompromitacji całego systemu. Jest to analogiczne do piaskownicy w której dziecko bawi się w piasku i nie ma możliwości zrobienia szkody innym dzieciom, które bawią się poza tą piaskownicą.\n\nTrzecia poprawna odpowiedź słusznie zaznacza, że hiperwizor pośredniczy w wywołaniach funkcji jądra systemu operacyjnego, co pozwala na wychwytywanie potencjalnie niebezpiecznych zachowań. Hiperwizor działa jako kontroler dostępu do zasobów, w tym do funkcji jądra. Z tego powodu może on analizować parametry wywoływanych funkcji jądra, próbując wyłapać niebezpieczne lub podejrzane zachowania danej maszyny wirtualnej. Na przykład, hiperwizor może wykryć próby bezpośredniego dostępu do określonych obszarów pamięci czy modyfikacji kluczowych struktur systemu operacyjnego i zablokować taką operację. Dzięki temu możliwe jest wykrycie niebezpiecznych działań złośliwego oprogramowania.\n\nOstatnia odpowiedź zwraca uwagę, że w systemie wirtualnym bezpośredni dostęp do pamięci fizycznej, w tym do pamięci urządzeń I/O, nie jest możliwy nawet dla rozkazów poziomu Ring 0. Z poziomu Ring 0 komputera hosta może być dokonywany bezpośredni dostęp do pamięci oraz do portów urządzeń I/O, jednak z poziomu systemu wirtualnego (pomimo że również pracuje w trybie Ring 0) bezpośredni dostęp do fizycznej pamięci oraz portów urządzeń I/O jest zabroniony przez hiperwizora. Dzięki takiemu rozwiązaniu możliwe jest stworzenie bardzo wysokiego poziomu izolacji maszyn wirtualnych, nawet w przypadku, gdy intruz uzyska uprawnienia administracyjne w danej maszynie wirtualnej. Zazwyczaj to użytkownik posiadający uprawnienia administracyjne jest uważany za najbardziej zaufanego użytkownika w systemie, w systemie wirtualnym niekoniecznie musi tak być, gdyż administrator maszyny wirtualnej pomimo iż może wykonać wiele operacji nadal nie ma możliwości ingerencji w mechanizm kontroli hiperwizora."
    },
    {
        "questionId": 27,
        "title": "Ktore z ponizszych cech dotycza szyfrowania asymetrycznego:",
        "answers": [
            {
                "text": "odpornosc na kolizje",
                "isCorrect": false
            },
            {
                "text": "gwarancja autentycznosci i niezaprzeczalnosci komunikacji",
                "isCorrect": true
            },
            {
                "text": "wieksza niz dla algorytmow symetrycznych efektywnosc",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie asymetryczne, w przeciwieństwie do symetrycznego, używa pary kluczy: klucza publicznego, który jest ogólnie dostępny, oraz klucza prywatnego, który jest znany tylko właścicielowi. Klucz publiczny służy do szyfrowania danych, a klucz prywatny do ich deszyfrowania. Ta fundamentalna różnica w mechanizmie szyfrowania powoduje, że asymetryczne algorytmy kryptograficzne zapewniają inne własności niż symetryczne.\n\n**\"odpornosc na kolizje\"** jest cechą funkcji skrótu, a nie szyfrowania asymetrycznego. Funkcja skrótu to algorytm, który przekształca dowolnej długości dane wejściowe na krótki ciąg o stałej długości (skrót). \"Odporność na kolizje\" oznacza, że znalezienie dwóch różnych danych wejściowych dających ten sam skrót jest obliczeniowo bardzo trudne. Funkcje skrótu są wykorzystywane w kryptografii asymetrycznej, ale nie definiują jej głównych własności. Na przykład, generując podpis cyfrowy w metodzie RSA najpierw obliczamy skrót wiadomości a następnie szyfrujemy ten skrót kluczem prywatnym. Skrót ten jest unikatowy dla danej wiadomości i służy do jej weryfikacji. Zatem, odpowiedź ta jest *nieprawidłowa*, gdyż odporność na kolizję nie jest charakterystyczną cechą szyfrowania asymetrycznego.\n\n**\"gwarancja autentycznosci i niezaprzeczalnosci komunikacji\"** to jedna z kluczowych własności szyfrowania asymetrycznego. \"Autentyczność\" oznacza, że możemy zweryfikować, kto jest nadawcą wiadomości. Osiągamy to poprzez zastosowanie podpisu cyfrowego, który polega na zaszyfrowaniu skrótu wiadomości kluczem prywatnym nadawcy. Odbiorca, posiadając klucz publiczny nadawcy, może zweryfikować podpis i upewnić się, że wiadomość pochodzi od nadawcy. \"Niezaprzeczalność\" oznacza, że nadawca nie może zaprzeczyć wysłaniu wiadomości. Wynika to z faktu, że tylko nadawca posiada klucz prywatny użyty do stworzenia podpisu. W praktyce, np. podpisując dokument elektroniczny kluczem prywatnym, uniemożliwiamy sobie wyparcie się autorstwa dokumentu. Odpowiedź ta jest *prawidłowa*, gdyż szyfrowanie asymetryczne jest podstawą mechanizmów autentyczności i niezaprzeczalności.\n\n**\"wieksza niz dla algorytmow symetrycznych efektywnosc\"** to nieprawda. Algorytmy szyfrowania asymetrycznego są o wiele wolniejsze od algorytmów symetrycznych. Z tego powodu w praktyce szyfrowanie asymetryczne stosuje się do wymiany kluczy sesyjnych, a szyfrowanie symetryczne do przesyłania dużych ilości danych. W rzeczywistych scenariuszach bezpiecznej komunikacji internetowej (np. SSL/TLS) serwer używa swojego klucza prywatnego i certyfikatu do uwierzytelnienia się przed klientem, który generuje klucz sesyjny, który z kolei jest szyfrowany kluczem publicznym serwera, a sama komunikacja jest szyfrowana algorytmem symetrycznym z użyciem wspomnianego klucza sesyjnego. Zatem odpowiedź ta jest *nieprawidłowa*, gdyż algorytmy asymetryczne nie są bardziej wydajne od algorytmów symetrycznych, a wręcz przeciwnie."
    },
    {
        "questionId": 28,
        "title": "Ktore z ponizszych cech dotycza szyfrowania symetrycznego:",
        "answers": [
            {
                "text": "odpornosc na kolizje",
                "isCorrect": false
            },
            {
                "text": "gwarancja autentycznosci i niezaprzeczalnosci komunikacji",
                "isCorrect": false
            },
            {
                "text": "wieksza niz dla algorytmow asymetrycznych efektywnosc",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie symetryczne to metoda kryptograficzna, która wykorzystuje jeden tajny klucz zarówno do szyfrowania, jak i deszyfrowania danych. Klucz ten musi być znany obu stronom komunikacji, co jest istotnym czynnikiem wpływającym na bezpieczeństwo i zastosowanie tej metody. Algorytmy symetryczne, takie jak AES, 3DES, czy Blowfish, przetwarzają dane szybko i wydajnie. Są szeroko stosowane do ochrony dużych ilości danych ze względu na swoją szybkość.\n    \n**Odporność na kolizje**  jest właściwością funkcji skrótu, a nie szyfrowania symetrycznego. Funkcja skrótu, taka jak SHA-256 lub MD5, przekształca dowolną ilość danych wejściowych w skrót o stałej długości. Funkcja skrótu ma być *odporna na kolizje*, co oznacza, że znalezienie dwóch różnych danych wejściowych, które dają ten sam skrót, powinno być obliczeniowo trudne. Odporność na kolizje jest kluczowa w ochronie integralności danych, gdzie celem jest ochrona danych przed nieautoryzowaną zmianą. Szyfrowanie symetryczne nie zapewnia tej ochrony w taki sam sposób. Szyfrowanie symetryczne, szyfruje dane, tak że tylko posiadacz klucza może je odszyfrować. Zatem jest ono odpowiedzialne za poufność, a nie integralność.\n    \n**Gwarancja autentyczności i niezaprzeczalności komunikacji**  jest domeną kryptografii asymetrycznej, a nie symetrycznej. Autentyczność (potwierdzenie tożsamości nadawcy) i niezaprzeczalność (nadawca nie może zaprzeczyć wysłania wiadomości, a odbiorca jej otrzymania) osiąga się poprzez podpis cyfrowy, który wykorzystuje parę kluczy (prywatny i publiczny) w systemie asymetrycznym.  W szyfrowaniu symetrycznym nie ma takiego mechanizmu z uwagi na ten sam klucz. Strony komunikacji muszą mieć zaufanie, że druga strona jest tą za kogo się podaje, ale nie ma żadnego technicznego mechanizmu umożliwiającego weryfikację, którą oferuje kryptografia asymetryczna. Przykładowo protokół SSH wykorzystuje uwierzytelnianie kryptograficzne, gdzie serwer potwierdza swoją tożsamość poprzez wysłanie certyfikatu podpisanego swoim kluczem prywatnym, który to certyfikat jest weryfikowany przez klienta, ale szyfrowanie właściwej komunikacji następuje algorytmem symetrycznym.\n    \n**Większa niż dla algorytmów asymetrycznych efektywność** jest cechą charakterystyczną dla szyfrowania symetrycznego. Algorytmy symetryczne są znacznie szybsze i mniej wymagające obliczeniowo niż algorytmy asymetryczne (np. RSA czy ECC). Powoduje to, że algorytmy symetryczne są optymalnym wyborem gdy trzeba chronić duże ilości danych np. przy przesyłaniu filmów, lub całych plików. Przykładowo, w protokole HTTPS do szyfrowania danych jest wykorzystywane szyfrowanie symetryczne, ponieważ w szybki sposób daje ono zadowalający poziom ochrony poufności przesyłanych danych. Kryptografia asymetryczna wykorzystywana jest natomiast do wymiany klucza symetrycznego."
    },
    {
        "questionId": 29,
        "title": "Ktore z ponizszych mechanizmow pozwalaja w systemie operacyjnym na chwilowe uzyskanie innych uprawnien dostepu niz posiadane aktualnie przez uzytkownika:",
        "answers": [
            {
                "text": "Windows UAC",
                "isCorrect": true
            },
            {
                "text": "POSIX ACL",
                "isCorrect": false
            },
            {
                "text": "sudo",
                "isCorrect": true
            },
            {
                "text": "POSIX CAP",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Mechanizmy  zezwalające na chwilowe uzyskanie innych uprawnień dostępu niż te, które użytkownik posiada domyślnie, służą do tymczasowej zmiany kontekstu bezpieczeństwa procesu. Umożliwia to wykonanie operacji wymagających wyższych uprawnień niż te, którymi dysponuje zwykły użytkownik, a jednocześnie zapobiega nadużyciom poprzez minimalizowanie czasu, w którym proces działa w podwyższonym kontekście bezpieczeństwa.\n\n**Windows UAC (User Account Control)**: UAC to składnik zabezpieczeń systemu Windows, który wymaga potwierdzenia ze strony użytkownika przed wykonaniem operacji wymagających uprawnień administratora. Gdy użytkownik próbuje wykonać akcję, która wymaga podwyższonych uprawnień, system wyświetla monit z prośbą o potwierdzenie akcji oraz wpisanie hasła administratora. W praktyce oznacza to, że nawet użytkownik posiadający uprawnienia administratora, domyślnie pracuje z uprawnieniami zwykłego użytkownika, a podwyższone uprawnienia są aktywne tylko w tymczasowo przez użytkownika podczas konkretnej operacji. UAC nie daje uprawnień tymczasowych dla wybranych aplikacji, umożliwia jedynie dostęp do konta posiadającego pełnie uprawnień administratora w danym systemie operacyjnym.\n\n**POSIX ACL (Access Control Lists):**  POSIX ACL (Access Control Lists) są mechanizmem kontroli dostępu w systemach Unix/Linux, który pozwala administratorowi na określenie precyzyjnych uprawnień dostępu do plików i katalogów. Mechanizm ten umożliwia definiowanie uprawnień dla poszczególnych użytkowników i grup, niezależnie od uprawnień właściciela, grupy i innych. Zatem ACL umożliwiają bardzo precyzyjne ustawienia uprawnień dostępu do systemu plików, ale to ustawienie jest statyczne (czyli ustawione raz, obowiązuje cały czas), nie umożliwia dynamicznego i tymczasowego podnoszenia uprawnień dla jakiejś aplikacji lub użytkownika.  Na przykład, administrator może ustawić uprawnienie zapisu dla użytkownika *kowalski* do katalogu */var/log/apache2*. Ustawione uprawnienia będą obowiązywać dla tego użytkownika przez cały czas, nie są tymczasowe,  chyba że administrator sam to ręcznie zmieni.\n\n**sudo:**  `sudo` jest narzędziem dostępnym w systemach Linux/Unix, które umożliwia użytkownikom uruchamianie poleceń z uprawnieniami innego użytkownika, najczęściej superużytkownika (root).  `sudo` jest skonfigurowane plikiem `/etc/sudoers`. Przykładowa konfiguracja użytkownika *piotr* z wykorzystaniem _sudo_ może wyglądać tak: `piotr ALL = /usr/bin/apt-get upgrade`. Użytkownik *piotr* może wykonać z uprawnieniami *root* tylko i wyłącznie polecenie `apt-get upgrade`. Użycie komendy `sudo` w praktyce pozwala na wykonanie jednorazowej operacji, która wymaga wyższych uprawnień. Wywołanie komendy z `sudo` wymaga albo hasła administratora(lub hasła użytkownika wywołującego w zależności od konfiguracji) albo wykonanie polecenia następuje bez żądania podania hasła. Uzyskane uprawnienia są ważne tylko dla danej komendy. Innymi słowy jest to tymczasowe nadanie wyższych uprawnień dla wykonania danej operacji.\n\n**POSIX CAP (Capabilities):** Mechanizm POSIX Capabilities w systemach Linux to zestaw granulowanych uprawnień, które mogą być przypisane do procesów. Te uprawnienia są bardziej precyzyjne niż tradycyjne uprawnienia użytkownika/grupy. Pozwalają na przyznawanie konkretnych możliwości np. uruchamianie gniazd sieciowych bez konieczności posiadania pełnych uprawnień roota. W przypadku, gdy jakaś aplikacja wymaga konkretnego uprawnienia, administrator ma możliwość dodania mu uprawnienia tylko do danego zadania. Podanie przykładowo uprawnienia  `cap_net_bind_service` daje aplikacji prawo do wiązania gniazd z portami o numerach poniżej 1024. Nie powoduje to automatycznie uzyskanie uprawnień do innych funkcji systemu. System PAM w połączeniu z systemem capabilities umożliwia nadanie takich uprawnień użytkownikom lub aplikacjom, tymczasowo tylko podczas fazy logowania użytkownika.  Przykładowo użytkownik ma ograniczone uprawnienia, jednak po procesie logowania i przy użyciu modułu pam_cap jego procesy mogą posiadać uprawnienia wykraczające poza jego uprawnienia ale tylko na czas sesji, nie ma do nich dostępu bezpośrednio."
    },
    {
        "questionId": 30,
        "title": "Wskaz cechy mechanizmu AppContainer:",
        "answers": [
            {
                "text": "kontroluje wywolania funkcji jadra systemu operacyjnego",
                "isCorrect": false
            },
            {
                "text": "jest \"lekkim\" odpowiednikiem maszyny wirtualnej, z ta roznica, ze nie zawiera zwirtualizowanego systemu operacyjnego, tylko aplikacje i potrzebne biblioteki",
                "isCorrect": false
            },
            {
                "text": "wykorzystuje wirtualizacje systemu plikow i rejestru systemu Windows",
                "isCorrect": true
            },
            {
                "text": "jest rodzajem kwarantanny dla potencjalnie zainfekowanych aplikacji, przetrzymywanych tam zanim antywirus otrzyma z chmury ostateczny rezultat analizy behawioralnej podejrzanego kodu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "AppContainer to mechanizm izolacji aplikacji stosowany w systemie Windows, który opiera się na wirtualizacji systemu plików i rejestru. Oznacza to, że aplikacja działająca w kontenerze AppContainer ma wirtualny widok systemu plików i rejestru, co uniemożliwia jej bezpośredni dostęp do rzeczywistych zasobów systemu oraz modyfikację ich. Jest to technika izolacji, która zabezpiecza system operacyjny przed niepowołanym działaniem aplikacji.\n\nPierwsza odpowiedź, \"kontroluje wywołania funkcji jądra systemu operacyjnego\", jest niepoprawna, ponieważ AppContainer nie działa na poziomie bezpośredniego przechwytywania wywołań jądra. Zamiast tego, opiera się na wirtualizacji zasobów, kontroli dostępu i separacji procesów, czyli działa na wyższym poziomie. Systemy kontrolujące wywołania funkcji jądra wykorzystują inne mechanizmy jak np. systemy MAC (Mandatory Access Control) jak np. SELinux (Security-Enhanced Linux). Przechwytywanie wywołań jądra, to technika bardziej inwazyjna i nie jest charakterystyczna dla mechanizmu AppContainer. \n\nDruga odpowiedź, \"jest 'lekkim' odpowiednikiem maszyny wirtualnej, z tą różnicą, że nie zawiera zwirtualizowanego systemu operacyjnego, tylko aplikacje i potrzebne biblioteki\", jest niepoprawna, chociaż AppContainer zapewnia pewien poziom izolacji podobny do maszyny wirtualnej, nie jest jej lekkim odpowiednikiem. Maszyna wirtualna (np. VirtualBox, VMware) zawiera całe zwirtualizowane środowisko systemowe. Natomiast AppContainer to mechanizm izolacji aplikacji działający w ramach jednego systemu operacyjnego, korzystający z mechanizmów wirtualizacji systemu plików i rejestru. AppContainer nie wirtualizuje samego systemu operacyjnego.  \n\nTrzecia odpowiedź, \"wykorzystuje wirtualizację systemu plików i rejestru systemu Windows\", jest poprawna. Jak zostało wspomniane na początku, mechanizm AppContainer opiera się na wirtualizacji tych zasobów. Daje to aplikacji wrażenie, jakby działała w odseparowanym środowisku, gdzie wszystkie zasoby są tylko jej własnością. Aplikacja nie ma możliwości bezpośredniego dostępu do prawdziwych zasobów w systemie operacyjnym. Przykładowo, aplikacja w kontenerze AppContainer może zapisywać pliki do swojego wirtualnego katalogu _Moje Dokumenty_, ale te pliki w rzeczywistości nie będą znajdować się w katalogu _Moje Dokumenty_ użytkownika, a w odseparowanej przestrzeni kontenera. Dzięki temu, nawet jeśli aplikacja zostanie zainfekowana, to potencjalny malware nie będzie miał dostępu do zasobów innych aplikacji czy systemu operacyjnego.\n\nCzwarta odpowiedź, \"jest rodzajem kwarantanny dla potencjalnie zainfekowanych aplikacji, przetrzymywanych tam zanim antywirus otrzyma z chmury ostateczny rezultat analizy behawioralnej podejrzanego kodu\", jest niepoprawna. Chociaż AppContainer może być stosowany do izolowania potencjalnie niebezpiecznych aplikacji, to jego głównym zadaniem nie jest pełnienie funkcji kwarantanny. Kwarantanną zajmują się aplikacje antywirusowe, które izolują podejrzane pliki na dysku i dopiero po analizie podejmują decyzję o usunięciu lub przywróceniu do działania. AppContainer stosowany jest do izolowania każdej aplikacji, bez konieczności analizowania jej zachowania. Dzięki AppContainer każda aplikacja jest izolowana z samego założenia."
    },
    {
        "questionId": 31,
        "title": "Wskaz cechy charakterystyczne ataku przez przepelnienie bufora (w segmencie stosu):",
        "answers": [
            {
                "text": "celem przepelnienia jest nadpisanie adresu powrotu w ramce funkcji odlozonej aktualnie na stosie",
                "isCorrect": true
            },
            {
                "text": "architektura pamieci musi byc taka by adresy rosly zgodnie z kierunkiem przyrostu stosu",
                "isCorrect": false
            },
            {
                "text": "celem przepelnienia jest nadpisanie pamieci jadra i wywolanie bledu obsluzonego przez zlosliwy kod",
                "isCorrect": false
            },
            {
                "text": "przepelnienie bufora mozna wykryc i odpowiednio zareagowac'",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Atak przez przepełnienie bufora (ang. *buffer overflow*) polega na zapisaniu większej ilości danych w buforze, niż ten bufor może pomieścić, co prowadzi do nadpisania sąsiednich obszarów pamięci. W przypadku przepełnienia bufora na stosie (ang. *stack-based buffer overflow*), celem ataku jest nadpisanie adresu powrotu funkcji, aktualnie odłożonej na stosie. Stos to obszar pamięci operacyjnej, który jest wykorzystywany do przechowywania informacji związanych z wywołaniami funkcji, takich jak zmienne lokalne i właśnie adresy powrotu (ang. *return address*). Kiedy funkcja jest wywoływana, na stosie tworzona jest ramka (ang. *stack frame*) dla tej funkcji, gdzie przechowywane są jej zmienne i adres powrotu. Adres powrotu to adres w pamięci, gdzie program powinien kontynuować wykonywanie po zakończeniu bieżącej funkcji.\n\n*   **\"celem przepelnienia jest nadpisanie adresu powrotu w ramce funkcji odlozonej aktualnie na stosie\"** - **Prawidłowa odpowiedź.** W ataku przez przepełnienie stosu, nadpisanie adresu powrotu na stosie (adresu, gdzie powinna wrócić wykonanie programu po zakończeniu funkcji) jest kluczowe. Atakujący nadpisuje ten adres adresem do kodu, który chce wykonać(np. kod powłoki umożliwiającej kontrolę nad systemem). Wykorzystując tę technikę, atakujący może przejąć kontrolę nad przebiegiem programu, a tym samym całego systemu.\n\n*   **\"architektura pamieci musi byc taka by adresy rosly zgodnie z kierunkiem przyrostu stosu\"** - **Nieprawidłowa odpowiedź.** Przepełnienie bufora na stosie może wystąpić niezależnie od kierunku przyrostu stosu (tj. czy rośnie w górę czy w dół pamięci). W rzeczywistości architektonicznie adresy mogą rosnąć zgodnie lub przeciwnie do kierunku przyrostu stosu, a mimo to podatność na ataki przepełnienia bufora nadal występuje. Ważne jest, że z punktu widzenia programisty który chce stworzyć zabezpieczenie dla systemu, nie ma pewności w jakim kierunku będzie rósł stos i w ten sposób nie może on się skutecznie obronić przed atakiem.\n\n*   **\"celem przepelnienia jest nadpisanie pamieci jadra i wywolanie bledu obsluzonego przez zlosliwy kod\"** - **Nieprawidłowa odpowiedź.** Atak przez przepełnienie bufora na stosie nie ma na celu bezpośredniego nadpisania pamięci jądra. W istocie celem takiego ataku jest nadpisanie adresu powrotu do wykonania innego kodu w obszarze pamięci przeznaczonym dla danej aplikacji. Choć teoretycznie możliwe jest, że błędnie napisana aplikacja może nadpisać obszar pamięci jądra, to jest to przypadek dużo rzadszy i wymagający bardziej skomplikowanych ataków. Zatem nadpisanie pamięci jądra nie jest celem ataku przez przepełnienie bufora na stosie.\n\n*   **\"przepelnienie bufora mozna wykryc i odpowiednio zareagowac\"** - **Prawidłowa odpowiedź.** Przepełnienie bufora można wykryć i na nie zareagować. Istnieje wiele technik (np. tzw. *stack canaries* - wartość, która jest umieszczana w ramce stosu) umożliwiających wykrycie próby nadpisania stosu lub nadpisania adresów powrotu oraz odpowiednie zareagowanie przez system operacyjny lub program, na przykład wywołując procedurę obsługi błędów lub przerywając wykonywanie programu. Wykrycie ataku i odpowiednia reakcja może zapobiec wykonaniu szkodliwego kodu. Systemy IDS i IPS analizują ruch sieciowy i logi, aby wykryć ataki wykorzystujące przepełnienie bufora."
    },
    {
        "questionId": 32,
        "title": "Zaznacz cechy charakterystyczne metody ARP detekcji podsluchu w sieci:",
        "answers": [
            {
                "text": "ogloszenie ARP skierowane pod falszywy adres IP",
                "isCorrect": false
            },
            {
                "text": "zapytanie ARP skierowane pod wlasciwy adres MAC odpytywanej stacji",
                "isCorrect": false
            },
            {
                "text": "zapytanie ARP skierowane pod rozgloszeniowy adres MAC",
                "isCorrect": false
            },
            {
                "text": "zapytanie ARP skierowane pod nierozgloszeniowy adres MAC",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół ARP (Address Resolution Protocol) służy do tłumaczenia adresów IP na adresy MAC w sieci lokalnej. Kiedy urządzenie w sieci chce skomunikować się z innym urządzeniem o znanym adresie IP, ale nie zna jego adresu MAC, wysyła zapytanie ARP. Zapytanie to jest rozgłaszane (broadcast) do wszystkich urządzeń w sieci lokalnej. Urządzenie, którego adres IP pasuje do zapytania, odpowiada, podając swój adres MAC. Atakujący może wykorzystać ARP do podsłuchu, manipulując odpowiedziami ARP tak, aby ofiara przekazywała ruch do jego maszyny.\n\n*   **\"ogloszenie ARP skierowane pod falszywy adres IP\"** - To jest nieprawidłowe. Atakujący nie rozgłasza ARP pod fałszywym adresem IP, ale **odpowiada** na zapytania ARP z fałszywym adresem MAC przypisanym do poprawnego adresu IP ofiary. Atakujący chce przejąć ruch przeznaczony dla ofiary, dlatego musi podać prawidłowy adres IP.\n\n*   **\"zapytanie ARP skierowane pod wlasciwy adres MAC odpytywanej stacji\"** - To jest nieprawidłowe. Zapytań ARP do właściwego adresu MAC się nie wysyła, bo adres MAC jest celem zapytania ARP, nie źródłem. Takie zapytania mogłyby pojawić się przy odświeżaniu tablicy ARP i są częścią poprawnego działania protokołu, nie wrogiego ataku.\n\n*   **\"zapytanie ARP skierowane pod rozgloszeniowy adres MAC\"** - To jest nieprawidłowe. Zapytania ARP są zwykle kierowane pod adres rozgłoszeniowy, co jest normalnym działaniem protokołu. Atakujący nie wysyła standardowego zapytania rozgłoszeniowego ARP. Atak ARP polega na wysłaniu sfałszowanej odpowiedzi na zapytanie ARP, ale nie na fałszowaniu samego zapytania.\n\n*   **\"zapytanie ARP skierowane pod nierozgloszeniowy adres MAC\"** - To jest poprawne. Atakujący wysyła spreparowane zapytanie ARP, w którym jako adres MAC docelowy wpisuje adres MAC ofiary, a nie adres rozgłoszeniowy. Takie zapytanie nie będzie rozgłaszane, tylko trafi bezpośrednio do ofiary. Atakujący, podszywając się pod bramę domyślną, kieruje zapytanie ARP do ofiary, podając swój własny adres MAC jako adres MAC bramy. Ofiara wpisuje do swojej tablicy ARP fałszywy adres MAC dla bramy, kierując cały swój ruch przez maszynę atakującego.\n\nNa przykład, w ataku ARP na komputerze o adresie IP 192.168.1.10 i adresie MAC AA:BB:CC:DD:EE:FF, haker posiadający adres MAC 00:11:22:33:44:55, podszywając się pod bramę domyślną (np. 192.168.1.1), wyśle spreparowane zapytanie ARP z IP 192.168.1.1, adresowane do MAC AA:BB:CC:DD:EE:FF, podając w nim swój adres MAC 00:11:22:33:44:55 jako prawidłowy dla adresu IP 192.168.1.1. Dzięki temu cała komunikacja komputera z adresem IP 192.168.1.10 zostanie przekierowana przez maszynę hakera. To umożliwia przechwytywanie i modyfikację pakietów przez atakującego (man-in-the-middle)."
    },
    {
        "questionId": 33,
        "title": "Wskaz problemy bezpieczenstwa wynikajace z fragmentacji IP:",
        "answers": [
            {
                "text": "fragmentacja jest przyczyna skutecznosci ataku SYN flood",
                "isCorrect": false
            },
            {
                "text": "potencjalna mozliwosc przepelnienia bufora pamieci przy scalaniu fragmentow",
                "isCorrect": true
            },
            {
                "text": "utrudniona mozliwosc filtracji fragmentow przez zapory sieciowe",
                "isCorrect": true
            },
            {
                "text": "kontrola fragmentacji wymaga uzycia ciasteczek SYN cookies",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Fragmentacja IP to proces dzielenia pakietu IP na mniejsze fragmenty w celu przesłania go przez sieć o mniejszej jednostce MTU (Maximum Transmission Unit). Te mniejsze fragmenty są następnie składane w całość przez odbiorcę. Sam proces fragmentacji, choć konieczny w wielu przypadkach, niesie ze sobą potencjalne zagrożenia.\n\n**Odpowiedź 1: \"fragmentacja jest przyczyna skutecznosci ataku SYN flood\"**\nJest to **nieprawidłowa** odpowiedź. Atak SYN flood to atak typu denial of service, który polega na zalewaniu serwera żądaniami nawiązania połączenia TCP (segmenty SYN) bez jego finalizacji (segmenty ACK). Celem tego ataku jest wyczerpanie zasobów serwera, a nie wykorzystanie podatności związanych z fragmentacją IP. Fragmentacja IP nie jest czynnikiem, który bezpośrednio wpływa na skuteczność ataku SYN flood.\n\n**Odpowiedź 2: \"potencjalna mozliwosc przepelnienia bufora pamieci przy scalaniu fragmentow\"**\nJest to **prawidłowa** odpowiedź. Implementacje stosu protokołów TCP/IP mogą mieć luki w procedurach ponownego składania pakietów. Złośliwie spreparowane fragmenty IP mogą próbować nadpisać obszary pamięci, które są wykorzystywane do buforowania fragmentów w trakcie ich reasemblacji. Gdy następuje przepełnienie bufora, atakujący może np. wstrzyknąć własny kod maszynowy do wykonywania przez zaatakowany system. Taki atak jest trudny do wykrycia, gdyż najczęściej analizowane są tylko początkowe fragmenty pakietu (a nie pozostałe).\n\n**Odpowiedź 3: \"utrudniona mozliwosc filtracji fragmentow przez zapory sieciowe\"**\nJest to **prawidłowa** odpowiedź. Zapory sieciowe często bazują na analizie nagłówków pakietów w celu podjęcia decyzji o przepuszczeniu lub zablokowaniu ruchu. W przypadku pakietów pofragmentowanych informacja istotna dla zapory może być rozproszona w wielu pakietach, co utrudnia (lub nawet uniemożliwia) skuteczne działanie filtrów (które często analizują tylko pierwszy fragment). Przykładowo, zapora może sprawdzać tylko port docelowy i zezwalać na ruch tylko na określonym porcie. Jeśli port jest tylko we fragmencie następnym, a nie początkowym, zapora może przepuścić ten pakiet. To zachowanie jest wykorzystywane w wielu atakach wykorzystujących fragmentację IP. Co więcej, niektóre zapory sieciowe w przypadku gdy nie przepuszczą pierwszego fragmentu, przepuszczają automatycznie kolejne.\n\n**Odpowiedź 4: \"kontrola fragmentacji wymaga uzycia ciasteczek SYN cookies\"**\nJest to **nieprawidłowa** odpowiedź. Mechanizm SYN cookies służy do ochrony przed atakami typu SYN flood. Atak ten polega na wysyłaniu dużej liczby pakietów SYN w celu wyczerpania zasobów serwera, a nie na wykorzystaniu podatności związanych z fragmentacją. SYN cookies jest zabezpieczeniem dla protokołu TCP i w żaden sposób nie jest związany z reasemblacją pakietów IP.\n\nPodsumowując, fragmentacja IP, mimo że jest integralną częścią protokołu IP, niesie ze sobą liczne problemy bezpieczeństwa, szczególnie dotyczące przepełnień bufora i utrudnionej filtracji. Odpowiednia konfiguracja zabezpieczeń systemu oraz zapory sieciowej jest niezbędna w celu minimalizacji negatywnych skutków związanych z fragmentacją IP."
    },
    {
        "questionId": 34,
        "title": "Zaznacz prawdziwe stwierdzenia dotyczace protokolu HTTP:",
        "answers": [
            {
                "text": "HTTP od wersji 1.1 uwierzytelnia nie tylko klienta, ale i serwer",
                "isCorrect": false
            },
            {
                "text": "Digest Authentication HTTP 1.1 realizuje metode challenge-response",
                "isCorrect": true
            },
            {
                "text": "Basic Authentication w HTTP 1.0 przesyla nazwe uzytkownika i haslo w postaci niezaszyfrowanej",
                "isCorrect": true
            },
            {
                "text": "Basic Authentication w HTTP 1.1 przesyla nazwe uzytkownika i haslo w postaci zaszyfrowanej",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół HTTP (Hypertext Transfer Protocol) używa różnych metod uwierzytelniania, aby kontrolować dostęp do zasobów serwera.  Podstawową metodą jest Basic Authentication, a bardziej zaawansowaną Digest Authentication.\n\n**Basic Authentication**  w HTTP (w wersjach 1.0 i 1.1) przesyła nazwę użytkownika i hasło w postaci zakodowanej Base64.  Chociaż zakodowane, to wciąż nie jest to szyfrowanie, dane mogą zostać łatwo odkodowane i odczytane.  Jest to zatem niebezpieczna metoda uwierzytelniania, szczególnie przy komunikacji niezabezpieczonej SSL/TLS.  W praktyce, przeglądarka na żądanie serwera wyświetla okno do wprowadzenia nazwy i hasła, a po ich podaniu dane te są przesyłane do serwera w nagłówku żądania w postaci \"Authorization: Basic <zakodowane_dane>\".  Przykład:  użytkownik 'test', hasło '123', zakodowane do postaci dGVzdDoxMjM= tworzą nagłówek 'Authorization: Basic dGVzdDoxMjM='.   Zatem jeśli atakujący przechwyci taki nagłówek, bez problemu odkoduje nazwę użytkownika i hasło.\n\n**Digest Authentication** w HTTP 1.1 jest ulepszeniem Basic Authentication, wykorzystującym mechanizm _challenge-response_.  W pierwszej kolejności serwer wysyła do klienta informację z 'wyzwaniem' (ang. _challenge_), będącym losowym ciągiem znaków i informacją o algorytmie skrótu, który powinien być użyty.  Klient do tego wyzwania dołącza swoją nazwę użytkownika, hasło, dodatkowe dane i wszystko to jest przetwarzane algorytmem skrótu MD5, czego wynikiem jest 'odpowiedź' (ang. _response_), przesyłana do serwera. Serwer wykonuje identyczną operację. Jeżeli wyliczone przez obie strony odpowiedzi są identyczne to znaczy, że użytkownik jest poprawnie uwierzytelniony.  W praktyce, chociaż hasło nie jest przesyłane w postaci jawnej, jego skrót jest generowany przy każdym żądaniu, co sprawia, że przechwycenie takiego skrótu nie jest wystarczające, aby skutecznie podszyć się pod użytkownika.  Dodatkowo, stosuje się jednorazowe parametry nonces (_ang. nonce_), utrudniające ataki typu _replay attack_.\n\n**Analiza odpowiedzi:**\n * **\"HTTP od wersji 1.1 uwierzytelnia nie tylko klienta, ale i serwer\"** - Jest to **nieprawda**. Protokół HTTP samodzielnie nie uwierzytelnia serwera. Uwierzytelnianie serwera możliwe jest poprzez SSL/TLS, ale to nie jest część HTTP. HTTP jest protokołem warstwy aplikacji, natomiast SSL/TLS to protokół warstwy sesji (i w niektórych warunkach transportu).  To właśnie SSL/TLS wykorzystuje certyfikaty do zweryfikowania autentyczności serwera.\n * **\"Digest Authentication HTTP 1.1 realizuje metode challenge-response\"** - Jest to **prawda**. Digest Authentication właśnie tak działa, chroniąc hasło użytkownika przed prostym podsłuchaniem. Serwer wysyła wyzwanie, a klient odsyła odpowiedź będącą skrótem (hash) hasła, wyzwania i innych danych.\n * **\"Basic Authentication w HTTP 1.0 przesyla nazwe uzytkownika i haslo w postaci niezaszyfrowanej\"** - Jest to **prawda**. Uwierzytelnianie _Basic_ używa kodowania Base64, które **nie** jest szyfrowaniem, tylko zamianą tekstu jawnego na ciąg znaków, który jest przenoszalny. Może być łatwo odkodowane. \n * **\"Basic Authentication w HTTP 1.1 przesyla nazwe uzytkownika i haslo w postaci zaszyfrowanej\"** - Jest to **nieprawda**. Basic Authentication,  w wersjach 1.0 jak i 1.1, używa kodowania Base64, które nie jest szyfrowaniem.  Szyfrowanie jest realizowane dopiero przy użyciu połączenia SSL/TLS z użyciem protokołu HTTPS."
    },
    {
        "questionId": 36,
        "title": "!żółte w bazie! Ktore z ponizszych cech prawidlowo opisuja protokol IPsec?[X]",
        "answers": [
            {
                "text": "moze dzialac z uwierzytelnianiem stron dokumentowanym tylko przez ESP",
                "isCorrect": false
            },
            {
                "text": "moze dzialac w trybie tylko z ochrona integralnosci przez ESP",
                "isCorrect": false
            },
            {
                "text": "moze dzialac z uwierzytelnianiem stron dokumentowanym tylko przez AH",
                "isCorrect": false
            },
            {
                "text": "moze dzialac w trybie tylko z ochrona integralnosci przez AH",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół IPsec (Internet Protocol Security) jest zbiorem protokołów służących do zabezpieczania komunikacji IP. Zasadniczo, IPsec działa na poziomie warstwy sieciowej modelu OSI. IPsec składa się z dwóch głównych protokołów: AH (Authentication Header) oraz ESP (Encapsulating Security Payload), które oferują różne mechanizmy bezpieczeństwa.\n\n**Protokół AH (Authentication Header)** zapewnia integralność i uwierzytelnianie danych. Integralność w tym przypadku oznacza, że dane nie zostały zmodyfikowane podczas transmisji, natomiast uwierzytelnianie, że przesyłane dane pochodzą od zaufanego źródła. AH nie zapewnia natomiast poufności danych. AH używa kryptograficznych funkcji skrótu (np. SHA1 lub MD5) do stworzenia tzw. skrótu, który jest dodawany do pakietu IP, aby zapewnić jego integralność. Uwierzytelnienie odbywa się poprzez wykorzystanie kluczy. Klucz jest znany zarówno nadawcy jak i odbiorcy.\n\n**Protokół ESP (Encapsulating Security Payload)** zapewnia integralność, uwierzytelnianie, ale w przeciwieństwie do AH, również poufność. ESP, oprócz mechanizmów skrótu kryptograficznego, stosuje też szyfrowanie do zabezpieczenia zawartości pakietu. Stosowane są algorytmy symetryczne takie jak AES, 3DES, lub Blowfish. ESP może działać w dwóch trybach, transportowym i tunelowym. \n\nPrzechodząc do analizy odpowiedzi:\n\n*   **\"moze dzialac z uwierzytelnianiem stron dokumentowanym tylko przez ESP\"** - Jest to odpowiedź niepoprawna, ponieważ ESP samodzielnie nie oferuje *tylko* uwierzytelnienia. ESP zazwyczaj ma na celu zarówno uwierzytelnienie, jak i zapewnienie poufności. W procedurze uzgadniania parametrów połączenia szyfrowanego z użyciem ESP dochodzi do weryfikacji tożsamości stron, ale z reguły nie jest to jedyna czynność wykonywana w danym połączeniu, gdyż ESP ma na celu również szyfrowanie danych.\n\n*  **\"moze dzialac w trybie tylko z ochrona integralnosci przez ESP\"** - Jest to odpowiedź niepoprawna, ponieważ ESP działa zawsze w celu zarówno ochrony integralności jak i poufności. Jeżeli dany użytkownik chce tylko ochrony integralności (i ew. uwierzytelniania) powinien wybrać AH. ESP używa skrótu kryptograficznego do weryfikacji integralności jak i szyfrowania w celu zapewnienia poufności danych. Wyłączenie szyfrowania przez ESP nie jest standardowym rozwiązaniem.\n\n*   **\"moze dzialac z uwierzytelnianiem stron dokumentowanym tylko przez AH\"** - Jest to odpowiedź niepoprawna, ponieważ AH samodzielnie oferuje *tylko* ochronę integralności i uwierzytelnienie stron. Zabezpieczenie tożsamości stron(uwierzytelnienie) w AH jest zawsze powiązane z integralnością. AH nie zapewnia poufności danych. Klucz użyty w AH znany jest obu stronom.\n\n*   **\"moze dzialac w trybie tylko z ochrona integralnosci przez AH\"** - Jest to odpowiedź poprawna. AH zapewnia ochronę integralności i uwierzytelnienie stron bez zapewniania poufności. Stosuje kryptograficzne sumy kontrolne HMAC na zawartości pakietów oraz dołącza je do nagłówka pakietu. Odbiorca, używając tego samego klucza, może zweryfikować integralność pakietu, wyliczając skrót z danych i porównując go z załączonym w pakiecie.\n    *   **Praktyczne implikacje:** AH może być użyteczne gdy poufność nie jest wymagana, np. zabezpieczenie autentyczności danych (potwierdzenie autentyczności danych jest wymagane ale ich treść jest jawna)."
    },
    {
        "questionId": 37,
        "title": "Wskaz cechy uprawnien POSIX CAP:",
        "answers": [
            {
                "text": "moga byc przypisywane do uzytkownikow",
                "isCorrect": true
            },
            {
                "text": "moga byc przypisywane do procesow",
                "isCorrect": true
            },
            {
                "text": "podlegaja dziedziczeniu przez procesy potomne",
                "isCorrect": true
            },
            {
                "text": "pozwalaja na delegowanie podmiotom wybranych elementarnych uprawnien administracyjnych",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "POSIX Capabilities (CAP) to mechanizm, który umożliwia precyzyjną kontrolę uprawnień w systemach operacyjnych zgodnych ze standardem POSIX (np. Linux). Zamiast tradycyjnego podziału na użytkowników zwykłych i superużytkownika (root), CAP pozwala dzielić uprawnienia administracyjne na mniejsze, bardziej szczegółowe jednostki, które można nadawać użytkownikom i procesom.  Dzięki temu mechanizmowi, aplikacje mogą działać z minimalnym zestawem uprawnień, niezbędnym do wykonania konkretnego zadania, co znacznie podnosi bezpieczeństwo systemu.\n\n*   **moga byc przypisywane do uzytkownikow:** Jest to **poprawne** stwierdzenie.  Tradycyjne uprawnienia systemu Unix opierają się na użytkowniku, grupie i innych (u/g/o). CAP rozszerza ten model umożliwiając nadawanie uprawnień konkretnym użytkownikom (a nie tylko grupom lub wszystkim). Przykładowo,  możesz nadać użytkownikowi `www-data` (używanemu przez serwer Apache) uprawnienie `CAP_NET_BIND_SERVICE`, aby mógł uruchamiać serwer na portach poniżej 1024, a jednocześnie nie miał on innych uprawnień administracyjnych, którymi dysponuje użytkownik `root`.  Bez CAP musiałbyś dawać serwerowi uprawnienia użytkownika `root` do uruchomienia się na porcie 80, co stanowi ogromne zagrożenie.\n\n*   **moga byc przypisywane do procesow:** Jest to **poprawne** stwierdzenie. Oprócz użytkowników, uprawnienia mogą być także przypisywane do procesów. Oznacza to, że nawet jeśli proces działa w imieniu danego użytkownika, może posiadać konkretny zestaw CAP niezależnie od uprawnień użytkownika. Na przykład, proces serwera WWW uruchamiany z uprawnieniami użytkownika `www-data` może mieć nadane  `CAP_NET_BIND_SERVICE`, by móc otworzyć port 80 lub 443, a jednocześnie mieć odebrane uprawnienia `CAP_DAC_OVERRIDE` zapobiegające zmianie praw dostępu do plików, nawet jeśli pliki należą do niego. Z punktu widzenia bezpieczeństwa jest to bardzo istotne, gdyż minimalizujemy możliwości wykorzystania danej aplikacji do ataku na nasz system operacyjny. \n\n*   **podlegaja dziedziczeniu przez procesy potomne:** Jest to **poprawne** stwierdzenie.  W systemie operacyjnym procesy potome są tworzone przez procesy rodzice. Jeśli proces rodzic ma przypisane jakieś CAP to proces potomny otrzymuje ten sam zestaw uprawnień CAP.  Dzięki mechanizmowi dziedziczenia mamy możliwość utworzenia drzewa procesów mających stosowne uprawnienia, bez potrzeby nadawania tych uprawnień wszystkim procesom w systemie. Dla przykładu,  proces `init` na starcie systemu dostaje pełen zestaw CAP, następnie może uruchamiać serwer SSH (proces potomny `sshd`), któremu przekazuje tylko uprawnienie `CAP_NET_BIND_SERVICE`, a następnie każde kolejne uruchomienie (na przykład połączenie sesyjne użytkownika) `bash` może dziedziczyć uprawnienia od procesu `sshd`.\n\n*   **pozwalaja na delegowanie podmiotom wybranych elementarnych uprawnien administracyjnych:** Jest to **poprawne** stwierdzenie. CAP pozwala zrezygnować z przyznawania całemu procesowi lub użytkownikowi uprawnień administracyjnych, tzw. konta root, nadając im tylko te uprawnienia z którymi ma działać konkretny program. Dzięki CAP możliwe jest delegowanie, tylko wybranych uprawnień administracyjnych, ograniczając tym samym potencjalne skutki ataku. Przykładowo, nie trzeba uruchamiać serwera bazodanowego, który musi działać na pewnym numerze portu, jako root. Możemy nadać procesowi serwera tylko `CAP_NET_BIND_SERVICE` i `CAP_DAC_OVERRIDE`, do otwarcia portu i korzystania z niektórych plików, a całą resztę uprawnień administracyjnych pozostawić użytkownikowi root."
    },
    {
        "questionId": 38,
        "title": "Ktore z ponizszych algorytmow kryptograficznych moga zostac wykorzystane w sieci VPN do szyfrowania transmisji przez protokol SSL/TLS lub IPsec:",
        "answers": [
            {
                "text": "RSA",
                "isCorrect": true
            },
            {
                "text": "ECDH",
                "isCorrect": false
            },
            {
                "text": "AES",
                "isCorrect": true
            },
            {
                "text": "DH",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "W kontekście sieci VPN, zarówno w protokołach SSL/TLS jak i IPsec, wykorzystuje się różne algorytmy kryptograficzne do zapewnienia poufności i bezpiecznej wymiany kluczy. Algorytmy te dzielą się na dwie główne kategorie: symetryczne i asymetryczne. Algorytmy symetryczne używane są do szyfrowania danych, natomiast algorytmy asymetryczne służą do uzgodnienia kluczy używanych do szyfrowania symetrycznego, jak i do uwierzytelniania stron komunikujących się.\n\n**RSA (Rivest–Shamir–Adleman)** jest algorytmem asymetrycznym, szeroko stosowanym w infrastrukturze klucza publicznego (PKI) i protokołach takich jak SSL/TLS. W kontekście VPN, RSA jest wykorzystywane do bezpiecznej wymiany kluczy sesyjnych, przy użyciu których następnie przesyłane są dane przy pomocy algorytmów symetrycznych. Na przykład, podczas nawiązywania połączenia SSL/TLS, serwer przedstawia klientowi swój certyfikat, który zawiera klucz publiczny serwera podpisany przez zaufany urząd certyfikacji. Klient, weryfikując podpis certyfikatu, a następnie używając klucza publicznego serwera, może zaszyfrować klucz sesyjny i przekazać go serwerowi. Serwer, posiadając klucz prywatny, może odszyfrować klucz sesyjny, i tak obie strony mogą użyć ten sam klucz sesyjny do szyfrowania symetrycznego. RSA nie jest typowym algorytmem do masowego szyfrowania danych, gdyż jest algorytmem bardzo kosztownym obliczeniowo, dlatego jego częste używanie przy szyfrowaniu dużej ilości danych byłoby nieefektywne. RSA ma szerokie zastosowanie w protokołach SSL/TLS i IPsec, gdzie jest stosowany jako jeden z mechanizmów wymiany kluczy oraz uwierzytelniania stron.\n\n**AES (Advanced Encryption Standard)** to algorytm symetryczny, który w VPN-ach, po uzgodnieniu klucza sesyjnego metodą asymetryczną, jest wykorzystywany do szyfrowania właściwej komunikacji. AES działa na zasadzie bloków danych, które są szyfrowane przy pomocy klucza symetrycznego. Algorytm AES został wybrany jako standard szyfrowania symetrycznego przez rząd USA, co jest dobrą rekomendacją zaufania wobec tego algorytmu. AES jest algorytmem bardzo wydajnym, dlatego też jest wykorzystywany jako algorytm do szyfrowania symetrycznego danych w protokołach VPN opartych o SSL/TLS oraz IPsec. Na przykład, po uzgodnieniu tajnego klucza sesyjnego protokołem Diffiego-Hellmana w protokole IPsec, algorytm AES może być wykorzystany do szyfrowania przesyłanych pakietów IP.\n\n**DH (Diffie-Hellman)** jest to algorytm asymetryczny, który umożliwia dwóm stronom bezpieczną wymianę tajnego klucza w publicznie dostępnym kanale. W protokołach VPN (zarówno SSL/TLS, jak i IPsec), Diffie-Hellman umożliwia uzgodnienie tajnego klucza symetrycznego, który jest następnie używany do szyfrowania danych. Jest to szczególnie istotne, gdyż nie ma konieczności uprzedniego uzgadniania klucza symetrycznego w bezpiecznym kanale, a jest on generowany automatycznie w trakcie zestawiania połączenia, co znacznie obniża koszt całego procesu negocjacji parametrów bezpiecznego połączenia. Uzgodniony za pomocą Diffiego-Hellmana klucz jest tajny i tylko obie strony komunikacji go znają. Na przykład, w sesji IPsec, strony wymieniają publiczne części kluczy Diffiego-Hellmana, by następnie niezależnie wygenerować ten sam tajny klucz sesyjny, który jest używany do szyfrowania algorytmem symetrycznym.\n\n**ECDH (Elliptic Curve Diffie-Hellman)** jest wariantem algorytmu Diffiego-Hellmana, gdzie operacje wykorzystują krzywe eliptyczne. Podobnie jak DH, jest algorytmem asymetrycznym służącym do uzgadniania kluczy sesyjnych w kanałach komunikacyjnych. ECDH, dzięki swojej budowie, pozwala użyć mniejszej długości klucza do osiągnięcia tego samego poziomu bezpieczeństwa, co w przypadku zwykłego algorytmu DH. ECDH, chociaż jest coraz bardziej popularny, nie jest typowo używany w protokołach IPsec i SSL/TLS. Jest algorytmem stosunkowo nowym i nie we wszystkich implementacjach wspierany, dlatego w przedstawionej sytuacji z wyżej wymienionych powodów odpowiedź ta jest niepoprawna."
    },
    {
        "questionId": 39,
        "title": "Ktore z ponizszych cech prawidlowo opisuja protokol IKE?",
        "answers": [
            {
                "text": "umozliwia zmiane kluczy szyfrowania protokolu IPsec ESP",
                "isCorrect": true
            },
            {
                "text": "uwierzytelnia sesje SA protokolu IPsec",
                "isCorrect": true
            },
            {
                "text": "negocjuje parametry sesji SA protokolu IPsec",
                "isCorrect": true
            },
            {
                "text": "umozliwia zmiane kluczy szyfrowania protokolu IPsec AH",
                "isCorrect": false
            },
            {
                "text": "oferuje uwierzytelnianie stron",
                "isCorrect": true
            },
            {
                "text": "koszysta z ICMP",
                "isCorrect": false
            },
            {
                "text": "korzysta z UDP",
                "isCorrect": true
            },
            {
                "text": "oferuje negocjacje algorytmow szyfrujacych",
                "isCorrect": true
            }
        ],
        "clue": 6,
        "isStarred": false,
        "explanation": "Protokół IKE (Internet Key Exchange) jest fundamentalnym elementem architektury IPsec, odpowiedzialnym za bezpieczne uzgadnianie parametrów sesji (Security Association, SA) oraz wymianę kluczy kryptograficznych używanych przez IPsec do ochrony danych. IKE nie szyfruje bezpośrednio danych, lecz tworzy bezpieczny kanał kontrolny, który jest wykorzystywany do negocjacji algorytmów szyfrowania i integralności oraz wymiany kluczy kryptograficznych potrzebnych do ochrony danych za pomocą protokołów ESP lub AH.  IKE działa w warstwie aplikacyjnej i bazuje na protokole transportowym UDP (port 500).\n\n*   **\"umożliwia zmiane kluczy szyfrowania protokolu IPsec ESP\"** - **Poprawna**. Protokół IKE odpowiada za uzgodnienie kluczy sesyjnych, które są potem wykorzystywane do szyfrowania danych w protokole ESP. W praktyce, po uzgodnieniu algorytmów i parametrów przez IKE, protokół ESP będzie wykorzystywał sesyjne klucze symetryczne (np. AES, 3DES) do szyfrowania danych. Mechanizm ten ma za zadanie dynamiczne odświeżanie kluczy, celem ograniczenia strat w przypadku kompromitacji klucza.\n\n*   **\"uwierzytelnia sesje SA protokolu IPsec\"** - **Poprawna**. IKE odpowiada za proces uwierzytelnienia stron biorących udział w połączeniu, tak aby upewnić się, że komunikacja jest prowadzona z zaufanym partnerem. IKE realizuje proces uwierzytelnienia partnerów wymiany informacji poprzez wykorzystanie hasła współdzielonego, sygnatur cyfrowych lub mechanizmu certyfikatów. Po pomyślnym procesie uwierzytelnienia, zostaje uzgodniona sesja bezpieczeństwa SA (ang. Security Association) protokołu IPsec.\n\n*   **\"negocjuje parametry sesji SA protokolu IPsec\"** - **Poprawna**. IKE jest odpowiedzialny za negocjację parametrów bezpieczeństwa sesji SA w protokole IPsec, włączając w to algorytmy szyfrowania (np. AES, 3DES), integralności (np. SHA-1, MD5), funkcje skrótu i metody wymiany kluczy. Negocjacja pozwala obu stronom na komunikację za pomocą najsilniejszych mechanizmów bezpieczeństwa, które obie strony wspierają.\n\n*   **\"umozliwia zmiane kluczy szyfrowania protokolu IPsec AH\"** - **Niepoprawna**. Protokół AH zapewnia ochronę integralności i uwierzytelniania pakietów, nie ich szyfrowania. IKE negocjuje i wymienia klucze dla sesji SA, które są wykorzystywane w protokole AH ale nie zmienia ich podczas trwania połączenia. Protokoły ESP i AH działają niezależnie od siebie.\n\n*   **\"oferuje uwierzytelnianie stron\"** - **Poprawna**. Protokół IKE w fazie I oraz w fazie II procesu uzgodnienia mechanizmów sesji SA IPsec wykonuje procedury uwierzytelniania stron połączenia. IKE oferuje kilka metod uwierzytelniania np. z użyciem hasła współdzielonego, sygnatur cyfrowych, certyfikatów. Uwierzytelnianie jest bardzo ważne z uwagi na to, że zapobiega tworzeniu połączeń z nieznanymi hostami i zmniejsza ryzyko podszywania się pod autoryzowane urządzenia.\n\n*   **\"koszysta z ICMP\"** - **Niepoprawna**. IKE nie wykorzystuje protokołu ICMP. IKE działa na protokole transportowym UDP. Protokołu ICMP najczęściej wykorzystywany jest w protokole IP jako mechanizm diagnostyczny i do wysyłania komunikatów o błędach.\n\n*   **\"korzysta z UDP\"** - **Poprawna**. IKE jest aplikacją warstwy aplikacyjnej i wykorzystuje do transmisji protokół transportowy UDP. Używanie UDP pozwala na zminimalizowanie złożoności protokołu IKE, ponieważ nie jest wymagana dodatkowa kontrola przepływu danych i odzyskiwania pakietów (jak ma to miejsce np. w TCP). W wypadku utraty pakietów protokołu IKE połączenie nie zostanie ustanowione i procedura negocjacji zostanie powtórzona.\n\n*  **\"oferuje negocjacje algorytmow szyfrujacych\"** - **Poprawna**. IKE ma za zadanie negocjować parametry połączenia IPsec. Do tych parametrów należy metoda szyfrowania oraz algorytm haszujący, które zostaną wykorzystane przez protokół ESP i AH. Przy uzgadnianiu algorytmów obie strony połączenia powinny wybrać najsilniejszy wspólny mechanizm kryptograficzny aby zapewnić jak najsilniejsze zabezpieczenie danych."
    },
    {
        "questionId": 40,
        "title": "Tunele OpenVPN:",
        "answers": [
            {
                "text": "stosuja protokol ESP do szyfrowania ruchu",
                "isCorrect": false
            },
            {
                "text": "stosuja protokol AH do szyfrowania ruchu",
                "isCorrect": false
            },
            {
                "text": "stosuja protokol TLS do szyfrowania ruchu",
                "isCorrect": true
            },
            {
                "text": "stosuja protokol ISAKMP do uwierzytelniania ruchu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "OpenVPN, jako system tworzenia wirtualnych sieci prywatnych (VPN), wykorzystuje protokół TLS (Transport Layer Security) do szyfrowania przesyłanego ruchu. TLS, następca protokołu SSL, zapewnia poufność i integralność danych przesyłanych przez tunel VPN. Proces szyfrowania w OpenVPN odbywa się na poziomie warstwy aplikacji, wykorzystując protokół TLS do utworzenia bezpiecznego kanału. Kluczowe elementy protokołu TLS to uzgadnianie parametrów szyfrowania i autentykacja stron. \n\n**\"stosuja protokol ESP do szyfrowania ruchu\"**: Ta odpowiedź jest niepoprawna. ESP (Encapsulating Security Payload) jest protokołem stosowanym w ramach IPsec (Internet Protocol Security) do zapewnienia poufności i autentyczności pakietów IP. IPsec operuje na poziomie warstwy sieciowej i jest alternatywą dla OpenVPN, ale nie jest przez OpenVPN stosowany. W praktyce oznacza to, że OpenVPN nie jest podatny na ataki skierowane w protokół ESP, a stosowanie protokołu ESP ma inne implementacje (np. w systemie Windows lub przy budowie tunelu pomiędzy routerami).\n\n**\"stosuja protokol AH do szyfrowania ruchu\"**: Ta odpowiedź jest niepoprawna. AH (Authentication Header) to kolejny protokół wchodzący w skład IPsec. Protokół ten służy do weryfikacji autentyczności i integralności nagłówka pakietu IP, ale nie szyfruje jego treści. Podobnie jak ESP, AH jest wykorzystywany w IPsec, a nie w OpenVPN. W praktyce oznacza to, że OpenVPN nie jest podatny na ataki wymierzone w protokół AH. \n\n**\"stosuja protokol TLS do szyfrowania ruchu\"**: Ta odpowiedź jest poprawna. OpenVPN wykorzystuje protokół TLS do szyfrowania ruchu w tunelu VPN. TLS, bazujący na SSL, jest protokołem warstwy sesji, który umożliwia szyfrowanie komunikacji poprzez tworzenie bezpiecznego połączenia między klientem a serwerem. W przypadku OpenVPN klientem i serwerem są zazwyczaj programy OpenVPN, które za pomocą TLS tworzą tunel VPN. TLS zapewnia ochronę przed podsłuchiwaniem i ingerencją w treść komunikacji. W realnym świecie protokół ten jest powszechnie wykorzystywany do ochrony protokołu HTTP - https. \n\n**\"stosuja protokol ISAKMP do uwierzytelniania ruchu\"**: Ta odpowiedź jest niepoprawna. ISAKMP (Internet Security Association and Key Management Protocol) to protokół używany w ramach IPsec do wymiany kluczy kryptograficznych i negocjacji parametrów bezpieczeństwa między dwoma punktami końcowymi połączenia. OpenVPN nie korzysta z ISAKMP; zamiast tego wykorzystuje mechanizmy uwierzytelniania i wymiany kluczy, które są częścią protokołu TLS.  W praktyce oznacza to, że OpenVPN nie jest podatny na ataki skierowane w protokół ISAKMP."
    },
    {
        "questionId": 41,
        "title": "Ktore z ponizszych slow kluczowych moga byc prawidlowym \"celem\" w regule iptables dla lancucha OUTPUT?",
        "answers": [
            {
                "text": "DROP",
                "isCorrect": true
            },
            {
                "text": "FORWARD",
                "isCorrect": false
            },
            {
                "text": "XOR",
                "isCorrect": false
            },
            {
                "text": "ACCEPT",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "`iptables` to narzędzie w systemach Linux służące do konfiguracji zapory sieciowej, działającej na poziomie jądra systemu. Reguły `iptables` składają się z wzorca i akcji. Akcja, czyli to co ma być zrobione z pakietem, jest określana jako `target`. Reguły są grupowane w łańcuchy (ang. `chains`), które reprezentują określony etap przetwarzania pakietów. Łańcuch `OUTPUT` jest używany dla pakietów generowanych lokalnie, czyli przez procesy działające na komputerze na którym uruchomiona jest zapora sieciowa. Do łańcucha `OUTPUT` można dodać reguły, które decydują czy lokalnie wygenerowany ruch ma być przepuszczony czy nie. \n\nOpcja `DROP` jest poprawnym celem (`targetem`) dla łańcucha `OUTPUT`. `DROP` powoduje odrzucenie pakietu bez przesyłania dodatkowych informacji o tym fakcie do nadawcy pakietu. Na przykład, reguła `iptables -A OUTPUT -p tcp --dport 80 -j DROP` spowoduje odrzucenie wszystkich pakietów TCP, które wychodzą z komputera z portem docelowym 80. W rezultacie, żadna lokalna aplikacja nie będzie w stanie wysłać pakietów do serwera WWW.\n\nOpcja `FORWARD` *nie* jest poprawnym celem (`targetem`) w łańcuchu `OUTPUT`. `FORWARD` jest nazwą innego łańcucha w tablicy `filter`, gdzie definiujemy reguły translacji adresów dla ruchu routowanego. Natomiast łańcuch `OUTPUT` dotyczy tylko ruchu generowanego lokalnie. Zatem nie można wykonać akcji routingu pakietu w łańcuchu `OUTPUT`, tylko w łańcuchu `FORWARD`.\n\nOpcja `XOR` jest *nie*poprawnym celem (`targetem`) dla łańcucha `OUTPUT`. `XOR` jest bitową operacją logiczną, którą można wykorzystać do tworzenia sumy kontrolnej na danych pakietu. Opcja `XOR` *nie* jest poprawnym targetem, gdyż nie jest ona akcją, lecz funkcją logiczną.  Nie można jej użyć w tablicy filtrów do akceptacji lub odrzucenia pakietu.\n\nOpcja `ACCEPT` jest poprawnym celem (`targetem`) dla łańcucha `OUTPUT`. Powoduje ona przepuszczenie pakietu dalej. Na przykład, reguła `iptables -A OUTPUT -p tcp --sport 80 -j ACCEPT` spowoduje przepuszczenie pakietów TCP które wychodzą z komputera z portem źródłowym 80, czyli komputer na którym działa zapora sieciowa może swobodnie komunikować się z serwerem www.\n\nZatem poprawne cele w łańcuchu `OUTPUT` to `DROP` i `ACCEPT` .  `FORWARD` jest nazwą łańcucha, a `XOR` jest operacją bitową, która nie jest celem (`targetem`) w `iptables`.  Podsumowując, `iptables` oferuje konkretne `targety` takie jak `ACCEPT` i `DROP` w łańcuchu `OUTPUT`, ale próba użycia  `FORWARD` lub `XOR` jako `targetu` w tym łańcuchu jest niepoprawna."
    },
    {
        "questionId": 42,
        "title": "Polecenie ulimit:",
        "answers": [
            {
                "text": "decyduje o tym czy moga byc tworzone zrzuty przestrzeni adresowej (obrazy) procesow",
                "isCorrect": true
            },
            {
                "text": "podaje biezace ograniczenia hard i soft, ale pozwala zmienic tylko soft",
                "isCorrect": false
            },
            {
                "text": "podaje biezace ograniczenia hard i soft, ale nie pozwala ich zmieniac",
                "isCorrect": false
            },
            {
                "text": "pozwala zmienic oba rodzaje limitow: i hard, i soft",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Polecenie `ulimit` w systemach Linux/Unix służy do zarządzania limitami zasobów, które procesy mogą wykorzystywać. Ograniczenia te pomagają kontrolować zużycie zasobów systemowych, takich jak pamięć, czas procesora, czy liczba otwartych plików, i tym samym zwiększać bezpieczeństwo systemu. Wyróżniamy dwa rodzaje limitów: miękkie (soft) i twarde (hard). Limity miękkie można modyfikować w ramach dozwolonych twardych limitów, natomiast twarde limity stanowią górną granicę ustawioną najczęściej przez administratora systemu i użytkownik nie ma możliwości ich przekroczyć.\n\n**Odpowiedź 1: \"decyduje o tym czy moga byc tworzone zrzuty przestrzeni adresowej (obrazy) procesow\" jest poprawna.**\n\nPolecenie `ulimit` ma wpływ na możliwość generowania przez procesy plików zrzutu pamięci (_core dumps_). Te pliki są tworzone w przypadku awaryjnego zakończenia działania programu i zawierają kopię stanu pamięci procesu, co może być przydatne do analizy przyczyn awarii lub szukania potencjalnych luk w zabezpieczeniach. Ustawiając limit _core file size_ za pomocą `ulimit -c`, można zablokować lub ograniczyć tworzenie tych plików. Na przykład, `ulimit -c 0` zablokuje tworzenie zrzutów pamięci, co jest czasem zalecane w środowiskach produkcyjnych, aby uniknąć niepotrzebnego zajmowania miejsca na dysku, lub chronić poufne dane przed wyciekiem w pliku _core_ dump. Limit ten można sprawdzić za pomocą `ulimit -c`, a ustawić za pomocą `ulimit -c <wartość>`. Przykładowo, `ulimit -c unlimited`  pozwoli na generowanie plików zrzutu pamięci bez ograniczeń.\n\n**Odpowiedź 2: \"podaje biezace ograniczenia hard i soft, ale pozwala zmienic tylko soft\" jest niepoprawna.**\n\nPolecenie `ulimit` pozwala odczytać wartości zarówno limitów miękkich (_soft limits_) jak i twardych (_hard limits_). Użytkownik ma możliwość zmiany wartości limitu miękkiego pod warunkiem, że nie przekroczy on wartości limitu twardego. Przykładowo, jeśli administrator ustawił limit twardy dla liczby otwartych plików na 1024, to użytkownik może ustawić limit miękki na 512, 800 czy 1024, ale nie będzie mógł go ustawić na 2048.  Aby to zweryfikować użyj `ulimit -a` lub bardziej konkretnie np. `ulimit -n`, gdzie \"n\" oznacza otwarte pliki. Ustawić wartość soft limity otwartych plików np na 100 użyj polecenia `ulimit -Sn 100`. Oczywiście po ustawieniu nowego soft limitu otwartych plików na 100 można to łatwo sprawdzić `ulimit -n`.\n\n**Odpowiedź 3: \"podaje biezace ograniczenia hard i soft, ale nie pozwala ich zmieniac\" jest niepoprawna.**\n\nPolecenie `ulimit` nie tylko wyświetla bieżące limity, ale też pozwala użytkownikowi na modyfikację limitów miękkich. Wyświetlenie twardych limitów jest możliwe przy użyciu opcji `ulimit -Ha`, a limitów miękkich `ulimit -Sa`. Ponadto, używając polecenia `ulimit` bez parametrów, zostaną zwrócone obecne limity miękkie.\n\n**Odpowiedź 4: \"pozwala zmienic oba rodzaje limitow: i hard, i soft\" jest częściowo poprawna.**\n\nPolecenie `ulimit` pozwala zmieniać limity zarówno miękkie (soft) jak i twarde (hard), ale tylko dla procesów potomnych. Użytkownik nie ma możliwości zmiany twardych limitów procesów, które już działają, również na proces, z którego wywoływana jest komenda `ulimit`. Twardy limit może być ustawiony tylko przez administratora.  Aby zmienić miękki limit, należy użyć opcji `-S` np. `ulimit -Sn 100`. Natomiast, aby zmienić limit twardy, należy użyć opcji `-H`, ale takie polecenie może być wykonane tylko przez uprzywilejowanego użytkownika. Ustawienie limitu twardego dla wszystkich procesów potomnych do aktualnej wartości limitu miękkiego można wykonać za pomocą polecenia `ulimit -Hn $(ulimit -Sn)`. Podsumowując, `ulimit` pozwala zmieniać limity, ale nie daje pełnej dowolności i kontroli nad każdym rodzajem limitu."
    },
    {
        "questionId": 43,
        "title": "Czym sie rozni twist od spawn w polityce tcp wrappera (np. w pliku hosts.allow)?",
        "answers": [
            {
                "text": "spawn sluzy do zapisywania wiadomosci w logu lub wysylania poczty, natomiast twist wysyla wiadomosc i odmawia dostepu do uslugi",
                "isCorrect": false
            },
            {
                "text": "oba polecenia uzyte w hosts.allow koncza sie odmowa polecenia, ale twist dodatkowo zapisuje informacje o tym w logu systemowym",
                "isCorrect": false
            },
            {
                "text": "twist przekierowuje polaczenie do innej, okreslonej opcja uslugi, podczas gdy spawn tworzy nowy proces wykonujacy dowolne polecenie",
                "isCorrect": false
            },
            {
                "text": "spawn tworzy nowy proces wykonujacy dane polecenie, natomiast twist wykonuje polecenie w ramach biezacego procesu",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`tcpd` (TCP wrapper) jest programem kontrolującym dostęp do usług sieciowych w systemach Linux/Unix. Działa jako \"opakowanie\"(_wrapper_) dla tych usług. Kiedy do systemu przychodzi żądanie połączenia z daną usługą, `tcpd` przechwytuje to żądanie, sprawdza je pod kątem reguł dostępu zdefiniowanych w plikach `/etc/hosts.allow` i `/etc/hosts.deny`, a następnie na podstawie tych reguł decyduje czy połączyć z żądaną usługą, czy też nie. \n\nPlik `/etc/hosts.allow` zawiera reguły, które pozwalają na dostęp do usług z wybranych adresów IP. Plik `/etc/hosts.deny` zawiera reguły, które odrzucają połączenia z wybranych adresów IP. Składnia tych plików jest prosta: `usługa: adres_IP_lub_wzorzec: opcja`. Część `opcja` w regule definiuje, co ma się wydarzyć, gdy reguła zostanie dopasowana. Opcje `spawn` i `twist` są dwiema możliwymi wartościami parametru `opcja` w pliku `/etc/hosts.allow` i modyfikują wykonanie żądanej usługi.\n\n**Opcja `spawn`** w pliku `/etc/hosts.allow` tworzy nowy proces systemowy w celu wykonania zdefiniowanej akcji. Akcja ta jest dowolnym poleceniem systemowym. Innymi słowy, jeśli w pliku `/etc/hosts.allow` znajdziemy wpis np. `usluga:adres_ip : spawn /bin/logger \"Próba logowania\"`, przy próbie połączenia do `usluga` z adresu `adres_ip` zostanie uruchomiony program `/bin/logger` z argumentem `\"Próba logowania\"`, a informacja zostanie przekazana do dziennika systemowego. `spawn` nie wpływa na to, czy połączenie z usługą zostanie nawiązane, czy też nie, a jedynie wykonuje polecenie. Przykładowo, jeśli zdefiniujemy regułę `telnetd: 192.168.1.0/24: spawn echo \"Dostęp do telnetu zezwolony\" >> /var/log/telnet.log`, to za każdym razem gdy klient z sieci 192.168.1.0/24 będzie się łączył z usługą telnetd, zostanie uruchomione polecenie `echo` i do pliku `/var/log/telnet.log` zostanie dopisany tekst `Dostęp do telnetu zezwolony`.\n\n**Opcja `twist`** w pliku `/etc/hosts.allow` powoduje natomiast, że połączenie jest przekierowywane do innej usługi, która zostaje uruchomiona w tym samym procesie, w którym działa `tcpd`. To znaczy, ze przy użyciu opcji `twist` nie powstaje nowy proces w systemie, jak ma to miejsce przy opcji `spawn`, lecz wykonywanie jest przejmowane przez inną wskazaną przez nas aplikację. Jeśli w pliku `/etc/hosts.allow` wpiszemy regułę  `usługa1: adres_ip : twist usluga2`, to próba połączenia z `usługa1` z adresu `adres_ip` spowoduje, że `tcpd` uruchomi program `usluga2` z tymi samymi uprawnieniami zamiast uruchomić `usługa1`. Przykładowo, jeśli zdefiniujemy regułę `telnetd: 192.168.1.0/24: twist /bin/logger` to próba połączenia z usługą `telnetd` z sieci 192.168.1.0/24 spowoduje że zamiast programu telnetd uruchomi się program `/bin/logger`. Zatem, opcja ta w przeciwieństwie do opcji `spawn` nie zezwala na dostęp do pierwotnie żądanej usługi. Często ta opcja wykorzystywana jest do uruchomienia tzw. usług przynęt, co pozwala na zebranie dodatkowych informacji o potencjalnym ataku.\n\nPrzeanalizujmy teraz podane odpowiedzi:\n\n*   **\"spawn sluzy do zapisywania wiadomosci w logu lub wysylania poczty, natomiast twist wysyla wiadomosc i odmawia dostepu do uslugi\"** - Jest to błędna odpowiedź.  `spawn` nie tylko służy do logowania ale i do uruchamiania dowolnych procesów, a  `twist` nie tyle odmawia dostępu do usługi, co przekierowuje do innej, zdefiniowanej usługi. \n\n*   **\"oba polecenia uzyte w hosts.allow koncza sie odmowa polecenia, ale twist dodatkowo zapisuje informacje o tym w logu systemowym\"** - Jest to błędna odpowiedź. Ani `spawn`, ani `twist` same w sobie nie kończą się odmową dostępu. Jak już wcześniej napisano `spawn` powoduje uruchomienie dodatkowego procesu bez wpływu na to czy pierwotne połączenie będzie akceptowane, a `twist` przekierowuje połączenie do innej usługi. Nie zawsze również `twist` musi logować informacje o połączeniu.\n\n*   **\"twist przekierowuje polaczenie do innej, okreslonej opcja uslugi, podczas gdy spawn tworzy nowy proces wykonujacy dowolne polecenie\"** - Jest to błędna odpowiedź. Opcja `twist` przekierowuje połączenie do innej usługi, ale nie jest to dowolna opcja, lecz definitywna zamiana usługi na inną, `spawn`  zaś tworzy nowy proces, jednak jest on wykonywany dodatkowo, w powiązaniu z pierwotnym połączeniem do usługi.\n\n*   **\"spawn tworzy nowy proces wykonujacy dane polecenie, natomiast twist wykonuje polecenie w ramach biezacego procesu\"** - Jest to prawidłowa odpowiedź, która zwięźle i dokładnie opisuje różnicę między oboma opcjami, `spawn` tworzy nowy proces, a `twist` wykonuje nową usługę w ramach już istniejącego procesu.\n\nZatem, poprawną odpowiedzią jest czwarta."
    },
    {
        "questionId": 44,
        "title": "Co oznacza udzial IPC$ i do czego jest wykorzystywany?",
        "answers": [
            {
                "text": "to udzial sluzacy w systemie Windows do zdalnego wywolania procedur (RPC)",
                "isCorrect": true
            },
            {
                "text": "to udzial domyslny sluzacy do zdalnej administracji systemem Windows",
                "isCorrect": false
            },
            {
                "text": "to udzial administracyjny obejmujacy wszystkie istniejace lokalne dyski",
                "isCorrect": false
            },
            {
                "text": "to udzial kolejek POSIX IPC sluzacy do lokalnej komunikacji miedzy procesami",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Udostępnienie IPC$ (Inter-Process Communication Share) w systemie Windows jest specjalnym, domyślnym współdzielonym zasobem sieciowym, który **nie służy** do udostępniania plików czy katalogów, ale umożliwia zdalne wywoływanie procedur (RPC, ang. *Remote Procedure Call*). RPC to mechanizm, który pozwala programom działającym na jednym komputerze wywoływać procedury lub funkcje działające na innym komputerze tak, jakby były one dostępne lokalnie.  Używa się go do budowania rozproszonych aplikacji, a w systemie Windows jest intensywnie wykorzystywany do komunikacji między usługami. IPC$ nie jest widoczny w standardowym oknie udostępnień sieciowych. Jest on ukryty i dostępny jedynie z określonych mechanizmów dostępu(np. w połączeniu z protokołem SMB). \n\n*   **\"to udzial sluzacy w systemie Windows do zdalnego wywolania procedur (RPC)\"** - To jest **poprawna** odpowiedź. IPC$ jest kluczowym elementem infrastruktury RPC w systemie Windows. Kiedy aplikacja na jednym komputerze chce skorzystać z usługi, która działa na innym komputerze, to często wykorzystuje mechanizm RPC. IPC$ staje się wtedy \"punktem końcowym\" tej komunikacji. Bez dostępu do IPC$, komunikacja poprzez mechanizm RPC nie byłaby możliwa. Przykładowo wiele mechanizmów zdalnej administracji używa RPC. \n*   **\"to udzial domyslny sluzacy do zdalnej administracji systemem Windows\"** - To jest **niepoprawna** odpowiedź, choć bliska poprawnej.  Udostępnienia domyślne, jak C$ czy ADMIN$, są używane do zdalnego zarządzania plikami i katalogami, a nie do wywoływania zdalnych procedur. Przez te udostępnienia administrator zdalnie może uzyskać dostęp do plików na dysku C: (w przypadku udostępnienia C$), ale nie jest to bezpośrednio związane z mechanizmem RPC. IPC$ jest używane przez mechanizm RPC który może używany być do administracji systemem, ale nie jest to celem udostępnienia IPC$ , tylko jego elementem. \n*   **\"to udzial administracyjny obejmujacy wszystkie istniejace lokalne dyski\"** - To jest **niepoprawna** odpowiedź. Udział administracyjny obejmujący wszystkie dyski to np. utworzenie udziału w którym mapowane są wszystkie lokalne dyski np. C$, D$, E$ itd. Zazwyczaj do tego celu wykorzystywane jest połączenie wykorzystujące udostępnienie ADMIN$.  Udostępnienia o takiej budowie nie mają związku z udostępnieniem IPC$. \n*   **\"to udzial kolejek POSIX IPC sluzacy do lokalnej komunikacji miedzy procesami\"** - To jest **niepoprawna** odpowiedź. Kolejki POSIX IPC (Inter-Process Communication) to mechanizm komunikacji wewnątrz jądra systemu operacyjnego, działający niezależnie od warstwy sieciowej i nie jest on związany z udostępnianiem zasobów sieciowych jak udostępnienie IPC$. Kolejki POSIX są standardem i działają też w systemach operacyjnych z rodziny Linux/Unix."
    },
    {
        "questionId": 45,
        "title": "SSH pozwala:",
        "answers": [
            {
                "text": "uwierzytelniac uzytkownikow z wykorzystaniem kluczy kryptograficznych",
                "isCorrect": true
            },
            {
                "text": "uwierzytelniac uzytkownikow z wykorzystaniem hasel",
                "isCorrect": true
            },
            {
                "text": "uwierzytelniac komputery (systemy operacyjne) z wykorzystaniem kluczy kryptograficznych",
                "isCorrect": false
            },
            {
                "text": "udostepnic zasoby serwera lokalnego przez przekierowanie portow z serwera zdalnego",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) służy do bezpiecznego, szyfrowanego zdalnego dostępu do systemów komputerowych. Kluczowym elementem bezpieczeństwa SSH jest mechanizm uwierzytelniania, który pozwala zweryfikować tożsamość użytkownika łączącego się ze zdalnym systemem. SSH oferuje kilka metod uwierzytelniania, różniących się poziomem bezpieczeństwa i sposobem konfiguracji.\n\n**Opcja 1: „uwierzytelniac uzytkownikow z wykorzystaniem kluczy kryptograficznych” - Poprawna.** SSH umożliwia uwierzytelnianie użytkowników za pomocą kryptografii klucza publicznego. W tym scenariuszu użytkownik generuje parę kluczy: prywatny, przechowywany na komputerze lokalnym, i publiczny, który jest udostępniany serwerowi. Podczas uwierzytelniania, serwer weryfikuje tożsamość klienta, zadając mu zadanie kryptograficzne, w którym wykorzystywany jest klucz prywatny użytkownika. Użycie kluczy kryptograficznych jest bezpieczniejszą metodą uwierzytelniania niż hasła, ponieważ nie wymaga przesyłania tajnych informacji przez sieć. W praktyce, wiele serwerów wymaga, aby użytkownicy przesyłali najpierw klucz publiczny w pliku _authorized_keys_. Umożliwia to bezpieczne logowanie i wyklucza etap negocjacji z hasłem.\n\n**Opcja 2: „uwierzytelniac uzytkownikow z wykorzystaniem hasel” - Poprawna.** SSH umożliwia również uwierzytelnianie użytkowników za pomocą haseł. Podczas logowania, serwer żąda hasła od klienta. Chociaż komunikacja jest szyfrowana, to sama metoda hasła jest podatna na ataki, takie jak zgadywanie hasła. Hasła użytkowników mogą być również mniej lub bardziej skomplikowane. Jest to podstawowa metoda uwierzytelniania w przypadku kiedy nie jest ustawione uwierzytelnianie za pomocą kluczy kryptograficznych. Z punktu widzenia bezpieczeństwa jest to metoda mniej preferowana.\n\n**Opcja 3: „uwierzytelniac komputery (systemy operacyjne) z wykorzystaniem kluczy kryptograficznych” - Niepoprawna.** SSH  może uwierzytelniać serwer za pomocą kluczy kryptograficznych, jednak nie jest to nazywane uwierzytelnianiem systemów operacyjnych czy komputerów. Mechanizm ten pozwala zweryfikować, że serwer, z którym się łączymy, jest tym, za kogo się podaje, a nie podstawionym przez atakującego. Klucz publiczny serwera jest zazwyczaj przechowywany w pliku known_hosts na komputerze klienta. Podczas łączenia się z nowym serwerem system SSH pyta o zgodę dodanie nowego klucza do _known_hosts_ celem weryfikowania tożsamości serwera w przyszłości. W przypadku ataków typu _man in the middle_ klucz może zostać zmieniony. Uwierzytelnianie użytkowników, tak jak w opcjach 1 i 2 odbywa się na wyższej warstwie niż samo uwierzytelnianie serwera.\n\n**Opcja 4: „udostepnic zasoby serwera lokalnego przez przekierowanie portow z serwera zdalnego” - Niepoprawna.** Chociaż SSH oferuje port forwarding (przekierowanie portów), to nie udostępnia zasobów serwera lokalnego. Port forwarding tworzy tunel, przez który przekierowywane są połączenia z lokalnego komputera do konkretnego portu zdalnego serwera (lub odwrotnie), a nie bezpośredni dostęp do zasobów (plików, drukarek etc.). Na przykład, za pomocą _ssh -L 8080:localhost:80 user@server_  możemy przekierować port 80 na serwerze zdalnym na lokalny port 8080, jednak nie spowoduje to że z lokalnego portu będzie dostęp do zasobów systemu zdalnego. Przekierowanie portów umożliwia tunelowanie innych usług, np. HTTP, poprzez zaszyfrowany kanał SSH."
    },
    {
        "questionId": 47,
        "title": "W ktorych z ponizszych przypadkow rekalkulowana jest maska uprawnien ACL w systemie Linux:",
        "answers": [
            {
                "text": "gdy podamy opcje -m dla polecenia setfacl",
                "isCorrect": false
            },
            {
                "text": "przy zmianie uprawnien wlasciciela przy pomocy polecenia chmod",
                "isCorrect": true
            },
            {
                "text": "przy kazdej zmianie uprawnien poleceniem setfacl, chyba ze uzyjemy opcji -n",
                "isCorrect": true
            },
            {
                "text": "przy dowolnej zmianie uprawnien danej kategorii praw (np. maska dla grupy modyfikowana jest przy modyfikacji praw dotyczacych grupy)",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Maska uprawnień w ACL (Access Control List) w systemie Linux służy do określenia maksymalnych uprawnień, jakie mogą być przyznane użytkownikom i grupom, nawet jeśli jawnie zostały im one przyznane za pomocą jawnych definicji ACL (użytkownik lub grupa z ACL) lub domyślnych praw do pliku (użytkownik, grupa, inni). Maska działa jak filtr. Wyznaczona wartość maski jest brana pod uwagę przy obliczaniu finalnych uprawnień dostępu do pliku przez danego użytkownika. Jest re obliczana gdy dokonujemy pewnych określonych działań na uprawnieniach. Zmiana uprawnień właściciela danego pliku powoduje, że maska musi zostać przeliczona, ponieważ maska jest też powiązana z uprawnieniami właściciela, stąd też zmiana uprawnień właściciela również wymaga wyliczenia maski. \n\nOpcja `-m` polecenia `setfacl` służy do modyfikacji *wpisów* na liście ACL, czyli np. do dodania uprawnień dla konkretnego użytkownika lub grupy, ale *nie* wywołuje *bezpośrednio* rekalkulacji maski, chyba że te zmiany na wpisach w liście ACL w sposób pośredni wymuszą ponowne obliczenie maski. W przeciwieństwie do tego, polecenie `chmod`  używane do modyfikowania *uprawnień* właściciela pliku(użytkownika, grupy lub innych) *zawsze* powoduje przeliczenie maski, ponieważ maska jest również w pośredni sposób związana z atrybutami samego pliku.\n\nPolecenie `setfacl`  przy *każdej* zmianie uprawnień do pliku (za wyjątkiem dodania lub modyfikacji pozycji z uprawnieniami domyślnymi `default:`)rekalkuluje maskę. Wyjątkiem jest przypadek, gdy użyjemy opcji `-n` z poleceniem `setfacl`. Wówczas maska nie jest przeliczana, nawet jeśli ta zmiana dotyczy właściciela, grupy czy innych. \nNa przykład: Mamy plik `plik.txt`  z następującymi ACL:\n```\nuser::rw-\ngroup::r--\nmask::r--\nother::---\n```\n\nWykonanie polecenia `setfacl -m user:kowalski:rwx plik.txt` spowoduje *doliczenie* do listy ACL nowego wpisu (dla użytkownika kowalski) z nadanymi uprawnieniami do odczytu, zapisu i wykonania: \n```\nuser::rw-\nuser:kowalski:rwx\ngroup::r--\nmask::rwx\nother::---\n```\n\nDodatkowo, w celu zachowania poprawności obliczeń uprawnień efektywnych, maska została również zmieniona, na wartość `rwx`.\nJeśli po powyższej operacji wykonamy polecenie: `setfacl -m user:kowalski:r plik.txt`, to maska również zostanie przeliczona do wartości `r`. Oznacza to, że nawet obniżenie uprawnień wywołuje ponowne obliczenie wartości maski.\nJeśli jednak wykonamy `setfacl -n -m u:kowalski:r plik.txt` (z opcją `-n`), to maska nie zostanie przeliczona i będzie nadal miała wartość `rwx`.\n\nNawet zmiana atrybutów właściciela za pomocą polecenia `chmod` również spowoduje ponowne przeliczenie maski. Na przykład, jeśli do pliku `plik.txt`  wykonamy polecenie `chmod 700 plik.txt`, to dotychczasowe ustawienia maski i rozszerzonych uprawnień zostaną w całości przeliczone, np.:\n```\nuser::rwx\ngroup::---\nmask::rwx\nother::---\n```\nJeżeli natomiast do pliku `plik.txt` (o pierwotnej postaci ACL) wykonamy polecenie `chmod g+w plik.txt`, to zostaną zmienione uprawnienia dla grupy a maska zostanie przeliczona: \n```\nuser::rw-\ngroup::rw-\nmask::rw-\nother::---\n```\nW rezultacie widać, że modyfikując uprawnienia samej grupy, modyfikuje się również wartość maski.\n\nW przypadku gdy dokonujemy zmiany *tylko* praw dostępu dla *konkretnej* kategorii uprawnień (na przykład grupy) i nie zmienia to uprawnień efektywnych, maska NIE będzie rekalkulowana. W naszym poprzednim przykładzie z ACL `user::rw-, group::r--, mask::r--, other::---`  wykonanie polecenia `setfacl -m g::r plik.txt` *nie*  spowoduje zmiany w masce. Zmiana uprawnień *tylko* dla danej kategorii powoduje ponowne przeliczenie maski tylko i wyłącznie jeśli ma wpływ na zmianę efektywnych uprawnień.\n\nPraktycznym zastosowaniem wiedzy o masce jest możliwość ograniczenia uprawnień nadanych użytkownikowi poprzez ustawienie odpowiedniej maski. Jeśli nadamy użytkownikowi pełne uprawnienia, jednak maska będzie miała ograniczenie tylko do odczytu, to nawet nadanie użytkownikowi uprawnień do zapisu, pozostawi go tylko z prawem odczytu. \n\nZatem:\n* **\"gdy podamy opcje -m dla polecenia setfacl\"** - To jest nieprawidłowe, ponieważ samo dodanie uprawnienia do listy nie powoduje przeliczenia maski, konieczne jest by ta modyfikacja  spowodowała zmianę uprawnień efektywnych.\n* **\"przy zmianie uprawnien wlasciciela przy pomocy polecenia chmod\"** - To jest prawidłowe, ponieważ każda zmiana uprawnień właściciela wymusza przeliczenie maski.\n* **\"przy kazdej zmianie uprawnien poleceniem setfacl, chyba ze uzyjemy opcji -n\"** - To jest prawidłowe, gdyż każda zmiana uprawnień powoduje ponowne przeliczenie maski, natomiast parametr `-n` wyłącza ponowne przeliczanie maski.\n* **\"przy dowolnej zmianie uprawnien danej kategorii praw (np. maska dla grupy modyfikowana jest przy modyfikacji praw dotyczacych grupy)\"** - To jest nieprawidłowe, ponieważ modyfikacja praw dla samej grupy, o ile nie powoduje zmiany w uprawnieniach efektywnych, nie wywoła zmiany maski."
    },
    {
        "questionId": 48,
        "title": "Domyslne udzialy administracyjne w systemie Windows:",
        "answers": [
            {
                "text": "dostepne sa tylko dla administratora",
                "isCorrect": false
            },
            {
                "text": "sa tworzone automatycznie przy instalacji systemu",
                "isCorrect": true
            },
            {
                "text": "nie moga byc usuniete",
                "isCorrect": false
            },
            {
                "text": "moga byc usuniete",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Domyślne udziały administracyjne w systemach Windows to ukryte udziały sieciowe, które system automatycznie tworzy, aby umożliwić administratorom zdalny dostęp do zasobów systemowych. Te udziały są niewidoczne podczas standardowego przeglądania otoczenia sieciowego, ale pozostają aktywne i dostępne, jeśli nie zostaną jawnie wyłączone lub usunięte. Te udziały, choć przydatne dla administratorów, mogą stać się furtką dla potencjalnych ataków.\n\n*   **\"dostepne sa tylko dla administratora\"** - Ta odpowiedź jest **nieprawidłowa**. Domyślne udziały administracyjne, takie jak `C$`, `D$`, i `ADMIN$`, nie są dostępne tylko dla lokalnego administratora. Użytkownicy na komputerach w tej samej domenie również mogą mieć dostęp do tych udziałów, o ile posiadają uprawnienia administratora. Zatem, uprawnienia są kluczowe i nie można powiedzieć, że są ograniczone tylko do lokalnego administratora.\n\n*   **\"sa tworzone automatycznie przy instalacji systemu\"** - Ta odpowiedź jest **prawidłowa**. Domyślne udziały administracyjne są tworzone automatycznie podczas instalacji systemu Windows, aby uprościć zdalne zarządzanie systemem. Zostają one utworzone w domyślnych konfiguracjach systemu operacyjnego Windows.\n\n*   **\"nie moga byc usuniete\"** - Ta odpowiedź jest **nieprawidłowa**. Domyślne udziały administracyjne mogą być usunięte, chociaż nie jest to zalecane dla systemów, które muszą być zdalnie zarządzane. Usuwanie udziałów domyślnych zwiększa poziom bezpieczeństwa, ale jednocześnie utrudnia zdalne administrowanie serwerem.\n\n*   **\"moga byc usuniete\"** - Ta odpowiedź jest **prawidłowa**.  Użytkownik z uprawnieniami administratora ma możliwość usunięcia udziałów domyślnych. Można to zrobić za pomocą wbudowanego narzędzia administracyjnego lub poprzez edycję rejestru systemu Windows.  Usunięcie tych udziałów jest jednym z kroków podnoszenia poziomu bezpieczeństwa systemu.\n\n**Konkretny przykład:** Aby zweryfikować istnienie domyślnych udziałów administracyjnych w systemie MS Windows, można użyć polecenia `net share` w wierszu poleceń. Wynik pokaże aktywne udziały w tym te, które są ukryte.  Aby usunąć udział, np. `C$`, można użyć polecenia `net share C$ /delete`.  Powyższa procedura pokazuje, że udziały domyślne nie tylko istnieją ale również można je usuwać. W efekcie nie można powiedzieć, że nie mogą być one usunięte.\n\nPodsumowując, udziały administracyjne są istotnym elementem systemu MS Windows. Warto zaznaczyć, iż domyślne udziały administracyjne to tylko ukryte foldery udostępniane w sieci a nie rzeczywiste uprawnienia administratora. Znajomość tego mechanizmu umożliwia podniesienie poziomu bezpieczeństwa systemu."
    },
    {
        "questionId": 49,
        "title": "Aby uzytkownik L na komputerze HL mogl logowac sie bez podawania hasla na komputer HR na konto R nalezy:",
        "answers": [
            {
                "text": "skopiowac klucz prywatny uzytkownika R z komputera HR do pliku ~/.ssh/authorized_keys na koncie L na komputerze HL",
                "isCorrect": false
            },
            {
                "text": "skopiowac klucz publiczny uzytkownika L z komputera HL do pliku ~/.ssh/authorized_keys na koncie R na komputerze HR",
                "isCorrect": true
            },
            {
                "text": "skopiowac klucz publiczny uzytkownika R z komputera HR do pliku ~/.ssh/authorized_keys na koncie L na komputerze HL",
                "isCorrect": false
            },
            {
                "text": "skopiowac klucz prywatny uzytkownika L z komputera HL do pliku ~/.ssh/authorized_keys na koncie R na komputerze HR",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Klucz publiczny jest używany do weryfikacji tożsamości i szyfrowania wiadomości, a klucz prywatny do odszyfrowywania wiadomości i tworzenia podpisów. Uwierzytelnianie z wykorzystaniem SSH bez hasła polega na wykorzystaniu kryptografii asymetrycznej. Proces ten umożliwia użytkownikowi `L` na komputerze `HL` zalogowanie się do konta `R` na komputerze `HR` bez konieczności podawania hasła.\n\nW tym celu należy na komputerze `HR`, na koncie użytkownika `R`, umieścić w pliku `~/.ssh/authorized_keys` klucz publiczny użytkownika `L` z komputera `HL`. Klucz publiczny ma za zadanie poświadczyć o tożsamości użytkownika `L` przy próbie zdalnego zalogowania do komputera `HR`, natomiast klucz prywatny służy do stworzenia tego poświadczenia. \n\n1.  **\"skopiowac klucz prywatny uzytkownika R z komputera HR do pliku ~/.ssh/authorized_keys na koncie L na komputerze HL\"**\n    *   Ta odpowiedź jest **niepoprawna**. Kopiowanie klucza prywatnego użytkownika `R` z komputera `HR` na komputer `HL` użytkownika `L` byłoby bardzo niebezpieczne. Użytkownik `L` otrzymałby możliwość podszywania się pod użytkownika `R` , a nie o to chodziło. Plik `~/.ssh/authorized_keys` na komputerze `HL` mówi o tym z jakich komputerów użytkownik `L` może się logować na konto użytkownika `L` bez użycia hasła i nie ma nic wspólnego z komputerem `HR`.  Praktycznie implikacje takiego stanu rzeczy sprowadzają się do tego, że użytkownik `L` na komputerze `HL` nie będzie mógł zalogować się na komputer `HR` bez hasła.\n\n2.  **\"skopiowac klucz publiczny uzytkownika L z komputera HL do pliku ~/.ssh/authorized_keys na koncie R na komputerze HR\"**\n    *   Ta odpowiedź jest **poprawna**. Klucz publiczny użytkownika `L` służy do potwierdzenia jego tożsamości, czyli tego, że jest on tym, za kogo się podaje. Klucz ten umieszczony w pliku `~/.ssh/authorized_keys` użytkownika `R` na komputerze `HR` pozwala na bezhasłowe zalogowanie się użytkownika `L` do konta użytkownika `R` na komputerze `HR`.  Praktycznie implikacje tego stanu rzeczy sprowadzają się do tego, że użytkownik `L` na komputerze `HL` będzie mógł zalogować się na komputer `HR` bez podania hasła.\n\n3.  **\"skopiowac klucz publiczny uzytkownika R z komputera HR do pliku ~/.ssh/authorized_keys na koncie L na komputerze HL\"**\n    *   Ta odpowiedź jest **niepoprawna**. Skopiowanie klucza publicznego użytkownika `R` na konto użytkownika `L` nie zezwala na bezhasłowe zalogowanie, gdyż klucz ten nie jest powiązany z kontem użytkownika `L`. Użytkownik `L` nie będzie mógł zalogować się bez hasła na komputer `HR`, a jedynie na swój własny komputer `HL` pod warunkiem wcześniejszego umieszczenia swojego publicznego klucza w `~/.ssh/authorized_keys`.\n\n4.  **\"skopiowac klucz prywatny uzytkownika L z komputera HL do pliku ~/.ssh/authorized_keys na koncie R na komputerze HR\"**\n    *   Ta odpowiedź jest **niepoprawna**. Plik `~/.ssh/authorized_keys` powinien zawierać klucze publiczne, nie prywatne. Umieszczenie klucza prywatnego użytkownika `L` do pliku `~/.ssh/authorized_keys` na koncie `R` w komputerze `HR` nie spełniłoby celu zadania, czyli bezhasłowego zalogowania się na konto `R`.  Praktyczne implikacje takiego stanu rzeczy to nieudane próby bez hasłowego logowania się do konta użytkownika `R`. Co więcej, umieszczenie klucza prywatnego w niechronionym miejscu jakim jest `authorized_keys`  znacznie osłabia bezpieczeństwo systemu."
    },
    {
        "questionId": 50,
        "title": "Model kontroli dostepu MIC zabrania podmiotowi o etykiecie P:",
        "answers": [
            {
                "text": "zapisu obiektu o wyzszej etykiecie niz P",
                "isCorrect": true
            },
            {
                "text": "odczytu obiektu o nizszej etykiecie niz P",
                "isCorrect": true
            },
            {
                "text": "zapisu obiektu o nizszej etykiecie niz P",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to model kontroli dostępu, w którym system operacyjny, a nie użytkownik, narzuca ograniczenia w dostępie do zasobów. Kluczowym elementem MAC są etykiety poufności (_ang. sensitivity labels_), które przypisywane są zarówno do podmiotów (np. procesów, użytkowników), jak i obiektów (np. plików, baz danych). MAC ma na celu uniemożliwienie wypływu danych do obiektów, które mają niższy poziom zaufania oraz uniemożliwienie przepływu danych do podmiotów o niższym poziomie zaufania. Ustawienia te gwarantują że poufne informacje pozostają poufne. \nW MAC obowiązują dwie główne zasady: „no read up” i „no write down”. Pierwsza z nich, „no read up”, oznacza, że podmiot o etykiecie poufności P nie może czytać obiektów o etykiecie poufności wyższej niż P. Druga zasada, „no write down”, oznacza, że podmiot o etykiecie poufności P nie może zapisywać (modyfikować) obiektów o etykiecie poufności niższej niż P. Zasad tych nie można obejść, nawet jeśli podmiot jest właścicielem obiektu. Celem tych zasad jest ochrona danych przed nieuprawnionym odczytem i zapisem w przypadku potencjalnej kompromitacji.  \nEtykiety poufności w systemach MAC najczęściej tworzone są hierarchicznie, np.: „jawne” < „poufne” < „tajne” < „ściśle tajne”.\n\n*   **\"zapisu obiektu o wyzszej etykiecie niz P\"** - Jest to poprawna odpowiedź. W modelu MAC obowiązuje zasada \"no write down\". Podmiot o etykiecie P nie ma prawa zapisać obiektu o niższej etykiecie od swojej. Obiekt o wyższej etykiecie jest tym bardziej niedostępny do zapisu dla podmiotu o etykiecie P.\n   *  **Przykład:** Użytkownik o etykiecie \"poufne\" nie może zapisywać zmian w pliku o etykiecie \"tajne\", gdyż to mogłoby naruszyć zasady MAC (np. obniżyć klasyfikację pliku).\n\n*   **\"odczytu obiektu o nizszej etykiecie niz P\"** - Jest to poprawna odpowiedź. W modelu MAC obowiązuje zasada \"no read up\". Podmiot o etykiecie P ma dostęp do odczytu obiektów o niższej etykiecie niż jego własna, ale nie ma prawa dostępu do obiektów o etykiecie wyższej niż jego własna, ale nie tylko tych wyższych. Ten warunek jest zachowany. Oznacza to, że dane o niższej klasyfikacji nie stanowią zagrożenia dla podmiotu o wyższej klasyfikacji.\n    *   **Przykład:** Proces działający z etykietą \"tajne\" może odczytywać dane z pliku \"poufne\".\n\n*   **\"zapisu obiektu o nizszej etykiecie niz P\"** - Jest to niepoprawna odpowiedź. Zasadą MAC jest, że nie można zapisywać do obiektów o niższej klasyfikacji zaufania niż P.\n   *   **Przykład:** Proces z etykietą \"tajne\" może zapisywać dane do pliku o etykiecie \"ściśle tajne\", ale nie do pliku o etykiecie \"poufne\". Oczywiście ten ostatni przykład jest nie wskazany."
    },
    {
        "questionId": 51,
        "title": "Wykorzystanie TCP Wrappera do ochrony okreslonej uslugi jest mozliwe:",
        "answers": [
            {
                "text": "jesli program serwera uslugi korzysta z biblioteki libwrap.so i sam czyta polityke TCP Wrappera",
                "isCorrect": true
            },
            {
                "text": "automatycznie po definicji polityki (host_access), bowiem TCP Wrapper jest zintegrowany z systemem operacyjnym",
                "isCorrect": false
            },
            {
                "text": "w przypadku przekazania nawiazywanego przez klienta uslugi polaczenia do demona TCP Wrappera zamiast do serwera obslugujacego te usluge",
                "isCorrect": false
            },
            {
                "text": "dopiero po skonfigurowaniu iptables do przekierowania ruchu na port nasluchujacego superserwera xinetd",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "TCP Wrapper, czyli owijka TCP, to mechanizm kontroli dostępu działający na poziomie hosta. Umożliwia on administratorowi systemu ograniczenie dostępu do usług sieciowych na podstawie adresu IP lub nazwy hosta, z którego inicjowane jest połączenie. Działa on jak swego rodzaju pośrednik, który „owija” usługę, stąd nazwa, przechwytując i analizując połączenia, zanim dotrą one do właściwej aplikacji serwera.\n\n**Mechanizm działania TCP Wrappera:**\n1.  **Intercepcja Połączenia:** TCP Wrapper nie działa automatycznie z całym systemem operacyjnym. Usługi, które mają być przez niego chronione, muszą być do tego przystosowane.  Osiąga się to poprzez dwie podstawowe metody.\n2.  **Biblioteka `libwrap.so`:** Jednym ze sposobów integracji TCP Wrappera jest **linkowanie** aplikacji serwera z biblioteką `libwrap.so`. Podczas nawiązywania połączenia biblioteka ta przechwytuje próbę połączenia, sprawdza, czy połączenie pasuje do reguł zdefiniowanych w plikach konfiguracyjnych TCP Wrappera (`/etc/hosts.allow` i `/etc/hosts.deny`), a następnie, zależnie od wyniku, zezwala lub odrzuca połączenie, a dalej ewentualnie przekazuje je do właściwej usługi serwera.\n3.  **Super Serwer `xinetd`:**  Inną metodą jest wykorzystanie tzw. **super serwera** `xinetd`, który sam jest podłączony do biblioteki `libwrap.so`. Zamiast bezpośrednio uruchamiać usługę, super serwer uruchamia program `tcpd` (czyli owijkę TCP), która sprawdza uprawnienia i jeśli są poprawne to uruchamia serwer. Z tego powodu w pliku konfiguracyjnym xinetd w opcji _server_ jest podana nazwa programu tcpd, a nie nazwa serwera. To właśnie program tcpd jest odpowiedzialny za sprawdzenie możliwości przyznania dostępu i w oparciu o to uruchomienie lub nie żądanego serwera.\n4.  **Pliki konfiguracyjne:** Działanie TCP Wrappera jest konfigurowane w dwóch plikach: `/etc/hosts.allow` i `/etc/hosts.deny`. Pliki te zawierają listy reguł, które decydują o tym, jakie połączenia są dozwolone, a jakie blokowane. Reguły w `/etc/hosts.allow` definiują wyjątki, tj. adresy lub zakresy adresów hostów, z których połączenia są dozwolone. Reguły w `/etc/hosts.deny` określają, które połączenia są blokowane.\n\n**Analiza odpowiedzi:**\n\n*   **\"jesli program serwera uslugi korzysta z biblioteki libwrap.so i sam czyta polityke TCP Wrappera\"**\n    *   **Poprawna.** Jest to jeden z dwóch podstawowych sposobów włączenia ochrony TCP Wrappera. Zazwyczaj wszystkie standardowe usługi systemowe z rodziny Unix/Linux są skompilowane z wykorzystaniem `libwrap.so`.\n    *   **Praktyczna Implikacja:** Aplikacje sieciowe, w celu wykorzystania TCP Wrappera muszą być przygotowane poprzez użycie `libwrap.so` w procesie kompilacji, bez tego nie będą mogły korzystać z TCP Wrappera.\n\n*   **\"automatycznie po definicji polityki (host_access), bowiem TCP Wrapper jest zintegrowany z systemem operacyjnym\"**\n    *   **Niepoprawna.** TCP Wrapper nie działa w sposób całkowicie automatyczny. Usługi muszą być jawnie linkowane z `libwrap.so` lub uruchamiane przez `xinetd`, aby podlegały kontroli. Samo zdefiniowanie polityki w plikach konfiguracyjnych nie aktywuje TCP Wrappera.\n    *   **Praktyczna Implikacja:** Włączenie filtracji połączeń TCP Wrapperem wymaga aktywnego udziału, czy to w procesie kompilacji aplikacji (z biblioteką libwrap.so) czy poprzez uruchomienie za pośrednictwem super serwera xinetd.\n\n*  **\"w przypadku przekazania nawiazywanego przez klienta uslugi polaczenia do demona TCP Wrappera zamiast do serwera obslugujacego te usluge\"**\n    *   **Niepoprawna.**  TCP Wrapper nie \"przekazuje połączenia\" bezpośrednio do demona serwera, lecz działa jako warstwa pośrednicząca. Sprawdza uprawnienia i zezwala lub nie na uruchomienie usługi serwera.\n    *   **Praktyczna Implikacja:**  TCP Wrapper działa jako strażnik, nie jako pośrednik w komunikacji. W przypadku połączenia z wykorzystaniem `xinetd` najpierw następuje próba otworzenia połączenia z TCP Wrapperem (`tcpd`), a następnie w przypadku pozytywnej weryfikacji, ten ostatni wywołuje właściwą aplikację serwera (np. `tftpd`).\n\n*  **\"dopiero po skonfigurowaniu iptables do przekierowania ruchu na port nasluchujacego superserwera xinetd\"**\n    *  **Poprawna**. Chociaż TCP Wrapper działa niezależnie od `iptables`, w praktyce często oba są stosowane równocześnie. W tym konkretnym przypadku, kiedy usługa chroniona TCP Wrapperem działa pod kontrolą super serwera `xinetd` to bez przekierowania pakietów do super serwera `xinetd` który uruchomi program tcpd, ten ostatni nie będzie miał okazji aby zadziałać. Program `iptables` wykonuje zadania na niższej warstwie modelu OSI, w związku z czym `iptables` może przekierować ruch na odpowiedni port, na którym nasłuchuje `xinetd`, a ten z kolei przekaże ruch do `tcpd`, który na końcu podejmie decyzję o przekazaniu ruchu do właściwej usługi sieciowej.\n    *   **Praktyczna Implikacja:**  `iptables` i `tcpd` są mechanizmami, które działają w różnych warstwach modelu OSI. `iptables` jest zaporą ogniową na poziomie warstwy sieciowej. Natomiast `tcpd` jest strażnikiem dostępu na poziomie aplikacji. W przypadku wykorzystania `xinetd` oba mechanizmy muszą ze sobą współpracować.\n\nPodsumowując, TCP Wrapper działa jako system kontroli dostępu, który współpracuje z aplikacjami (poprzez `libwrap.so`) lub poprzez super serwer `xinetd` , a nie jest elementem systemu operacyjnego, który funkcjonuje automatycznie. Dodatkowo program `iptables` jest niezależnym mechanizmem działającym w innej warstwie modelu ISO/OSI i może być wykorzystywany równolegle z TCP Wrapperem."
    },
    {
        "questionId": 52,
        "title": "Strumien ADS:",
        "answers": [
            {
                "text": "jest czescia naglowka pliku dolaczana zawsze przez system Windows podczas operacji pakowania do archiwum lub udostepniania w sieci",
                "isCorrect": false
            },
            {
                "text": "jest wykorzystywany przez mechanizm informujacy o stopniu zaufania do pliku (okreslajacy jego pochodzenie przez wpis ZoneId)",
                "isCorrect": true
            },
            {
                "text": "pozwala zwiazac z dowolnym plikiem lub katalogiem dowolne (zarowno tekstowe, jak i binarne) dane",
                "isCorrect": true
            },
            {
                "text": "jest wykorzystywany przez procesy w systemie Windows do informowania o bledach wykonania (tzw. metainformacje)",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Strumień ADS (_Alternate Data Stream_) to ukryta właściwość systemu plików NTFS, która pozwala na skojarzenie z każdym plikiem lub katalogiem dodatkowych danych, które nie są integralną częścią tych plików, a są z nimi powiązane. Strumień ADS nie jest elementem nagłówka pliku, który może być analizowany w celu pozyskania informacji o pliku. Natomiast strumień ten stanowi dołączony do pliku element. Strumień ADS można porównać do małego pliku, którego nazwa jest utworzona przez dwukropek i dodatkowy identyfikator np. plik.txt:dane. W standardowy sposób otwierając plik plik.txt, nie uzyskamy dostępu do strumienia ADS dane. Dostęp do strumienia uzyskamy poprzez odpowiednie narzędzia systemu operacyjnego Windows (o tym poniżej). Strumienie ADS mogą przechowywać dowolne dane, nie tylko tekstowe, również wykonywalne, stąd ich istotne znaczenie z punktu widzenia bezpieczeństwa. \n\n*   **\"jest czescia naglowka pliku dolaczana zawsze przez system Windows podczas operacji pakowania do archiwum lub udostepniania w sieci\"**  \n    To stwierdzenie jest nieprawidłowe. Strumień ADS nie jest częścią nagłówka pliku, ale jest do niego dołączany jako odrębny byt i nie ma związku z archiwizacją czy udostępnianiem w sieci. Standardowe operacje na plikach, takie jak pakowanie do archiwum ZIP, czy udostępnianie w sieci w standardzie protokołu SMB, nie przenoszą informacji o strumieniach ADS. Strumienie te są ukryte i wymagają użycia specjalnych narzędzi do ich odczytu i modyfikacji.\n\n*   **\"jest wykorzystywany przez mechanizm informujacy o stopniu zaufania do pliku (okreslajacy jego pochodzenie przez wpis ZoneId)\"**  \n    To stwierdzenie jest prawdziwe. System Windows, aby ostrzegać użytkowników przed otwieraniem plików nieznanego pochodzenia (np. pobranych z internetu) wykorzystuje strumień ADS o nazwie **Zone.Identifier**. W tym strumieniu Windows zapisuje informację o strefie pochodzenia pliku, strefy te to np. \"Internet\", \"Intranet\", \"Zaufane Strony\". Informacja ta, na etapie uruchomienia pliku, generuje stosowne ostrzeżenie o tym, że aplikacja pochodzi np. z internetu. Ten strumień jest przykładem legalnego zastosowania strumienia ADS.\n\n*   **\"pozwala zwiazac z dowolnym plikiem lub katalogiem dowolne (zarowno tekstowe, jak i binarne) dane\"**  \n    To stwierdzenie jest prawdziwe. Strumienie ADS umożliwiają powiązanie z plikiem lub katalogiem dowolnej sekwencji danych, nie są ograniczone rodzajem, ani wielkością. Daje to bardzo dużą swobodę w wykorzystaniu tej właściwości, zarówno w sposób legalny, jak i w złośliwy. Należy tutaj wspomnieć, że to powiązanie ze strumieniem nie ujawnia się w zwykły sposób w eksploratorze plików. Do uzyskania informacji o strumieniach ADS niezbędne są odpowiednie narzędzia (np. polecenie \"dir /r\" w powłoce systemowej cmd). Z punktu widzenia atakującego, strumienie ADS mogą służyć do ukrywania złośliwego kodu, narzędzi, i innych artefaktów ataku.\n\n*   **\"jest wykorzystywany przez procesy w systemie Windows do informowania o bledach wykonania (tzw. metainformacje)\"**  \n    To stwierdzenie jest nieprawidłowe. Strumienie ADS nie służą do informowania o błędach wykonania programów w systemie Windows. Do tego celu system używa innych mechanizmów, takich jak dzienniki zdarzeń (ang. *event logs*) oraz pliki zawierające tzw. zrzuty pamięci (ang. *core dumps*). Strumienie ADS wykorzystywane są do przechowywania dodatkowych danych, z którymi powiązany jest plik lub katalog.\n\n**Podsumowując:** Strumienie ADS stanowią ukrytą, a przez to często pomijaną, funkcjonalność systemu plików NTFS, którą można wykorzystać zarówno do celów legalnych, jak i szkodliwych. Z punktu widzenia bezpieczeństwa, ważne jest, aby znać koncepcję strumieni ADS, aby skutecznie wykrywać i przeciwdziałać potencjalnym zagrożeniom związanym z ich wykorzystaniem przez złośliwe oprogramowanie."
    },
    {
        "questionId": 552,
        "title": "Mechanizm EFS:",
        "answers": [
            {
                "text": "zabezpiecza dostep do tresci poszczegolnych plikow zarowno w czasie dzialania systemu, jak i po jego wylaczeniu (at rest)",
                "isCorrect": true
            },
            {
                "text": "stosuje kryptografie asymetryczna do szyfrowania tresci plikow",
                "isCorrect": false
            },
            {
                "text": "realizuje full disc encyption w celu zabezpieczenia systemu operacyjnego przed niepowolanym uruchomieniem i dostepem",
                "isCorrect": false
            },
            {
                "text": "wymaga do swojego dzialania konta DRA",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Encrypting File System (EFS) to funkcja systemu Windows, która służy do szyfrowania plików i folderów. Jest to mechanizm ochrony danych \"at rest\", czyli w stanie spoczynku, gdy system jest uruchomiony jak i wyłączony. W przeciwieństwie do mechanizmów kontroli dostępu (ACL) które chronią przed nieuprawnionym dostępem gdy system operacyjny działa, EFS chroni dane przed nieuprawnionym odczytaniem gdy system nie jest uruchomiony.\n\nEFS wykorzystuje szyfrowanie symetryczne do szyfrowania zawartości plików, to znaczy ten sam klucz szyfruje i deszyfruje zawartość danego pliku. Klucz symetryczny jest generowany losowo dla każdego zaszyfrowanego pliku i jest on przechowywany (zaszyfrowany) za pomocą klucza publicznego właściciela pliku. Jest to tzw. hybrydowy system szyfrowania, w którym szyfrowanie asymetryczne jest wykorzystywane tylko do ochrony klucza symetrycznego, a szyfrowanie symetryczne jest wykorzystywane do szyfrowania danych. Szyfrowanie symetryczne jest z natury dużo szybsze niż szyfrowanie asymetryczne, dlatego tylko klucz szyfrowania symetrycznego jest szyfrowany asymetrycznie, reszta danych pliku jest szyfrowana symetrycznie. Mechanizm ten zapewnia wysoki stopień bezpieczeństwa i jest on również szybki.\n\nW kontekście EFS nie mówimy o pełnym szyfrowaniu dysku (ang. *full disk encryption*). Pełne szyfrowanie dysku (np. BitLocker) szyfruje całą partycję lub dysk, łącznie z systemem operacyjnym, a nie tylko wybrane pliki i katalogi. EFS działa na poziomie pliku, co oznacza, że tylko pliki i katalogi oznaczone jako zaszyfrowane są chronione szyfrowaniem. \nCertyfikat DRA (ang. *Data Recovery Agent*) nie jest wymagany do działania mechanizmu EFS. Mechanizm EFS do poprawnego działania potrzebuje certyfikatu lub klucza właściciela pliku, aby proces deszyfrowania pliku był możliwy. Certyfikat DRA jest użyteczny w przypadku gdy użytkownik straci dostęp do swojego certyfikatu np. w przypadku awarii systemu operacyjnego, to klucz DRA może zostać wykorzystany do odszyfrowania danych.\n\n**Odpowiedź 1 jest poprawna**, ponieważ EFS faktycznie zapewnia ochronę danych zarówno w trakcie działania systemu, jak i gdy jest on wyłączony. Zabezpiecza to dane przed nieautoryzowanym odczytem gdy dysk twardy zostaje skradziony.\n**Odpowiedź 2 jest niepoprawna**, ponieważ EFS wykorzystuje kryptografię symetryczną do szyfrowania danych, a asymetryczną do ochrony klucza użytego do szyfrowania symetrycznego. \n**Odpowiedź 3 jest niepoprawna**, ponieważ EFS szyfruje pliki i foldery a nie cały dysk. Pełne szyfrowanie dysku realizują inne mechanizmy.\n**Odpowiedź 4 jest niepoprawna**, ponieważ konto DRA jest opcjonalne, aczkolwiek bardzo pomocne w sytuacjach awaryjnych."
    },
    {
        "questionId": 53,
        "title": "Jakie haslo jest domyslnie wymagane przez polecenie sudo, jezeli w konfiguracji nie bedzie ustawione inaczej (czyli jezeli wszystkie ustawienia beda mialy wartosci domyslne)?",
        "answers": [
            {
                "text": "administratora systemu",
                "isCorrect": false
            },
            {
                "text": "wlasciciela programu (SUID) uruchamianego tym poleceniem",
                "isCorrect": false
            },
            {
                "text": "haslo puste (domyslnie sudo nie pyta o haslo)",
                "isCorrect": false
            },
            {
                "text": "uzytkownika wywolujacego polecenie sudo",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Polecenie `sudo` (superuser do) jest narzędziem w systemach Linux i innych systemach typu Unix, które pozwala uprawnionemu użytkownikowi na wykonanie polecenia z uprawnieniami innego użytkownika, zazwyczaj administratora systemu (root). Domyślnie `sudo` wymaga podania hasła użytkownika wywołującego polecenie, a nie hasła administratora systemu, ani hasła właściciela programu uruchamianego za pomocą sudo (mechanizm setuid/setgid). Domyślna konfiguracja `sudo` jest zaprojektowana w taki sposób aby uniemożliwić wykonywania niepożądanych operacji przez niepowołanych użytkowników. Hasło wykorzystywane podczas logowania umożliwia identyfikacje użytkownika. Użytkownik, który jest zweryfikowany może następnie wykorzystywać program _sudo_ w celu nadania sobie uprawnień do wykonania komendy o podwyższonych uprawnieniach. \n\n*   **\"administratora systemu\"**: Ta odpowiedź jest niepoprawna, gdyż domyślnie `sudo` nie wymaga hasła administratora systemu. Choć `sudo` pozwala na wykonywanie poleceń jako administrator, to dla kontroli procesu nadawania uprawnień, do uzyskania tych uprawnień, domyślnie, jest sprawdzane hasło osoby żądającej podwyższenia swoich uprawnień.  Użycie `sudo` umożliwia wykonanie uprzywilejowanej operacji, ale do tego wykorzystuje hasło żądającego a nie hasło administratora. Na przykład,  jeśli użytkownik `jan` uruchomi `sudo apt update`, system będzie wymagał hasła użytkownika `jan`, a nie hasła użytkownika root. Użytkownik `jan` z poprawnym hasłem ma prawo wykonać polecenie `apt update` z uprawnieniami administratora. Hasło administratora jest tylko potrzebne przy logowaniu się na konto administratora.\n\n*   **\"wlasciciela programu (SUID) uruchamianego tym poleceniem\"**: To również nieprawidłowa odpowiedź. Bit SUID (Set User ID) i SGID (Set Group ID) to mechanizmy związane z plikami wykonywalnymi, które pozwalają na uruchomienie programu z uprawnieniami właściciela tego pliku, a nie z uprawnieniami użytkownika wywołującego polecenie. `sudo` działa niezależnie od bitów SUID i SGID i jest dedykowanym narzędziem do przydzielania uprawnień na czas wykonania komendy, do czasu zakończenia wykonania komendy. Domyślnie `sudo` nie uwzględnia uprawnień właściciela programu.  Na przykład, jeśli program `abc` posiada ustawiony bit SUID na użytkownika root, to każdy użytkownik wywołujący `abc` uruchomi ten program z uprawnieniami użytkownika root. Nie ma to jednak nic wspólnego z tym, jakie hasło jest potrzebne do wywołania `sudo`. Aplikacja _sudo_ ignoruje uprawnienia właściciela uruchamianego programu i pyta tylko i wyłącznie o hasło osoby, która chce wykonać daną komendę.\n\n*   **\"haslo puste (domyslnie sudo nie pyta o haslo)\"**: To jest błędna odpowiedź. Domyślnie `sudo` wymaga hasła, aby zweryfikować użytkownika, który chce podnieść swoje uprawnienia. Bez hasła każdy mógłby wykonać dowolne operacje w systemie z podwyższonymi uprawnieniami, co stanowiłoby duże naruszenie bezpieczeństwa. Brak wpisanego hasła w domyślnej konfiguracji spowoduje zwrócenie przez program sudo informacji o błędzie. W realnej sytuacji spowodowałoby to zablokowanie polecenia do czasu podania poprawnego hasła.\n\n*   **\"uzytkownika wywolujacego polecenie sudo\"**: To jest prawidłowa odpowiedź. Domyślnie `sudo` prosi o hasło użytkownika, który wydał polecenie, nie zaś o hasło administratora (root). Jest to podstawowa funkcja `sudo`, umożliwiająca tymczasowe podniesienie uprawnień bez konieczności logowania się na konto administratora. Przykładem jest użytkownik `jan`, chcący zainstalować aktualizację: `sudo apt update`. System zapyta go o jego hasło, jeśli hasło jest poprawne i jan ma ustawione uprawnienia do wykonania polecenia `apt update`, program ten będzie wykonany z uprawnieniami administratora systemu. Wykorzystywanie własnego hasła jako mechanizmu zabezpieczenia umożliwia indywidualną identyfikację osoby, która wydała daną komendę."
    },
    {
        "questionId": 54,
        "title": "Gdy w poleceniu iptables nie podamy celu reguly, przy pomocy opcji -j (np. -j REJECT), wowczas:",
        "answers": [
            {
                "text": "po dopasowaniu reguly iptables przerywa przetwarzanie, ale pakiet jest przepuszczany",
                "isCorrect": false
            },
            {
                "text": "po dopasowaniu reguly iptables przetwarza kolejne reguly",
                "isCorrect": true
            },
            {
                "text": "uzywany jest cel domyslny dla danego lancucha, tzw. polityka (ustawiana przy pomocy -P)",
                "isCorrect": false
            },
            {
                "text": "regula zostanie odrzucona jako bledna, chyba ze jest to modyfikacja wczesniej istniejacej reguly (przy pomocy opcji -R), kiedy to zostanie zastosowany taki cel, jaki byl ustawiony dotychczas w tej regule",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "W poleceniu `iptables`, opcja `-j` służy do określenia celu (ang. _target_), czyli akcji, którą należy podjąć w przypadku, gdy pakiet pasuje do zdefiniowanego wzorca w regule.  Jeśli w regule pominiemy opcję `-j`, czyli nie określimy celu, to `iptables` nie podejmie żadnej domyślnej akcji (np. nie zastosuje domyślnej polityki łańcucha). Zamiast tego pakiet jest nadal sprawdzany w kontekście kolejnych reguł zdefiniowanych w danym łańcuchu.\n\n**Poprawna odpowiedź:**\n*\"po dopasowaniu reguly iptables przetwarza kolejne reguly\"*\nJest to prawda. W przypadku gdy brakuje opcji `-j` czyli celu reguły, pakiet nie zostaje ani odrzucony ani przepuszczony. W takiej sytuacji program `iptables` kontynuuje przetwarzanie, czyli zaczyna testowanie pakietu w kontekście kolejnych reguł z danego łańcucha. \nZałóżmy, że mamy łańcuch INPUT z dwiema regułami. Pierwsza reguła dopasowuje się do pakietów UDP o docelowym porcie 53(DNS) i nie posiada opcji celu(-j), a druga reguła akceptuje wszystkie pakiety(-j ACCEPT). W tej sytuacji reguła pierwsza mimo, że zadziała na pakiet o porcie docelowym 53, to nie przerywa przetwarzania pakietu. Pakiet dalej jest analizowany z uwzględnieniem kolejnej reguły i ostatecznie zostanie zaakceptowany.\n**Niepoprawne odpowiedzi:**\n*\"po dopasowaniu reguly iptables przerywa przetwarzanie, ale pakiet jest przepuszczany\"*\nJest to nieprawda. Brak opcji `-j` w definicji reguły nie powoduje automatycznego przepuszczenia pakietu, lecz przejście do kolejnej reguły łańcucha. Pakiet jest analizowany dalej i ostateczny rezultat zależy od akcji w następnych regułach.\n\n*\"uzywany jest cel domyslny dla danego lancucha, tzw. polityka (ustawiana przy pomocy -P)\"*\nJest to nieprawda. Domyślna polityka jest używana tylko, gdy pakiet nie pasuje do żadnej z reguł danego łańcucha. Natomiast w przypadku dopasowania pakietu do reguły bez opcji `-j`, łańcuch jest dalej przetwarzany według kolejnych reguł.\n\n*\"regula zostanie odrzucona jako bledna, chyba ze jest to modyfikacja wczesniej istniejacej reguly (przy pomocy opcji -R), kiedy to zostanie zastosowany taki cel, jaki byl ustawiony dotychczas w tej regule\"*\nJest to nieprawda. Program iptables nie odrzuca reguły bez opcji `-j`. Reguła ta jest traktowana jako poprawna ale bez wskazania co dalej ma być zrobione z pasującym pakietem, dlatego przetwarzanie pakietu przechodzi do kolejnej reguły. Jeżeli reguła z opcja `-R` jest modyfikowana to stara reguła jest całkowicie nadpisywana nową regułą. W przypadku braku celu w nowej regule stara reguła jest nadpisywana regułą bez celu.\n\nBrak celu w regule `iptables` nie oznacza pominięcia tej reguły, odrzucenia pakietu ani zastosowania domyślnej polityki łańcucha. Oznacza, że pakiet jest dopasowany do wzorca w tej regule, ale dalsze przetwarzanie następuje na podstawie kolejnych reguł w łańcuchu."
    },
    {
        "questionId": 55,
        "title": "Impersonation w systemie Windows to:",
        "answers": [
            {
                "text": "przypisanie tokenu bezpieczenstwa ogolnego przeznaczenia do konkretnego uzytkownika stanowiacego instancje pewnego SID",
                "isCorrect": false
            },
            {
                "text": "rodzaj zdalnego ataku na system, w ktorym napastnik podszywa sie pod jednego z uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "przechwycenie tokenu bezpieczenstwa SID przez nieuprawnionego uzytkownika",
                "isCorrect": false
            },
            {
                "text": "czasowe przejecie przez proces (watek) uprawnien innego podmiotu",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Impersonation w systemie Windows to mechanizm, który pozwala procesowi (lub wątkowi procesu) czasowo przyjąć uprawnienia innego podmiotu. Podmiotem może być użytkownik lub inny proces. Kluczowym elementem tego procesu jest token bezpieczeństwa (ang. _security token_). Token bezpieczeństwa zawiera informacje o tożsamości podmiotu, a także o jego uprawnieniach. Każdy podmiot w systemie Windows ma przypisany token bezpieczeństwa, który decyduje o tym, jakie działania może on wykonać.  Identyfikator bezpieczeństwa (ang. _Security Identifier_ - SID) jest unikalnym identyfikatorem podmiotu.\n\n**Odpowiedź 1:** \"przypisanie tokenu bezpieczenstwa ogolnego przeznaczenia do konkretnego uzytkownika stanowiacego instancje pewnego SID\" - jest **niepoprawna**.  Impersonation nie polega na przypisaniu ogólnego tokenu do użytkownika, a na czasowym przejęciu konkretnego tokenu. Tokeny są  związane z SIDem użytkownika lub procesu, nie sa ogólnego przeznaczenia. Zasadniczo proces nie przejmuje SIDa a token, a to duża różnica.\n\n**Odpowiedź 2:** \"rodzaj zdalnego ataku na system, w ktorym napastnik podszywa sie pod jednego z uzytkownikow\" - jest **niepoprawna**.  Impersonation nie jest zdalnym atakiem. Jest to mechanizm działania w ramach systemu operacyjnego, umożliwiający procesowi wykonywanie operacji z uprawnieniami innego podmiotu w danym systemie. Atak na system, który podszywa się pod innego użytkownika to _spoofing_, nie _impersonation_. Impersonation wykorzystywane jest raczej dla celów  legitimnych.\n\n**Odpowiedź 3:** \"przechwycenie tokenu bezpieczenstwa SID przez nieuprawnionego uzytkownika\" - jest **niepoprawna**. Impersonation nie polega na przechwyceniu SIDa, a na czasowym przejęciu tokenu bezpieczeństwa. Token nie jest tym samym co SID. SID jest unikalnym identyfikatorem podmiotu, natomiast token opisuje uprawnienia nadane temu podmiotowi. Proces dokonujący impersonacji nie \"kradnie\" SIDa, a uzyskuje czasowy dostęp do tokena. \n\n**Odpowiedź 4:** \"czasowe przejecie przez proces (watek) uprawnien innego podmiotu\" - jest **poprawna**.  Impersonation w systemie Windows polega właśnie na tym, że proces lub wątek czasowo działa z uprawnieniami innego podmiotu, nie tracąc przy tym swojej tożsamości.  Na przykład, serwer WWW działający w imieniu usługi systemowej, może na czas obsługi żądania klienta stać się procesem z prawami tego klienta. Dzięki temu serwer WWW ma dostęp tylko do tych zasobów, do których ma dostęp klient."
    },
    {
        "questionId": 56,
        "title": "Hasla uzytkownikow systemu Windows sa przechowywane:",
        "answers": [
            {
                "text": "w rejestrze systemowym",
                "isCorrect": true
            },
            {
                "text": "w bazie SAM na dysku",
                "isCorrect": true
            },
            {
                "text": "w formie nieodwracalnego wyniku funkcji mieszajacej",
                "isCorrect": true
            },
            {
                "text": "w pliku shadow zaszyfrowanym kluczem RSA (SYSKEY), do ktorego dostep ma tylko administrator systemu",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Hasła użytkowników systemu Windows nie są przechowywane bezpośrednio jako tekst jawny, lecz w formie przetworzonej, aby utrudnić ich odzyskanie w razie nieuprawnionego dostępu do systemowych plików. Mechanizm ten składa się z kilku warstw zabezpieczeń, co komplikuje potencjalny proces złamania haseł przez osoby trzecie.\nSystem Windows przechowuje hasła w dwóch głównych miejscach:\n\n1.  **Rejestr systemowy:**  Rejestr systemu Windows jest hierarchiczną bazą danych, gdzie zapisywane są ustawienia i opcje konfiguracyjne systemu operacyjnego oraz zainstalowanych aplikacji. Część haseł (szczególnie tych używanych przez usługi) jest przechowywana w zabezpieczonym obszarze rejestru zwanym LSA (Local Security Authority). Hasła te nie są dostępne dla zwykłego użytkownika i są chronione przez system kontroli dostępu. W kontekście tego pytania to miejsce jest jednym z prawidłowych odpowiedzi.\n\n2.  **Baza SAM (Security Accounts Manager) na dysku:** Baza SAM to plik, który przechowuje informacje o kontach użytkowników i grup, w tym również skróty haseł (ang. *password hashes*). Hasła nie są w tej bazie przechowywane w formie jawnej, ale jako wynik działania funkcji haszującej, inaczej mówiąc jako skrót kryptograficzny. Użycie funkcji haszującej, które są nieodwracalne w praktyce, powoduje, że nie można odzyskać hasła na podstawie tego skrótu. Baza SAM, jest przechowywana na dysku i jest bardzo dobrze chroniona przed dostępem nieuprawnionym. Jest to kolejne prawidłowe wskazanie w tym pytaniu.\n\n3.  **Forma nieodwracalnego wyniku funkcji mieszającej (hash):**  System Windows, jak i większość systemów operacyjnych, do przechowywania haseł wykorzystuje jednokierunkowe funkcje haszujące. Funkcja haszująca tworzy z hasła wejściowego ciąg znaków o stałej długości, zwany skrótem lub wartością haszującą. Ten skrót jest charakterystyczny dla danego hasła i jego wyznaczenie jest łatwe. Jednak funkcja haszująca jest jednokierunkowa, co oznacza że nie można odtworzyć hasła na podstawie wyznaczonego skrótu (w praktycznym czasie). Ten skrót jest przechowywany w bazie SAM i w rejestrze. W kontekście tego pytania jest to kolejna prawidłowa odpowiedź. Popularnymi algorytmami haszującymi, używanymi w Windows, są MD5 lub SHA1.\n\n4.  **W pliku shadow zaszyfrowanym kluczem RSA (SYSKEY):** Ta odpowiedź jest niepoprawna, ponieważ systemy z rodziny Windows, w przeciwieństwie do systemów Unix/Linux nie wykorzystują pliku o nazwie shadow do przechowywania skrótów haseł. Zamiast tego hasła przechowywane są w SAM i w rejestrze. Technologia SYSKEY istnieje w systemach Windows, jednak nie służy bezpośrednio do szyfrowania całego pliku ze skrótami haseł. SYSKEY dodaje dodatkową warstwę szyfrowania, która utrudnia, ewentualne odzyskanie skrótów haseł z rejestru systemowego. Algorytm RSA nie służy wprost do tworzenia skrótu hasła, tylko jest algorytmem szyfrowania asymetrycznego. Dodatkowo klucz RSA nie jest dostępny tylko dla administratora systemu, dostęp jest możliwy dla usługi systemowej. Podsumowując, wskazana odpowiedź jest niepoprawna ponieważ miesza kilka niepowiązanych ze sobą elementów z różnych systemów i technologii.\n\nPodsumowując, hasła użytkowników systemów Windows są przechowywane w formie nieodwracalnego skrótu, w rejestrze oraz bazie SAM. Nie są one przechowywane w postaci pliku shadow."
    },
    {
        "questionId": 57,
        "title": "W poleceniu: iptables -I INPUT -p icmp -icmp-type echo-request -m recent -name \"ping\" -set nazwa \"ping\":",
        "answers": [
            {
                "text": "jest to komentarz, pozwalajacy na szybka identyfikacje reguly w przyszlosci (np. w celu modyfikacji lub skasowania)",
                "isCorrect": false
            },
            {
                "text": "okresla ten z ostatnio inicjowanych modulow filtracji (lancuchow), ktory teraz bedzie przechwytywal wskazane pakiety",
                "isCorrect": false
            },
            {
                "text": "identyfikuje konkretne statystyki, ktore pozniej mozna wykorzystac do dalszej selekcji ruchu",
                "isCorrect": true
            },
            {
                "text": "definiuje nazwe pliku, ktory zawierac bedzie informacje o ruchu pakietow do biezacej reguly zapory",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Moduł `recent` w `iptables` służy do dynamicznego tworzenia i zarządzania listami adresów IP, które niedawno spełniły określone kryteria.  Opcja `-m recent` w poleceniu `iptables` aktywuje ten moduł, umożliwiając śledzenie pakietów. Opcja `-name` pozwala na zdefiniowanie nazwy, która będzie identyfikować konkretną listę adresów IP. Tak zdefiniowana nazwa, w tym konkretnym przypadku `ping`, nie jest komentarzem, ale unikalnym identyfikatorem zbioru IP i jest niezbędna do późniejszego wykorzystania do analizy ruchu sieciowego. Polecenie `iptables` pozwala wykorzystać stworzoną nazwę zbioru, np. w celu sprawdzenia czy na liście znajdują się dane hosty.\n\n**Analiza opcji odpowiedzi:**\n\n*   **\"jest to komentarz, pozwalajacy na szybka identyfikacje reguly w przyszlosci (np. w celu modyfikacji lub skasowania)\"** - Jest to niepoprawna odpowiedź. Opcja `-name` nie służy do dodawania komentarzy do reguły iptables. Choć komentarze są pomocne przy zarządzaniu regułami, to w `iptables` nie ma opcji do tworzenia komentarzy. Do tego celu można użyć modułu `comment`. Opcja `-name` ma inne, konkretne zastosowanie.\n\n*   **\"okresla ten z ostatnio inicjowanych modulow filtracji (lancuchow), ktory teraz bedzie przechwytywal wskazane pakiety\"** - Jest to niepoprawna odpowiedź.  Opcja `-name` nie definiuje kolejności przetwarzania pakietu przez łańcuchy. Kolejność łańcuchów jest ustalona przez architekturę Netfiltera. Opcja ta definiuje nazwę dla listy adresów ip i nic więcej.\n\n*   **\"identyfikuje konkretne statystyki, ktore pozniej mozna wykorzystac do dalszej selekcji ruchu\"** - Jest to poprawna odpowiedź.  Opcja `-name` w połączeniu z modułem `recent` identyfikuje konkretną listę adresów IP, którą możemy wykorzystać w dalszych regułach `iptables`.  Na przykład, po utworzeniu listy `ping`, możemy dodać regułę, która zablokuje ruch z adresów IP dodanych do listy `ping`, które nie spełnią dodatkowych warunków, jak limit częstotliwości połączeń.  \n\n    Przykładowo, możemy stworzyć zbiór nazwany `ping` dla każdego hosta, z którego wysłane zostało żądanie `ICMP echo-request`:\n     `iptables -I INPUT -p icmp --icmp-type echo-request -m recent --name ping --set`\n\n    Następnie możemy zablokować wszystkie kolejne przychodzące żądania ping z konkretnego adresu IP, jeżeli został wcześniej dodany na listę `ping`: \n     `iptables -I INPUT -p icmp --icmp-type echo-request -m recent --name ping --update -j DROP`\n     \n    W powyższym przykładzie druga reguła wykorzystuje utworzoną listę adresów `ping`, używając flagi `--update` sprawdza czy dany adres IP znajduje się w stworzonej wcześniej liście. W ten sposób można tworzyć dynamiczne listy adresów ip, który podlegają blokowaniu na określony czas.\n*   **\"definiuje nazwe pliku, ktory zawierac bedzie informacje o ruchu pakietow do biezacej reguly zapory\"** - Jest to niepoprawna odpowiedź.  Opcja `-name` nie wskazuje na plik, gdzie mają być logowane pakiety. Do logowania pakietów wykorzystuje się opcję `-j LOG` w połączeniu z odpowiednimi parametrami modułu `LOG` lub `-j ULOG` co kieruje informację do przestrzeni użytkownika.\n\n**Podsumowanie:**\n\nOpcja `-m recent --name \"ping\"` w poleceniu `iptables` tworzy lub wykorzystuje listę adresów IP o nazwie \"ping\", używaną do dynamicznego śledzenia połączeń. Nie jest to ani komentarz, ani nazwa pliku z logami, ani nie wpływa na kolejność łańcuchów w iptables. Kluczowym aspektem jest zrozumienie, że moduł `recent` pozwala zarządzać dynamicznymi zbiorami adresów, a opcja `-name` nadaje tym zbiorom konkretną identyfikację, co umożliwia ich późniejsze użycie w kolejnych regułach."
    },
    {
        "questionId": 58,
        "title": "Serwer OpenVPN umozliwia uwierzytelnianie klientow poprzez:",
        "answers": [
            {
                "text": "klucze kryptograficzne",
                "isCorrect": true
            },
            {
                "text": "hasla uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "certyfikaty X.509",
                "isCorrect": true
            },
            {
                "text": "protokol Kerberos",
                "isCorrect": false
            },
            {
                "text": "biometrycznie, poprzez analize dlugosci rzutu beretem",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Uwierzytelnianie w kontekście sieci VPN, a konkretnie w OpenVPN, odnosi się do procesu weryfikacji tożsamości klienta łączącego się z serwerem VPN. OpenVPN, jako elastyczne narzędzie, oferuje kilka metod uwierzytelniania, a nie tylko jedną.\n\n**Klucze kryptograficzne** - są jedną z metod uwierzytelniania w OpenVPN. Używa się ich do weryfikacji tożsamości i ustanowienia szyfrowanego połączenia. OpenVPN wspiera zarówno symetryczne, jak i asymetryczne klucze. Klucze symetryczne są wykorzystywane do szyfrowania danych po uwierzytelnieniu, natomiast asymetryczne mogą być używane do uwierzytelniania serwera i klienta, oraz do bezpiecznego uzgodnienia klucza symetrycznego. W praktyce, oznacza to że po stronie serwera i klienta wymagana jest znajomość tego samego ciągu danych, który jest wykorzystywany przez bibliotekę OpenSSL do stworzenia unikalnych kluczy do szyfrowania oraz weryfikacji tożsamości. Klucze kryptograficzne, szczególnie te generowane asymetrycznie, są bardzo bezpieczną metodą uwierzytelniania, gdyż trudność ich złamania i odgadnięcia jest duża. OpenVPN, pozwala w sposób bezpieczny przekazać tajny klucz, do którego nie ma dostępu żaden potencjalny napastnik.\n\n**Hasła użytkowników** - w kontekście OpenVPN same hasła nie są zalecanym mechanizmem uwierzytelniania, ponieważ są podatne na przechwycenie lub złamanie. OpenVPN wspiera uwierzytelnianie z wykorzystaniem hasła (w połączeniu z mechanizmem opartym o klucze kryptograficzne) co dodatkowo wzmacnia bezpieczeństwo. Nie można jednak polegać tylko na haśle użytkownika, które na przykład może być nieskomplikowane i łatwe do odgadnięcia.\n\n**Certyfikaty X.509** - to kolejny obsługiwany przez OpenVPN mechanizm uwierzytelniania. Certyfikat X.509 zawiera klucz publiczny użytkownika lub serwera, oraz informacje identyfikacyjne powiązane z tym kluczem. Dodatkowo zawarty jest podpis cyfrowy urzędu certyfikacji, potwierdzający autentyczność klucza. OpenVPN umożliwia uwierzytelnianie serwera oraz klienta z użyciem certyfikatów X.509. Takie podejście pozwala zyskać dodatkowy poziom bezpieczeństwa, gdyż klucz publiczny oraz informacje identyfikujące podmiot są dodatkowo poświadczone przez zaufany urząd certyfikacji.\n\n**Protokół Kerberos** - to system uwierzytelniania oparty na biletach. Mechanizm ten nie jest natywnie obsługiwany przez OpenVPN. Kerberos jest często używany w systemach korporacyjnych, ale nie jest bezpośrednią metodą uwierzytelniania w OpenVPN bez dodatkowej konfiguracji, np z użyciem wtyczki PAM. Takie wtyczki są dostępne, ale nie są domyślną opcją w OpenVPN. \n\n**Biometrycznie, poprzez analizę długości rzutu beretem** - to absurdalny przykład uwierzytelniania, nie jest to żadna metoda uwierzytelniania i nie ma nic wspólnego z OpenVPN. W pytaniu celowo został użyty absurdalny przykład, aby odrzucić błędne rozwiązania. Biometria jest ciekawą metodą uwierzytelniania, ale w kontekście protokołu OpenVPN nie jest ona wykorzystywana.\n\nPodsumowując, OpenVPN do uwierzytelnienia klientów wykorzystuje głównie klucze kryptograficzne i certyfikaty X.509, a hasła i biometria nie są jego domyślnymi opcjami."
    },
    {
        "questionId": 59,
        "title": "Po uruchomieniu Notatnika na niskim poziomie integralnosci, moze on zapisywac pliki:",
        "answers": [
            {
                "text": "tylko w katalogach o przypisanym poziomie integralnosci co najwyzej niskim, np. %userprofile&/AppData/LocalLow",
                "isCorrect": true
            },
            {
                "text": "tylko w katalogach o przypisanym poziomie integralnosci co najmniej niskim, np. %userprofile&/Documents",
                "isCorrect": false
            },
            {
                "text": "nigdzie",
                "isCorrect": false
            },
            {
                "text": "tylko w katalogu z danymi tymczasowymi, np. %systemroot%/Temp",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "System Windows wykorzystuje mechanizm obowiązkowej kontroli integralności (ang. Mandatory Integrity Control - MIC) do regulowania dostępu procesów do obiektów systemu plików. Każdemu procesowi oraz obiektowi (plikom, folderom, procesom, rejestrze) przypisywany jest tzw. poziom integralności. Poziomy integralności to: Niski, Średni, Wysoki oraz System. Poziom niski ma najmniejsze uprawnienia, zaś poziom systemowy ma najwyższe. Procesy działające na poziomie niskim integralności są nazywane procesami o ograniczonym zaufaniu, typowym przykładem jest proces przeglądarki internetowej. Mechanizm MIC uniemożliwia procesom o niższym poziomie integralności zapisywanie danych do obiektów o wyższym poziomie integralności. Innymi słowy procesy z wyższym poziomem integralności mogą zapisywać dane w obiektach o niższym poziomie integralności, zaś procesy z niższym poziomem integralności nie mogą zapisywać danych w obiektach o wyższym poziomie integralności. Konkretne domyślne wartości poziomów integralności są przypisane do obiektów systemu plików i do katalogów.\n\n**Odpowiedź a: \"tylko w katalogach o przypisanym poziomie integralności co najwyżej niskim, np. %userprofile%\\AppData\\LocalLow\" jest poprawna.**\nProces działający z niskim poziomem integralności, na przykład Notatnik uruchomiony w takim trybie, ma ograniczone uprawnienia do zapisu w systemie plików. Oznacza to, że nie będzie miał prawa do zapisu danych do typowych folderów użytkownika o poziomie średnim, np. `Dokumenty`. Zapis może być dokonany tylko do katalogów o niskim poziomie integralności. Folder `%userprofile%\\AppData\\LocalLow` jest katalogiem przeznaczonym do przechowywania danych aplikacji pracujących z niskim poziomem integralności, dlatego zapis w nim będzie możliwy. W systemie Windows do przypisania określonego poziomu integralności do katalogu wykorzystuje się koncepcję tzw. etykiet integralności.\n\n**Odpowiedź b: \"tylko w katalogach o przypisanym poziomie integralności co najmniej niskim, np. %userprofile%\\Documents\" jest niepoprawna.**\nFolder `%userprofile%\\Documents` to typowy folder użytkownika, który domyślnie posiada średni poziom integralności. Proces o niskim poziomie integralności (np. Notatnik uruchomiony na niskim poziomie) nie może zapisać do tego folderu z uwagi na mechanizm obowiązkowej kontroli integralności MIC (proces o niższym poziomie nie ma uprawnień do zapisu do obiektów o wyższym poziomie). \n\n**Odpowiedź c: \"nigdzie\" jest niepoprawna.**\nProces o niskim poziomie integralności ma ograniczony dostęp do systemu plików, jednakże nadal może tworzyć pliki w specjalnie do tego przeznaczonych folderach np. `%userprofile%\\AppData\\LocalLow`. Zatem proces ten nie jest całkowicie odcięty od możliwości zapisu do systemu plików. \n\n**Odpowiedź d: \"tylko w katalogu z danymi tymczasowymi, np. %systemroot%\\Temp\" jest niepoprawna.**\nFolder `%systemroot%\\Temp` to folder systemowy do którego dostęp mają procesy pracujące z poziomu systemu. Domyślnie posiadają do niego dostęp procesy działające z wysokim poziomem integralności i nie tylko. Natomiast proces działający na niskim poziomie integralności nie może zapisywać danych do katalogu o wyższym poziomie."
    },
    {
        "questionId": 60,
        "title": "Wykorzystanie kryptograficznego podpisu wiadomosci pozwala odbiorcy zweryfikowac:",
        "answers": [
            {
                "text": "autentycznosc wiadomosci przy uzyciu klucza prywatnego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "autentycznosc wiadomosci przy uzyciu klucza publicznego nadawcy",
                "isCorrect": true
            },
            {
                "text": "autentycznosc wiadomosci przy uzyciu klucza prywatnego nadawcy",
                "isCorrect": false
            },
            {
                "text": "autentycznosc wiadomosci przy uzyciu klucza publicznego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "pochodzenie wiadomości przy użyciu klucza prywatnego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "pochodzenie wiadomości przy użyciu klucza publicznego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "pochodzenie wiadomości przy użyciu klucza prywatnego nadawcy",
                "isCorrect": false
            },
            {
                "text": "pochodzenie wiadomości przy użyciu klucza publicznego nadawcy",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Kryptograficzny podpis wiadomości, realizowany za pomocą kryptografii asymetrycznej, służy do zapewnienia autentyczności oraz nienaruszalności danych. Autentyczność potwierdza, że wiadomość pochodzi od deklarowanego nadawcy, natomiast nienaruszalność gwarantuje, że treść wiadomości nie została zmieniona podczas transmisji. \nProces podpisywania wiadomości wykorzystuje klucz prywatny nadawcy. Klucz prywatny jest znany tylko właścicielowi i służy do utworzenia podpisu, czyli specjalnego ciągu znaków. Ten podpis jest dołączany do wiadomości. Odbiorca, posiadając klucz publiczny nadawcy, może zweryfikować ten podpis. Klucz publiczny jest jawny i powszechnie dostępny, nie nadaje się do szyfrowania, ale doskonale nadaje się do weryfikacji podpisu, utworzonego za pomocą klucza prywatnego. \n\n**Odpowiedź 1: \"autentyczność wiadomości przy użyciu klucza prywatnego odbiorcy\" jest nieprawidłowa.** Klucz prywatny odbiorcy służy do odszyfrowywania wiadomości, a nie do weryfikacji podpisu cyfrowego. \n\n**Odpowiedź 2: \"autentyczność wiadomości przy użyciu klucza publicznego nadawcy\" jest prawidłowa.** Odbiorca używa klucza publicznego nadawcy do zweryfikowania podpisu wiadomości, potwierdzając, że nadawca jest tym, za kogo się podaje, oraz że wiadomość nie została zmodyfikowana. Bez odpowiedniego klucza prywatnego nadawcy niemożliwe byłoby wytworzenie prawidłowego podpisu, który można zweryfikować publicznym kluczem nadawcy. \nPrzykładowo, bank internetowy po przesłaniu do klienta dokumentu zawierającego dane dotyczące transakcji używa swojego klucza prywatnego aby złożyć podpis cyfrowy na tym dokumencie. Klient banku przy pomocy klucza publicznego banku jest w stanie zweryfikować pochodzenie dokumentu (i jego zawartość), że pochodzi on od zaufanego źródła (banku) i nie został po drodze zmodyfikowany.\n\n**Odpowiedź 3: \"autentyczność wiadomości przy użyciu klucza prywatnego nadawcy\" jest nieprawidłowa.** Klucz prywatny nadawcy służy do generowania podpisu cyfrowego, a nie do jego weryfikacji. Zatem odbiorca nie posłuży się kluczem prywatnym nadawcy do weryfikacji autentyczności wiadomości.\n\n**Odpowiedź 4: \"autentyczność wiadomości przy użyciu klucza publicznego odbiorcy\" jest nieprawidłowa.** Klucz publiczny odbiorcy służy do szyfrowania wiadomości przesyłanej do odbiorcy, a nie do weryfikacji podpisu cyfrowego. Zatem odbiorca nie posłuży się kluczem publicznym odbiorcy aby zweryfikować autentyczność wiadomości.\n\n**Odpowiedź 5: \"pochodzenie wiadomości przy użyciu klucza prywatnego odbiorcy\" jest nieprawidłowa.** Klucz prywatny odbiorcy służy do odszyfrowania wiadomości i nie ma nic wspólnego z potwierdzeniem pochodzenia (nadawcy). Zatem odbiorca nie posłuży się kluczem prywatnym odbiorcy aby zweryfikować pochodzenie wiadomości.\n\n**Odpowiedź 6: \"pochodzenie wiadomości przy użyciu klucza publicznego odbiorcy\" jest nieprawidłowa.** Klucz publiczny odbiorcy służy do szyfrowania wiadomości przesyłanej do odbiorcy, a nie do weryfikacji pochodzenia (nadawcy). Zatem odbiorca nie posłuży się kluczem publicznym odbiorcy aby zweryfikować pochodzenie wiadomości.\n\n**Odpowiedź 7: \"pochodzenie wiadomości przy użyciu klucza prywatnego nadawcy\" jest nieprawidłowa.** Klucz prywatny nadawcy służy do generowania podpisu, a nie do weryfikacji. Klucz prywatny, z definicji, jest znany tylko nadawcy, zatem odbiorca nie ma do niego dostępu i nie może go wykorzystać do weryfikacji pochodzenia wiadomości.\n\n**Odpowiedź 8: \"pochodzenie wiadomości przy użyciu klucza publicznego nadawcy\" jest prawidłowa.** Odbiorca używa klucza publicznego nadawcy do zweryfikowania podpisu, potwierdzając tym samym, że wiadomość pochodzi od deklarowanego nadawcy. Jeśli podpis jest poprawny wiadomość na pewno pochodzi od nadawcy, ponieważ wiadomość została podpisana jego kluczem prywatnym. Tylko posiadacz klucza prywatnego może złożyć poprawny podpis wiadomości.  Podpis cyfrowy jest generowany przy użyciu klucza prywatnego nadawcy, a następnie weryfikowany przy użyciu publicznego klucza nadawcy. Dzięki temu odbiorca ma pewność co do pochodzenia wiadomości. Przykładowo, aby mieć pewność, że aktualizacja oprogramowania, którą pobierasz, faktycznie pochodzi od producenta, a nie od osoby podszywającej się pod producenta, należy użyć klucza publicznego producenta do zweryfikowania podpisu cyfrowego na tej aktualizacji."
    },
    {
        "questionId": 61,
        "title": "Wykorzystanie kryptograficznego podpisu wiadomosci pozwala odbiorcy zweryfikowac:",
        "answers": [
            {
                "text": "pochodzenie wiadomosci przy uzyciu klucza prywatnego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "pochodzenie wiadomosci przy uzyciu klucza publicznego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "pochodzenie wiadomosci przy uzyciu klucza prywatnego nadawcy",
                "isCorrect": false
            },
            {
                "text": "pochodzenie wiadomosci przy uzyciu klucza publicznego nadawcy",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Kryptograficzny podpis wiadomości (podpis cyfrowy) wykorzystuje asymetryczną kryptografię, gdzie każda strona ma parę kluczy: prywatny i publiczny. Klucz prywatny jest znany tylko właścicielowi i służy do podpisywania wiadomości (tworzenia podpisu), klucz publiczny jest powszechnie dostępny i służy do weryfikacji autentyczności podpisu.\n\n**Odpowiedź 1: \"pochodzenie wiadomości przy użyciu klucza prywatnego odbiorcy\" - Niepoprawna**\n   - Ta odpowiedź jest niepoprawna, ponieważ klucz prywatny odbiorcy służy do odszyfrowania wiadomości, która została zaszyfrowana kluczem publicznym odbiorcy, a nie do weryfikacji podpisu. Do weryfikacji podpisu wykorzystywany jest klucz publiczny, nie prywatny.\n    - **Przykład:** Jeśli Alicja wysyła zaszyfrowaną i podpisaną wiadomość do Bolka, to Bolek użyje swojego klucza prywatnego, aby odszyfrować treść wiadomości (w przypadku jeśli wiadomość została zaszyfrowana), natomiast wykorzystuje klucz publiczny Alicji aby sprawdzić autentyczność jej podpisu.\n\n**Odpowiedź 2: \"pochodzenie wiadomości przy użyciu klucza publicznego odbiorcy\" - Niepoprawna**\n    - Ta odpowiedź jest niepoprawna, ponieważ klucz publiczny odbiorcy służy do szyfrowania wiadomości, która może być potem odszyfrowana tylko za pomocą klucza prywatnego odbiorcy. Klucz publiczny odbiorcy nie ma żadnego zastosowania przy weryfikacji podpisu.\n    - **Przykład:** Jeśli Alicja wysyła wiadomość do Bolka, to Bolek użyje swojego klucza publicznego do zaszyfrowania wiadomości, natomiast nie do weryfikacji podpisu.\n\n**Odpowiedź 3: \"pochodzenie wiadomości przy użyciu klucza prywatnego nadawcy\" - Niepoprawna**\n    - Ta odpowiedź jest niepoprawna, ponieważ klucz prywatny nadawcy służy do podpisania wiadomości (tworzenia podpisu), ale nie do weryfikacji tego podpisu. Weryfikacji może dokonać każdy, kto ma dostęp do klucza publicznego nadawcy.\n     - **Przykład:** Jeśli Alicja wysyła wiadomość, to użyje swojego klucza prywatnego do podpisania wiadomości. Nie może sama zweryfikować własnego podpisu (gdyż do tego służy publiczny klucz).\n\n**Odpowiedź 4: \"pochodzenie wiadomości przy użyciu klucza publicznego nadawcy\" - Poprawna**\n    - Ta odpowiedź jest poprawna, ponieważ do weryfikacji kryptograficznego podpisu wiadomości używa się klucza publicznego nadawcy. Podpis generowany jest kluczem prywatnym nadawcy, a klucz publiczny jest dostępny dla każdego i używany w procesie weryfikacji. Ten mechanizm daje pewność co do pochodzenia wiadomości.\n    - **Przykład:** Jeśli Alicja podpisze wiadomość swoim kluczem prywatnym, a następnie roześle tę wiadomość publicznie, każdy może sprawdzić autentyczność tego podpisu używając klucza publicznego Alicji (który powszechnie udostępniła) . Zatem tożsamość nadawcy jest w ten sposób udowodniona, nikt nie może podszyć się pod nią.\n\n**Praktyczne implikacje:**\n   - **S/MIME:** W emailach podpisy cyfrowe, bazujące na podobnych zasadach, pozwalają na sprawdzenie, czy nadawca wiadomości jest tym, za kogo się podaje.\n   - **Code signing:** Podpisy cyfrowe są również stosowane do podpisywania plików wykonywalnych, co pozwala upewnić się, że program pochodzi od zaufanego twórcy.\n   - **SSL/TLS:** Certyfikaty SSL/TLS używane do zabezpieczenia stron internetowych wykorzystują podpis cyfrowy do zweryfikowania autentyczności serwera (który jest połączony ze swoim kluczem publicznym)."
    },
    {
        "questionId": 62,
        "title": "Dodanie klucza wygenerowanego dla nowego agenta DRA, do istniejacego wczesniej zaszyfrowanego pliku, mozna uzyskac:",
        "answers": [
            {
                "text": "automatycznie, poprzez otwarcie tego pliku przez nowego agenta DRA",
                "isCorrect": false
            },
            {
                "text": "automatycznie, przy pierwszym otwarciu tego pliku przez dowolnego administratora",
                "isCorrect": false
            },
            {
                "text": "samoczynnie, przy okazji pierwszego dostepu do pliku kogos mogacego odszyfrowac ten plik",
                "isCorrect": false
            },
            {
                "text": "wydajac polecenie cipher /u",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm EFS (Encrypting File System) w systemach operacyjnych Windows umożliwia szyfrowanie plików i katalogów w systemie plików NTFS. Dane są szyfrowane za pomocą klucza symetrycznego, który jest generowany losowo dla każdego pliku. Klucz ten jest z kolei szyfrowany kluczem publicznym użytkownika, który stworzył plik i tylko ten użytkownik może dany plik odszyfrować. Mechanizm Data Recovery Agent (DRA) pozwala administratorom systemu lub osobom posiadającym odpowiednie uprawnienia odzyskać pliki zaszyfrowane przez EFS, gdy zwykli użytkownicy stracą dostęp do klucza szyfrowania (np. zapomną hasła lub w przypadku awarii dysku i braku kopii certyfikatów). Każdy plik szyfrowany przez EFS ma listę DRA z którymi jest powiązany.  \nDodanie klucza wygenerowanego dla nowego agenta DRA, do istniejacego wczesniej zaszyfrowanego pliku, nie jest procesem automatycznym. Do tego celu służy narzędzie wiersza poleceń `cipher`, które pozwala zarządzać ustawieniami szyfrowania dla EFS.  \n  * **automatycznie, poprzez otwarcie tego pliku przez nowego agenta DRA** - jest to niepoprawna odpowiedź. Działanie DRA jest powiązane z listą DRA zaszyfrowanych danych. Dodanie nowego klucza DRA wymaga jawnej modyfikacji metadanych pliku. Samo otwarcie pliku nie spowoduje, że nowy klucz DRA zostanie dodany do metadanych pliku.   \n  * **automatycznie, przy pierwszym otwarciu tego pliku przez dowolnego administratora** - jest to niepoprawna odpowiedź. Administrator nie ma automatycznego dostępu do zaszyfrowanych danych. Jedynie użytkownik, który zaszyfrował plik oraz agenci odzyskiwania danych powiązani z plikiem, poprzez certyfikat, mają możliwość odszyfrowania zaszyfrowanych plików.   \n  * **samoczynnie, przy okazji pierwszego dostepu do pliku kogos mogacego odszyfrowac ten plik** - jest to niepoprawna odpowiedź. Ponieważ proces odszyfrowania powiązany jest z użytkownikiem, który zaszyfrował dane lub osobę, która posiada uprawnienia odzyskiwania danych, procedura dodania nowego agenta DRA nie następuje automatycznie. \n  * **wydajac polecenie cipher /u** - jest to poprawna odpowiedź. Narzędzie `cipher` jest narzędziem wiersza poleceń (ang. command-line tool) w systemie Windows, które służy do zarządzania szyfrowaniem plików i folderów. Opcja `/u`  spowoduje dodanie klucza DRA do już zaszyfrowanego pliku. Powoduje to, że agent DRA, którego klucz publiczny został użyty przy dodaniu, będzie mógł bez problemu odzyskać plik. Na przykład: `cipher /u plik.txt` doda DRA do zaszyfrowanego pliku `plik.txt`. Należy podkreślić iż, polecenie jest wykonywane w kontekście użytkownika z uprawnieniami administratora lub w kontekście użytkownika posiadającego certyfikat DRA. \n    \n    Przykładowo administrator systemu \"admin\" generuje nowy certyfikat DRA i dodaje go do pliku zaszyfrowanego przez użytkownika \"jan\". Zastosowanie polecenia `cipher /u` przez administratora \"admin\" spowoduje, że dane będzie mógł odczytać również administrator \"admin\" a nie tylko użytkownik \"jan\" oraz poprzedni agenci odzyskiwania danych. Polecenie nie będzie miało efektu, jeśli klucz certyfikatu nie będzie ważny lub będzie niekompletny, gdyż samo odczytanie hasła nie spowoduje dodania do pliku metadanych nowego agenta DRA."
    },
    {
        "questionId": 63,
        "title": "Program SSH mozna wykorzystac m.in. do:",
        "answers": [
            {
                "text": "stworzenia dynamicznego proxy aplikacyjnego",
                "isCorrect": true
            },
            {
                "text": "przekierowywania portow zdalnego serwera do maszyny lokalnej (klienta)",
                "isCorrect": true
            },
            {
                "text": "stworzenia proxy www wylacznie dla protokolu HTTPS",
                "isCorrect": false
            },
            {
                "text": "przekierowywania portow maszyny lokalnej (klienta) do zdalnego serwera",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) to narzędzie umożliwiające bezpieczne zdalne logowanie oraz tunelowanie. Tunelowanie polega na przekierowywaniu ruchu sieciowego przez zaszyfrowane połączenie SSH, co pozwala na ochronę przesyłanych danych i ominięcie niektórych ograniczeń sieciowych. SSH, bazując na kryptografii symetrycznej i asymetrycznej, zapewnia poufność, integralność i autentyczność przesyłanych danych. \n\n**Odpowiedź 1: \"stworzenia dynamicznego proxy aplikacyjnego\" - POPRAWNA.**\nSSH może pełnić funkcję dynamicznego proxy aplikacyjnego (SOCKS proxy) dzięki opcji `-D`.  Dzięki temu aplikacje (np. przeglądarka internetowa) mogą wykorzystać tunel SSH, aby kierować swój ruch przez serwer SSH, maskując swój adres IP i zapewniając bezpieczną komunikację. Przykładowo, uruchamiając `ssh -D 8080 user@host` utworzymy dynamiczny proxy SOCKS na porcie 8080 na lokalnym komputerze. Aplikacje skonfigurowane, aby korzystać z tego proxy, będą mogły  przesyłać swój ruch przez  zaszyfrowany tunel do hosta, a następnie do internetu. Dzięki temu, gdy jesteśmy połączeni z niezaufaną siecią WiFi, możemy skierować cały ruch naszej przeglądarki przez nasz komputer z ssh. \n\n**Odpowiedź 2: \"przekierowywania portów zdalnego serwera do maszyny lokalnej (klienta)\" - POPRAWNA.**\nSSH umożliwia przekierowanie portów z serwera zdalnego na porty maszyny lokalnej przy pomocy opcji `-R` (remote port forwarding).  Używamy tego w sytuacji, gdy serwer zdalny znajduje się za firewall-em, nie jest publicznie dostępny, a my chcemy udostępnić usługę z tego serwera w lokalnej sieci.  Przykładowo, aby udostępnić bazę danych z portu 3306 na zdalnym serwerze, na lokalnym komputerze można uruchomić  `ssh -R 9999:localhost:3306 user@host`. W efekcie, wszelki ruch na port 9999 lokalnego hosta zostanie zaszyfrowany, przesłany na serwer SSH i z serwera przekierowany na port 3306  serwera z bazą danych.  \n\n**Odpowiedź 3: \"stworzenia proxy www wylacznie dla protokolu HTTPS\" - NIEPOPRAWNA.**\nSSH nie jest proxy dedykowanym tylko dla HTTPS. Chociaż SSH może być wykorzystane do utworzenia bezpiecznego tunelu, który następnie może być użyty przez przeglądarkę do tunelowania ruchu HTTPS, to sam SSH obsługuje połączenia TCP i nie zależy od protokołu wyższych warstw, takich jak HTTP czy HTTPS. Tunel SSH jest uniwersalny i może być wykorzystany do transferu danych dowolnej usługi w warstwie transportowej (TCP) i opcjonalnie (w nowszych implementacjach OpenSSH) do dowolnego ruchu warstwy niższej.\n\n**Odpowiedź 4: \"przekierowywania portów maszyny lokalnej (klienta) do zdalnego serwera\" - POPRAWNA.**\nSSH umożliwia przekierowanie portów lokalnej maszyny na porty serwera zdalnego z użyciem opcji `-L` (local port forwarding).  Używamy tego w sytuacji, gdy z naszego komputera chcemy bezpiecznie  połączyć się z usługą działającą na serwerze zdalnym. Na przykład,  `ssh -L 8080:localhost:80  user@host` spowoduje przekierowanie ruchu z portu 8080 lokalnego komputera, przez zaszyfrowany kanał ssh, na port 80  zdalnego serwera. Dzięki temu możemy bezpiecznie  korzystać z usługi HTTP na serwerze zdalnym, nawet jeśli port 80 serwera zdalnego jest niedostępny publicznie."
    },
    {
        "questionId": 64,
        "title": "Uprawnienia domyslne na liscie POSIX ACL nadawane sa:",
        "answers": [
            {
                "text": "jedynie plikom wykonywalnym w celu uscislenia jakie uprawnienia maja miec pliki tworzone w czasie dzialania tych programow",
                "isCorrect": false
            },
            {
                "text": "jedynie katalogom w celu inicjowania list ACL nowo tworzonym plikom",
                "isCorrect": true
            },
            {
                "text": "plikom i katalogom w celu okreslenia uprawnien w przypadku braku pasujacego wpisu ACE",
                "isCorrect": false
            },
            {
                "text": "plikom i katalogom w celu okreslenia ACL w przypadku ich kopiowania lub przenoszenia do innego katalogu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Domyślne uprawnienia w listach kontroli dostępu POSIX ACL (_ang. Access Control Lists_) są stosowane **wyłącznie do katalogów**, aby inicjować ACL dla nowo tworzonych plików i katalogów wewnątrz tego katalogu.  POSIX ACL to rozszerzenie tradycyjnego systemu uprawnień w systemach Linux/Unix, który definiuje prawa dostępu dla właściciela pliku, grupy do której należy plik oraz pozostałych użytkowników systemu. ACL pozwala na zdefiniowanie praw dla konkretnych użytkowników i/lub grup, niezależnie od właściciela pliku lub jego grupy. Dodatkowo w listach ACL występuje mechanizm domyślnych uprawnień, które nie odnoszą się do istniejących plików, a jedynie do tych, które zostaną stworzone w przyszłości w katalogu z ustawionymi domyślnymi uprawnieniami. Domyślne uprawnienia działają jako swego rodzaju szablon, który ma określić automatycznie jak będą wyglądać uprawnienia do nowo utworzonego pliku lub katalogu. \n\n**Odpowiedź 1: \"jedynie plikom wykonywalnym w celu uscislenia jakie uprawnienia maja miec pliki tworzone w czasie dzialania tych programow\"** jest **niepoprawna** ponieważ uprawnienia domyślne nie działają na pliki, a jedynie na katalogi. Intencją tych uprawnień nie jest również ścisłe określenie jakie uprawnienia mają mieć pliki tworzone w czasie działania programu, a jedynie inicjowanie tych uprawnień poprzez listę kontroli dostępu. Mechanizm ten nie kontroluje tego w jaki sposób program tworzy pliki. To, jak program ustawi uprawnienia tworzonego pliku, zależy od konkretnej implementacji programu.\n\n**Odpowiedź 2: \"jedynie katalogom w celu inicjowania list ACL nowo tworzonym plikom\"** jest **poprawna**, gdyż domyślne ACL stosowane są wyłącznie do katalogów i mają na celu ustawianie ACL dla nowo tworzonych plików. Oznacza to, że istniejące pliki i katalogi nie są objęte domyślnymi uprawnieniami.\n\n**Odpowiedź 3: \"plikom i katalogom w celu okreslenia uprawnien w przypadku braku pasujacego wpisu ACE\"** jest **niepoprawna**. Mechanizm domyślnych uprawnień nie ma na celu działania w przypadku gdy brak wpisu ACE(ang. _Access Control Entry_), domyślne uprawnienia definiują ACE, które zostaną ustawione dla nowo tworzonego zasobu(pliku lub katalogu). Brak ACE w liście ACL objawia się w odrzuceniu danego żądania dostępu.\n\n**Odpowiedź 4: \"plikom i katalogom w celu okreslenia ACL w przypadku ich kopiowania lub przenoszenia do innego katalogu\"** jest **niepoprawna** gdyż mechanizm domyślnych uprawnień nie działa w ten sposób. Domyślne uprawnienia działają w momencie tworzenia zasobu i odnoszą się do nowo tworzonego pliku. Kopiowanie i przenoszenie zasobu pomija mechanizm domyślnych uprawnień, chociaż niektóre systemy operacyjne posiadają rozszerzenia pozwalające zachować uprawnienia ACL, które zostały nadane do konkretnego zasobu. \n\nPrzykład: Użytkownik *adam* tworzy katalog `test_dir` i ustawia domyślne uprawnienia, które pozwalają użytkownikowi *ewa* na odczyt plików.\n```\nmkdir test_dir\nsetfacl -d -m user:ewa:r test_dir\n```\nTeraz jeśli użytkownik *adam* stworzy w katalogu test_dir nowy plik *newfile.txt*, to użytkownik *ewa* automatycznie otrzyma prawo do odczytu tego pliku. Plik ten zostanie stworzony z ACL zainicjowaną przez mechanizm domyślnych uprawnień. Istotne jest, iż jeśli użytkownik *adam* stworzy plik newfile.txt poza katalogiem test_dir, a następnie skopiuje go do katalogu test_dir, to uprawnienia nie zostaną zmodyfikowane. Do modyfikacji uprawnień konieczne jest użycie polecenia `setfacl`. Domyślne uprawnienia nie działają wstecz, a jedynie przy tworzeniu nowych plików i katalogów."
    },
    {
        "questionId": 65,
        "title": "(żółte odpowiedzi) Ktore z ponizszych zdarzen sa efektami braku wirtualizacji danego klucza rejestru systemu Windows?",
        "answers": [
            {
                "text": "operacja zapisu wartosci parametrow tego klucza przez proces nie posiadajacy uprawnienia zapisu konczy sie powodzeniem",
                "isCorrect": false
            },
            {
                "text": "operacja zapisu wartosci parametrow tego klucza przez proces posiadajacy uprawnienie zapisu konczy sie bledem",
                "isCorrect": false
            },
            {
                "text": "operacja zapisu wartosci parametrow tego klucza przez proces nie posiadajacy uprawnienia zapisu konczy sie powodzeniem",
                "isCorrect": true
            },
            {
                "text": "operacja zapisu wartosci parametrow tego klucza przez proces nie posiadajacy uprawnienia zapisu konczy sie bledem",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Wirtualizacja kluczy rejestru w systemie Windows ma na celu izolowanie procesów od bezpośredniego dostępu do kluczy rejestru. Bez wirtualizacji, aplikacje (procesy) mogą próbować bezpośrednio zapisywać do rzeczywistych kluczy rejestru. Rejestr systemu Windows to hierarchiczna baza danych, która przechowuje ustawienia konfiguracyjne systemu operacyjnego oraz zainstalowanych aplikacji. Uprawnienia (ang. *privileges*) do kluczy rejestru decydują o tym, które aplikacje i użytkownicy mogą odczytywać lub zapisywać te ustawienia.\n\n**Odpowiedź 1: \"operacja zapisu wartości parametrów tego klucza przez proces nie posiadający uprawnienia zapisu kończy się powodzeniem\" - NIEPRAWIDŁOWA.**\nBez wirtualizacji, proces nieposiadający uprawnień zapisu, który próbuje zapisać dane do rzeczywistego klucza, *nie powinien* zakończyć operacji sukcesem, jeżeli system operacyjny właściwie stosuje mechanizmy kontroli dostępu. Wirtualizacja rejestru to mechanizm dodany w nowszych systemach Windows, który ma za zadanie m.in. chronić uprzywilejowane klucze przed nieautoryzowanym dostępem. Bez niego działają klasyczne mechanizmy uprawnień systemu. W praktyce, jeśli proces nie ma uprawnień, jego próba zapisu powinna się zakończyć błędem. Należy podkreślić, że brak wirtualizacji *nie oznacza* automatycznie, że proces nie mający uprawnień, będzie mógł dokonać zapisu.\n\n**Odpowiedź 2: \"operacja zapisu wartości parametrów tego klucza przez proces posiadający uprawnienie zapisu kończy się błędem\" - NIEPRAWIDŁOWA.**\nProces posiadający uprawnienia zapisu do danego klucza rejestru *powinien* mieć możliwość zapisu, jeśli włączone są standardowe mechanizmy kontroli dostępu a wirtualizacja nie występuje. Wirtualizacja nie jest mechanizmem utrudniającym standardowe działanie systemu. Brak wirtualizacji nie powoduje, że uprawnienia systemu przestają działać, jedynie oznacza brak mechanizmów izolacji dostępu do kluczy.\n\n**Odpowiedź 3: \"operacja zapisu wartości parametrów tego klucza przez proces nie posiadający uprawnienia zapisu kończy się powodzeniem\" - PRAWIDŁOWA.**\nBrak wirtualizacji oznacza, że proces (program) próbuje zapisać wartość parametru w *rzeczywistym* kluczu rejestru. Jeżeli proces nie ma *bezpośredniego* uprawnienia do zapisu, to w idealnym środowisku (z poprawnie działającym mechanizmem kontroli dostępu) taka próba zakończy się błędem. Jednakże, w środowiskach w których nie wszystkie funkcje kontroli dostępu są włączone może zdarzyć się sytuacja, że proces bez uprawnień dokona jednak zapisu do chronionego klucza. Taki przypadek również świadczy o niepoprawnie działającym mechanizmie kontroli dostępu. W środowisku z włączoną wirtualizacją taka operacja nie powinna się powieść. Brak wirtualizacji oznacza tutaj, że nie ma dodatkowej warstwy pośredniczącej w obsłudze dostępu do kluczy. Przy włączonej wirtualizacji, proces, nawet jeśli próbuje zapisywać do chronionego klucza, to w istocie zapisuje do jego wirtualnego odpowiednika, co chroni rzeczywisty klucz przed nieautoryzowanymi zmianami. Dlatego, brak wirtualizacji stwarza potencjalną furtkę do nadużyć. \n\n**Odpowiedź 4: \"operacja zapisu wartości parametrów tego klucza przez proces nie posiadający uprawnienia zapisu kończy się błędem\" - PRAWIDŁOWA.**\nBrak wirtualizacji oznacza, że proces próbuje zapisać bezpośrednio w kluczu rejestru, który jest chroniony z wykorzystaniem standardowych mechanizmów kontroli dostępu systemu Windows, ale system nie wykorzystuje żadnych dodatkowych mechanizmów. Brak odpowiednich uprawnień do zapisu powinien w takim przypadku spowodować wystąpienie błędu. Zatem brak wirtualizacji nie oznacza, że proces bez uprawnień *zawsze* dokona zapisu. Jest to potencjalnie możliwe i należy na to zwracać szczególną uwagę, gdyż zablokowanie takiej możliwości za każdym razem jest celem wdrożenia wirtualizacji. Podsumowując brak wirtualizacji tworzy *potencjalne* zagrożenie, że proces bez uprawnień jednak zdoła zapisać, lecz nie ma gwarancji, że zawsze tak będzie. Zatem, brak wirtualizacji powoduje, że operacje zapisu przez nieautoryzowane procesy *powinny* kończyć się błędem, lecz może zdarzyć się inaczej - co jest niepożądane, lecz możliwe."
    },
    {
        "questionId": 66,
        "title": "Z jaka inna opcja polityki silnych hasel ma bezposredni zwiazek ilosc hasel pamietanych w historii?",
        "answers": [
            {
                "text": "maksymalny okres waznosci hasla",
                "isCorrect": false
            },
            {
                "text": "minimalny okres waznosci",
                "isCorrect": true
            },
            {
                "text": "minimalna dlugosc hasla",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm historii haseł, czyli \"ilość haseł pamiętanych w historii\", to funkcja bezpieczeństwa systemu operacyjnego, która zapobiega ponownemu użyciu wcześniej stosowanych haseł. Gdy użytkownik zmienia hasło, system przechowuje określony wcześniej zbiór poprzednich haseł. Podczas każdej próby zmiany hasła system porównuje nowe hasło ze wszystkimi hasłami zapisanymi w historii i nie pozwala na ustawienie hasła, które znajduje się w tym zbiorze. Ten mechanizm ma za zadanie utrudnić sytuacje, w której użytkownik cyklicznie wraca do swoich ulubionych i dobrze znanych haseł, które mogą okazać się podatne na złamanie. \n\nMinimalny okres ważności hasła (\"minimalny okres ważności\") jest parametrem, który określa minimalny czas jaki musi upłynąć zanim użytkownik będzie mógł ponownie zmienić hasło. Parametr ten w połączeniu z mechanizmem historii haseł powoduje, że użytkownik nie może tak często zmieniać hasła aby ominąć ochronę oferowaną przez mechanizm historii. Na przykład, jeżeli minimalny okres ważności hasła wynosi 2 dni a historia haseł przechowuje 3 ostatnie hasła, użytkownik będzie musiał użyć przynajmniej 4 nowego hasła, aby w pełni ominąć mechanizm historii haseł. W przypadku braku tego parametru, a włączeniu jedynie mechanizmu historii haseł, użytkownik, aby pominąć tą ochronę musiałby wprowadzić odpowiednio dużą liczbę nowych haseł aby te hasła zamazać w historii haseł, następnie mógłby powrócić do hasła wcześniej wykorzystywanego. \n\nMaksymalny okres ważności hasła (\"maksymalny okres ważności hasła\") określa po jakim czasie hasło przestaje być ważne i system zmusza użytkownika do zmiany hasła, w tym przypadku nie ma bezpośredniego powiązania z \"ilością haseł pamiętanych w historii\", aczkolwiek pośrednio wpływa to na bezpieczeństwo. Zmiana hasła co pewien czas powoduje, że nawet jak hasło zostanie wykradzione przez osoby trzecie to po upływie określonego czasu haseł będzie nieprzydatne. \n\nMinimalna długość hasła (\"minimalna długość hasła\") to parametr, który określa minimalną liczbę znaków jaką musi mieć wpisywane hasło. Ma to znaczenie w kontekście trudności złamania hasła. Im hasło dłuższe tym trudniejsze jest złamanie takiego hasła metodą ataku siłowego. Jednak długość hasła nie ma wpływu na mechanizm historii haseł. \n\nPodsumowując, \"ilość haseł pamiętanych w historii\" ma bezpośredni związek z parametrem minimalny okres ważności hasła. Jeżeli dany parametr nie jest ustawiony na odpowiednio dużą wartość to mechanizm historii haseł traci na wartości. Na przykład jeżeli minimalny okres ważności hasła jest ustawiony na 0 dni, a mechanizm historii pamięta 10 haseł, użytkownik po 10 zmianach hasła może powrócić do wcześniej wykorzystywanego hasła. A w celu utrudnienia tego procesu należy minimalny okres ważności hasła ustawić na jakąś wartość większą niż zero, aby wymusić na użytkowniku w dłuższej perspektywie czasowej ciągłego ustawiania nowych haseł."
    },
    {
        "questionId": 67,
        "title": "Jak modyfikowana jest maska uprawnien POSIX ACL przy zmianie uprawnien do danego pliku:",
        "answers": [
            {
                "text": "nowa maska jest alternatywa bitowa uprawnien nazwanych uzytkownikow, grupy i nazwanych grup",
                "isCorrect": true
            },
            {
                "text": "nowa maska jest alternatywa bitowa starej maski i wszystkich uprawnien nowo nadanych przez setfacl",
                "isCorrect": false
            },
            {
                "text": "nowa maska jest iloczynem logicznym starej maski i wszystkich uprawnien nowo nadanych przez setfacl",
                "isCorrect": false
            },
            {
                "text": "nowa maska jest alternatywa bitowa wszystkich uprawnien danego pliku (wlasciciela, grupy, pozostalych, nazwanych uzytkownikow, nazwanych grup)",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Maska uprawnień w POSIX ACL jest dynamicznie modyfikowana, aby odzwierciedlać efektywne uprawnienia, które są przyznawane nazwanych użytkownikom i grupom.  Nie jest to oddzielna, statyczna wartość, która jest niezależna od tych uprawnień.\n\n**Poprawna odpowiedź: \"nowa maska jest alternatywą bitową uprawnień nazwanych użytkowników, grupy i nazwanych grup\"**\n\nMaska uprawnień w POSIX ACL (Access Control List) działa jak filtr. Zapisujemy konkretne uprawnienia dla właściciela pliku, grupy, pozostałych użytkowników oraz użytkowników i grup nazwanym (którzy są dodani do ACL za pomocą polecenia `setfacl`). Maska reguluje uprawnienia dla nazwanych grup i użytkowników. Nowa maska jest obliczana na podstawie uprawnień, jakie zostały explicitnie nadane dla nazwanych grup i użytkowników za pomocą polecenia `setfacl`.  Do obliczenia nowej maski uprawnień, brane są wszystkie uprawnienia, jakie zostały przyznane danemu plikowi lub katalogowi dla wszystkich nazwanych grup i użytkowników, czyli sumowane w postaci alternatywy bitowej.\n\nNa przykład, jeśli użytkownik `user1` ma prawa odczytu i zapisu (`rw-`) do pliku, a grupa `group1` ma prawa odczytu i wykonania (`r-x`) do tego samego pliku, to maska jest tworzona poprzez bitową operację OR (alternatywa bitowa) uprawnień `rw-` i `r-x`, co w rezultacie da maskę posiadającą uprawnienia do odczytu, zapisu i wykonania (`rwx`). Oznacza to, że użytkownik `user1` będzie miał dostęp do zapisu a użytkownicy z grupy `group1` będą mogli wykonywać skrypty.\n\n**Niepoprawna odpowiedź: \"nowa maska jest alternatywą bitową starej maski i wszystkich uprawnień nowo nadanych przez setfacl\"**\n\nTa odpowiedź jest niepoprawna, ponieważ stara maska nie uczestniczy w procesie tworzenia nowej maski. Nowa maska tworzona jest jedynie na podstawie sumy uprawnień przypisanych za pomocą polecenia `setfacl`, a nie poprzez sumowanie starej maski z nowymi uprawnieniami. Maska w POSIX ACL jest dynamiczna i wynika z nadawanych uprawnień, a nie z wcześniej ustawionej wartości.  Za pomocą polecenia setfacl ustawiamy uprawnienia, nie modyfikujemy maski uprawnień, modyfikacja maski następuje niejako jako efekt uboczny po nadaniu uprawnień.\n\n**Niepoprawna odpowiedź: \"nowa maska jest iloczynem logicznym starej maski i wszystkich uprawnień nowo nadanych przez setfacl\"**\n\nTa odpowiedź jest niepoprawna, ponieważ do obliczenia nowej maski wykorzystywana jest alternatywa bitowa, a nie iloczyn bitowy. Operacja AND (iloczyn bitowy) powodowałaby, że maska byłaby zbyt restrykcyjna i uniemożliwiłaby uzyskanie jakichkolwiek uprawnień, które nie były zawarte w obu argumentach operacji. W POSIX ACL do obliczania maski stosuje się OR (alternatywa bitowa).\n\n**Niepoprawna odpowiedź: \"nowa maska jest alternatywą bitową wszystkich uprawnień danego pliku (właściciela, grupy, pozostałych, nazwanych użytkowników, nazwanych grup)\"**\n\nTa odpowiedź jest niepoprawna, ponieważ maska w POSIX ACL nie ma powiązania z uprawnieniami właściciela, grupy i pozostałych użytkowników. Maskę ustawia się, aby regulować uprawnienia tylko i wyłącznie dla nazwanych grup i użytkowników dodanych do ACL i tylko na ich podstawie jest tworzona nowa maska. Nie ma żadnej zależności między uprawnieniami właściciela grupy i pozostałych użytkowników a maską."
    },
    {
        "questionId": 68,
        "title": "Czyje haslo wymagane jest przy uruchomieniu polecenia sudo?",
        "answers": [
            {
                "text": "zawsze administratora systemu",
                "isCorrect": false
            },
            {
                "text": "zawsze uzytkownika wywolujacego dane polecenie",
                "isCorrect": false
            },
            {
                "text": "w zaleznosci od ustawien w polityce sudoers",
                "isCorrect": true
            },
            {
                "text": "zawsze uzytkownika z uprawnieniami ktorego chcemy wykonac dane polecenie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`sudo` to polecenie w systemach Linux i Unix umożliwiające użytkownikom uruchamianie programów z uprawnieniami innego użytkownika, najczęściej administratora (root). Domyślnie, `sudo` wymaga podania hasła użytkownika, który wywołuje polecenie, aby potwierdzić, że ten użytkownik ma prawo do eskalacji uprawnień. Jednak ta zasada może być całkowicie zmieniona poprzez konfiguracje pliku `/etc/sudoers`. Plik ten definiuje, które polecenia mogą być wykonywane przez jakich użytkowników lub grupy użytkowników, i z jakimi uprawnieniami (jakiego innego użytkownika). Może również określać czy do wykonania polecenia wymagane jest podanie hasła.  \n\nOpcja **zawsze administratora systemu** jest niepoprawna. `sudo` nie wymaga *zawsze* hasła administratora. W pliku `/etc/sudoers` można zdefiniować, że konkretne polecenia mogą być wykonywane przez konkretnych użytkowników *bez* potrzeby podawania hasła. Na przykład, użytkownik `piotr` może być uprawniony do uruchamiania polecenia `systemctl restart apache2` bez podawania hasła. Konfiguruje się to wpisem w `sudoers`, pozwalającym na wyeliminowanie podawania hasła root przez `piotr` w wybranej sytuacji: \n```\npiotr   ALL = NOPASSWD: /usr/bin/systemctl restart apache2 \n```\nW takim przypadku, polecenie `sudo systemctl restart apache2` wykonane przez użytkownika `piotr` nie poprosi o hasło administratora. Ta opcja ma na celu umożliwienie delegowania wyznaczonych zadań administracyjnych bez ujawniania hasła administratora.\n\nOpcja **zawsze użytkownika wywołującego dane polecenie** jest również niepoprawna.  Domyślnie, `sudo` zazwyczaj pyta o hasło użytkownika wywołującego polecenie, ale to zachowanie jest konfigurowalne.  W pliku `/etc/sudoers` można zdefiniować, że hasło *nie* jest wymagane dla konkretnych poleceń i użytkowników. Dostępne jest też definiowanie użytkownika, który jest uprawniony do wydawania poleceń, nie będącego aktualnie zalogowanym użytkownikiem systemu, na przykład: \n```\npiotr   ALL = (root)  /usr/bin/ls\n```\nW tym przykładzie, użytkownik `piotr` uruchamiając  `sudo /usr/bin/ls` nie będzie musiał podawać hasła użytkownika `piotr`, ponieważ ten konkretny wpis w `sudoers` mówi, że użytkownik `piotr` wywołując polecenie `ls` ma je wykonać z uprawnieniami użytkownika `root` i nie będzie proszony o podanie żadnego hasła.\n\nOpcja **w zależności od ustawień w polityce sudoers** jest poprawna. Plik `/etc/sudoers` pozwala administratorom systemu na precyzyjne określenie, które polecenia mogą być uruchamiane przez jakich użytkowników, i czy podanie hasła jest wymagane. Polityka ta określa, jak `sudo` ma się zachowywać, przyznając lub odmawiając uprawnienia. Przykładowo, konfiguracja może wymagać hasła dla wszystkich poleceń `sudo`, albo tylko dla wybranych, a nawet żadnego. Plik sudoers to bardzo potężne narzędzie i jednocześnie duża odpowiedzialność dla administratora systemu, ponieważ błędnie zdefiniowana polityka sudoers może narazić cały system na kompromitację.\n\nOpcja **zawsze użytkownika z uprawnieniami którego chcemy wykonać dane polecenie** jest niepoprawna.  `sudo` nie wymaga znajomości hasła użytkownika, z którego uprawnieniami wykonywane jest polecenie (np. root). Chociaż *można* skonfigurować `sudo` tak, aby wymagało hasła innego użytkownika, nie jest to typowe ani domyślne zachowanie.  Konfiguracja tego typu wymagałaby użycia opcji `-u` przy wywołaniu polecenia sudo, oraz ustawienie w pliku sudoers uprawnień w specjalny sposób,  np.: \n```\npiotr ALL=(oracle) ALL\n```\nW takim wypadku, użytkownik `piotr`,  wywołując `sudo -u oracle whoami`  zostanie poproszony o hasło użytkownika `oracle`, aby wykonać polecenie  `whoami` z uprawnieniami użytkownika `oracle`. Jeżeli pominie się `u oracle` sudo zapyta o hasło bieżącego użytkownika - co wynika z braku opcji NOPASSWD w regule."
    },
    {
        "questionId": 69,
        "title": "Kolejnosc sprawdzania regul polityki przez TCP Wrappera (pomijajac opcje only_from oraz no_access) jest nastepujaca:",
        "answers": [
            {
                "text": "najpierw hosts.allow, potem hosts.deny, do odnalezienia pasujacej reguly",
                "isCorrect": true
            },
            {
                "text": "sprawdzane sa wszystkie reguly i jezeli zadna z nich nie konczy sie DENY, przyznawany jest dostep",
                "isCorrect": false
            },
            {
                "text": "najpierw hosts.deny, potem hosts.allow, do odnalezienia pierwszej pasujacej reguly",
                "isCorrect": false
            },
            {
                "text": "sprawdzane sa wszystkie reguly i jezeli zadna z nich nie konczy sie DENY, a chociaz jedna konczy sie ALLOW, przyznawany jest dostep",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "TCP Wrappers to mechanizm kontroli dostępu oparty na hoście, który działa jak warstwa pośrednicząca między usługą sieciową (np. sshd, telnetd) a żądaniem połączenia od klienta. Kluczowymi elementami tego mechanizmu są dwa pliki konfiguracyjne: `hosts.allow` i `hosts.deny`. `hosts.allow` zawiera reguły, które jawnie zezwalają na połączenie do określonej usługi dla określonych klientów. `hosts.deny` natomiast, zawiera reguły, które jawnie blokują połączenia. Mechanizm TCP Wrappers przegląda te pliki w określonej kolejności, aby zdecydować czy konkretne połączenie powinno być dozwolone czy zablokowane. \n\n**Poprawna odpowiedź:**\n*  \"najpierw hosts.allow, potem hosts.deny, do odnalezienia pasującej reguły\"\n\n   Jest to prawidłowy opis sekwencji sprawdzania reguł. System najpierw przegląda plik `hosts.allow` w poszukiwaniu pasującej reguły. Jeżeli znajdzie taką regułę, która zezwala na połączenie, to połączenie zostanie przyznane i nie są już analizowane reguły z pliku `hosts.deny`. Jeżeli w pliku `hosts.allow` nie zostanie znaleziona reguła pasująca do analizowanego połączenia, to proces wyszukiwania pasujących reguł jest kontynuowany w pliku `hosts.deny`. Jeżeli znajdzie się tam reguła blokująca to połączenie zostanie zablokowane. Jeśli proces wyszukiwania w `hosts.deny` również nie da efektu, to połączenie jest dopuszczalne. Zatem, to w jakiej kolejności są analizowane pliki ma znaczenie, w pierwszej kolejności analizowany jest `hosts.allow` potem `hosts.deny`. Proces poszukiwania pasującej reguły kończy się na pierwszym dopasowaniu, nie są analizowane dalsze reguły w pliku.\n\n**Niepoprawne odpowiedzi:**\n* \"sprawdzane sa wszystkie reguly i jezeli zadna z nich nie konczy sie DENY, przyznawany jest dostep\"\n\n    Ta odpowiedź jest nieprawidłowa. System nie analizuje wszystkich reguł we wszystkich plikach. Analiza przerywana jest w chwili odnalezienia pasującej reguły w pliku `hosts.allow` lub `hosts.deny`. Jeżeli reguła pasująca zostanie znaleziona w pliku `hosts.allow`, to reguły z pliku `hosts.deny` nie są brane pod uwagę. W takiej konfiguracji mogło by również dojść do przeciążenia komputera, gdyż analizowanie wszystkich reguł zabierałoby czas procesora.\n\n* \"najpierw hosts.deny, potem hosts.allow, do odnalezienia pierwszej pasującej reguly\"\n\n    Ta odpowiedź jest nieprawidłowa, gdyż w pierwszej kolejności analizowany jest plik `hosts.allow`, a dopiero potem, jeśli w nim nie znajdzie się żadna pasująca reguła, analizowany jest plik `hosts.deny`.\n\n*  \"sprawdzane sa wszystkie reguly i jezeli zadna z nich nie konczy sie DENY, a chociaz jedna konczy sie ALLOW, przyznawany jest dostep\"\n   Ta odpowiedź jest nieprawidłowa, gdyż system analizuje pliki konfiguracyjne w kolejności `hosts.allow` potem `hosts.deny` i przerywa proces wyszukiwania na pierwszej znalezionej pasującej regule. System nie analizuje wszystkich reguł w obu plikach, a tym samym nie przechodzi po wszystkich regułach do końca. A dodatkowo istnienie gdzieś w pliku konfiguracyjnym reguły ALLOW nie gwarantuje uzyskania dostępu. Kolejność ma kluczowe znaczenie, to w jaki plik i jaką regułę zostanie dopasowana w pierwszej kolejności determinuje ostateczną decyzję.\n\n**Przykłady:**\n1.  **Przykład z praktyki:** Jeżeli w `hosts.allow` mamy regułę `sshd: 192.168.1.0/24` to wszystkie połączenia do usługi ssh (sshd) z sieci lokalnej o adresach 192.168.1.0/24 będą automatycznie dozwolone, pod warunkiem, że w `hosts.deny` nie ma jawnie zdefiniowanej reguły blokującej ten dostęp.  Jeśli natomiast z pliku `hosts.allow` usuniemy ta regułę, a w `hosts.deny` będzie zdefiniowana reguła `sshd: ALL` to wszystkie połączenia do sshd zostaną zablokowane.\n\n2. **Błąd konfiguracji:** Administrator, mylnie zakładając, że `hosts.deny` ma pierwszeństwo, wpisuje w nim regułę `sshd: ALL EXCEPT 192.168.1.0/24`, a w `hosts.allow` ma regułę `sshd: 192.168.1.10`. Zgodnie z prawem priorytetu `hosts.allow` pierwszeństwo będzie miała reguła z pliku `hosts.allow` i połączenie z adresu `192.168.1.10` będzie dozwolone. Inne adresy z tej podsieci nie uzyskają dostępu. Poprawną regułą w `hosts.deny`  w tej konfiguracji powinno być np. `sshd: ALL` a reguła do `hosts.allow` powinna mieć postać `sshd: 192.168.1.0/24` aby umożliwić dostęp całej podsieci."
    },
    {
        "questionId": 70,
        "title": "Ustawienia protokolu ESP w systemie Windows umozliwiaja:",
        "answers": [
            {
                "text": "przesylanie niezaszyfrowanego pakietu zabezpieczonego przed modyfikacja przy pomocy kryptograficznych funkcji mieszajacych",
                "isCorrect": false
            },
            {
                "text": "komunikacje w trybie transportowym (bezposrednim, host-to-host)",
                "isCorrect": true
            },
            {
                "text": "komunikacje w trybie tunelowym (net-to-net)",
                "isCorrect": true
            },
            {
                "text": "ustanowienie bezpiecznego kanalu do zarzadzania asocjacja IPsec",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół IPsec (Internet Protocol Security) to zbiór protokołów, które zapewniają bezpieczną komunikację IP poprzez uwierzytelnianie i szyfrowanie każdego pakietu IP w sesji. ESP (Encapsulating Security Payload) to jeden z protokołów IPsec, który zapewnia poufność danych poprzez szyfrowanie. Opcjonalnie może również zapewniać integralność i autentyczność danych, ale sam ESP nie odpowiada za zarządzanie kluczami ani za uwierzytelnianie tożsamości. Działanie protokołu ESP różni się w zależności od trybu pracy.\n\n**Odpowiedź 1:** \"przesylanie niezaszyfrowanego pakietu zabezpieczonego przed modyfikacja przy pomocy kryptograficznych funkcji mieszajacych\" jest **niepoprawna**. Ta odpowiedź opisuje działanie protokołu AH (Authentication Header), który chroni pakiet przed modyfikacją przy pomocy kryptograficznej funkcji skrótu, ale nie szyfruje jego zawartości. ESP, oprócz opcjonalnej integralności, przede wszystkim szyfruje dane.\n\n**Odpowiedź 2:** \"komunikacje w trybie transportowym (bezposrednim, host-to-host)\" jest **poprawna**. Tryb transportowy ESP szyfruje tylko zawartość pakietu IP (payload). W nagłówku IP nie ma zmian. Taki tryb używany jest gdy tylko chcemy zaszyfrować komunikacje między konkretnymi hostami w sieci, np. serwerem a stacją roboczą. Nie ma natomiast szyfrowania całej trasy komunikacyjnej jak w przypadku tunelu VPN.\n\n**Odpowiedź 3:** \"komunikacje w trybie tunelowym (net-to-net)\" jest **poprawna**. Tryb tunelowy protokołu ESP szyfruje całą zawartość pakietu IP, a następnie umieszcza go wewnątrz innego pakietu IP z nowym nagłówkiem. Taki tryb jest używany do tworzenia sieci VPN pomiędzy odległymi lokalizacjami (np. sieć firmowa z oddziałem). Zapewnia on najwyższy stopień bezpieczeństwa z uwagi na ukrycie całej oryginalnej trasy.\n\n**Odpowiedź 4:** \"ustanowienie bezpiecznego kanalu do zarzadzania asocjacja IPsec\" jest **niepoprawna**. Protokół ESP zapewnia ochronę danych. Natomiast protokół IKE (Internet Key Exchange), który często działa w tandemie z IPsec, jest odpowiedzialny za zarządzanie asocjacjami bezpieczeństwa (SA) i uzgadnianie kluczy. System Windows może i bardzo często wykorzystuje IKE z IPsec ale w konfiguracji ESP nie ma mechanizmów zarządzania asocjacjami. Asocjacja (Security Association, SA) to  zbiór parametrów kryptograficznych, które są potrzebne do ustanowienia bezpiecznego połączenia, w tym np. klucze, algorytmy szyfrowania i integralności.\n\n**Przykład z życia:** Wyobraź sobie firmę z oddziałami w różnych miastach. Użycie IPsec w trybie tunelowym pozwala na zbudowanie wirtualnej prywatnej sieci VPN, gdzie ruch sieciowy pomiędzy oddziałami będzie całkowicie zaszyfrowany, w tym ukrywane są wszystkie nagłówki. Natomiast komunikacja pomiędzy serwerem a klientem za pomocą przeglądarki WWW przy użyciu SSL to typowy przykład trybu transportowego, gdzie chroniona jest jedynie zawartość pakietów, które nie stanowią tunelu kryptograficznego w sensie IPsec (taki tunel buduje wyższy protokół SSL, na innej warstwie ISO/OSI, nie widoczny na poziomie warstwy IP). W systemie Windows można skonfigurować obydwa te tryby działania IPsec z wykorzystaniem mechanizmu ESP."
    },
    {
        "questionId": 71,
        "title": "Mechanizm iptables moze dokonywac wyboru regul filtracji dla danego pakietu przez:",
        "answers": [
            {
                "text": "zasade pierwszego dopasowania i zawsze przerywa szukanie przy pierwszym dopasowaniu",
                "isCorrect": true
            },
            {
                "text": "zasade najlepszego dopasowania (najbardziej szczegolowa regula)",
                "isCorrect": false
            },
            {
                "text": "zasade pierwszego dopasowania, ale niekoniecznie przerywa szukanie przy pierwszym dopasowaniu",
                "isCorrect": false
            },
            {
                "text": "zasade okreslona w polityce danego lancucha (np. BESTMATCH, FIRSTMATCH)",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`iptables` jest narzędziem w systemie Linux służącym do konfiguracji zapory sieciowej (firewalla).  Zapora sieciowa służy do filtrowania ruchu sieciowego, czyli do decydowania, które pakiety sieciowe powinny być przepuszczone (akceptowane), a które odrzucone. Działanie `iptables` polega na przetwarzaniu każdego przychodzącego lub wychodzącego pakietu przez zbiór reguł. Reguły te są umieszczane w uporządkowanych zbiorach, zwanych łańcuchami (ang. chains), a łańcuchy z kolei są umieszczane w tabelach (ang. tables). W obrębie jednej tabeli reguły przetwarzane są w kolejności w jakiej zostały umieszczone w łańcuchu.\n**Dla danego pakietu `iptables` wybiera regułę filtrującą, stosując zasadę pierwszego dopasowania i zawsze przerywa szukanie przy pierwszym dopasowaniu.** Oznacza to, że kiedy pakiet przechodzi przez dany łańcuch reguł, sprawdzane jest, czy pakiet pasuje do pierwszej reguły. Jeśli tak, wykonywana jest akcja przypisana do tej reguły (np. przepuszczenie pakietu, odrzucenie pakietu) i dalsze reguły nie są już analizowane. Jeśli pakiet nie pasuje do pierwszej reguły, sprawdzana jest kolejna reguła, i tak dalej, aż do znalezienia dopasowania lub do osiągnięcia końca łańcucha. W tym ostatnim przypadku stosuje się politykę domyślną łańcucha, czyli akcję definiowaną za pomocą `-P` (np. `iptables -P INPUT DROP`).\n\n**Opcja 1: \"zasade pierwszego dopasowania i zawsze przerywa szukanie przy pierwszym dopasowaniu\"** jest **poprawna**. `iptables` działa sekwencyjnie w obrębie danego łańcucha. Gdy pakiet pasuje do danej reguły, natychmiast przerywa analizę i wykonuje akcję zdefiniowaną w tej regule. Zatem dopasowanie do pierwszej pasującej reguły wyklucza sprawdzenie kolejnych reguł.\n*   **Praktyczne implikacje:**  O kolejności reguł w `iptables` zawsze decyduje administrator, dlatego umieszczenie bardziej szczegółowych reguł przed bardziej ogólnymi jest zasadnicze. Przykładowo, jeśli reguła blokująca konkretny adres IP jest umieszczona po regule, która ogólnie akceptuje ruch z każdej sieci, to reguła blokująca adres nie będzie nigdy zastosowana.\n\n**Opcja 2: \"zasade najlepszego dopasowania (najbardziej szczegolowa regula)\"** jest **niepoprawna**. `iptables` nie dokonuje wyboru reguły, która ma najbardziej szczegółowe wymagania do pakietu, ale wybiera regułę do której pasuje ona jako pierwszej. Nie ma znaczenia jak szczegółowa jest reguła kolejna, nie będzie nigdy zastosowana jeśli wcześniej pakiet dopasował się do jakiejkolwiek innej.\n*   **Praktyczne implikacje:** Użytkownik mógłby logicznie zakładać, iż skoro napisał bardzo szczegółową regułę, to ona będzie na pewno zastosowana, jednak brak wiedzy o tym mechanizmie zmusza użytkownika do poprawnego ułożenia reguł, od bardziej szczegółowej po bardziej ogólną w danym łańcuchu reguł.\n\n**Opcja 3: \"zasade pierwszego dopasowania, ale niekoniecznie przerywa szukanie przy pierwszym dopasowaniu\"** jest **niepoprawna**. `iptables` zawsze przerywa szukanie po znalezieniu pierwszej pasującej reguły. Nie ma możliwości, aby pakiet przetestował więcej reguł w tym samym łańcuchu po dopasowaniu. Wyjątkiem od tej reguły są reguły wykorzystujące cel RETURN, które nie powodują zaprzestania analizowania pakietu, jednak reguły są analizowane w innych łańcuchach a nie aktualnym.\n*   **Praktyczne implikacje:**  Gdyby iptables nie przerywał dopasowywania do reguł po pierwszym dopasowaniu i testowałby wszystkie reguły z łańcucha, to cały proces filtrowania byłby mało efektywny gdyż czas analizy każdego pakietu znacząco by wzrósł.\n\n**Opcja 4: \"zasade okreslona w polityce danego lancucha (np. BESTMATCH, FIRSTMATCH)\"** jest **niepoprawna**. `iptables` nie oferuje możliwości wyboru polityki dopasowania reguł do pakietów. Mechanizm dopasowania zawsze działa na zasadzie pierwszego dopasowania. \n*   **Praktyczne implikacje:** Nie ma możliwości zmiany domyślnego działania `iptables`. Konieczność działania `iptables` według prostej reguły wymusza na administratorze planowanie kolejności reguł, tak aby nie tracił możliwości nadania odpowiednich uprawnień do pakietu."
    },
    {
        "questionId": 72,
        "title": "Wirtualizacja rejestru w systemie Windows:",
        "answers": [
            {
                "text": "chroni konfiguracje systemu przed niepozadanymi zmianami",
                "isCorrect": true
            },
            {
                "text": "pozwala aplikacji 32-bitowej na modyfikacje obszarow rejestru, do ktorych aplikacja nie ma prawa zapisu",
                "isCorrect": true
            },
            {
                "text": "dotyczy wszystkich galezi rejestru",
                "isCorrect": false
            },
            {
                "text": "jest mechanizmem koniecznym do uruchomienia wirtualnych systemow Windows",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Wirtualizacja rejestru systemu Windows jest mechanizmem, który ma na celu ochronę stabilności systemu operacyjnego oraz zapewnienie kompatybilności aplikacji, szczególnie tych starszych, które mogą nie być w pełni przystosowane do nowoczesnych systemów Windows. Rejestr systemu Windows to hierarchiczna baza danych, w której przechowywane są ustawienia i konfiguracje systemu operacyjnego oraz zainstalowanych aplikacji. Zmiany w rejestrze mogą mieć znaczący wpływ na działanie systemu, dlatego też mechanizmy ochronne, takie jak wirtualizacja rejestru, są kluczowe.\n\nWirtualizacja rejestru polega na przekierowaniu operacji zapisu (ang. *write access*) dokonywanych przez aplikację do specjalnie wydzielonego obszaru w systemie plików, zamiast bezpośredniego zapisu do fizycznej struktury rejestru. Aplikacja, która próbuje dokonać zapisu do chronionego obszaru, w rzeczywistości zapisuje dane do swojego wirtualnego widoku rejestru, który jest przechowywany w dedykowanej lokacji. Dzięki temu główne ustawienia systemu są zabezpieczone przed nieuprawnionymi modyfikacjami dokonywanymi przez aplikacje. \n\n*   **\"chroni konfiguracje systemu przed niepozadanymi zmianami\"**: Jest to **poprawna** odpowiedź. Wirtualizacja rejestru, jak wspomniano, ma za zadanie ochronę kluczowych ustawień systemu przed nieautoryzowanymi zmianami.  Przykładowo, aplikacja, która z założenia nie powinna zmieniać ustawień globalnych systemu, nie będzie mogła tego zrobić, bo zapisy dokonuje w swoim prywatnym, wirtualnym widoku rejestru. Realnym przykładem jest instalacja aplikacji bez uprawnień administratora: instalator zapisuje dane w wirtualnej przestrzeni rejestru, nie zmieniając globalnej konfiguracji systemu.\n\n*   **\"pozwala aplikacji 32-bitowej na modyfikacje obszarow rejestru, do ktorych aplikacja nie ma prawa zapisu\"**: Jest to **poprawna** odpowiedź. W systemach 64-bitowych, 32-bitowe aplikacje (często starsze), które próbują zapisać dane do rejestru w lokalizacjach przeznaczonych dla aplikacji 64-bitowych, miałyby domyślnie odmowę dostępu. Wirtualizacja rejestru przekierowuje te próby zapisu do innego, wirtualnego obszaru rejestru, gdzie aplikacja 32-bitowa może zapisywać dane. Przykładem jest sytuacja, w której stara aplikacja 32-bitowa potrzebuje zapisać ustawienia do systemowego rejestru. Bez wirtualizacji, aplikacja ta mogłaby nie działać poprawnie, ponieważ nie ma uprawnień do zapisu w docelowej lokalizacji w systemie 64-bitowym. Dzięki wirtualizacji rejestru dane te zapisywane są w chronionej przestrzeni.\n\n*   **\"dotyczy wszystkich galezi rejestru\"**: Jest to **niepoprawna** odpowiedź. Wirtualizacja rejestru nie dotyczy wszystkich gałęzi rejestru. Niektóre kluczowe gałęzie systemowe pozostają niezwirtualizowane i są bezpośrednio chronione. Wirtualizacja jest stosowana tylko w przypadku konkretnych lokalizacji, które są często modyfikowane przez aplikacje. W przeciwnym wypadku wirtualizacja objęłaby całą bazę rejestru, co spowodowało by duże problemy z wydajnością całego systemu. Przykładem jest gałąź HKEY\\_LOCAL\\_MACHINE, gdzie aplikacje nie mogą zapisywać w sposób wirtualizowany, a jedynie z prawami administratora. \n\n*  **\"jest mechanizmem koniecznym do uruchomienia wirtualnych systemow Windows\"**: Jest to **niepoprawna** odpowiedź. Wirtualizacja rejestru nie jest mechanizmem koniecznym do uruchamiania systemów wirtualnych. Mechanizm ten chroni pojedynczy system Windows. W systemach wirtualizacyjnych np. VirtualBox czy Vmware cała maszyna wirtualna jest umieszczana w oddzielnym pliku i oddzielnej przestrzeni adresowej systemu operacyjnego hosta, dzięki czemu wirtualizacja rejestru nie odgrywa w tym procesie żadnej roli. Natomiast system operacyjny uruchamiany jako maszyna wirtualna posiada w sobie mechanizmy wirtualizacji rejestru takie same jak w systemie operacyjnym instalowanym bezpośrednio na dysku twardym."
    },
    {
        "questionId": 73,
        "title": "Tunele IPsec:",
        "answers": [
            {
                "text": "stosuja protokol TLS do szyfrowania ruchu",
                "isCorrect": false
            },
            {
                "text": "stosuja protokol AH do szyfrowania ruchu",
                "isCorrect": false
            },
            {
                "text": "stosuja protokol ESP do szyfrowania ruchu",
                "isCorrect": true
            },
            {
                "text": "stosuja protokol AH do uwierzytelniania stron tunelu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Tunel IPsec to bezpieczny kanał komunikacji tworzony w warstwie sieciowej protokołu IP, wykorzystujący mechanizmy kryptograficzne do zapewnienia poufności, integralności i uwierzytelniania danych.  W tunelu IPsec stosuje się dwa główne protokoły: AH (Authentication Header) i ESP (Encapsulating Security Payload).  Protokół AH (nagłówek uwierzytelniania) zapewnia integralność danych i uwierzytelnianie pakietów, ale nie zapewnia szyfrowania ich zawartości. Protokół ESP (enkapsulacja bezpiecznego ładunku) zapewnia zarówno szyfrowanie danych (poufność) jak i ich integralność.\n\n*   **\"stosuja protokol TLS do szyfrowania ruchu\"** - Jest to nieprawidłowa odpowiedź. TLS (Transport Layer Security) jest protokołem, który działa na wyższym poziomie niż IPsec. TLS, podobnie jak SSL,  zapewnia bezpieczną komunikację na poziomie warstwy transportowej lub aplikacyjnej (np. https), a nie w tunelach IPsec, które działają na poziomie sieciowym.  Przykładem zastosowania TLS jest przeglądanie stron www z użyciem protokołu https, gdzie dane przesyłane między przeglądarką a serwerem www są szyfrowane protokołem TLS.\n\n*   **\"stosuja protokol AH do szyfrowania ruchu\"** - Jest to nieprawidłowa odpowiedź. Protokół AH (Authentication Header) służy głównie do zapewnienia integralności danych (potwierdza, że dane nie zostały zmodyfikowane) oraz uwierzytelnienia (potwierdza, że dane pochodzą od uprawnionego nadawcy). AH nie zapewnia szyfrowania danych, wiec nie chroni ich poufności. AH dodaje do pakietu IP nagłówek zawierający skrót kryptograficzny z pakietu, umożliwiając wykrycie nieautoryzowanej modyfikacji danych. \n\n*   **\"stosuja protokol ESP do szyfrowania ruchu\"** - Jest to prawidłowa odpowiedź. Protokół ESP (Encapsulating Security Payload) jest odpowiedzialny za enkapsulację (opakowanie) danych i ich zaszyfrowanie. ESP zapewnia poufność danych poprzez ich zaszyfrowanie, oraz może opcjonalnie, zapewniać uwierzytelnianie i integralność. W praktyce, to właśnie ESP jest używany, gdy w tunelu IPsec wymagane jest szyfrowanie przesyłanych informacji. ESP szyfruje pakiet IP (w trybie tunelowym) lub tylko ładunek pakietu (w trybie transportowym) za pomocą algorytmów takich jak AES, 3DES, Blowfish, i innych.\n\n*   **\"stosuja protokol AH do uwierzytelniania stron tunelu\"** - Jest to nieprawidłowa odpowiedź, chociaż częściowo prawidłowa, bo AH faktycznie uwierzytelnia pakiet.  W IPsec protokół AH (Authentication Header) zapewnia uwierzytelnianie _źródła_ pakietu w obrębie tunelu - czyli potwierdza, że pakiet pochodzi z prawidłowego źródła i nie został sfałszowany, ale nie jest wykorzystywany do uwierzytelniania samych stron tunelu (np. bram VPN). Uwierzytelnienie stron tunelu następuje zazwyczaj podczas negocjacji sesji IPsec (czyli w etapie nawiązywania połączenia) przy pomocy protokołu IKE (Internet Key Exchange), a nie protokołu AH (który ochrania ruch wewnątrz tunelu). Podczas tej fazy, uwierzytelnienie obu stron może odbyć się przez hasło, certyfikaty cyfrowe czy metodą Diffiego-Hellmana."
    },
    {
        "questionId": 74,
        "title": "Ktore z ponizszych twierdzen jest prawdziwe?",
        "answers": [
            {
                "text": "program SSH na komputerze A moze polaczyc sie z komputerem B, tak by B nasluchiwal na polaczenia na porcie X. Metoda ta nazywa sie local port forwarding (-L)",
                "isCorrect": false
            },
            {
                "text": "program SSH do uwierzytelniania oraz szyfrowania komunikacji pomiedzy komputerem A i B wykorzystuje algorytm RSA",
                "isCorrect": false
            },
            {
                "text": "program SSH na komputerze A wykorzystuje klucz publiczny komputera B w celu weryfikacji czy tozsamosc B sie nie zmienila",
                "isCorrect": true
            },
            {
                "text": "program SSH na komputerze A moze polaczyc sie z komputerem B, tak by B nasluchiwal na polaczenia na porcie X. Metoda ta nazywa sie remote port forwarding (-R)",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) to protokół kryptograficzny, który służy do bezpiecznej komunikacji. SSH zapewnia poufność danych, integralność danych i uwierzytelnianie stron komunikujących się. Protokół SSH w procesie uwierzytelniania wykorzystuje kryptografię asymetryczną. Algorytm RSA jest stosowany głównie do wymiany kluczy podczas fazy uwierzytelniania i do podpisywania podczas uwierzytelniania kluczem publicznym, a nie do szyfrowania całej komunikacji. Szyfrowanie danych przesyłanych za pomocą SSH odbywa się z wykorzystaniem symetrycznych algorytmów kryptograficznych, takich jak 3DES, Blowfish lub AES. Mechanizm przesyłania danych w protokole SSH jest taki, że wymiana klucza symetrycznego następuje z wykorzystaniem algorytmu asymetrycznego np. RSA a przesyłanie właściwych danych następuje za pomocą algorytmu symetrycznego.\n\n**Odpowiedź 1:** \"program SSH na komputerze A może połączyć się z komputerem B, tak by B nasłuchiwał na połączenia na porcie X. Metoda ta nazywa się local port forwarding (-L)\". To twierdzenie jest **nieprawdziwe**.  Port forwarding, czyli przekierowanie portów,  za pomocą SSH to metoda przekierowywania ruchu z danego portu lokalnego komputera na zdalny serwer (lokalne przekierowanie portów, ang. _local port forwarding_) lub z portu zdalnego serwera na port lokalny (zdalne przekierowanie portów, ang. _remote port forwarding_). Opcja `-L` (local port forwarding) tworzy tunel od lokalnego portu na komputerze A do portu na zdalnym komputerze B. W opisanym przypadku to komputer A nasłuchuje na danym porcie, aby następnie przekierować ruch do komputera B, a nie odwrotnie.  Załóżmy, że na komputerze A chcemy uruchomić przeglądarkę która będzie wykorzystywała protokół SSH do tunelowania ruchu wysyłanego do serwera http na komputerze B.  W takim przypadku należy wykorzystać opcję lokalnego przekierowania portów `-L` na komputerze A z ustawieniem lokalnego portu na 8080, zdalnego portu na 80 i zdalnego adresu np.:127.0.0.1. Polecenie uruchamiające połączenie przez SSH na komputerze A powinno wyglądać następująco: `ssh -L 8080:127.0.0.1:80  uzytkownik@komputerB`. A następnie uruchomić przeglądarkę i w pasku adresu należy wpisać adres `127.0.0.1:8080`, tak aby ruch był kierowany do lokalnego portu 8080, który to poprzez ssh jest przekierowywany do komputera B na port 80.\n\n**Odpowiedź 2:** \"program SSH do uwierzytelniania oraz szyfrowania komunikacji pomiędzy komputerem A i B wykorzystuje algorytm RSA\". To twierdzenie jest **nieprawdziwe**.  Algorytm RSA jest wykorzystywany przez SSH podczas wymiany kluczy oraz podczas weryfikacji podpisu cyfrowego, ale nie do szyfrowania całej komunikacji między komputerami A i B. Pełne szyfrowanie komunikacji odbywa się przy wykorzystaniu algorytmów symetrycznych, takich jak AES, 3DES, lub Blowfish po uprzednim ich uzgodnieniu na etapie nawiązywania połączenia SSH. Algorytm RSA jest wykorzystywany w procedurze uzgadniania klucza symetrycznego.\n\n**Odpowiedź 3:** \"program SSH na komputerze A wykorzystuje klucz publiczny komputera B w celu weryfikacji czy tożsamość B się nie zmieniła\". To twierdzenie jest **prawdziwe**. Podczas nawiązywania połączenia SSH, komputer A (klient SSH)  pobiera od komputera B (serwer SSH) jego klucz publiczny. Następnie, komputer A porównuje ten pobrany klucz z zapisanym lokalnie, w celu upewnienia się, że łączy się z tym samym, zaufanym serwerem i, że po drodze nie nastąpiło podszycie pod inny serwer (atak _man-in-the-middle_). Jeśli klucz publiczny serwera (komputera B) uległ zmianie (np. przy reinstalacji systemu na B) to SSH zaalarmuje użytkownika i zażąda potwierdzenia nowego klucza. Poprawność klucza jest podstawą do nawiązania połączenia, gdy ta weryfikacja się powiedzie można przejść do fazy w której serwer wymaga uwierzytelniania klienta a nie tylko samego siebie, gdyż w ogólnym przypadku klient i serwer uwierzytelniają się wzajemnie. Bez kryptograficznej weryfikacji klucza publicznego nie można mówić o bezpiecznej komunikacji. \n\n**Odpowiedź 4:** \"program SSH na komputerze A może połączyć się z komputerem B, tak by B nasłuchiwał na połączenia na porcie X. Metoda ta nazywa się remote port forwarding (-R)\". To twierdzenie jest **prawdziwe**. Opcja `-R` (remote port forwarding) tworzy tunel od portu na zdalnym komputerze (B) do portu na lokalnym komputerze (A). Pozwala komputerowi A na nasłuchiwanie na porcie na zdalnym komputerze B a następnie na tunelowanie tego ruchu do lokalnego portu na komputerze A. Przykładowo, możemy chcieć udostępnić usługę działającą na komputerze A (np. serwer WWW działający na porcie 80) komputerowi B. W takim przypadku należy wykonać polecenie `ssh -R 8080:127.0.0.1:80 użytkownik@komputerB`. Polecenie to sprawi, że na komputerze B na porcie 8080 będzie nasłuchiwał tunel SSH, a ruch przekazywany przez ten port będzie tunelowany do komputera A na port 80. W takim przypadku na komputerze B z przeglądarki wpisując adres 127.0.0.1:8080 będzie można podejrzeć zawartość serwera http działającego na komputerze A."
    },
    {
        "questionId": 75,
        "title": "Agent DRA w systemie Windows to:",
        "answers": [
            {
                "text": "administrator systemu Windows, ktoremy przypisano prawo tworzenia strumieni ADS",
                "isCorrect": false
            },
            {
                "text": "lokalny administrator stacji roboczej w srodowisku domenowym mogacy robic kopie zapasowe",
                "isCorrect": false
            },
            {
                "text": "glowny administrator domeny (serwera AD)",
                "isCorrect": false
            },
            {
                "text": "konto pozwalajace na dostep do plikow zaszyfrowanych przez EFS",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Agent odzyskiwania danych (DRA), to specjalne konto w systemie Windows, które umożliwia dostęp do plików zaszyfrowanych za pomocą funkcji EFS (Encrypting File System), w przypadku gdy klucz użytkownika który zaszyfrował plik jest niedostępny. EFS jest mechanizmem wbudowanym w system Windows, który transparentnie dla użytkownika szyfruje pliki na poziomie systemu plików NTFS. Nie można mylić tego z szyfrowaniem plików za pomocą np. ZIP lub 7zip, gdzie proces szyfrowania jest jawny dla użytkownika. Hasło które tworzy klucz szyfrowania jest powiązane z kluczem użytkownika w systemie Windows. Użytkownik może stracić swój klucz (np.: hasło do konta użytkownika) i z tego powodu utraci dostęp do swoich danych. Z tego też powodu system Windows umożliwia utworzenie specjalnego konta DRA, które posiada dostęp do wszystkich plików zaszyfrowanych przez EFS. \nGłównym zadaniem konta DRA jest obsługa sytuacji awaryjnych, w których użytkownik utracił klucz szyfrowania (np. zapomniał hasła lub usunął swoje konto), w takim przypadku administrator lub wybrany użytkownik może odzyskać dostęp do zaszyfrowanych danych w imieniu wybranego użytkownika. Oczywiście nie jest to operacja wykonywana automatycznie a w sposób kontrolowany. \n\n*   **\"administrator systemu Windows, któremu przypisano prawo tworzenia strumieni ADS\"** - To jest błędna odpowiedź. Administrator systemu Windows ma wiele uprawnień, w tym uprawnienie do tworzenia strumieni ADS (Alternate Data Streams) w systemie plików NTFS, jednak to nie jest jego główną funkcją. Strumienie ADS umożliwiają ukrycie dodatkowych informacji w pliku a nie służą do mechanizmu odzyskiwania danych. Konto DRA nie musi być również administratorem systemu. \n\n*   **\"lokalny administrator stacji roboczej w środowisku domenowym mogący robić kopie zapasowe\"** - To jest błędna odpowiedź. Administrator lokalnej stacji roboczej w środowisku domenowym ma uprawnienia do wykonywania kopii zapasowej, ale nie jest to kluczowa cecha agenta DRA. DRA to wyspecjalizowane konto, którego głównym zadaniem jest odzyskiwanie danych w przypadku utraty klucza do zaszyfrowanych plików. Administrator lokalny nie ma automatycznie dostępu do szyfrowanych przez EFS plików innych użytkowników. \n\n*   **\"główny administrator domeny (serwera AD)\"** - To jest błędna odpowiedź. Główny administrator domeny(serwera Active Directory) posiada uprawnienia administratora domeny, który na ogół posiada dostęp do wszystkich komputerów w domenie. Jednak on również nie ma automatycznie dostępu do plików zaszyfrowanych przez EFS. Konto DRA jest kontem oddzielnym i nie można go zastąpić kontem głównego administratora domeny.\n\n*   **\"konto pozwalające na dostęp do plików zaszyfrowanych przez EFS\"** - To jest poprawna odpowiedź. DRA jest wyznaczone konto, które może służyć do odzyskiwania dostępu do plików zaszyfrowanych przez EFS, gdy klucz oryginalnego użytkownika nie jest już dostępny. Klucz DRA, niezbędny do odszyfrowania plików w takim przypadku, jest przechowywany w certyfikacie systemowym i w przypadku standardowych konfiguracji jest również szyfrowany. Jest to klucz symetryczny, którego używa system do szyfrowania plików EFS. Administrator decydując się na wyznaczenie konta DRA powinien mieć pełną świadomość tego iż w wyznaczonej sytuacji może on uzyskać dostęp do wszystkich danych na dysku. \n\nKonkretny przykład działania mechanizmu DRA jest następujący: Użytkownik Jan Kowalski z użyciem własnego hasła do konta użytkownika w systemie Windows szyfruje plik. W ten sposób klucz szyfrowania jest powiązany z kontem użytkownika Jan Kowalski. Użytkownik ten traci dostęp do konta lub usuwa konto z systemu Windows. Dane pozostają zaszyfrowane i niedostępne dla wszystkich innych użytkowników. Wyznaczony Administrator(lub inne wyznaczone konto użytkownika) w danym systemie może jednak jako DRA odzyskać dostęp do wszystkich zaszyfrowanych plików poprzez swój certyfikat DRA. Oczywiście do uzyskania dostępu wymagane jest jeszcze podanie hasła do konta, jednak to już jest inna procedura uwierzytelniania. \n\nPamiętajmy, że funkcja EFS w systemie Windows nie gwarantuje 100% bezpieczeństwa przetrzymywania plików, a jedynie ochronę przed niepowołanym dostępem. Nie chroni np. przed atakiem typu brute force lub innym atakiem mającym na celu odzyskanie hasła dostępu do konta."
    },
    {
        "questionId": 76,
        "title": "Ktore z ponizszych twierdzen dotyczacych POSIX ACL sa prawdziwe?",
        "answers": [
            {
                "text": "w momencie tworzenia katalogu jego uprawnienia ACL kopiowane sa z domyslnych uprawnien (Default ACL) folderu nadrzednego z wykluczeniem uprawnienia do wykonywania",
                "isCorrect": false
            },
            {
                "text": "w momencie tworzenia pliku jego uprawnienia domyslne (Default ACL) zostaja odziedziczone z folderu nadrzednego",
                "isCorrect": false
            },
            {
                "text": "w momencie tworzenia pliku jego uprawnienia ACL kopiowane sa z domyslnych uprawnien (Default ACL) folderu nadrzednego z wykluczeniem uprawnienia do wykonywania",
                "isCorrect": false
            },
            {
                "text": "w momencie tworzenia katalogu jego uprawnienia domyslne (Default ACL) zostaja odziedziczone z folderu nadrzednego",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm POSIX ACL (Access Control List) pozwala na rozszerzenie podstawowego systemu uprawnień do plików i katalogów, znanego z systemów Linux/Unix. Oprócz właściciela pliku, grupy, do której plik przynależy oraz pozostałych użytkowników, uprawnienia mogą być przypisane konkretnym użytkownikom i grupom z wykorzystaniem list ACL. W przypadku **domyślnej listy kontroli dostępu (Default ACL)**, uprawnienia te nie dotyczą bezpośrednio danego katalogu, a *definiują jak uprawnienia będą dziedziczone w momencie tworzenia plików i podkatalogów* w danym katalogu.  W istocie, domyślne ACL definiuje wzorzec dla nowych obiektów.\n\n**Pierwsza odpowiedź:** \"w momencie tworzenia katalogu jego uprawnienia ACL kopiowane sa z domyslnych uprawnien (Default ACL) folderu nadrzednego z wykluczeniem uprawnienia do wykonywania\" - **NIEPOPRAWNA**. Jest to częściowo prawda, w momencie tworzenia katalogu jego uprawnienia domyślne (default ACL) są odczytywane z katalogu nadrzędnego (rodzica) jednak nie wyklucza to uprawnień do wykonywania. Nowo tworzony katalog może posiadać uprawnienia do wykonywania. \n\n**Druga odpowiedź:** \"w momencie tworzenia pliku jego uprawnienia domyslne (Default ACL) zostaja odziedziczone z folderu nadrzednego\" - **NIEPOPRAWNA**. W momencie tworzenia pliku, jego *uprawnienia ACL nie są dziedziczone z domyślnych uprawnień katalogu nadrzędnego*. Plik otrzymuje domyślne uprawnienia zdefiniowane poprzez maskę domyślną, a nie z listy uprawnień default ACL. \n\n**Trzecia odpowiedź:** \"w momencie tworzenia pliku jego uprawnienia ACL kopiowane sa z domyslnych uprawnien (Default ACL) folderu nadrzednego z wykluczeniem uprawnienia do wykonywania\" - **NIEPOPRAWNA**. Ta opcja łączy w sobie błędy dwóch poprzednich opcji. Po pierwsze plik *nie dziedziczy uprawnień z Default ACL*, a po drugie ewentualne uprawnienia odziedziczone nie są pozbawione uprawnień do wykonywania.\n\n**Czwarta odpowiedź:** \"w momencie tworzenia katalogu jego uprawnienia domyslne (Default ACL) zostaja odziedziczone z folderu nadrzednego\" - **POPRAWNA**. Jest to poprawna odpowiedź, ponieważ w momencie tworzenia katalogu, w jego rozszerzonych uprawnieniach ACL, zostają zapisane informacje o *domyślnych uprawnieniach odczytanych z katalogu nadrzędnego*. To oznacza, że *nowy katalog będzie domyślnie tworzył wewnątrz siebie pliki i katalogi z zachowaniem schematu dziedziczenia uprawnień z katalogu rodzica*.\n\n**Przykład praktyczny:**\n\nZałóżmy, że mamy katalog `dokumenty` z default ACL:\n\n```\nuser::rwx\ngroup::r-x\ngroup:programisci:rwx\ndefault:user::rwx\ndefault:group::r-x\ndefault:group:programisci:rwx\ndefault:mask::rwx\ndefault:other::r-x\n```\nPowyższe uprawnienia default ACL określają, że: \n * właściciel (user) ma pełne uprawnienia (rwx), \n * grupa właściciela ma odczyt i przeszukiwanie (r-x), \n * a grupa *programisci* ma pełne uprawnienia (rwx) przy czym te prawa są dziedziczone domyślnie dla nowo utworzonych katalogów i plików. \n * *mask* określa uprawnienia, które w ostateczności są odebrane użytkownikom i grupom, przy założeniu, że w nowo utworzonych zasobach nie definiuje się dodatkowych parametrów.\n\nTeraz, jeśli w katalogu `dokumenty` zostanie utworzony plik `raport.txt`, to ten plik nie przejmie atrybutów Default ACL, a jedynie atrybuty: właściciela, grupy właściciela i inne, odczytane z Default ACL katalogu rodzica (dokumenty). \nJednak, gdy zostanie utworzony w katalogu `dokumenty` podkatalog `finanse`, to ten katalog przejmie uprawnienia z Default ACL i będzie posiadał uprawnienia default. \n\n*Nowy plik nie dziedziczy z katalogu rodzica atrybutów z Default ACL.*\n\nMechanizm ten pozwala tworzyć podkatalogi, w których uprawnienia default są identyczne jak te w katalogu rodzicu, natomiast pliki zachowują domyślne uprawnienia zdefiniowane w katalogu rodzica. Mechanizm ten również zmusza do tego, aby system plików oferował obsługę rozszerzonych ACL."
    },
    {
        "questionId": 77,
        "title": "Standard IEEE 802.1ae:",
        "answers": [
            {
                "text": "to odpowiednik IPsec na poziomie warstwy transportowej",
                "isCorrect": false
            },
            {
                "text": "oferuje uwierzytelnianie na poziomie warstwy sieciowej OSI",
                "isCorrect": false
            },
            {
                "text": "oferuje ochrone poufnosci i integralnosci komunikacji na poziomie warstwy MAC",
                "isCorrect": true
            },
            {
                "text": "oferuje ochrone poufnosci i integralnosci komunikacji na poziomie warstwy OSI",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Standard IEEE 802.1ae, znany również jako MACsec, definiuje protokół bezpieczeństwa działający na poziomie warstwy MAC (Media Access Control), czyli w warstwie drugiej modelu OSI.  Warstwa MAC zajmuje się kontrolą dostępu do medium transmisyjnego w sieciach lokalnych (LAN) i realizuje adresowanie sprzętowe, umożliwiając unikalną identyfikację interfejsów sieciowych. Zabezpieczenia tej warstwy mają na celu ochronę przed atakami lokalnymi, takimi jak podsłuch i manipulowanie przesyłanymi ramkami. Protokół IEEE 802.1ae jest protokołem warstwy łącza danych (ang. _data link layer_), którego zadaniem jest ochrona przed naruszeniem poufności oraz integralności danych transmitowanych w lokalnej sieci komputerowej.\n\n**Odpowiedź \"to odpowiednik IPsec na poziomie warstwy transportowej\" jest niepoprawna.** IPsec (Internet Protocol Security) to protokół bezpieczeństwa działający w warstwie sieciowej OSI (warstwa 3), a nie transportowej (warstwa 4). IPsec zapewnia poufność, integralność i autentyczność danych poprzez szyfrowanie i uwierzytelnianie pakietów IP, które mogą być routowane w różnych sieciach, w odróżnieniu od IEEE 802.1ae, który chroni ramki Ethernet w lokalnej sieci. IPsec jest wykorzystywany przy budowie tuneli VPN. Przykładowo, gdy użytkownik łączy się zdalnie do sieci firmowej poprzez VPN, IPsec zapewnia, że cały ruch między komputerem użytkownika i siecią firmową jest chroniony, niezależnie od tego, jakie konkretne aplikacje użytkownik uruchomi.\n\n**Odpowiedź \"oferuje uwierzytelnianie na poziomie warstwy sieciowej OSI\" jest niepoprawna.** IEEE 802.1ae skupia się na zapewnieniu bezpieczeństwa w warstwie MAC, a nie w warstwie sieciowej. Protokół ten nie implementuje uwierzytelniania dla wyższych warstw. Protokół IPsec, jak wspomniano, operuje w warstwie sieciowej OSI, zapewniając uwierzytelnianie i ochronę pakietów IP podczas przesyłania ich między sieciami. Przykładowo, IPsec może używać certyfikatów cyfrowych do uwierzytelniania tożsamości stron połączenia VPN.\n\n**Odpowiedź \"oferuje ochrone poufnosci i integralnosci komunikacji na poziomie warstwy MAC\" jest poprawna.**  IEEE 802.1ae, działając w warstwie MAC, bezpośrednio chroni ramki Ethernet poprzez szyfrowanie (zapewniając poufność) i obliczanie kodów uwierzytelniających (zapewniając integralność). Oznacza to, że komunikacja w ramach sieci lokalnej zabezpieczonej MACsec jest chroniona przed podsłuchem i manipulacją na najniższym poziomie, gdzie ramy są fizycznie przesyłane. Przykładowo, w dużej firmie, gdzie wiele urządzeń komunikuje się przez sieć lokalną, 802.1ae chroni przed atakami wewnątrz sieci, na przykład gdy pracownik próbuje podejrzeć ruch innego pracownika lub zmodyfikować pakiety.\n\n**Odpowiedź \"oferuje ochrone poufnosci i integralnosci komunikacji na poziomie warstwy OSI\" jest niepoprawna.** Chociaż IEEE 802.1ae faktycznie oferuje ochronę poufności i integralności, jest specyficzna dla warstwy MAC. Zatem mówienie tylko o warstwie OSI (ang. _Open Systems Interconnection_) jest zbyt ogólne. OSI to model referencyjny, a nie warstwa komunikacji.  Protokoły bezpieczeństwa są często implementowane na określonych warstwach, tak aby najskuteczniej chronić transmisję na danym poziomie. Nieprawidłowe jest myślenie o \"warstwie OSI\" jako o jakiejś konkretnej warstwie gdzie dany protokół działa."
    },
    {
        "questionId": 78,
        "title": "Wskaz, ktore z wymienionych operacji obslugiwane sa przez mechanizm POSIX CAP (capabilities):",
        "answers": [
            {
                "text": "administrowanie siecia",
                "isCorrect": true
            },
            {
                "text": "administrowanie modulami jadra",
                "isCorrect": true
            },
            {
                "text": "omijanie limitow zasobowych",
                "isCorrect": true
            },
            {
                "text": "omijanie ograniczen dotyczacych kontroli dostepu do plikow",
                "isCorrect": true
            },
            {
                "text": "dowiazanie do gniazd numerow portow systemowych",
                "isCorrect": true
            },
            {
                "text": "realizacja komunikacji grupowej rozgloszeniowej w sieci",
                "isCorrect": true
            }
        ],
        "clue": 6,
        "isStarred": false,
        "explanation": "Mechanizm POSIX capabilities (CAP) to sposób na rozbicie wszechmocnych uprawnień superużytkownika root w systemach Unix/Linux na mniejsze, bardziej precyzyjne uprawnienia.  Zamiast przyznawać procesowi pełne uprawnienia administratora, CAP umożliwia przypisanie mu tylko tych uprawnień, które są mu rzeczywiście potrzebne do działania. To podejście znacznie zwiększa bezpieczeństwo systemu.\n\n*   **administrowanie siecią:** Jest to **poprawna** odpowiedź. CAP pozwala na przykład na przyznanie procesowi możliwości tworzenia gniazd sieciowych, wysyłania pakietów, zmiany tras routingu lub zarządzanie firewall. Bez pełnych uprawnień root, proces z taką możliwością ma kontrolę tylko nad tymi aspektami sieci, które zostały mu wyraźnie przyznane. Przykładowo, serwer DHCP może potrzebować możliwości otwierania portów sieciowych, ale nie zarządzania dyskami. \n*   **administrowanie modulami jadra:** Jest to **poprawna** odpowiedź. CAP umożliwia procesom ładowanie i usuwanie modułów jądra, co jest operacją wymagającą normalnie uprawnień administratora. Bez tego uprawnienia nawet działający serwer nie był by w stanie np. zmienić modułu karty sieciowej.\n*   **omijanie limitow zasobowych:** Jest to **poprawna** odpowiedź. CAP pozwala procesowi ignorować standardowe limity zasobów narzucane przez system (np. ograniczenia pamięci czy czasu procesora). Mechanizm ten jest istotny dla aplikacji, które wymagają dużej elastyczności w wykorzystywaniu zasobów (np. serwery baz danych). Oczywiście nadużywanie tego mechanizmu spowoduje utratę stabilności całego systemu operacyjnego.\n*   **omijanie ograniczen dotyczacych kontroli dostepu do plikow:** Jest to **poprawna** odpowiedź. Standardowo proces nie może czytać ani modyfikować danych należących do innych użytkowników (chyba, że posiada uprawnienia superużytkownika), ale CAP umożliwia obejście tego ograniczenia. Proces może mieć przyznane uprawnienie, które pozwala mu na odczyt lub zapis plików bez konieczności bycia ich właścicielem. Ma to znaczenie w przypadku takich procesów jak na przykład skanery antywirusowe.\n*   **dowiazanie do gniazd numerow portow systemowych:** Jest to **poprawna** odpowiedź. W systemach Linux/Unix porty o numerach niższych niż 1024 (tzw. porty uprzywilejowane) normalnie mogą być wykorzystane tylko przez procesy uruchomione przez administratora. CAP pozwala procesowi przypisywanie się do tych portów. Jest to przydatne dla aplikacji typu serwer WWW, czy serwer pocztowy, które standardowo korzystają z portów systemowych.\n*    **realizacja komunikacji grupowej rozgloszeniowej w sieci:** Jest to **poprawna** odpowiedź. CAP pozwala procesom na wysyłanie pakietów rozgłoszeniowych i grupowych w sieci, co normalnie wymaga uprawnień administratora. Z tego mechanizmu korzystają np. niektóre mechanizmy wykrywania sprzętu w sieci lokalnej.\n\nDzięki CAP możliwe jest tworzenie bardziej bezpiecznych i elastycznych systemów, poprzez precyzyjne definiowanie uprawnień aplikacji i usług systemowych."
    },
    {
        "questionId": 79,
        "title": "Cecha single-sign-on jest:",
        "answers": [
            {
                "text": "stosowanie funkcji skrotu w celu uzyskania podpisu cyfrowego",
                "isCorrect": false
            },
            {
                "text": "jednokrotne uwierzytelnianie uzytkownika sieci",
                "isCorrect": true
            },
            {
                "text": "podpisywanie kazdego pliku innym kluczem",
                "isCorrect": false
            },
            {
                "text": "szyfrowanie sesji przy pomocy jednorazowego klucza",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Single Sign-On (SSO) to metoda uwierzytelniania użytkownika, która pozwala na jednorazowe zalogowanie się i uzyskanie dostępu do wielu różnych zasobów, systemów lub aplikacji bez konieczności ponownego podawania danych uwierzytelniających (np. nazwy użytkownika i hasła). Użytkownik po uwierzytelnieniu w systemie SSO uzyskuje dostęp do wszystkich systemów, które są w ramach danej domeny zaufania, bez konieczności wielokrotnego logowania się.\n\n*   **\"stosowanie funkcji skrotu w celu uzyskania podpisu cyfrowego\"** - Odpowiedź ta jest **niepoprawna**. Funkcje skrótu (np. MD5, SHA-256) są używane w kryptografii do generowania skrótów danych, które służą do weryfikacji integralności danych lub jako element podpisu cyfrowego, jednak nie stanowią one istoty mechanizmu SSO. Podpis cyfrowy gwarantuje autentyczność i nienaruszalność dokumentu. Chociaż elementy kryptografii są wykorzystywane w mechanizmach SSO, nie jest to definiujące SSO, które jest bardziej o jednokrotnym uwierzytelnianiu niż o konkretnym algorytmie szyfrowania. Przykład:  w systemie plików Linux i programie rsync możemy wykorzystać skrót SHA-256 do weryfikacji poprawności plików, ale nie ma to żadnego związku z SSO.\n\n*   **\"jednokrotne uwierzytelnianie uzytkownika sieci\"** - Odpowiedź ta jest **poprawna**. Istotą SSO jest umożliwienie użytkownikowi jednorazowego uwierzytelnienia, które jest następnie wykorzystywane do dostępu do wielu systemów. Dzięki temu użytkownik unika wielokrotnego logowania się i zapamiętywania wielu haseł. Zaletą jest wygoda i wzrost produktywności użytkowników. Przykład: W środowisku korporacyjnym, po jednorazowym zalogowaniu się do systemu operacyjnego, użytkownik ma dostęp do swoich aplikacji, poczty elektronicznej i innych systemów wewnętrznych firmy bez ponownego logowania się.\n\n*   **\"podpisywanie kazdego pliku innym kluczem\"** - Odpowiedź ta jest **niepoprawna**. Idea podpisywania plików różnymi kluczami nie jest powiązana z ideą SSO. Podpisywanie plików służy do ochrony integralności danych oraz do poświadczenia autorstwa pliku. Każdy z podpisów powiązany jest z kluczem osoby podpisującej. Natomiast SSO pozwala uwierzytelnić danego użytkownika i przypisać do niego zbiór uprawnień. Przykład: Podpisywanie kodu źródłowego projektów open source za pomocą mechanizmu GPG daje gwarancję, że kod nie został zmieniony po jego publikacji.\n\n*   **\"szyfrowanie sesji przy pomocy jednorazowego klucza\"** - Odpowiedź ta jest **niepoprawna**. Szyfrowanie sesji, najczęściej przy użyciu jednorazowego klucza, to technika zapewniania poufności przesyłanych danych. Takie podejście najczęściej wykorzystywane jest w połączeniach SSL i TLS, gdzie do ustalenia jednorazowego klucza symetrycznego używa się algorytmów kryptografii asymetrycznej, jednak takie rozwiązanie nie jest istotą SSO. Przykład: Przeglądanie stron internetowych w trybie HTTPS zapewnia szyfrowanie danych przesyłanych między przeglądarką a serwerem, co chroni przed przechwyceniem ich przez niepowołane osoby. To szyfrowanie sesji, ale nie jest to mechanizm SSO."
    },
    {
        "questionId": 80,
        "title": "Ktory z wymienionych protokolow pozwala w procesie uwierzytelniania calkowicie uniknac przesylania hasla podmiotu uwierzytelnianego (w jakiejkolwiek postaci):",
        "answers": [
            {
                "text": "SSH",
                "isCorrect": true
            },
            {
                "text": "SSL",
                "isCorrect": false
            },
            {
                "text": "CHAP",
                "isCorrect": true
            },
            {
                "text": "PAP",
                "isCorrect": false
            },
            {
                "text": "SPAP",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) i CHAP (Challenge Handshake Authentication Protocol) umożliwiają uwierzytelnianie bez przesyłania hasła w jakiejkolwiek postaci, wykorzystując do tego celu inne mechanizmy, takie jak kryptografia asymetryczna.\n\n**SSH (Secure Shell):** SSH używa kryptografii klucza publicznego do uwierzytelniania. W tym procesie, serwer prezentuje klientowi swój klucz publiczny. Klient weryfikuje tożsamość serwera na podstawie posiadanej kopii klucza publicznego serwera. Jeśli strona klienta posiada klucz prywatny powiązany z kluczem publicznym skojarzonym z kontem użytkownika po stronie serwera, to wówczas, bez podawania hasła, sesja zostaje ustanowiona. W przypadku braku takiego klucza, hasło może być wymagane, ale nawet wówczas przesyłane jest w zaszyfrowanej postaci, więc nie spełnia wymogów zadania. W przypadku wykorzystania kluczy użytkownika w procesie autentykacji hasło nie jest nigdzie przesyłane, dlatego jest to odpowiedź poprawna. W praktyce, gdy logujemy się przez SSH na serwer, najpierw klient weryfikuje serwer, potem klient wykorzystując klucz prywatny uwierzytelnia się przed serwerem.\n\n**SSL (Secure Sockets Layer)/TLS (Transport Layer Security):** SSL/TLS służy do szyfrowania komunikacji, w tym uwierzytelniania serwera (lub klienta) za pomocą certyfikatów cyfrowych. SSL/TLS może wykorzystywać *różne* metody uwierzytelniania użytkownika, w tym hasła, jednak nie unika tego rodzaju uwierzytelniania całkowicie. Protokół SSL *może* działać na podstawie certyfikatów (które nie zawierają hasła), jednak w wielu przypadkach (np. bankowość elektroniczna) proces uwierzytelnienia użytkownika opiera się na podaniu hasła, dlatego też nie jest to odpowiedź poprawna. SSL służy głównie do ochrony komunikacji (w tym chroni przed podsłuchem przesyłania hasła), a nie do całkowitego uniknięcia jego przesyłania.\n\n**CHAP (Challenge Handshake Authentication Protocol):** CHAP działa na zasadzie wyzwania-odpowiedzi. Serwer wysyła losowe wyzwanie, klient na podstawie swojego hasła wylicza odpowiedź i odsyła ją. Nigdzie w procesie nie jest przesyłane hasło w postaci jawnej, ale hasło jest wykorzystywane przez algorytm kryptograficzny do wygenerowania odpowiedzi, czyli hasło jest nadal wykorzystywane w tym mechanizmie. Jest to metoda lepsza od PAP, jednak nadal hasło (w postaci przekształconej) jest wykorzystywane w procesie autentykacji. Natomiast w treści pytania nie ma informacji, że hasło ma być w ogóle użyte w procesie autentykacji, stąd odpowiedź ta jest poprawna. W praktyce, CHAP używa się do uwierzytelnienia w protokole PPP (Point-to-Point Protocol).\n\n**PAP (Password Authentication Protocol):** PAP jest protokołem, który przesyła hasło w postaci jawnej, bezpośrednio przez sieć. Nie używa szyfrowania. Jest to bardzo niebezpieczne, gdyż hasło może być łatwo przechwycone przez osoby niepowołane. Z tego powodu nie jest to odpowiedź poprawna. W praktyce użycie PAP, gdy jest do dyspozycji protokół CHAP, jest nieuzasadnione.\n\n**SPAP (Shiva Password Authentication Protocol):** SPAP jest to ulepszona odmiana PAP. Hasło nie jest wysyłane tekstem jawnym lecz zaszyfrowane za pomocą algorytmu szyfrowania odwracalnego. Mimo tego, że hasło jest zaszyfrowane nadal jest ono przesłane, a zadaniem tego pytania jest wybranie odpowiedzi, w których hasło nie jest w ogóle przesyłane."
    },
    {
        "questionId": 81,
        "title": "Metoda programowego generowania hasel jednorazowych opracowana przez L.Lamporta polega m.in. na:",
        "answers": [
            {
                "text": "wygenerowaniu losowe listy N hasel wykorzystywanych wyrywkowo przez system",
                "isCorrect": false
            },
            {
                "text": "wygenerowaniu N-elementowej sekwencji wywierdoznej deterministycznie z zadanego hasla",
                "isCorrect": true
            },
            {
                "text": "wykorzystywaniu silnej kryptografii z kluczem rownym poczatkowemu haslu do ochrony kolejnych hasel",
                "isCorrect": false
            },
            {
                "text": "wykorzystywaniu wygenerowanych hasel w kolejnosci odwrotnej (od ostatniego poczawszy)",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Metoda generowania haseł jednorazowych zaproponowana przez L. Lamporta opiera się na deterministycznym tworzeniu sekwencji haseł z jednego początkowego hasła. Deterministyczność oznacza, że dla danego hasła wejściowego (nazywanego też „ziarnem”) oraz tej samej funkcji generującej, zawsze otrzymamy identyczną sekwencję wyjściową.\n\nMetoda Lamporta nie polega na generowaniu losowej listy haseł używanych w przypadkowej kolejności. Zamiast tego, z hasła początkowego tworzona jest sekwencja haseł w sposób, który uniemożliwia odtworzenie poprzednich haseł z następnych – a dokładniej poprzednie hasło jest tworzone z następnego za pomocą funkcji jednokierunkowej. Funkcja jednokierunkowa to taka funkcja, którą można łatwo wykonać w jedną stronę, natomiast obliczenie jej odwrotności jest praktycznie niewykonalne. Funkcja taka nie jest szyfrowaniem ani deszyfrowaniem, ale bardzo często są to funkcje skrótu kryptograficznego lub bardzo podobne algorytmy. Funkcja jednokierunkowa jest wykonywana wielokrotnie na haśle początkowym (albo na poprzednim haśle sekwencji), a jej wynik – kolejne hasło – jest wykorzystywane w sekwencji. Tak stworzona sekwencja jest przechowywana przez system uwierzytelniający oraz przez użytkownika, a następnie hasła są wykorzystywane w kolejności odwrotnej – od ostatniego do pierwszego.\n\n**Odpowiedź 1: wygenerowaniu losowe listy N hasel wykorzystywanych wyrywkowo przez system** - Ta odpowiedź jest **niepoprawna**, ponieważ metoda Lamporta opiera się na deterministycznym wygenerowaniu sekwencji haseł, a nie na losowej liście, gdzie każde hasło jest niezależne. W metodzie Lamporta hasła są tworzone na podstawie poprzednich haseł używając funkcji jednokierunkowej, co nie zachodzi dla listy haseł losowych. Metoda losowej listy jest standardowym podejściem do tworzenia list haseł jednorazowych, w którym każde hasło jest niezależne.\n\n**Odpowiedź 2: wygenerowaniu N-elementowej sekwencji wywierdoznej deterministycznie z zadanego hasla** - Ta odpowiedź jest **poprawna**. Z początkowego hasła, za pomocą deterministycznej funkcji, generowana jest sekwencja N haseł. Deterministyczność oznacza, że dla danego hasła początkowego zawsze powstanie taka sama sekwencja haseł. To jest kluczowe dla metody Lamporta. Na przykład, startując od hasła „secret123”, deterministyczna funkcja generuje „hash1”, a następnie z „hash1” generuje „hash2” i tak dalej, aż do „hashN”. Każdy krok generacji jest jednoznaczny.\n\n**Odpowiedź 3: wykorzystywaniu silnej kryptografii z kluczem rownym poczatkowemu haslu do ochrony kolejnych hasel** - Ta odpowiedź jest **niepoprawna**. Chociaż w metodzie Lamporta hasło początkowe jest wykorzystywane, ale nie w sposób standardowego algorytmu szyfrowania. Kolejne hasła są generowane z poprzednich haseł przy pomocy funkcji jednokierunkowej, nie stosuje się tutaj algorytmów szyfrowania. Funkcja jednokierunkowa służy do tego aby odtworzenie hasła poprzedniego na podstawie następnego było bardzo trudne, lub nie wykonalne. Celem nie jest tutaj ochrona hasła w sensie jego zaszyfrowania, tylko uniemożliwienie jego odtworzenia.\n\n**Odpowiedź 4: wykorzystywaniu wygenerowanych hasel w kolejnosci odwrotnej (od ostatniego poczawszy)** - Ta odpowiedź jest **poprawna**. W metodzie Lamporta, z powodu właściwości funkcji jednokierunkowej, hasła wykorzystuje się w kolejności odwrotnej do ich generowania. Z hasła początkowego generuje się hasło pierwsze (którego użytkownik nie używa do logowania), hasło drugie i tak dalej do hasła N, które ma być wykorzystane jako pierwsze. Kolejne próby logowania wykorzystują hasła kolejno: N, N-1, N-2, ..., 2, 1. Taki sposób używania haseł zabezpiecza system przed potencjalnym odtworzeniem przyszłych haseł. Jeśli ktoś pozna hasło N-3 nie będzie w stanie obliczyć hasła N-4 ponieważ funkcja jest jednokierunkowa. Ta kolejność jest kluczowa dla bezpieczeństwa metody Lamporta, bez niej metoda ta traci swój sens."
    },
    {
        "questionId": 82,
        "title": "Ktore narzedzia wykorzystywane sa do ochrony antyspamowej w systemie pocztowym?",
        "answers": [
            {
                "text": "open proxy",
                "isCorrect": false
            },
            {
                "text": "open relay",
                "isCorrect": false
            },
            {
                "text": "szare listy",
                "isCorrect": true
            },
            {
                "text": "filtry Bayesa",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizmy antyspamowe w systemach pocztowych służą do filtrowania i redukowania niechcianych wiadomości e-mail. Działają na różnych poziomach przetwarzania poczty, od serwera poczty odbierającego wiadomości (MTA), po klienta poczty odbierającego wiadomości (MUA).\n\n**Szare listy (ang. greylisting)** to technika obrony przed spamem, która wykorzystuje tymczasowe odrzucanie wiadomości od nieznanych serwerów. Działa to w ten sposób, że gdy serwer poczty odbiera wiadomość od serwera, którego wcześniej nie zna, to nie odrzuca jej na stałe, ale odrzuca ją tymczasowo z informacją, że ma spróbować za jakiś czas (np. 15 minut). Legitymne serwery pocztowe wysyłają ponownie wiadomość i są one odbierane, natomiast serwery spamu, których celem jest masowe rozsyłanie wiadomości z reguły nie ponawiają próby ich wysłania. Zatem mechanizm ten pozwala odfiltrować większość spamu, jednak powoduje to, że odbiór poczty nastąpi z opóźnieniem.\n\n**Filtry Bayesa** to zaawansowane filtry, które działają w sposób statystyczny, tzn. uczą się na podstawie wcześniej wprowadzonych przykładów wiadomości. Użytkownik musi określić czy dana wiadomość jest spamem czy też nie. Filtr na podstawie wielu takich decyzji uczy się na jakie słowa lub ich kombinacje należy zwracać uwagę oraz jakie cechy posiada dana wiadomość spamerska i na tej podstawie filtruje wiadomości. Filtr Bayesa wykorzystuje twierdzenie Bayesa do obliczenia prawdopodobieństwa, że dana wiadomość jest spamem, na podstawie częstotliwości występowania pewnych słów lub fraz w wiadomościach spamowych i nie spamowych. Im więcej wiadomości użytkownik poda do nauki dla filtru Bayesa, tym skuteczność filtru jest większa.\n\n**Otwarte serwery przekazujące (ang. open relay)** są **niepoprawnym** rozwiązaniem w kontekście ochrony antyspamowej. Open relay to serwery pocztowe, które nie wymagają uwierzytelniania przed wysłaniem wiadomości, przez co każda nieuprawniona osoba(spamer) może użyć takiego serwera do rozsyłania spamu bez ujawnienia swojej tożsamości, a w konsekwencji serwer staje się źródłem rozsyłania spamu. Dlatego tez serwery pocztowe starają się chronić przed otwartym przekazywaniem. \nOchrona przed otwartymi serwerami przekazującymi opiera się na uwierzytelnianiu przesyłek wychodzących, np. przy pomocy protokołu SMTP AUTH. Dzięki tej procedurze serwer sprawdza czy użytkownik żądający przesłanie poczty ma do tego prawo (czy ma konto w domenie chronionej przez dany serwer). \n\n**Otwarte serwery proxy (ang. open proxy)** są również **niepoprawnym** rozwiązaniem w kontekście ochrony antyspamowej. Otwarte serwery proxy umożliwiają anonimowe połączenie z siecią Internet poprzez tunelowanie połączenia. Spamerzy wykorzystują je do maskowania swojego adresu IP podczas rozsyłania spamu, przez co utrudniona jest identyfikacja źródła spamu. Open proxy tak jak open relay jest problemem, a nie rozwiązaniem."
    },
    {
        "questionId": 83,
        "title": "Sposrod podanych mechanizmow wskaz te wykorzystujace kryptografie:",
        "answers": [
            {
                "text": "X.509",
                "isCorrect": true
            },
            {
                "text": "podpis cyfrowy",
                "isCorrect": true
            },
            {
                "text": "ROT13",
                "isCorrect": false
            },
            {
                "text": "UUencoding",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Kryptografia to nauka o metodach utajniania danych, a mechanizmy wykorzystujące kryptografie są oparte na algorytmach matematycznych, które zapewniają poufność, integralność, autentyczność i niezaprzeczalność danych. \n\n**X.509** jest to standard definiujący format certyfikatów klucza publicznego. Certyfikaty X.509 wykorzystywane są do uwierzytelniania i szyfrowania komunikacji. Zawierają klucz publiczny, informacje o właścicielu klucza i podpis wystawcy (urzędu certyfikacji), który gwarantuje autentyczność klucza i jego powiązanie z daną tożsamością. Certyfikaty X.509 są fundamentem infrastruktury klucza publicznego (PKI) i są szeroko stosowane w protokołach SSL/TLS (HTTPS) do ochrony komunikacji internetowej. Mechanizm X.509 wykorzystuje algorytmy kryptografii asymetrycznej (RSA, DSA, ElGamal) do podpisywania i przesyłania kluczy.  Na przykład, podczas bezpiecznego połączenia z serwerem banku (HTTPS), przeglądarka pobiera certyfikat serwera, w którym znajduje się klucz publiczny serwera. Przeglądarka weryfikuje ten certyfikat za pomocą podpisu urzędu certyfikacji, co zapewnia, że komunikacja odbywa się z autentycznym serwerem bankowym, a nie z fałszywą stroną.  \n\n**Podpis cyfrowy** to metoda kryptograficzna zapewniająca autentyczność oraz integralność danych. Polega na wygenerowaniu skrótu danych za pomocą funkcji haszującej i zaszyfrowaniu tego skrótu kluczem prywatnym nadawcy. Odbiorca odszyfrowuje skrót za pomocą klucza publicznego nadawcy i porównuje z hashem wyliczonym z otrzymanych danych. Jeśli oba hashe są identyczne, oznacza to że wiadomość nie została zmodyfikowana i pochodzi od właściwego nadawcy. Podpis cyfrowy wykorzystuje kryptografię asymetryczną (RSA, DSA, ElGamal) oraz funkcje skrótu (MD5, SHA-1, SHA-256). Na przykład, w transakcjach elektronicznych podpis cyfrowy jest wykorzystywany do potwierdzania autentyczności przelewów bankowych. Przelew jest podpisywany kluczem prywatnym banku, a bank odbiorcy weryfikuje podpis za pomocą klucza publicznego tego banku, upewniając się, że przelew jest autentyczny i nie został zmieniony.\n\n**ROT13** to bardzo prosty szyfr podstawieniowy, który polega na przesunięciu każdej litery o 13 pozycji w alfabecie. Nie jest to mechanizm kryptograficzny, ponieważ nie zapewnia poufności ani integralności danych. ROT13 jest formą zamaskowania tekstu i jest łatwo odwracalny. ROT13 nie wykorzystuje algorytmów kryptograficznych, jest tylko prostym szyfrem, który łatwo jest złamać, nie jest stosowany do zabezpieczenia poufnych danych.  Na przykład, w niektórych forum internetowych ROT13 jest wykorzystywany, aby \"ukryć\" spoilery z fabuł filmowych czy książek, jednak ma on charakter bardziej zabawny niż faktycznie ochronny.\n\n**UUencoding** to metoda kodowania binarnych danych do formatu tekstowego za pomocą znaków ASCII, tak aby można je było przesyłać w kanałach przeznaczonych tylko do przesyłania danych tekstowych np. poczta elektroniczna, nie jest to mechanizm kryptograficzny i nie zapewnia poufności. Jest to prosty algorytm kodowania znaków binarnych, aby były przesyłane w formie tekstu i nie są wykorzystywane mechanizmy kryptograficzne. Na przykład, UUencoding używany był do przesyłania plików binarnych jako załączników w emailach, ale obecnie zostało to zastąpione przez bardziej efektywne i niezawodne rozwiązania (MIME)."
    },
    {
        "questionId": 84,
        "title": "Wskaz cechy SNAT:",
        "answers": [
            {
                "text": "wymaga utrzymywania listy aktywnych translacji",
                "isCorrect": true
            },
            {
                "text": "ukrywa rzeczywisty adres nadawcy pakietu",
                "isCorrect": true
            },
            {
                "text": "moze byc pomyslnie wykonane posrodku tunelu VPN zarowno w trybie tunelowym jak i transportowym",
                "isCorrect": false
            },
            {
                "text": "moze byc pomyslnie wykonane posrodku tunelu VPN tylko w trybie transportowym",
                "isCorrect": false
            },
            {
                "text": "wymaga uwierzytelnienia stron przed zestawieniem polaczenia",
                "isCorrect": false
            },
            {
                "text": "pozwala uniknac powtornego sprawdzania regul filtracji dla ruchu zweryfikowanego uprzednio",
                "isCorrect": false
            },
            {
                "text": "dokonuje podmiany zarowno adresu jak i numeru portu",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Source Network Address Translation (SNAT) to technika modyfikacji adresów IP, która jest wykonywana w routerach, zaporach sieciowych i serwerach. Jej głównym zadaniem jest umożliwienie hostom w sieci lokalnej z prywatnymi adresami IP łączenie się z siecią publiczną, taką jak internet, wykorzystując pojedynczy publiczny adres IP. SNAT działa poprzez zamianę prywatnego adresu IP źródła pakietu danych na publiczny adres IP interfejsu, przez który pakiet opuszcza sieć lokalną, a także poprzez zmianę numeru portu źródłowego. \n\n*   **\"wymaga utrzymywania listy aktywnych translacji\"** - **Prawidłowa odpowiedź.** SNAT jest mechanizmem stanowym. Oznacza to, że urządzenie wykonujące SNAT musi śledzić i zapamiętywać informacje o aktywnych połączeniach, aby móc poprawnie przetłumaczyć zwrotne pakiety od serwera docelowego. Urządzenie SNAT prowadzi tablicę, w której przechowuje relacje pomiędzy oryginalnym adresem IP i portem komputera w sieci lokalnej a zewnętrznym adresem IP i portem używanym podczas połączenia z Internetem. \n\n*   **\"ukrywa rzeczywisty adres nadawcy pakietu\"** - **Prawidłowa odpowiedź.** SNAT z założenia ukrywa oryginalne adresy IP komputerów w sieci prywatnej, zamieniając je na adres IP urządzenia wykonującego translację. Komputery docelowe w sieci publicznej widzą tylko adres IP rutera lub zapory sieciowej jako źródło połączenia, a nie rzeczywiste adresy komputerów wewnętrznych. Zwiększa to anonimowość i utrudnia ewentualne ataki bezpośrednio na komputery wewnętrzne.\n\n*   **\"moze byc pomyslnie wykonane posrodku tunelu VPN zarowno w trybie tunelowym jak i transportowym\"** - **Nieprawidłowa odpowiedź.** SNAT jest operacją translacji adresów IP, która zachodzi na poziomie warstwy sieciowej. Tunel VPN, niezależnie od trybu (tunelowy lub transportowy), jest mechanizmem warstwy sieciowej i wyższej, czyli może być zrealizowany po lub przed operacją SNAT. SNAT nie działa \"wewnątrz\" tunelu VPN, a raczej na brzegu sieci. Sam tunel nie potrzebuje i nie zależy od SNAT.\n\n*  **\"moze byc pomyslnie wykonane posrodku tunelu VPN tylko w trybie transportowym\"** - **Nieprawidłowa odpowiedź.** Jak objaśniono powyżej, SNAT nie jest uzależniony od trybu tunelowania VPN.\n\n*   **\"wymaga uwierzytelnienia stron przed zestawieniem polaczenia\"** - **Nieprawidłowa odpowiedź.** SNAT to mechanizm translacji adresów IP, a nie uwierzytelniania. Uwierzytelnianie, czyli potwierdzanie tożsamości stron komunikacji, to odrębny proces i jest obsługiwany przez inne mechanizmy np. hasła, klucze, certyfikaty - często w protokołach wyższych warstw modelu OSI.\n\n*   **\"pozwala uniknac powtornego sprawdzania regul filtracji dla ruchu zweryfikowanego uprzednio\"** - **Nieprawidłowa odpowiedź.** Mechanizmy unikania powtórnego sprawdzania reguł filtracji, są mechanizmami stanowej inspekcji, a nie samego SNAT. System stanowej inspekcji zapamiętuje połączenie które zostało uprzednio zweryfikowane i dzięki temu nie musi ponownie sprawdzać wszystkich reguł filtrujących, co znacznie przyspiesza działanie zapory sieciowej. Natomiast SNAT nie jest takim mechanizmem.\n\n*   **\"dokonuje podmiany zarowno adresu jak i numeru portu\"** - **Prawidłowa odpowiedź.** Podczas translacji SNAT oprócz zmiany adresu IP źródła pakietu, następuje również zamiana numeru portu źródłowego na nowy wolny numer portu. Ma to na celu zwiększenie liczby urządzeń w sieci lokalnej mających jednocześnie dostęp do sieci publicznej z wykorzystaniem tylko jednego zewnętrznego adresu IP. W wielu środowiskach najczęściej widoczne jest połączenie SNAT z PAT (_ang. Port Address Translation_), gdzie numery portów źródłowych są podstawiane dynamicznie i wykorzystywane do jednoznacznego zidentyfikowania przepływającego ruchu sieciowego. Na przykład gdy dwa komputery z tej samej sieci lokalnej uzyskują dostęp do tej samej usługi (np. serwera WWW) na komputerze zdalnym, ich pakiety mają ten sam docelowy adres IP i port serwera WWW, ale z uwagi na mechanizm SNAT różnią się portem źródłowym w nagłówku pakietu. Zmiana portów jest niezbędna do poprawnej komunikacji zwrotnej z serwera."
    },
    {
        "questionId": 85,
        "title": "Komputery kwantowe i obliczenia kwantowe moga stanowic powazne zagrozenie dla:",
        "answers": [
            {
                "text": "steganografii",
                "isCorrect": false
            },
            {
                "text": "aktualnych mechanizmow detekcji anomalii w systemach IDS",
                "isCorrect": false
            },
            {
                "text": "wspolczesnych algorytmow kryptografii asymetrycznej, takich jak RSA",
                "isCorrect": true
            },
            {
                "text": "zapor sieciowych typu proxy",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Komputery kwantowe, dzięki wykorzystaniu zjawisk mechaniki kwantowej, posiadają potencjał do rozwiązywania problemów obliczeniowych, które są poza zasięgiem klasycznych komputerów. W kontekście bezpieczeństwa systemów komputerowych, algorytmy kryptografii asymetrycznej, takie jak RSA, są szczególnie podatne na ataki za pomocą komputerów kwantowych. Kryptografia asymetryczna opiera się na trudności obliczeniowej pewnych problemów matematycznych, które na klasycznych komputerach są bardzo trudne do rozwiązania w rozsądnym czasie. Przykładowo, RSA opiera się na trudności faktoryzacji dużych liczb. Komputery kwantowe, wykorzystując algorytm Shora, mogą rozwiązać problem faktoryzacji w czasie wielomianowym, co oznacza, że są w stanie w relatywnie krótkim czasie złamać szyfrowanie RSA, a tym samym odczytać zaszyfrowaną informację, pozyskując klucz prywatny.\n\n**steganografia** - nie jest kryptografią lecz metodą ukrywania informacji w innych, jawnych informacjach, np. w obrazie, dźwięku. Komputery kwantowe nie stanowią bezpośredniego zagrożenia dla technik ukrywania danych, lecz mogą potencjalnie zwiększyć zdolność do analizowania i wykrywania tych ukrytych informacji (np. poprzez kryptonalizę ewentualnego szyfrowania zawartości, lub przez zaawansowane techniki analizy obrazu czy dźwięku). Jednak to nadal nie jest bezpośrednie zagrożenie dla steganografii samej w sobie, tylko dla metod dodatkowego ukrywania zawartości.\n\n**aktualne mechanizmy detekcji anomalii w systemach IDS** - systemy IDS (Intrusion Detection Systems) monitorują ruch sieciowy w poszukiwaniu anomalii lub sygnatur zdefiniowanych dla znanych ataków. Komputery kwantowe nie są bezpośrednim atakiem na algorytmy detekcji anomalii w systemach IDS. Problemem będą raczej skomplikowane ataki, które będzie można wykonać za pomocą komputerów kwantowych. Komputery kwantowe mogłyby np. zwiększyć trudność w detekcji ataku typu DDoS poprzez generowanie dużego ruchu rozproszonego z wielu źródeł na bardzo krótki czas. Jednak na same mechanizmy detekcji anomalii w systemach IDS nie będzie to miało bezpośredniego wpływu. Natomiast wzrośnie stopień skomplikowania ataków, a co za tym idzie utrudnione będzie tworzenie definicji dla nowych ataków, tym samym zwiększy się liczba fałszywych alarmów i systemy IDS będą mniej efektywne.\n\n**współczesne algorytmy kryptografii asymetrycznej, takich jak RSA** - algorytmy kryptografii asymetrycznej, takie jak RSA, są oparte o trudność obliczeniową problemów matematycznych, które dla klasycznych komputerów są bardzo trudne do rozwiązania w rozsądnym czasie. Komputery kwantowe, wykorzystując na przykład algorytm Shora, mogą rozwiązać problem faktoryzacji dużych liczb w relatywnie krótkim czasie, co oznacza, że są w stanie w relatywnie krótkim czasie złamać szyfrowanie RSA. Takie możliwości komputerów kwantowych wywołują poważny problem braku możliwości zapewnienia poufności przesyłanych danych za pomocą dotychczasowych technik. To właśnie ten fakt sprawia, że powstaje nowa dziedzina w kryptografii jaką jest kryptografia postkwantowa.\n\n**zapory sieciowe typu proxy** - zapory sieciowe typu proxy działają na poziomie warstwy aplikacji, przekazując ruch sieciowy w imieniu klienta, i samodzielnie nawiązując połączenia z serwerami w imieniu klientów. Zapory proxy kontrolują dostęp do usług i ich treść ale nie decydują o bezpieczeństwie samego szyfrowania przesyłanych danych. Komputery kwantowe potencjalnie zagrożają algorytmom kryptograficznym używanym w protokołach przesyłania danych a nie technologię pośrednictwa w połączeniu. Dlatego zapory proxy, jako takie nie są bezpośrednio zagrożone przez komputery kwantowe, aczkolwiek poufność przesyłanych danych może być zagrożona jeśli algorytmy kryptograficzne wykorzystywane w protokołach nie będą odporne na ataki ze strony komputerów kwantowych."
    },
    {
        "questionId": 86,
        "title": "Jak zachowa sie system kontroli ACL standardu POSIX w przypadku uzytkownika U nalezacego do grupy G i wpisanego na liscie ACL obiektu p, jesli ani U ani G nie maja jawnie przydzielonego prawa r, ale kategoria \"wszyscy uzytkownicy\" (others) takie uprawnienie do obiektu p posiada:",
        "answers": [
            {
                "text": "prawo do obiektu p nie zostanie efektywnie przyznane, ale U odziedziczy je w glab, jesli p jest katalogiem",
                "isCorrect": false
            },
            {
                "text": "prawo r do obiektu p zostanie efektywnie przyznane bezwarunkowo",
                "isCorrect": false
            },
            {
                "text": "prawo r do obiektu p zostanie efektywnie przyznane, o ile U jest wlascicielem p",
                "isCorrect": false
            },
            {
                "text": "prawo r do obiektu p nie zostanie efektywnie przyznane",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Standard POSIX ACL (Access Control Lists), stosowany między innymi w systemie Linux, oferuje rozszerzony model kontroli dostępu do zasobów (np. plików, katalogów) w porównaniu do podstawowego systemu uprawnień (właściciel, grupa, inni). Przy rozpatrywaniu dostępu do obiektu, system analizuje uprawnienia w określonej kolejności: najpierw sprawdza, czy uprawnienia są nadane wprost użytkownikowi, następnie sprawdza uprawnienia grupowo, a dopiero na końcu uprawnienia z kategorii \"inni\" (others). **Efektywne uprawnienia** to faktyczne uprawnienia, które użytkownik ma do obiektu po uwzględnieniu wszystkich wpisów ACL.\n\n**Odpowiedź A jest niepoprawna**, ponieważ system najpierw sprawdza uprawnienia nadane wprost użytkownikowi (U) i grupie (G). Jeżeli ani użytkownikowi U ani jego grupie G nie zostały jawnie nadane uprawnienia, prawo r do obiektu nie jest przyznawane, nawet jeśli zadeklarowane jest to prawo dla kategorii \"inni\". Co więcej, dziedziczenie uprawnień ma znaczenie jedynie dla nowo tworzonych plików/katalogów. Jeśli obiekt 'p' jest katalogiem, to użytkownik U nie odziedziczy prawa r.\n\n**Odpowiedź B jest niepoprawna**, ponieważ nie ma bezwarunkowego przyznawania uprawnień.  Uprawnienia dla kategorii \"inni\" są rozpatrywane jedynie wtedy, gdy ani użytkownikowi U, ani grupie G, do której należy, nie zostały nadane jawne uprawnienia do obiektu 'p'. Efektywnie, to jest na końcu algorytmu sprawdzania.\n\n**Odpowiedź C jest niepoprawna**, ponieważ bycie właścicielem obiektu nie ma pierwszeństwa przed nadanymi uprawnieniami na liście ACL. Właściciel nie jest uprzywilejowany podczas sprawdzania rozszerzonej listy dostępu. Własność ma jedynie znaczenie, jeśli na liście ACL nie ma żadnego wpisu ani dla konkretnego użytkownika, ani dla grupy do której należy ten użytkownik. Wtedy system sprawdza własność i uprawnienia dla właściciela.\n\n**Odpowiedź D jest poprawna**, ponieważ w algorytmie POSIX ACL uprawnienia z kategorii \"inni\" (others) są brane pod uwagę tylko, gdy ani użytkownikowi U, ani grupie G nie zostały przypisane żadne, nawet zabraniające uprawnienia. Czyli uprawnienie dla innych (others) będzie skuteczne tylko, gdy nie ma wpisu ACL ani dla U, ani dla G. Dopiero brak pasującej reguły dla U i G powoduje sprawdzenie praw \"others\". W tym przypadku, ponieważ użytkownik U i jego grupa G są uwzględnione w ACL (choć bez jawnych uprawnień), prawo \"r\" dla \"others\" nie będzie brane pod uwagę. Praktycznie oznacza to, że jeśli chcemy dać dostęp do obiektu wszystkim, to nie możemy w ogóle definiować użytkowników i grup w liście ACL obiektu.\n\n**Przykład**:\nMamy plik `test.txt` z ACL:\n```\nuser::---\ngroup::---\nother::r--\n```\nUżytkownik `jan` nie ma nadanych uprawnień, należy do grupy `users`, która też nie ma nadanych uprawnień. Zgodnie z algorytmem najpierw sprawdza się uprawnienia użytkownika (jan), potem grupy (users) i dopiero na końcu uprawnienia \"others\". W tym przypadku Jan nie może czytać pliku, mimo że grupa \"others\" może to robić.\n\nJeśli chcemy, aby użytkownik `jan` mógł odczytać plik, należy jawnie dodać go do listy ACL z uprawnieniem do odczytu `setfacl -m u:jan:r test.txt` lub dodać uprawnienie odczytu do grupy `setfacl -m g:users:r test.txt`."
    },
    {
        "questionId": 87,
        "title": "Funkcja skrotu SHA-3 rozni sie od SHA-2:",
        "answers": [
            {
                "text": "ograniczeniami eksportowymi",
                "isCorrect": false
            },
            {
                "text": "posiadaniem strumieniowego trybu pracy",
                "isCorrect": false
            },
            {
                "text": "odpornoscia na ataki Length extension",
                "isCorrect": true
            },
            {
                "text": "uzyciem asymetrycznego schematu szyfrowania",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Funkcje skrótu (ang. hash functions) to algorytmy kryptograficzne, które przekształcają dane wejściowe o dowolnej długości na wyjście o stałej, zwykle znacznie krótszej długości, zwane skrótem (ang. hash). Funkcje te są zaprojektowane tak, aby były jednokierunkowe, co oznacza, że ​​na podstawie skrótu bardzo trudno jest odtworzyć oryginalne dane. Dodatkowo, dobra funkcja skrótu powinna być odporna na kolizje, tj. znalezienie dwóch różnych danych wejściowych, które dają ten sam skrót, powinno być obliczeniowo niewykonalne. SHA-2 (Secure Hash Algorithm 2) to rodzina funkcji skrótu zaprojektowana przez NSA i opublikowana przez NIST w 2001 roku, a w jej skład wchodzą algorytmy takie jak SHA-256, SHA-384 i SHA-512. SHA-3, z kolei, to funkcja skrótu, która wygrała konkurs NIST na nowy standard funkcji skrótu. W przeciwieństwie do SHA-2, SHA-3 nie jest oparty na konstrukcji Merkle-Damgård i jest oparty na konstrukcji gąbki (ang. sponge construction), która z kolei wykorzystuje permutacje Keccak.\n\n**\"ograniczeniami eksportowymi\"** - Jest to odpowiedź niepoprawna. Ograniczenia eksportowe dotyczą często algorytmów szyfrowania, a nie funkcji skrótu. SHA-2 i SHA-3 są algorytmami powszechnie znanymi i nie są objęte takimi ograniczeniami.\n\n**\"posiadaniem strumieniowego trybu pracy\"** - Jest to odpowiedź niepoprawna. Zarówno SHA-2 jak i SHA-3 są funkcjami skrótu. Oznacza to, że nie posiadają trybu pracy strumieniowego, jak ma to miejsce w algorytmach szyfrowania.\n\n**\"odpornoscia na ataki Length extension\"** - Jest to odpowiedź poprawna. Atak Length Extension to rodzaj ataku na funkcje skrótu wykorzystujące konstrukcję Merkle-Damgård (jak SHA-2, MD5). Atak ten pozwala na modyfikację skrótu poprzez dołączenie dodatkowych danych bez znajomości oryginalnego wejścia. Konstrukcja gąbki SHA-3 jest odporna na ten rodzaj ataków. Przykładowo, jeśli ktoś ma skrót SHA-2 wiadomości i wie o długości wiadomości, ale nie zna samej wiadomości, i jest w stanie dołączyć do niej nowe dane to może utworzyć nowy skrót. Atak ten jest zagrożeniem dla konstrukcji MD5 oraz SHA1 i SHA2, ale nie dotyczy SHA-3.\n\n**\"uzyciem asymetrycznego schematu szyfrowania\"** - Jest to odpowiedź niepoprawna. Zarówno SHA-2 jak i SHA-3 to funkcje skrótu, a nie algorytmy szyfrowania. Algorytmy szyfrowania dzielimy na symetryczne i asymetryczne. Funkcje skrótu używa się najczęściej do tworzenia podpisu cyfrowego w oparciu o kryptografię asymetryczną(np RSA). A algorytmy symetryczne do szyfrowania danych."
    },
    {
        "questionId": 88,
        "title": "Wersja 3DES-EDE jest wzmocnieniem algorytmu kryptograficznego DES osiagnietym poprzez:",
        "answers": [
            {
                "text": "trzystopniowe sprawdzenie losowosci doboru klucza",
                "isCorrect": false
            },
            {
                "text": "trzykrotne uzycie algorytmu DES w trybie szyfrowania, deszyfrowania i ponownie szyfrowania",
                "isCorrect": true
            },
            {
                "text": "trzykrotne zastosowanie konwencji jednokierunkowej Electronic Data Exchange",
                "isCorrect": false
            },
            {
                "text": "podzial wyniku szyfrowania na 3 porcje roznej dlugosci wg standardu electronic Data Exchange",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Algorytm 3DES-EDE (Triple DES Encrypt-Decrypt-Encrypt) jest wzmocnieniem algorytmu DES (Data Encryption Standard), który sam w sobie jest symetrycznym algorytmem szyfrowania blokowego. Szyfrowanie symetryczne oznacza, że do szyfrowania i deszyfrowania używany jest ten sam klucz. W przypadku DES długość klucza wynosi 56 bitów, co w dzisiejszych czasach jest uważane za niebezpieczne, z uwagi na możliwość złamania szyfru metodą brutalnego ataku (przeszukiwania wszystkich możliwych kombinacji klucza). 3DES powstał, aby rozwiązać ten problem. W algorytmie 3DES-EDE, zamiast pojedynczego szyfrowania DES, blok danych przechodzi przez trzy następujące po sobie etapy. Najpierw blok danych jest szyfrowany algorytmem DES z pierwszym kluczem, potem wynik szyfrowania jest deszyfrowany przy użyciu drugiego klucza DES, a na końcu wynik deszyfrowania jest ponownie szyfrowany przy użyciu pierwszego klucza DES. Efektem tej sekwencji jest to, że do zaszyfrowania danych używane są dwa klucze DES. Długość klucza to 112 bitów co jest teoretycznie dwukrotnie dłuższym kluczem niż w algorytmie DES z jednym kluczem 56-bitowym. W praktyce używane są również wersje z trzema kluczami o długości 168 bitów. \nZatem, w 3DES-EDE, klucz jest 112-bitowy (lub 168-bitowy) i jego siła wynika z trzykrotnego zastosowania algorytmu DES w trybie szyfrowania-deszyfrowania-szyfrowania.\n\n*   **\"trzystopniowe sprawdzenie losowosci doboru klucza\"**  - Ta odpowiedź jest **niepoprawna**. Choć generowanie klucza powinno uwzględniać element losowości, to akurat algorytm 3DES-EDE nie modyfikuje tego procesu, bazuje tylko na dwóch lub trzech kluczach DES, które same w sobie są odpowiednio długie i losowe. Podstawowe znaczenie ma tutaj sposób wykorzystania algorytmu DES, a nie sposób generowania klucza.\n*   **\"trzykrotne uzycie algorytmu DES w trybie szyfrowania, deszyfrowania i ponownie szyfrowania\"** - Ta odpowiedź jest **poprawna**. Dokładnie opisuje proces 3DES-EDE, czyli szyfrowanie za pomocą DES, następnie deszyfrowanie przy użyciu drugiego klucza DES, a następnie ponowne szyfrowanie z użyciem pierwszego klucza DES. To sekwencja operacji wzmacnia szyfrowanie względem pojedynczego DES.\n*   **\"trzykrotne zastosowanie konwencji jednokierunkowej Electronic Data Exchange\"** - Ta odpowiedź jest **niepoprawna**. „Electronic Data Exchange\" (EDI) to standard wymiany danych w biznesie i administracji, nie ma on nic wspólnego z konkretnymi algorytmami kryptograficznymi. Koncepcja „konwencji jednokierunkowej\" jest tutaj również nieadekwatna, gdyż dotyczy działania funkcji skrótu, które same w sobie nie są metodami szyfrowania i wykorzystywane są na innej płaszczyźnie protokołów bezpieczeństwa. \n*   **\"podzial wyniku szyfrowania na 3 porcje roznej dlugosci wg standardu electronic Data Exchange\"** - Ta odpowiedź jest **niepoprawna**. 3DES-EDE nie dzieli wyniku szyfrowania na porcje, wykorzystuje trzy etapy szyfrowania/deszyfrowania całego bloku danych. Standard EDI nie ma tu żadnego odniesienia."
    },
    {
        "questionId": 89,
        "title": "Wlasnosc Perfect Forward Secrecy w przypadku generowania kluczy kryptograficznych:",
        "answers": [
            {
                "text": "wymaga stosowania kazdego klucza glownego (master) tylko jeden raz",
                "isCorrect": true
            },
            {
                "text": "ogranicza skutki znalezienia klucza sesji jedynie do czesci komunikacji",
                "isCorrect": true
            },
            {
                "text": "kazdy klucz sesji generowany jest z innego klucza glownego (master)",
                "isCorrect": true
            },
            {
                "text": "stosuje rozne klucze sesji do szyfrowania komunikacji w przeciwnych kierunkach",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Perfect Forward Secrecy (PFS) to właściwość protokołów uzgadniania kluczy, która zapewnia, że kompromitacja jednego klucza sesyjnego nie ujawnia przeszłych ani przyszłych sesji komunikacyjnych. Klucz sesyjny to tymczasowy klucz kryptograficzny używany do szyfrowania danych w obrębie jednej sesji komunikacyjnej. Jest on generowany na podstawie klucza głównego lub sekretu głównego (_master secret_). Klucz główny natomiast jest kluczem długoterminowym, którego zadaniem jest generowanie wielu kluczy sesyjnych. PFS uzyskuje się przez wymianę efemerycznych (tymczasowych, jednorazowych) kluczy, z których generowane są klucze sesyjne.\n\n**Odpowiedź 1: \"wymaga stosowania kazdego klucza glownego (master) tylko jeden raz\"**\nJest to **poprawna** odpowiedź. PFS, wymaga, aby z każdego klucza głównego (_master key_) lub sekretu głównego(_master secret_) generowany był tylko jeden klucz sesyjny. To sprawia, że atakujący po uzyskaniu klucza sesyjnego nie będzie mógł odtworzyć kluczy użytych w innych sesjach. Wykorzystanie kluczy jednorazowych podnosi poziom bezpieczeństwa systemu. \n\n**Odpowiedź 2: \"ogranicza skutki znalezienia klucza sesji jedynie do czesci komunikacji\"**\nJest to **poprawna** odpowiedź. PFS, przez jednorazowe generowanie kluczy sesyjnych,  ogranicza skutki wycieku klucza sesji. Jeżeli taki klucz zostanie przechwycony lub w inny sposób ujawniony to tylko ruch sieciowy z danej sesji będzie zagrożony, poprzednie i następne sesje są bezpieczne z uwagi, że korzystały z innych wygenerowanych kluczy sesyjnych. Ograniczenie skutków wycieku ma bardzo duże znaczenie w przypadku, gdy dane są przesyłane z bardzo długim opóźnieniem, z uwagi, że przechwycenie jednego klucza sesyjnego z sesji trwającej wiele miesięcy nie będzie umożliwiało odszyfrowania wszystkich danych. \n\n**Odpowiedź 3: \"kazdy klucz sesji generowany jest z innego klucza glownego (master)\"**\nJest to **poprawna** odpowiedź. Klucz sesyjny generowany jest na podstawie klucza głównego, ale w mechanizmie PFS klucz główny nie jest wykorzystywany do ponownego generowania innego klucza sesyjnego. Klucz sesyjny jest generowany przy wykorzystaniu losowego klucza efemerycznego, który jest za każdym razem inny i nigdy nie jest przechowywany. Efektem tego jest to, że klucz sesyjny jest odrębny i nie powtarzalny dla danej sesji. Należy zwrócić uwagę na to, że klucz główny może być użyty do uzgodnienia klucza efemerycznego. \n\n**Odpowiedź 4: \"stosuje rozne klucze sesji do szyfrowania komunikacji w przeciwnych kierunkach\"**\nJest to **niepoprawna** odpowiedź. Chociaż w praktyce tak często bywa, nie jest to wymóg PFS. PFS dba o to, by klucze sesyjne były efemeryczne i nie ujawniały przeszłych i przyszłych danych, a nie o to, by były różne w obu kierunkach komunikacji. W niektórych protokołach, takich jak TLS, faktycznie używane są różne klucze sesyjne do szyfrowania komunikacji w dwóch kierunkach, ale jest to odrębna cecha protokołu, a nie warunek PFS. \n\n**Przykład:**\nWyobraźmy sobie, że logujemy się do serwera pocztowego. Bez PFS, jeśli ktoś przechwyci klucz prywatny serwera, będzie mógł rozszyfrować wszystkie sesje pocztowe, które były szyfrowane za pomocą klucza publicznego tego serwera, również te z przeszłości. Z PFS, nawet jeśli klucz prywatny serwera zostanie ujawniony, atakujący będzie mógł co najwyżej odszyfrować tylko bieżącą i przyszłe sesje, nie będzie miał dostępu do danych z poprzednich sesji."
    },
    {
        "questionId": 90,
        "title": "Separacje srodowiska wykonania poprzez wirtualizacje (jadra) systemu operacyjnego oferuje:",
        "answers": [
            {
                "text": "Trusted Execution Environment (TEE)",
                "isCorrect": true
            },
            {
                "text": "funkcja systemowa chroot()",
                "isCorrect": false
            },
            {
                "text": "Address Space Layout Randomization (ASLR)",
                "isCorrect": false
            },
            {
                "text": "Windows Virtualization-Based Security (VBS)",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "**Trusted Execution Environment (TEE)** to bezpieczne, odizolowane środowisko wykonawcze, które gwarantuje poufność i integralność kodu oraz danych w nim przetwarzanych. TEE jest często implementowany w sprzęcie (np. procesory z rozszerzeniami TrustZone lub Intel SGX), zapewniając warstwę izolacji na poziomie jądra systemu operacyjnego. Oznacza to, że nawet w przypadku przejęcia kontroli nad systemem operacyjnym, procesy uruchomione w TEE pozostają chronione. To umożliwia uruchamianie wrażliwego kodu w sposób bezpieczny, bez konieczności polegania na całym systemie operacyjnym. Przykładem praktycznego zastosowania TEE jest przechowywanie i zarządzanie kluczami kryptograficznymi, bezpieczne wykonywanie procedur uwierzytelniania czy ochrona danych biometrycznych. Aplikacje uruchomione w TEE są izolowane, co zmniejsza ryzyko naruszenia bezpieczeństwa poprzez złośliwe oprogramowanie działające w środowisku systemu operacyjnego.\n\n**Funkcja systemowa chroot()**, często nazywana \"więzieniem\", zmienia katalog główny procesu, ograniczając jego dostęp do systemu plików. Po wykonaniu `chroot()`, proces widzi tylko poddrzewo systemu plików, które zostało ustawione jako jego nowy katalog główny. To nie jest wirtualizacja jądra, bo jądro systemu operacyjnego pozostaje wspólne i nie izolowane. `chroot()` to izolacja na poziomie systemu plików. Niestety ten mechanizm jest podatny na ataki ucieczki z uwięzienia. Wykorzystuje się tu błędy jądra lub niepoprawną konfigurację aplikacji działającej w środowisku `chroot()`. Nie ma więc separacji środowiska wykonania. Typowym zastosowaniem `chroot()` jest izolacja serwerów FTP, serwerów WWW czy serwerów DNS. Ma ona na celu uniemożliwienie (lub przynajmniej utrudnienie) potencjalnemu atakującemu, który uzyskał dostęp do takiego serwera, uzyskania dostępu do reszty systemu. Przykładowo, jeśli serwer WWW jest uruchomiony w środowisku `chroot()`, to nawet jeśli zostanie przejęty przez atakującego, dostęp do systemu plików poza obszarem poddrzewa `chroot` będzie utrudniony.\n\n**Address Space Layout Randomization (ASLR)** to technika bezpieczeństwa systemu operacyjnego, która losowo rozmieszcza w przestrzeni adresowej kluczowe obszary (np. biblioteki, stos, stertę). Ma to utrudnić ataki polegające na wykorzystaniu przepełnienia bufora lub podobnych luk, gdzie atakujący potrzebuje znać konkretne adresy w pamięci procesu. ASLR nie separuje jednak środowiska wykonania i nie tworzy wirtualnego środowiska. ASLR jest techniką, która chroni proces przed atakami, które wykorzystują błędy w pamięci, więc atak nie będzie przeprowadzony z powodzeniem jeśli adres docelowy ataku jest nieznany, ale ASLR nie izoluje procesu i nie chroni przed atakami logicznymi, które nie korzystają z błędów w zarządzaniu pamięcią. ASLR jest użyteczne, gdyż ma na celu utrudnienie wykorzystania exploitów, które wykorzystują luki w oprogramowaniu, ale nie tworzy nowego wirtualnego środowiska dla aplikacji. ASLR jest często stosowane w systemach operacyjnych, ale nie jest techniką wirtualizacji jądra.\n\n**Windows Virtualization-Based Security (VBS)** to funkcja w systemach Windows, która wykorzystuje wirtualizację do utworzenia odizolowanego środowiska, w którym działa chroniony kod. VBS wykorzystuje hypervisor (wirtualizator na poziomie jądra systemu operacyjnego), który pozwala stworzyć warstwę izolacji pomiędzy kodem (np. mechanizmów bezpieczeństwa) oraz resztą systemu. Dzięki temu kod działający w VBS jest bardziej odporny na ataki i modyfikacje ze strony reszty systemu operacyjnego czy oprogramowania. VBS używany jest w Windows głównie do ochrony poświadczeń (Credential Guard) lub kodu jądra (Hypervisor-Protected Code Integrity (HVCI)). Przykładem praktycznego zastosowania VBS jest np. ochrona mechanizmów logowania, która utrudnia kradzież haseł lub uzyskanie dostępu do kont użytkowników, lub ochrona kodu kernela przed modyfikacją. Tak samo jak TEE, VBS pozwala na tworzenie odizolowanego środowiska wykonawczego w którym mamy pewność, że aplikacja jest wykonywana w bezpieczny sposób. Jest to wirtualizacja jądra systemu operacyjnego."
    },
    {
        "questionId": 91,
        "title": "Tryb strumieniowy szyfrowania:",
        "answers": [
            {
                "text": "umozliwia szyfrowanie komunikacji asynchronicznej",
                "isCorrect": true
            },
            {
                "text": "wymaga klucza prywatnego i publicznego",
                "isCorrect": false
            },
            {
                "text": "polega na szyfrowaniu kazdorazowego po jednym znaku",
                "isCorrect": true
            },
            {
                "text": "wykorzystuje wektor inicjujacy rejestr szyfrowania",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Szyfr strumieniowy to algorytm szyfrowania, który przetwarza dane bit po bicie lub bajt po bajcie, w przeciwieństwie do szyfrów blokowych, które operują na blokach o stałej wielkości. Kluczową cechą szyfrów strumieniowych jest generowanie strumienia klucza (ang. *keystream*), który jest następnie łączony z tekstem jawnym (najczęściej za pomocą operacji XOR) aby uzyskać szyfrogram. Do generowania strumienia klucza używany jest tajny klucz, który musi być znany obu stronom komunikacji, oraz opcjonalnie wektor inicjujący (*Initialization Vector* - IV), który służy do zapewnienia, że nawet przy użyciu tego samego klucza i tego samego tekstu jawnego otrzymamy inny szyfrogram. Wektor inicjujący jest jawny i nie musi być tajny, jednak musi być inny dla każdego szyfrowania tym samym kluczem, co uniemożliwia powtarzanie strumienia klucza.\n\n*   **\"umożliwia szyfrowanie komunikacji asynchronicznej\"** - To jest **poprawne**. Szyfry strumieniowe, ze względu na bitowy lub bajtowy sposób przetwarzania danych, są idealne do szyfrowania danych przesyłanych asynchronicznie, gdzie dane mogą pojawiać się w nieregularnych odstępach czasu. Przykładem może być transmisja danych z klawiatury. Nie musimy czekać na utworzenie pełnego bloku danych by rozpocząć szyfrowanie.\n\n*   **\"wymaga klucza prywatnego i publicznego\"** - To jest **niepoprawne**. Szyfry strumieniowe, w podstawowej formie, wykorzystują wyłącznie **klucz symetryczny** który jest współdzielony przez obie strony komunikacji. Szyfrowanie asymetryczne, które wykorzystuje klucz prywatny i publiczny (np. RSA), jest stosowane w innych protokołach do wymiany kluczy symetrycznych lub podpisywania danych, a nie do szyfrowania strumienia danych w szyfrach strumieniowych.\n\n*   **\"polega na szyfrowaniu każdorazowo po jednym znaku\"** - To jest **poprawne**. Jak wspomniano wcześniej szyfry strumieniowe operują na poziomie bitów, lub bajtów, czyli de facto na poziomie znaków w standardzie ASCII lub UTF-8. Innymi słowy – szyfrują one dane „strumieniowo”. Dla porównania – szyfry blokowe operują na blokach danych o stałej wielkości, np. 64, 128, lub 256 bitów i całe bloki poddawane są szyfrowaniu i deszyfrowaniu.\n\n*   **\"wykorzystuje wektor inicjujący rejestr szyfrowania\"** - To jest **poprawne**. Szyfry strumieniowe, szczególnie te bezpieczniejsze, do generowania strumienia klucza wykorzystują rejestr, którego stan jest inicjalizowany za pomocą wektora inicjującego (IV). Wektor inicjujący (IV) to wartość losowa ( lub pseudolosowa) wykorzystywana do zainicjowania rejestru szyfrowania. Wektor ten jest wysyłany jawnie wraz z szyfrogramem (nie musi być tajny, lecz musi być unikalny dla każdego szyfrowania tym samym kluczem).  Użycie wektora inicjującego jest niezbędne do uniknięcia generowania tych samych strumieni klucza dla kolejnych wiadomości, co z kolei byłoby poważnym problemem bezpieczeństwa. Bez użycia IV, te same dane zakodowane za pomocą szyfru strumieniowego z tym samym kluczem dałyby dokładnie taki sam szyfrogram."
    },
    {
        "questionId": 92,
        "title": "Okresl jakie potencjalne zagrozenia dla bezpieczenstwa niesie funkcja CreateRemotethread():",
        "answers": [
            {
                "text": "wywolanie zdalnych procedur (RPC) bez kontroli jadra zdalnego systemu operacyjnego",
                "isCorrect": false
            },
            {
                "text": "wykonanie nieautoryzowanych operacji podszywajac sie pod autoryzowany proces (obejscie autoryzacji)",
                "isCorrect": true
            },
            {
                "text": "wstrzykniecie zlosliwego kodu do przestrzeni adresowej innego procesu w systemie operacyjnym",
                "isCorrect": true
            },
            {
                "text": "nie uwierzytelniony dostep do komunikacji sieciowej ponizej warstwy transportowej",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Funkcja `CreateRemoteThread` w systemie Windows umożliwia utworzenie nowego wątku wykonawczego w przestrzeni adresowej innego, działającego już procesu. Przestrzeń adresowa procesu to wyizolowany obszar pamięci, w którym przechowywane są dane i kod tego procesu. Domyślnie, jeden proces nie ma dostępu do pamięci drugiego, co jest podstawą bezpieczeństwa systemu operacyjnego. Jednakże, `CreateRemoteThread` pozwala na ominięcie tego ograniczenia.\n\n**Odpowiedź 1: „wywołanie zdalnych procedur (RPC) bez kontroli jadra zdalnego systemu operacyjnego” jest niepoprawna.** Remote Procedure Call (RPC) to mechanizm komunikacji między procesami, pozwalający jednemu procesowi wywołać funkcję w innym procesie, często na innym komputerze w sieci. Chociaż RPC może być wykorzystane w atakach, `CreateRemoteThread` nie jest bezpośrednio związane z RPC. Ta funkcja operuje na poziomie pojedynczego systemu operacyjnego, manipulując bezpośrednio przestrzenią adresową procesów. Błędem jest zatem sugerowanie omijania jądra zdalnego systemu poprzez wywołanie RPC.\n\n**Odpowiedź 2: „wykonanie nieautoryzowanych operacji podszywajac sie pod autoryzowany proces (obejscie autoryzacji)” jest poprawna.** Użycie funkcji `CreateRemoteThread` daje atakującemu możliwość uruchomienia złośliwego kodu w kontekście (z uprawnieniami) innego, działającego już procesu. Przykładowo, proces działający jako użytkownik z uprawnieniami administratora może zostać wykorzystany do ataku. Atakujący tworząc wątek w tak uprzywilejowanym procesie, skutecznie obejdzie mechanizmy autoryzacji i otrzyma uprawnienia tego procesu. Efektem jest wykonanie nieautoryzowanych operacji (złośliwych działań), do których w normalnej sytuacji atakujący nie posiadałby uprawnień. Ten mechanizm, zwany również eskalacją uprawnień(_ang. privilege escalation_), jest bardzo często wykorzystywany przez złośliwe oprogramowanie.\n\n**Odpowiedź 3: „wstrzykniecie zlosliwego kodu do przestrzeni adresowej innego procesu w systemie operacyjnym” jest poprawna.** Właśnie na tym polega istota zagrożenia związanego z funkcją `CreateRemoteThread`. Atakujący za jej pomocą wstrzykuje(ang. _inject_) swój kod do działającego procesu. Kod ten może być np. komponentem keyloggera, trojana, backdoora.  Kod ten jest uruchamiany w kontekście procesu docelowego. Proces ten nie ma żadnej wiedzy o tym, że wykonuje nie swój kod. W efekcie działanie takiego kodu, nie jest postrzegane przez system jako coś nienaturalnego. Przykładowo: wywołanie funkcji WinAPI `CreateRemoteThread` i przekazanie jako parametr wykonywalnego kodu, pozwala na wstrzyknięcie tego kodu w inny proces. Innym, bardziej wyrafinowanym sposobem wstrzykiwania kodu jest załadowanie biblioteki DLL. Atakujący posiadając dostęp do dowolnej części pamięci innego procesu (co umożliwia omawiana funkcja) mogą ładować biblioteki dll do pamięci i natychmiast je wykonywać.\n\n**Odpowiedź 4: „nie uwierzytelniony dostep do komunikacji sieciowej ponizej warstwy transportowej” jest niepoprawna.** Funkcja `CreateRemoteThread` działa na poziomie systemu operacyjnego i dotyczy manipulacji procesami. Nie ingeruje ona w warstwę sieciową poniżej warstwy transportowej (czyli w warstwę sieciową i łącza danych). Oczywiście funkcja ta pośrednio może służyć do inicjowania komunikacji sieciowej, jednak samo użycie funkcji `CreateRemoteThread` nie gwarantuje nieautoryzowanego dostępu do komunikacji sieciowej poniżej warstwy transportowej. Dlatego też odpowiedź ta jest niepoprawna."
    },
    {
        "questionId": 93,
        "title": "Koncepcja ,,zamknietych grup uzytkownikow\" dotyczy odseparowania danych przetwarzanych przez odrebne grupy uzytkownikow tego samego srodowiska sieciowego. Ktore z ponizszych mechanizmow sa realizacja tej koncepcji:",
        "answers": [
            {
                "text": "sandbox net jail",
                "isCorrect": false
            },
            {
                "text": "Trusted Execution Environment (TEE)",
                "isCorrect": false
            },
            {
                "text": "Virtualization-Based Security (VBS)",
                "isCorrect": false
            },
            {
                "text": "sieci wirtualne VLAN",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Koncepcja „zamkniętych grup użytkowników” odnosi się do segmentacji sieci, czyli logicznego odseparowania ruchu sieciowego generowanego przez różne grupy użytkowników w ramach tej samej fizycznej infrastruktury. Chodzi o to, by ruch od jednej grupy użytkowników nie był widoczny dla innej, nawet jeśli te grupy korzystają z tych samych przełączników i kabli.  Realizacja tej koncepcji ma na celu zwiększenie bezpieczeństwa i ograniczenie rozprzestrzeniania się potencjalnych zagrożeń, jak również umożliwia tworzenie odseparowanych środowisk sieciowych.\n\n**Sieci wirtualne VLAN (Virtual Local Area Networks)** są prawidłową odpowiedzią. VLANy to logiczne podziały w sieci fizycznej, które pozwalają na grupowanie portów przełącznika w oddzielne domeny rozgłoszeniowe. Komunikacja pomiędzy urządzeniami należącymi do różnych VLANów jest ograniczona, o ile nie zostanie celowo skonfigurowana za pomocą mechanizmów trasowania (routingu) pomiędzy tymi VLANami.  Przykładowo, można stworzyć VLAN dla działu HR i VLAN dla działu IT. Pracownicy HR będą w swoim VLANie i ruch sieciowy przez nich generowany będzie widoczny tylko w ich VLANie.  Pracownicy IT będą widzieć swój ruch w VLANie IT i nie będą widzieć ruchu HR.  Dzięki temu, gdyby na przykład komputer pracownika HR został zainfekowany wirusem lub złośliwym oprogramowaniem, to jego aktywność będzie ograniczona do jego VLANu i nie będzie on mógł łatwo przeskoczyć do VLANu IT i np. zainfekować serwerów IT.  W praktyce VLANy tworzy się konfigurując przełączniki sieciowe, przypisując poszczególne porty do odpowiednich VLANów. Ruch w VLANach jest tagowany specjalnymi etykietami, co umożliwia przełącznikom rozróżnianie domen rozgłoszeniowych.\n\n**Sandbox net jail** jest nieprawidłową odpowiedzią. Koncepcja piaskownicy (ang. sandbox) odnosi się do środowiska, w którym uruchamiana jest aplikacja, mająca ograniczone możliwości dostępu do zasobów systemu operacyjnego. Chodzi o stworzenie bezpiecznego środowiska, w którym aplikacja nie może wyrządzić szkód. Mechanizm _chroot_ w systemach Linux/Unix jest jednym z przykładów techniki piaskownicy na poziomie systemu operacyjnego, ale nie jest to bezpośrednio związane z segmentacją sieci i tworzeniem \"zamkniętych grup użytkowników\" w kontekście ruchu sieciowego. Aplikacja zamknięta w _chroot jail_ nie powoduje ograniczenia w widoczności sieci, a tylko w dostępie do lokalnych plików systemu.  Na przykład serwer WWW umieszczony w piaskownicy będzie nadal widoczny w sieci. \n\n**Trusted Execution Environment (TEE)** jest nieprawidłową odpowiedzią. TEE to bezpieczne środowisko wykonywania kodu na poziomie sprzętu (procesora), w którym kod działa w odseparowaniu od reszty systemu.  TEE jest wykorzystywane do przechowywania kluczy kryptograficznych lub wykonywania wrażliwych operacji, ale nie służy do segmentacji sieci ani do definiowania grup izolowanych użytkowników na poziomie ruchu sieciowego. Na przykład smartfon może wykorzystać TEE do ochrony klucza szyfrującego połączenia z serwerem banku, ale TEE nie spowoduje, że ten telefon będzie w odseparowanej sieci.\n\n**Virtualization-Based Security (VBS)** jest nieprawidłową odpowiedzią. VBS to funkcja systemu Windows, która wykorzystuje wirtualizację do tworzenia bezpiecznych kontenerów dla aplikacji lub komponentów systemu. Zapewnia dodatkową warstwę ochrony, izolując te komponenty od reszty systemu operacyjnego. Podobnie jak TEE, VBS nie służy do segmentacji sieci, a jedynie do wzmocnienia bezpieczeństwa na poziomie pojedynczego komputera.  Przykładowo Windows Defender System Guard używa VBS do ochrony przed złośliwym oprogramowaniem, ale nie separuje ruchu sieciowego między różnymi grupami użytkowników.\n\nPodsumowując,  VLANy to technologia warstwy drugiej, która bezpośrednio dotyczy segmentacji sieci i tworzenia odseparowanych logicznie grup użytkowników. Pozostałe mechanizmy tworzą izolacje na poziomie procesów, aplikacji lub pojedynczego systemu, co nie rozwiązuje problemu tworzenia „zamkniętych grup użytkowników” w odniesieniu do sieci."
    },
    {
        "questionId": 94,
        "title": "Ktore z ponizszych protokolow sluza realizacji kryptograficznych tuneli wirtualnych z ochrona poufnosci:",
        "answers": [
            {
                "text": "PEM",
                "isCorrect": false
            },
            {
                "text": "ESP",
                "isCorrect": true
            },
            {
                "text": "TLS",
                "isCorrect": true
            },
            {
                "text": "S/MIME",
                "isCorrect": false
            },
            {
                "text": "IPsec",
                "isCorrect": true
            },
            {
                "text": "SSL",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Protokół tunelowania wirtualnego z ochroną poufności to mechanizm, który pozwala na stworzenie zabezpieczonego kanału transmisji danych pomiędzy dwoma punktami. Zabezpieczenie to obejmuje szyfrowanie danych tak, aby niepowołane osoby nie mogły odczytać przesyłanej treści. \n\n**PEM (Privacy Enhanced Mail)**, choć zawiera w nazwie \"Privacy\" (poufność), jest standardem dla zabezpieczania wiadomości email, który definiuje mechanizmy takie jak podpisy cyfrowe oraz szyfrowanie wiadomości. Jednakże, PEM nie tworzy tuneli wirtualnych. Z tego powodu **odpowiedź jest niepoprawna**.\n\n**ESP (Encapsulating Security Payload)** jest protokołem z rodziny IPsec, zaprojektowanym w celu zapewnienia poufności poprzez szyfrowanie ładunku pakietu IP. ESP może działać w trybie tunelowym, gdzie cały pakiet IP (łącznie z nagłówkiem) jest enkapsulowany i szyfrowany, tworząc w ten sposób bezpieczny tunel, chroniący przed podsłuchem. Zatem **odpowiedź jest poprawna**.\n\n**TLS (Transport Layer Security)** to następca protokołu SSL, który jest szeroko stosowany do tworzenia szyfrowanych połączeń. TLS zazwyczaj pracuje na warstwie transportowej, tworząc bezpieczny kanał (tunel) dla protokołów aplikacyjnych, takich jak HTTP (HTTPS). TLS zapewnia poufność przesyłanych danych. Zatem **odpowiedź jest poprawna**.\n\n**S/MIME (Secure/Multipurpose Internet Mail Extensions)** jest standardem dla bezpiecznej komunikacji email, podobnie jak PEM. S/MIME umożliwia szyfrowanie oraz cyfrowe podpisywanie wiadomości email. Choć S/MIME zapewnia poufność poprzez szyfrowanie treści wiadomości, sam w sobie nie tworzy tunelu wirtualnego, a jedynie zabezpiecza treść wiadomości. Z tego powodu **odpowiedź jest niepoprawna**.\n\n**IPsec (Internet Protocol Security)** to protokół warstwy sieciowej, zapewniający bezpieczeństwo komunikacji IP. IPsec pozwala na tworzenie tuneli wirtualnych poprzez szyfrowanie pakietów. Protokół ten może być używany do tworzenia tuneli VPN (Virtual Private Network), zapewniając poufność. W szczególności, protokół ESP z rodziny IPsec jest odpowiedzialny za szyfrowanie ładunku przesyłanego pakietu, a opcjonalnie także jego nagłówka. Zatem **odpowiedź jest poprawna**.\n\n**SSL (Secure Sockets Layer)** jest protokołem używanym do tworzenia tuneli kryptograficznych w warstwie transportowej. SSL, poprzednik TLS, jest szeroko stosowany w sieci WWW (HTTPS) do ochrony komunikacji pomiędzy przeglądarką a serwerem WWW, w tym poufności danych, gdyż dane są szyfrowane w obrębie tunelu. Zatem **odpowiedź jest poprawna**.\n\nPodsumowując, ESP, TLS, IPsec oraz SSL tworzą szyfrowane tunele wirtualne chroniąc dane przed nieautoryzowanym odczytem, natomiast PEM i S/MIME nie tworzą tuneli wirtualnych a jedynie zabezpieczają przesyłaną treść."
    },
    {
        "questionId": 95,
        "title": "Wskaz cechy filtracji kontekstowej (SPF) realizowanej przez zapory sieciowe:",
        "answers": [
            {
                "text": "pozwala uniknac niepotrzebnego sprawdzania regul dla pakietow powracajacych w ruchu zweryfikowanym w strone przeciwna",
                "isCorrect": true
            },
            {
                "text": "zapora utrzymuje liste aktywnych polaczen",
                "isCorrect": true
            },
            {
                "text": "dopasowuje pakiety do zapamietanej historii komunikacji",
                "isCorrect": false
            },
            {
                "text": "historia komunikacji nie ma wplywu na decyzje zapory",
                "isCorrect": false
            },
            {
                "text": "pozwala na dynamiczne modyfikacje regul filtracji",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Filtracja kontekstowa (SPF), czyli *stateful packet filtering*, w zaporach sieciowych to mechanizm, który śledzi stan połączeń sieciowych, a nie tylko analizuje pojedyncze pakiety. Zapora SPF analizuje nagłówki pakietów i na ich podstawie tworzy _rekord sesji_, czyli wpis w wewnętrznej bazie danych. Rekord ten zawiera informacje o pakietach wymienianych między dwoma komputerami, takie jak adresy IP, porty, numery sekwencyjne i flagi protokołów TCP. Dzięki temu, zapora nie musi ponownie analizować pakietów, które są częścią wcześniej ustanowionego połączenia, co wpływa na większą wydajność działania. \n\n**Odpowiedź pierwsza (\"pozwala uniknac niepotrzebnego sprawdzania regul dla pakietow powracajacych w ruchu zweryfikowanym w strone przeciwna\") jest poprawna.** Filtracja kontekstowa zapamiętuje ustanowione połączenia. Dla każdego nowego połączenia zapora musi przeanalizować pakiet i sprawdzić czy jest ono zgodne z zadanymi regułami. Jeżeli połączenie zostanie nawiązane, wszelkie pakiety powracające w stronę przeciwną będą już automatycznie przepuszczane, bez potrzeby analizowania na podstawie list filtrów. Oznacza to oszczędność zasobów oraz czasu potrzebnego do analizy. Dla przykłady, jeżeli wysyłamy zapytanie HTTP, to serwer w odpowiedzi musi nam przesłać dane (stronę HTML). Zapora, która stosuje SPF, przepuści pakiety z odpowiedzią, bez konieczności analizy, ponieważ pamięta że to połączenie zostało nawiązane z sieci zaufanej. \n\n**Odpowiedź druga (\"zapora utrzymuje liste aktywnych polaczen\") jest poprawna.** Istotą SPF jest właśnie śledzenie stanu połączeń. Zapora przechowuje informacje o każdym aktywnym połączeniu w specjalnej tablicy, zwanej _tablicą stanów połączeń_. Informacje te są niezbędne do prawidłowej weryfikacji pakietów, które są częścią wcześniej ustanowionych połączeń. Na przykład, zapora SPF, po zaakceptowaniu pierwszego pakietu TCP z flagą SYN, tworzy wpis w tablicy stanów i oczekuje na pakiet z flagą SYN-ACK. Bez takiej tablicy, nie można by rozróżnić pakietów inicjujących połączenie od pakietów będących jego kontynuacją.\n\n**Odpowiedź trzecia (\"dopasowuje pakiety do zapamietanej historii komunikacji\") jest niepoprawna.** Mimo że SPF śledzi historię komunikacji, to pakiety dopasowywane są do parametrów zapamiętanych aktywnych połączeń, a nie do całej historii komunikacji. Informacje o poprzednich pakietach w danej sesji nie są analizowane, jest analizowany tylko stan połączenia. SPF nie dąży do odtworzenia wszystkich pakietów, które w danym połączeniu zostały wysłane, wykorzystuje jedynie informacje z nagłówków, w szczególności porty źródłowe i docelowe, flagi TCP oraz adresy źródłowe i docelowe.\n\n**Odpowiedź czwarta (\"historia komunikacji nie ma wplywu na decyzje zapory\") jest niepoprawna.** SPF wręcz przeciwnie opiera się na zapamiętanej historii połączenia. To ta historia, czyli zbiór informacji o wcześniej wymienionych pakietach, ma decydujący wpływ na to, czy kolejny pakiet z danego połączenia zostanie zaakceptowany. Bez informacji o historii komunikacji, SPF nie działa.\n\n**Odpowiedź piąta (\"pozwala na dynamiczne modyfikacje regul filtracji\") jest niepoprawna.** Choć SPF zapamiętuje stan połączeń i na tej podstawie filtruje ruch, samo śledzenie stanów połączeń nie implikuje dynamicznych zmian w regułach filtracji. Zapora SPF wykorzystuje zdefiniowane wcześniej reguły, jednak bierze pod uwagę stan każdego połączenia (sesji). Dynamiczne modyfikacje reguł są możliwe, lecz nie są częścią definicji SPF. Dynamiczne modyfikacje mogą występować na zaporach działających w wyższych warstwach modelu ISO/OSI - np. w zaporach warstwy aplikacji (np. w _Web Application Firewall_), ale nie należą do definicji filtracji kontekstowej."
    },
    {
        "questionId": 96,
        "title": "Ktore stwierdzenie poprawnie opisuja protokol IKE w IPsec:",
        "answers": [
            {
                "text": "realizuje uwierzytelnianie stron",
                "isCorrect": true
            },
            {
                "text": "realizuje podpis cyfrowy pakietow IP",
                "isCorrect": false
            },
            {
                "text": "korzysta z UDP",
                "isCorrect": true
            },
            {
                "text": "korzysta z ICMP",
                "isCorrect": false
            },
            {
                "text": "realizuje negocjacje algorytmow szyfrujacych",
                "isCorrect": true
            },
            {
                "text": "realizuje wymiane kluczy metoda Diffiego-Hellmana",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Protokół IKE (Internet Key Exchange) w IPsec jest odpowiedzialny za bezpieczne uzgodnienie parametrów sesji IPsec pomiędzy dwoma stronami, w tym za uwierzytelnienie stron oraz wymianę kluczy kryptograficznych. IKE nie szyfruje bezpośrednio przesyłanych danych. Realizację szyfrowania i autentykacji danych IP przejmują inne mechanizmy wchodzące w skład IPsec, czyli AH (Authentication Header) i ESP (Encapsulating Security Payload). \n\n**Odpowiedź 1: \"realizuje uwierzytelnianie stron\" - PRAWDA**\n\nIKE *rzeczywiście* realizuje uwierzytelnianie stron, które chcą nawiązać połączenie IPsec. Robi to m.in. przez wymianę certyfikatów cyfrowych lub weryfikację współdzielonego sekretu, które pozwalają udowodnić tożsamość danej strony. Na przykład, przy łączeniu dwóch firmowych oddziałów przez Internet za pomocą VPN, protokół IKE zapewnia, że tylko autoryzowane oddziały mogą nawiązać bezpieczne połączenie.\n\n**Odpowiedź 2: \"realizuje podpis cyfrowy pakietow IP\" - FAŁSZ**\n\nIKE *nie* realizuje bezpośrednio podpisu cyfrowego *pakietów IP*. To zadanie protokołu AH (Authentication Header), który zresztą *może*, ale nie musi być użyty w połączeniu IPsec. IKE służy do *ustalenia* bezpieczeństwa dla *całej* sesji IPsec, podczas której dochodzi między innymi do wymiany kluczy symetrycznych i weryfikacji kluczy asymetrycznych użytych do podpisów cyfrowych *komunikatów IKE*. Natomiast *same dane IP* są podpisywane/szyfrowane przez protokół AH (integralność) i/lub ESP (poufność). \n\n**Odpowiedź 3: \"korzysta z UDP\" - PRAWDA**\n\nIKE *rzeczywiście* korzysta z protokołu UDP (User Datagram Protocol) jako protokołu transportowego. UDP, w przeciwieństwie do TCP, jest protokołem bezpołączeniowym i nie gwarantuje dostarczenia pakietów. Zaletą UDP jest jego prostota i szybkość. W przypadku IKE pakiety IKE stanowią krótkie komunikaty które przesyłane są bez dużego obciążenia. Wykorzystanie protokołu TCP jest możliwe, ale nie jest to rozwiązanie typowe. \n\n**Odpowiedź 4: \"korzysta z ICMP\" - FAŁSZ**\n\nProtokół IKE *nie* używa protokołu ICMP (Internet Control Message Protocol). ICMP jest protokołem pomocniczym, który służy do wysyłania komunikatów o błędach i do diagnozowania sieci, np. narzędzie ping używa pakietów ICMP. IKE działa w warstwie transportowej wykorzystując protokół UDP, ale nie ma nic wspólnego z protokołem ICMP. \n\n**Odpowiedź 5: \"realizuje negocjacje algorytmow szyfrujacych\" - PRAWDA**\n\nIKE *rzeczywiście* realizuje negocjacje algorytmów szyfrujących. W czasie procedury uzgadniania bezpieczeństwa, IKE pozwala dwóm stronom wybrać wspólnie obsługiwane i wystarczająco silne algorytmy szyfrowania, uwierzytelniania oraz generowania kluczy sesyjnych. To umożliwia współpracę nawet między systemami, które różnią się w implementacjach algorytmów szyfrujących. Przykładowo, serwer VPN może obsługiwać różne protokoły i algorytmy szyfrowania, które będą uzgodnione z klientem w czasie nawiązywania bezpiecznego połączenia VPN.\n\n**Odpowiedź 6: \"realizuje wymiane kluczy metoda Diffiego-Hellmana\" - PRAWDA**\n\nIKE *rzeczywiście* realizuje wymianę kluczy metodą Diffiego-Hellmana. Ta metoda umożliwia bezpieczne uzgodnienie klucza sesyjnego między dwoma stronami w sieci publicznej, nawet jeśli podsłuchujący śledzi ich komunikację. Klucz ten następnie jest używany do szyfrowania przesyłanych danych. Na przykład, dwa serwery komunikujące się przez VPN używają Diffiego-Hellmana, aby wygenerować tajny klucz, który jest używany do szyfrowania danych wymienianych w tunelu VPN."
    },
    {
        "questionId": 97,
        "title": "Mechanizm SYN cookies:",
        "answers": [
            {
                "text": "odpowiada na wlasnie odebrany pakiet SYN, tylko jesli spelnia zadane kryteria poprawnosci",
                "isCorrect": false
            },
            {
                "text": "nie rozpoczyna zestawienia polaczenia po odebraniu segmentu SYN",
                "isCorrect": true
            },
            {
                "text": "jest wykorzystywany do przeprowadzania rozproszonego ataku DoS",
                "isCorrect": false
            },
            {
                "text": "ogranicza zasoby przydzielane przez system przy odbiorze zadania nawiazania polaczenia",
                "isCorrect": true
            },
            {
                "text": "identyfikuje polaczenie wartoscia pola ACK",
                "isCorrect": true
            },
            {
                "text": "odpowiada na wcześniej odebrany pakiet SYN po zadanym czasie oczekiwania",
                "isCorrect": false
            },
            {
                "text": "pozwala przeglądarce na bezpieczną aktualizację ciasteczek",
                "isCorrect": false
            },
            {
                "text": "minimalizuje ilość informacji potrzebnych przeglądarce do uwierzytelniania zdalnego dostępu",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Mechanizm SYN cookies to metoda obrony przed atakami typu SYN flood, które wykorzystują proces nawiązywania połączenia TCP do przeciążenia serwera. W standardowym trójfazowym uzgadnianiu połączenia TCP, klient wysyła segment SYN, serwer odpowiada segmentem SYN-ACK, a klient potwierdza połączenie segmentem ACK. Atak SYN flood polega na tym, że atakujący wysyła dużą liczbę segmentów SYN z fałszywymi adresami źródłowymi. Serwer, nie wiedząc, że te pakiety są fałszywe, przechowuje w pamięci informacje o niekompletnych połączeniach. Przy dużej liczbie takich niekompletnych połączeń serwer może ulec przeciążeniu i odmówić dalszej obsługi połączeń.\n\nMechanizm SYN cookies rozwiązuje ten problem w taki sposób, że serwer nie przydziela zasobów w pamięci podczas odbierania segmentu SYN. Zamiast tego, w segmencie SYN-ACK wysyła specjalnie zakodowaną wartość, tzw. cookie. Wartość cookie zależy od inicjalnego numeru sekwencyjnego (ISN) pakietu SYN. Kodowanie to wykorzystuje kryptograficzne funkcje skrótu, z użyciem tajnego klucza serwera, dlatego atakujący, nie znając tego klucza, nie jest w stanie wygenerować poprawnych cooki. Serwer przechowuje tylko informację niezbędną do odtworzenia cookie, np. adresy IP i numer portu, co jest niewielkim obciążeniem dla systemu. Kiedy klient odpowiada segmentem ACK zawierającym numer sekwencyjny, serwer na podstawie tego numeru sekwencyjnego jest w stanie odtworzyć wartość cookie. Jeżeli cookie jest poprawny, serwer zakłada, że ten klient nie jest elementem ataku SYN flood i kontynuuje nawiązywanie połączenia. Jeżeli cookie jest niepoprawny, połączenie jest odrzucane.\n\nPrzejdźmy teraz do analizy poszczególnych odpowiedzi:\n\n*   **\"odpowiada na wlasnie odebrany pakiet SYN, tylko jesli spelnia zadane kryteria poprawnosci\"** - Niepoprawne. SYN cookies nie *odpowiada* na pakiet SYN z natychmiastową weryfikacją poprawności. Zamiast tego odpowiada segmentem SYN-ACK z zakodowanym cookie, w ten sposób odracza decyzję o alokacji zasobów do momentu nadejścia pakietu ACK.\n\n*   **\"nie rozpoczyna zestawienia polaczenia po odebraniu segmentu SYN\"** - Poprawne. To jest kluczowa cecha SYN cookies – serwer nie przydziela zasobów, tak długo jak nie zweryfikuje poprawności kolejnego segmentu ACK.\n\n*   **\"jest wykorzystywany do przeprowadzania rozproszonego ataku DoS\"** - Niepoprawne. SYN cookies są mechanizmem *obronnym* przed atakami DoS, a nie narzędziem do ich przeprowadzania.\n\n*  **\"ogranicza zasoby przydzielane przez system przy odbiorze zadania nawiazania polaczenia\"** - Poprawne. To jest właśnie sedno działania SYN cookies - ograniczenie zasobów używanych przez serwer, a tym samym, zwiększenie jego odporności na ataki.\n\n*   **\"identyfikuje polaczenie wartoscia pola ACK\"** - Poprawne. Wartość w polu ACK jest używana do weryfikacji połączenia, ale jest tam przechowywany zaszyfrowany cookie, a nie tylko identyfikator połączenia. Oznacza to, że serwer nie przydziela zasobów aż nie będzie pewny, że dany pakiet ACK nie jest częścią ataku SYN flood.\n\n*   **\"odpowiada na wcześniej odebrany pakiet SYN po zadanym czasie oczekiwania\"** - Niepoprawne. Mechanizm SYN cookie odpowiada na pakiet SYN, wysyłając SYN-ACK, ale nie ma w tym żadnego dodatkowego czasu oczekiwania. Oczekiwanie jest *przed* przydzieleniem zasobów dla połączenia TCP do czasu nadejścia ACK.\n\n*   **\"pozwala przeglądarce na bezpieczną aktualizację ciasteczek\"** - Niepoprawne. SYN cookies nie mają nic wspólnego z ciasteczkami internetowymi i ich aktualizacją.\n\n*   **\"minimalizuje ilość informacji potrzebnych przeglądarce do uwierzytelniania zdalnego dostępu\"** - Niepoprawne. SYN cookies nie dotyczy kwestii uwierzytelniania przeglądarki ani minimalizacji informacji z tym związanej.\n\n**Przykład z życia:** Wyobraźmy sobie popularny sklep internetowy, który w normalnych warunkach jest w stanie obsłużyć na bieżąco zamówienia tysiąca klientów. W przypadku ataku SYN flood, gdzie atakujący wysyłałby miliony fałszywych zapytań o połączenie, bez mechanizmu SYN cookies serwer sklepu bardzo szybko uległby przeciążeniu i stałby się niedostępny dla normalnych klientów. Dzięki SYN cookies serwer jest w stanie obsłużyć prawdziwych klientów, ignorując większość fałszywych prób połączenia, ponieważ nie przydziela dla nich zasobów dopóki nie otrzyma poprawnego ACK."
    },
    {
        "questionId": 98,
        "title": "Firewalking to:",
        "answers": [
            {
                "text": "polaczenia zapor filtrujacych ruch sieciowy z uslugami proxy",
                "isCorrect": false
            },
            {
                "text": "technika odkrywania istnienia zapory sieciowej i otwartych na niej portow",
                "isCorrect": true
            },
            {
                "text": "szeregowe polaczenia zapor sieciowych typu proxy",
                "isCorrect": false
            },
            {
                "text": "kaskadowe polaczenia zapor sieciowych filtrujacych pakiety",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Firewalking to technika pasywnej rekonesansu sieciowego, używana w celu zidentyfikowania reguł filtrowania zapory sieciowej i otwartych na niej portów. Nie jest to metoda bezpośredniego ataku na zaporę, ale technika służąca do mapowania konfiguracji. Działa poprzez wysyłanie specjalnie spreparowanych pakietów TCP lub UDP z nadzieją, że zapora przepuści je do docelowego hosta, a odpowiedź zostanie zwrócona. Analiza odpowiedzi pozwala na identyfikację tego czy dany port jest otwarty i jakie jest filtrowanie na zaporze. Technika Firewalking pozwala ustalić, które porty są otwarte na firewallu oraz jakie adresy IP i protokoły są dozwolone. \n\n**Option 1: \"połączenia zapor filtrujących ruch sieciowy z usługami proxy\"**\nThis is incorrect. Firewalking nie dotyczy połączeń między zaporami sieciowymi i serwerami proxy. Te elementy działają na różnych warstwach modelu OSI i pełnią odmienne role. Serwery proxy pośredniczą w dostępie do usług, a zapory sieciowe filtrują ruch sieciowy na podstawie reguł. Firewalking nie bada połączeń między nimi, ale wykorzystuje te elementy do mapowania ich reguł.\n\n**Option 2: \"technika odkrywania istnienia zapory sieciowej i otwartych na niej portów\"**\nThis is **correct**. Firewalking is specifically a reconnaissance technique used to map the rules of a firewall and identify which ports are open. It does this by sending packets through the firewall, observing how they are treated and noting the responses. A response indicates that the traffic was allowed by the firewall's rules, so it can give an intruder a clear understanding of what is and is not allowed through the firewall. \n\n**Option 3: \"szeregowe połączenia zapor sieciowych typu proxy\"**\nThis is incorrect. Firewalking nie dotyczy szeregowego łączenia zapór proxy. Konfiguracje zapor szeregowych mogą obejmować zapory pracujące w trybie proxy, ale nie są to elementy definicji Firewalking'u. Firewalking służy do identyfikowania otwartych portów i zasad filtrowania zapory, a nie jej konfiguracji z innymi zaporami.\n\n**Option 4: \"kaskadowe połączenia zapor sieciowych filtrujących pakiety\"**\nThis is incorrect. Firewalking nie jest związane z kaskadowym łączeniem zapor filtrujących pakiety, chociaż w praktyce może być wykorzystane do badania takiej konfiguracji. Kaskadowe łączenie zapor oznacza ich łączenie szeregowe. Firewalking służy do ustalenia zasad filtrowania i otwartych portów dla *pojedynczej* zapory.\n\n**Przykład praktyczny:**\nWyobraźmy sobie, że tester penetracyjny chce sprawdzić bezpieczeństwo serwera WWW, który znajduje się za zaporą sieciową. Tester wykorzystuje firewalking, aby zmapować reguły tej zapory i porty które przepuszczają ruch do serwera WWW. Wysyła on specjalnie spreparowane pakiety, które przechodzą przez zaporę tylko gdy port 80 jest otwarty. Analizując odpowiedzi, tester jest w stanie ustalić, że port 80 jest otwarty i co ważniejsze może rozpocząć dalsze skanowanie i ataki na tą właśnie usługę. Firewalking w tym przypadku pozwala przejść od analizy struktury sieci do konkretnych usług."
    },
    {
        "questionId": 99,
        "title": "Ktore z ponizszych podatnosci moga potencjalnie pozwolic na wykonanie nieuprawnionego (zlosliwego) kodu w aplikacji:",
        "answers": [
            {
                "text": "remapowanie adresu 0 (dereferencja)",
                "isCorrect": true
            },
            {
                "text": "randomizacja przydzialu przestrzeni adresowej procesu",
                "isCorrect": false
            },
            {
                "text": "przepelnienie bufora",
                "isCorrect": true
            },
            {
                "text": "nadpisanie adresu obslugi przerwania/wyjatku",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Do wykonania nieuprawnionego kodu w aplikacji może dojść w wyniku wykorzystania pewnych luk w oprogramowaniu lub błędów w zarządzaniu pamięcią. Kluczowe są tutaj dwie z wymienionych podatności: dereferencja adresu zerowego i przepełnienie bufora.\n\n*   **Remapowanie adresu 0 (dereferencja)**: Dereferencja to operacja dostępu do pamięci poprzez wskaźnik.  W systemach operacyjnych adres pamięci o wartości zero (0) jest często zastrzeżony i nie powinien być używany przez procesy użytkownika. Dostęp do tego adresu zwykle powoduje wyjątek, co w przypadku nieumiejętnego obsłużenia przez programistę może skutkować jego zakończeniem.  Jeśli program błędnie wskaże na adres zero (np. poprzez niezainicjowany wskaźnik, błąd w obliczeniach adresów) i spróbuje odczytać lub zapisać w tym miejscu, system operacyjny zgłosi wyjątek. W pewnych specyficznych okolicznościach, atakujący może manipulować tym błędem. Na przykład w systemach Unix, wywołanie `ptrace` z adresem 0, może pozwolić na zmianę jego zawartości w pamięci. Manipulując w ten sposób wskaźnikami, atakujący może uzyskać uprawnienia innego użytkownika lub wykonać niechciany kod. Zatem, dereferencja adresu 0 może prowadzić do wykonania kodu, jeśli atakujący znajdzie sposób na wykorzystanie tego błędu. W praktyce spotykamy się z sytuacją w której, w szczególności w programach napisanych w C, wskaźnik przybiera wartość zero, a w dalszej części programu nie sprawdzamy czy ta wartość została prawidłowo ustawiona, programista zakłada, że wskaźnik jest prawidłowy, po czym następuje próba odczytania z niego danych. Powoduje to błąd i system operacyjny zmusza program do zakończenia działania, natomiast atakujący, który wie co zrobił programista może wykorzystać tą lukę do podłożenia pod tym adresem kodu, który po wykonaniu zrobi coś czego on oczekuje, a nie program.\n\n*   **Randomizacja przydziału przestrzeni adresowej procesu:** Randomizacja przestrzeni adresowej (ASLR) to technika obronna, która losowo przydziela adresy pamięci do kluczowych obszarów procesu, np. biblioteki, stos.  Ma ona na celu utrudnienie ataków typu \"Return-Oriented Programming\" (ROP), w których atakujący wstrzykuje fragmenty kodu z istniejących bibliotek. Atakujący, który nie zna dokładnych adresów bibliotek i funkcji, ma utrudnione zadanie.  Mimo to, technika ASLR nie chroni przed błędami samego programu (np. przepełnienie bufora), więc w istocie sama w sobie nie jest podatnością, którą można wykorzystać. Wręcz przeciwnie,  utrudnia wykorzystanie innych podatności, przez co utrudnia wykonanie nieuprawnionego kodu.\n\n*   **Przepełnienie bufora:** Przepełnienie bufora to błąd programistyczny, który występuje, gdy program zapisuje dane poza przeznaczonym do tego obszarem pamięci (buforem). Ten nadmiar danych nadpisuje sąsiednie obszary pamięci, w tym adres powrotu z funkcji lub wskaźniki na inne dane.  Atakujący może wykorzystać przepełnienie bufora w celu nadpisania adresu powrotu z funkcji adresem, który prowadzi do kodu stworzonego przez atakującego. W ten sposób ma on możliwość wykonania dowolnego kodu, najczęściej kodu do otwarcia konta w systemie operacyjnym, usunięcia zabezpieczeń, przesłania danych do atakującego itp. Przepełnienie bufora jest jedną z najczęściej wykorzystywanych luk bezpieczeństwa w systemach informatycznych. Dla przykładu system operacyjny Linux posiada specjalne API, które ma na celu uchronienie programisty przed możliwością wystąpienia takiego błędu, są to np. funkcje strncpy zamiast strcpy, które same sprawdzają czy zapisywane dane nie wychodzą poza bufor.\n\n*   **Nadpisanie adresu obsługi przerwania/wyjątku:** Adresy obsługi przerwań i wyjątków wskazują na procedury, które mają być wykonane, gdy w systemie wystąpi określone zdarzenie. Atakujący może dążyć do manipulacji tymi adresami, aby system zaczął wykonywać kod podłożony przez atakującego, zamiast wykonywania standardowej obsługi. Mimo to,  atak polegający na nadpisaniu adresu obsługi przerwania/wyjątku w większości sytuacji (bez dodatkowych warunków) nie pozwala na wykonanie dowolnego kodu, lecz jedynie na spowodowanie awarii systemu, lub co najwyżej wykonanie ograniczonego zbioru operacji, w ramach zdefiniowanych wcześniej procedur.  Samo w sobie nadpisanie adresu nie powoduje zmiany biegu wykonywania programu, z którym wiążę się wykonanie dowolnego kodu, tylko może posłużyć do stworzenia warunków do wykonania tego. Atakujący musi zadbać, aby pod zmienionym adresem był kod, który ma zostać wykonany."
    },
    {
        "questionId": 100,
        "title": "Ataki o nazwie phishing:",
        "answers": [
            {
                "text": "dotycza wykradzenia zaufanych certyfikatow uzytkownika",
                "isCorrect": false
            },
            {
                "text": "pozwalaja w efekcie podszyc sie pod atakowanego",
                "isCorrect": true
            },
            {
                "text": "moga byc w pewnym stopniu udaremnianie przy pomocy ,,czarnych list\"",
                "isCorrect": true
            },
            {
                "text": "zmierzaja do falszowania ciasteczek www",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Atak phishing to forma inżynierii społecznej, która ma na celu wyłudzenie od użytkownika poufnych informacji, takich jak hasła, dane kart kredytowych lub dane osobowe. Phishing opiera się na oszustwie, gdzie atakujący podszywa się pod zaufaną osobę lub organizację, aby nakłonić ofiarę do ujawnienia tych danych lub podjęcia niebezpiecznej akcji. \n\n**Odpowiedź 1:** „dotycza wykradzenia zaufanych certyfikatow uzytkownika” - **Niepoprawna.** Phishing nie polega na kradzieży certyfikatów użytkownika. Ataki phishingowe skupiają się na nakłonieniu ofiary do dobrowolnego ujawnienia poufnych danych, a nie na bezpośrednim kradnięciu plików certyfikatów. Certyfikaty są używane do uwierzytelniania tożsamości, a ich kradzież to odrębny problem bezpieczeństwa. \n  *   **Przykład:** Użytkownik nieświadomie podaje swój login i hasło na fałszywej stronie logowania.\n\n**Odpowiedź 2:** „pozwalaja w efekcie podszyc sie pod atakowanego” - **Poprawna.** W wyniku udanego ataku phishingowego, atakujący uzyskuje dostęp do konta lub danych ofiary i w efekcie może się pod nią podszywać. Może to prowadzić do kradzieży tożsamości, oszustw finansowych lub kompromitacji innych użytkowników w sieci.\n   *  **Przykład:** Atakujący, po uzyskaniu hasła użytkownika do skrzynki email, wysyła w jego imieniu wiadomości z żądaniem przelania pieniędzy lub linkami do szkodliwych stron.\n\n**Odpowiedź 3:** „moga byc w pewnym stopniu udaremnianie przy pomocy ,,czarnych list\"\" - **Poprawna.**  „Czarne listy” (ang. blacklists) w kontekście phishingu to bazy danych, które zawierają adresy URL znanych fałszywych stron internetowych wykorzystywanych w atakach phishingowych. Filtry antyphishingowe, w przeglądarkach internetowych czy klientach poczty, sprawdzają adresy URL z którymi próbuje połączyć się użytkownik, z takimi listami i blokują dostęp do potencjalnie niebezpiecznych stron. Jest to istotna linia obrony, lecz atakujący mogą tworzyć nowe, jeszcze nieznane na czarnych listach, strony internetowe aby uniknąć blokowania, tym samym skuteczność „czarnych list” jest ograniczona.\n   *  **Przykład:** Przeglądarka internetowa ostrzega użytkownika przed wejściem na stronę, która znajduje się na liście znanych witryn phishingowych.\n\n**Odpowiedź 4:** „zmierzaja do falszowania ciasteczek www” - **Niepoprawna.** Chociaż ciasteczka HTTP mogą być wykorzystywane w atakach internetowych i służyć do śledzenia aktywności użytkownika w Internecie, to nie jest to bezpośredni cel ataków phishingowych. Fałszowanie ciasteczek to odrębny typ ataku (np. wykorzystywanie luk w zabezpieczeniach aplikacji www), który nie opiera się na oszustwie i wyłudzaniu danych od użytkownika. \n   *   **Przykład:** Atakujący za pomocą ataku XSS kradnie sesję uwierzytelniania poprzez przechwycenie ciasteczka użytkownika."
    },
    {
        "questionId": 101,
        "title": "Mechanizm umozliwiajacy przydzielenie poszczegolnych uprawnien administracyjnych (uprzywilejowanych operacji jadra systemy operacyjnego) uzytkownikom to:",
        "answers": [
            {
                "text": "capabilities",
                "isCorrect": true
            },
            {
                "text": "sandbox",
                "isCorrect": false
            },
            {
                "text": "remote administration",
                "isCorrect": false
            },
            {
                "text": "switch root",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm **capabilities** umożliwia przydzielanie poszczególnych, uprzywilejowanych operacji jądra systemu operacyjnego konkretnym użytkownikom lub procesom. W tradycyjnych systemach operacyjnych, takich jak Linux, uprawnienia administratora (root) są traktowane jako \"wszystko albo nic\". Oznacza to, że posiadanie uprawnień root daje dostęp do wszystkich operacji i zasobów systemu, co jest niebezpieczne, ponieważ nawet pojedynczy błąd lub luka w programie uruchomionym z uprawnieniami root,  może być wykorzystany do przejęcia kontroli nad całym systemem.  Mechanizm capabilities pozwala na bardziej precyzyjne zarządzanie uprawnieniami administracyjnymi, dając możliwość przydzielenia konkretnym użytkownikom lub aplikacjom tylko tych uprawnień, które są im rzeczywiście potrzebne do wykonania określonych zadań, bez potrzeby nadawania im pełnych uprawnień administratora.\n\n**Opcja \"capabilities\" jest prawidłową odpowiedzią,**  ponieważ dokładnie opisuje mechanizm przydzielania uprawnień administracyjnych.  Na przykład,  serwer WWW uruchamiany jako oddzielny proces może potrzebować uprawnienia do bindowania do portów o numerach poniżej 1024 (co zwykle wymaga uprawnień root),  ale nie musi mieć uprawnień do modyfikacji plików systemowych czy zarządzania innymi procesami.  Dzięki capabilities, serwer WWW  może uzyskać tylko te uprawnienia  potrzebne do poprawnego działania, a nie pełny dostęp roota.\n\n**Opcja \"sandbox\" jest nieprawidłowa**,  ponieważ sandbox to izolowane środowisko, w którym uruchamiany jest program.  Sandbox ma na celu ograniczenie dostępu aplikacji do zasobów systemu, ale nie ma na celu delegowania pojedynczych, uprzywilejowanych operacji.  Przykładowo, aplikacja uruchomiona w sandboxie może mieć ograniczony dostęp do systemu plików, sieci i innych zasobów, ale nie będzie miała przypisanych konkretnych uprawnień do wykonywania pojedynczych operacji systemowych.  Sandbox to raczej \"klatka\", niż system uprawnień.\n\n**Opcja \"remote administration\" jest nieprawidłowa**, ponieważ to określenie odnosi się do zdalnego zarządzania komputerem, a nie do sposobu przydzielania uprawnień administracyjnych w obrębie danego systemu operacyjnego.  Narzędzia zdalnej administracji (np. SSH, VNC) mogą oczywiście wymagać pewnych uprawnień w zdalnym systemie, ale to nie jest mechanizm przydzielania uprawnień do poszczególnych operacji w systemie.\n\n**Opcja \"switch root\" jest nieprawidłowa**, ponieważ odnosi się do mechanizmu zmiany katalogu głównego dla procesu, co służy do stworzenia odizolowanego środowiska (często w połączeniu z jail). Zmiana katalogu głównego ogranicza widoczność systemu plików dla procesu, ale nie przydziela uprawnień administracyjnych. Proces uruchomiony w środowisku zmienionym za pomocą  `switch root`, może nadal potrzebować konkretnych uprawnień do wykonywania uprzywilejowanych operacji (które mogłyby być mu nadane przez  `capabilities`, jeśli mechanizm ten byłby użyty)."
    },
    {
        "questionId": 102,
        "title": "Jakie restrykcje wprowadza flaga Secure w definicji ciasteczka WWW?",
        "answers": [
            {
                "text": "do ciasteczka nie mozna uzyskac dostepu w skryptach",
                "isCorrect": false
            },
            {
                "text": "dostep do ciasteczka ma tylko oryginalna strona, ktora utworzyla ciasteczko",
                "isCorrect": false
            },
            {
                "text": "ciasteczko bedzie wysylane do serwera tylko w tunelach kryptograficznych",
                "isCorrect": true
            },
            {
                "text": "ciasteczko musialo zostac sprawdzone przez filtr SOP",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Flaga `Secure` w definicji ciasteczka (ang. cookie) w protokole HTTP służy do określenia w jaki sposób ciasteczko może być wysyłane pomiędzy przeglądarką internetową a serwerem. Ciasteczka (ang. cookies) to małe fragmenty tekstu, które serwer WWW może zapisać w przeglądarce użytkownika. Przeglądarka przy każdym kolejnym zapytaniu wysyła ciasteczka, co pozwala serwerowi zapamiętać dane użytkownika, stan jego sesji, czy też inne ustawienia. Flaga `Secure` jest mechanizmem kontrolującym przesył danych, który gwarantuje że ciasteczko może być wysłane jedynie przy nawiązywaniu połączenia z wykorzystaniem szyfrowanego kanału komunikacyjnego, tzn. przy użyciu protokołu HTTPS.\n\n* **\"do ciasteczka nie mozna uzyskac dostepu w skryptach\"** - To stwierdzenie jest **nieprawidłowe**.  Flaga `Secure` nie ma wpływu na dostęp do ciasteczka z poziomu skryptów.  Do kontroli dostępu za pomocą skryptów służy atrybut `HttpOnly`. Jeśli ciasteczko ma atrybut `HttpOnly` ustawiony na wartość true to znaczy, że skrypty języka JavaScript nie mają do niego dostępu.  Brak atrybutu `HttpOnly` oznacza, że do ciasteczka można odczytać za pomocą języka JavaScript. Ustawienie samej flagi `Secure` nie ma wpływu na dostęp do ciasteczka z poziomu skryptów.\n* **\"dostep do ciasteczka ma tylko oryginalna strona, ktora utworzyla ciasteczko\"** - To stwierdzenie jest **nieprawidłowe**. Taką kontrolę dostępu wprowadza atrybut `SameSite`. Domyślnie ciasteczka mogą być wysyłane do serwera niezależnie od tego która strona jest żądana, pod warunkiem, że przeglądarka z danym ciasteczkiem będzie się łączyła z domeną na której zostało zapisane ciasteczko. Atrybut `SameSite` definiuje w jakich sytuacjach ciasteczko będzie przesyłane do serwera, czy zawsze, czy tylko w obrębie tej samej witryny. Flaga `Secure` nie kontroluje tego aspektu. \n* **\"ciasteczko bedzie wysylane do serwera tylko w tunelach kryptograficznych\"** - To stwierdzenie jest **prawidłowe**. Flaga `Secure` nakazuje przeglądarce aby wysyłała ciasteczko tylko przy połączeniach HTTPS, które są szyfrowane. Jeśli strona internetowa nie działa w trybie HTTPS ciasteczko z atrybutem secure nie zostanie wysłane do serwera w celu jego aktualizacji. Wykorzystanie tej flagi chroni ciasteczko przed nieuprawnionym podejrzeniem jego wartości i modyfikacją. Jeżeli flaga secure nie jest ustawiona to ciasteczko może zostać wysłane do serwera przy użyciu nie szyfrowanego protokołu HTTP.\n* **\"ciasteczko musialo zostac sprawdzone przez filtr SOP\"** - To stwierdzenie jest **nieprawidłowe**. Filtr SOP (Same-origin policy) chroni przed nie uprawnionym dostępem do ciasteczka z poziomu skryptu w innym domenie, ale to nie jest związane z flaga `Secure`. Mechanizm SOP jest sprawdzany w przeglądarce zanim dojdzie w ogóle do próby wysłania ciasteczka. Atrybut `Secure` nie ma wpływu na reguły filtru SOP. \n\nPrzykład praktyczny: Użytkownik loguje się do serwisu bankowego. Serwer generuje ciasteczko sesyjne z flagą `Secure` do identyfikacji sesji zalogowanego użytkownika. Ciasteczko jest wysyłane przez serwer wyłącznie z wykorzystaniem protokołu HTTPS, dzięki czemu atakujący nie ma możliwości podejrzenia sesji zalogowanego użytkownika. Natomiast, jeśli użytkownik logował by się do serwisu bankowego z użyciem protokołu HTTP bez flagi `Secure` to wówczas, atakujący podsłuchując ruch sieciowy może przechwycić ciasteczko sesji i przejąć kontrole nad kontem bankowym ofiary."
    },
    {
        "questionId": 103,
        "title": "Uzycie IPsec + IKE wprost chroni przed atakiem:",
        "answers": [
            {
                "text": "name spoofing",
                "isCorrect": true
            },
            {
                "text": "ARP cache spoofing",
                "isCorrect": false
            },
            {
                "text": "TCP spoofing",
                "isCorrect": true
            },
            {
                "text": "session hijacking",
                "isCorrect": true
            },
            {
                "text": "network sniffing",
                "isCorrect": true
            },
            {
                "text": "ARP spoofing",
                "isCorrect": false
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Protokół IPsec (Internet Protocol Security) w połączeniu z protokołem IKE (Internet Key Exchange) zapewnia ochronę przed różnymi typami ataków sieciowych, działając na warstwie sieciowej (warstwa 3 modelu OSI). IPsec samodzielnie definiuje architekturę bezpieczeństwa transmisji a IKE umożliwia uwierzytelnienie i negocjację kluczy w fazie inicjalizacji tunelu VPN. IPsec, a dokładniej jego składowe protokoły AH (Authentication Header) i ESP (Encapsulating Security Payload), chronią integralność danych (AH), poufność (ESP) oraz zapewniają uwierzytelnienie stron połączenia, natomiast IKE umożliwia dynamiczne uzgadnianie kluczy symetrycznych na potrzeby szyfrowania ruchu przesyłanego tunelami IPsec.\n\n**Name spoofing:** Poprzez mechanizmy uwierzytelniania IKE IPsec chroni przed atakami, gdzie napastnik próbuje podszyć się pod inną jednostkę, używając nieautoryzowanej nazwy. Protokół IKE w połączeniu z protokołami AH lub ESP zapewnia uwierzytelnianie każdej strony połączenia VPN, co umożliwia weryfikację ich prawdziwej tożsamości i chroni przed podstawieniem fałszywej nazwy (np. przy fałszowaniu serwerów DNS). Ponadto, jeśli protokół AH jest wykorzystany, weryfikowana jest integralność nagłówka IP, przez co nie ma możliwości jego modyfikacji. **Dlatego ta odpowiedź jest poprawna.**\n\n**ARP cache spoofing:** Ataki oparte na ARP (Address Resolution Protocol) działają w warstwie łącza danych (warstwa 2 modelu OSI), czyli poniżej warstwy sieciowej, w której działa IPsec. Protokół IPsec nie chroni przed atakami manipulującymi adresami MAC, gdyż w ogóle nie analizuje ramek warstwy drugiej, a jego ochrona sprowadza się do bezpieczeństwa przesyłanych danych przez połączenie sieciowe.  **Dlatego ta odpowiedź jest niepoprawna.**\n\n**TCP spoofing:**  IPsec z IKE zabezpiecza przed atakami TCP spoofing poprzez uwierzytelnianie stron komunikujących się za pomocą tunelu IPsec oraz przez zapewnienie integralności przesyłanych nagłówków TCP/IP oraz danych. Napastnik nie jest w stanie sfałszować nagłówka pakietu IP, gdyż na etapie nawiązywania połączenia IPsec, jego tożsamość musi być potwierdzona kluczem kryptograficznym oraz, co równie ważne, integralność wszystkich nagłówków oraz przesyłanych danych jest chroniona.  **Dlatego ta odpowiedź jest poprawna.**\n\n**Session hijacking:** IPsec i IKE uniemożliwiają udane przejęcie sesji poprzez zapewnienie poufności kluczy sesyjnych (dzięki IKE) oraz integralności przesyłanych pakietów. Ponieważ na etapie uwierzytelniania połączenia IPsec każda ze stron potwierdza swoja tożsamość, nie ma możliwości na późniejsze podstawienie się pod którąkolwiek ze stron. **Dlatego ta odpowiedź jest poprawna.**\n\n**Network sniffing:** IPsec w trybie ESP (Encapsulating Security Payload) zapewnia poufność danych poprzez ich szyfrowanie.  Dzięki temu podsłuchiwanie ruchu sieciowego staje się bezużyteczne, gdyż przesyłane dane są zaszyfrowane. Co więcej, protokoł AH zapewnia integralność nagłówków IP, przez co podsłuchujący nie ma możliwości na ich modyfikacje. **Dlatego ta odpowiedź jest poprawna.**\n\n**ARP spoofing:** Podobnie jak w przypadku ARP cache poisoning, IPsec nie chroni przed ARP spoofing. Atak ten polega na manipulacji ramek warstwy drugiej modelu OSI. Protokół IPsec chroni na poziomie warstwy trzeciej, czyli sieciowej, a więc powyżej ataku ARP. **Dlatego ta odpowiedź jest niepoprawna.**\n\nPodsumowując: IPsec z IKE zapewnia silną ochronę na poziomie warstwy sieciowej przed różnymi atakami na nagłówki i pakiety IP, ale nie jest panaceum na wszystkie zagrożenia, szczególnie te występujące poniżej warstwy sieciowej."
    },
    {
        "questionId": 104,
        "title": "Mechanizm single-sign-on cechuje:",
        "answers": [
            {
                "text": "uwierzytelnianie uzytkownika wobec wielu serwerow jednorazowa procedura",
                "isCorrect": true
            },
            {
                "text": "podpisywanie kazdego pakietu danych VPN innym kluczem",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie uzytkownika za kazdym razem innym haslem",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie uzytkownika innym haslem wobec kazdego serwera",
                "isCorrect": false
            },
            {
                "text": "autoryzacja podmiotu zgodnie z modelem MAC",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie podmiotu za kazdym razem innych haslem jednorazowym",
                "isCorrect": false
            },
            {
                "text": "zastosowanie echanizmu szyfrowania asymetrycznego w procesie autoryzacji",
                "isCorrect": false
            },
            {
                "text": "zastosowanie pojedynczego uwierzytelniania podmiotu w dostepie do wielu roznych zasobow",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Single Sign-On (SSO) to mechanizm uwierzytelniania, który umożliwia użytkownikowi dostęp do wielu różnych zasobów (aplikacji, usług, systemów) po jednorazowym uwierzytelnieniu. Oznacza to, że po pomyślnym zalogowaniu się raz, użytkownik nie musi ponownie podawać hasła lub innych danych uwierzytelniających przy próbie dostępu do innych, powiązanych z SSO, zasobów. Jest to rozwiązanie mające na celu zwiększenie wygody użytkownika, przy jednoczesnym zachowaniu bezpieczeństwa dostępu do chronionych zasobów.\n\n*   **\"uwierzytelnianie uzytkownika wobec wielu serwerow jednorazowa procedura\"** - **Poprawna.** To jest kluczową cechą SSO. Użytkownik poddaje się procesowi weryfikacji tożsamości (np. podając hasło) tylko raz, a potem system SSO umożliwia mu dostęp do wielu serwerów. Praktycznym przykładem może być dostęp do różnych aplikacji webowych w firmowej sieci, gdzie po zalogowaniu do firmowego portalu, użytkownik ma dostęp do poczty, kalendarza i innych aplikacji, bez ponownego podawania hasła.\n\n*   **\"podpisywanie kazdego pakietu danych VPN innym kluczem\"** - **Niepoprawna.** To dotyczy protokołów VPN (Virtual Private Network), gdzie klucze sesyjne są dynamicznie generowane i mogą być różne dla każdego pakietu. SSO nie dotyczy szyfrowania danych VPN. Podpisywanie pakietów VPN różnymi kluczami ma na celu zwiększenie bezpieczeństwa transferowanych danych i ochronę przed ewentualnym odczytaniem danych przez niepowołanych użytkowników.\n\n*   **\"uwierzytelnianie uzytkownika za kazdym razem innym haslem\"** - **Niepoprawna.** To opisuje hasła jednorazowe (OTP, One-Time Password) używane np. w dwuskładnikowym uwierzytelnianiu, a nie SSO. W SSO raz uwierzytelniony użytkownik używa tego samego 'poświadczenia' dostępu, nie musi za każdym razem podawać unikalnego hasła.\n\n*   **\"uwierzytelnianie uzytkownika innym haslem wobec kazdego serwera\"** - **Niepoprawna.** Jest to dokładne przeciwieństwo SSO, gdzie idea jest taka, żeby tego unikać. Standardowe podejście, które SSO próbuje zastąpić. Bez SSO użytkownik musiałby zapamiętać wiele haseł do różnych usług.\n\n*   **\"autoryzacja podmiotu zgodnie z modelem MAC\"** - **Niepoprawna.** Model MAC (Mandatory Access Control) to jeden z modeli *autoryzacji* (kontroli dostępu), a nie *uwierzytelniania*. SSO dotyczy uwierzytelniania, czyli potwierdzania tożsamości, a nie uprawnień (autoryzacji), jakie dany użytkownik ma do zasobów. Autoryzacja w systemach SSO może być różna i niekoniecznie musi odwoływać się do modelu MAC. Model MAC jest modelem, w którym decyzję o dostępie do zasobów podejmuje system operacyjny a nie właściciel zasobu.\n\n*   **\"uwierzytelnianie podmiotu za kazdym razem innych haslem jednorazowym\"** - **Niepoprawna.** To łączy w sobie mechanizm jednorazowych haseł (OTP) ale z ideą autentykacji przy każdym dostępie do usługi, a nie ideą jednokrotnego uwierzytelniania. Chociaż niektóre implementacje SSO mogą *wykorzystywać* hasła jednorazowe, to sam mechanizm SSO nie wymaga tego.\n\n*   **\"zastosowanie echanizmu szyfrowania asymetrycznego w procesie autoryzacji\"** - **Niepoprawna.** Szyfrowanie asymetryczne jest szeroko stosowane *w procesie uwierzytelniania*, szczególnie w fazie uzgadniania klucza sesyjnego (np. w protokołach SSL/TLS). W niektórych implementacjach SSO wykorzystuje się kryptografię asymetryczną, ale sam mechanizm SSO tego nie wymaga. SSO z definicji nie jest mechanizmem autoryzacji, do której to może być zastosowane szyfrowanie asymetryczne.\n\n*   **\"zastosowanie pojedynczego uwierzytelniania podmiotu w dostepie do wielu roznych zasobow\"** - **Poprawna**. Dokładnie opisuje koncepcję SSO. Chodzi o jednokrotne potwierdzenie tożsamości użytkownika i używanie tego poświadczenia do dostępu do różnych zasobów w systemie. Praktyczny przykład to logowanie się do konta Google, dające dostęp do Gmaila, Google Drive i innych usług, bez potrzeby ponownego logowania."
    },
    {
        "questionId": 105,
        "title": "Prosze wskazac algorytmy podpisu cyfrowego:",
        "answers": [
            {
                "text": "ElGamal",
                "isCorrect": true
            },
            {
                "text": "Blowfish",
                "isCorrect": false
            },
            {
                "text": "Rijndael",
                "isCorrect": false
            },
            {
                "text": "SHA-1",
                "isCorrect": false
            },
            {
                "text": "MD5",
                "isCorrect": false
            },
            {
                "text": "zadne z powyzszych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Algorytmy podpisu cyfrowego służą do zapewnienia autentyczności i integralności danych, czyli do weryfikacji, czy dane pochodzą od zadeklarowanego nadawcy i czy nie zostały zmienione po podpisaniu. Algorytm podpisu cyfrowego, w odróżnieniu od algorytmu szyfrowania, nie ma na celu utajnienia danych. Dane, wraz z wygenerowanym na podstawie danych podpisem, są jawne i każdy odbiorca może je odczytać.\nDo algorytmów podpisu cyfrowego zaliczamy algorytm ElGamala, który wykorzystuje logarytm dyskretny w grupie multiplikatywnej modulo p. Algorytm RSA również może być wykorzystywany do podpisu cyfrowego jak i algorytm DSA(_ang. Digital Signature Algorithm_). \n\n*   **ElGamal:** Jest to algorytm asymetryczny, który może być używany zarówno do szyfrowania, jak i do podpisu cyfrowego. W przypadku podpisu, nadawca używa swojego klucza prywatnego do wygenerowania podpisu, który jest dołączany do wiadomości. Odbiorca następnie weryfikuje podpis za pomocą klucza publicznego nadawcy. Klucz prywatny nadawcy jest tajny i jest znany tylko nadawcy, podczas gdy klucz publiczny jest jawny i ogólnie dostępny. Zatem tylko posiadacz klucza prywatnego może utworzyć podpis weryfikowany kluczem publicznym.\n\n*   **Blowfish:** Jest to algorytm symetryczny, co oznacza, że ten sam klucz jest używany zarówno do szyfrowania, jak i deszyfrowania danych. Blowfish jest algorytmem szyfrowania, więc nie służy do tworzenia podpisów cyfrowych, które wykorzystują asymetryczne pary kluczy, gdzie podpis generowany jest kluczem prywatnym, a weryfikowany kluczem publicznym. Blowfish zapewnia poufność, a nie autentyczność i integralność.\n\n*   **Rijndael:** Jest to również algorytm symetryczny, znany powszechnie jako AES (Advanced Encryption Standard). Jak Blowfish, służy on do szyfrowania i deszyfrowania danych i nie może być użyty jako algorytm podpisu cyfrowego. Rijndael podobnie jak Blowfish zapewnia poufność, a nie autentyczność i integralność.\n\n*   **SHA-1:** SHA-1 (Secure Hash Algorithm 1) jest algorytmem funkcji skrótu kryptograficznego. Funkcje skrótu generują skrót o stałej długości na podstawie danych wejściowych o zmiennej długości. SHA-1 sam w sobie nie generuje podpisu cyfrowego, chociaż jest wykorzystywany w algorytmach podpisu cyfrowego. W algorytmie podpisu funkcja SHA-1 jest wykorzystana do utworzenia skrótu wiadomości(ang. _message digest_), a skrót ten jest następnie szyfrowany kluczem prywatnym nadawcy, stanowiąc podpis cyfrowy wiadomości. Skrót taki, gwarantuje, że dane nie zostały zmienione.\n\n*   **MD5:** MD5 (Message Digest Algorithm 5) jest kolejnym algorytmem funkcji skrótu. Podobnie jak SHA-1, MD5 nie generuje podpisu cyfrowego, a jest wykorzystywany do generowania skrótu kryptograficznego wiadomości, który jest następnie szyfrowany w algorytmie podpisu. Podobnie jak SHA-1, MD5 zapewnia ochronę integralności danych, ale sam nie stanowi algorytmu podpisu. Algorytm ten nie jest rekomendowany do stosowania w nowych rozwiązaniach z uwagi na wykryte kolizje, czyli sytuację w której dwa różne dokumenty wytwarzają ten sam skrót kryptograficzny.\n\n*  **żadne z powyższych:** Ta odpowiedź jest niepoprawna, ponieważ ElGamal jest algorytmem podpisu cyfrowego.\n\nPodsumowując, tylko algorytm ElGamala może być wykorzystany jako algorytm podpisu cyfrowego. Blowfish i Rijndael to algorytmy szyfrowania, a SHA-1 i MD5 to algorytmy funkcji skrótu, które mogą być wykorzystane w algorytmach podpisu cyfrowego ale same z siebie nie są algorytmami podpisu cyfrowego."
    },
    {
        "questionId": 106,
        "title": "Wskaz prawidlowe stwierdzenia dotyczace metod uwierzytelniania systemow operacyjnych MS Windows w srodowisku sieciowym:",
        "answers": [
            {
                "text": "NTLM jest bezpieczniejszy niz LM",
                "isCorrect": true
            },
            {
                "text": "Kerberos jest bezpieczniejszy niz LM",
                "isCorrect": true
            },
            {
                "text": "Kerberos jest dostepny tylko w srodowisku domenowym",
                "isCorrect": true
            },
            {
                "text": "LM jest bezpieczniejszy niz NTLM",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół LM (Lan Manager) to starszy, przestarzały protokół uwierzytelniania używany w systemach Microsoft Windows, szczególnie w starszych wersjach. Protokół ten wykorzystuje prostą funkcję skrótu, co sprawia, że hasła zakodowane przy jego użyciu są podatne na ataki, zwłaszcza słownikowe i typu brute-force. Hasła są ograniczone do maksymalnie 14 znaków, co dodatkowo ułatwia kryptoanalizę.  NTLM (NT LAN Manager) jest następcą LM i wprowadza pewne usprawnienia. NTLM używa algorytmu MD4 a następnie MD5, co znacznie podnosi odporność na kryptoanalizę. Dodatkowo hasła nie muszą być ograniczone do 14 znaków, choć często, w celu zachowania kompatybilności ze starszymi systemami, nadal są przechowywane skróty haseł w formacie LM.  Kerberos to zaawansowany protokół uwierzytelniania oparty na systemie biletów, które potwierdzają tożsamość użytkownika w sieci. Jest uważany za bezpieczniejszy od LM i NTLM, ponieważ wykorzystuje kryptografię symetryczną z dynamicznie generowanymi kluczami sesyjnymi oraz dodatkową ochronę przed atakami typu _replay_. Kerberos jest domyślnie stosowany w środowiskach domenowych, gdzie istnieje scentralizowana kontrola nad kontami użytkowników i dostępem do zasobów, co podnosi bezpieczeństwo całej infrastruktury. Protokół Kerberos w systemach Windows działa w oparciu o Active Directory.\n\n**\"NTLM jest bezpieczniejszy niż LM\"** - To stwierdzenie jest **poprawne**, ponieważ NTLM, choć też nie jest uważany za bardzo bezpieczny, wprowadza silniejszą funkcję skrótu (MD4 i MD5) od LM, co zwiększa jego odporność na ataki. Używanie protokołu LM może spowodować ujawnienie skrótów haseł a następnie łatwiejsze uzyskanie dostępu do systemu przez napastnika.\n\n**\"Kerberos jest bezpieczniejszy niż LM\"** - To stwierdzenie jest **poprawne**. Kerberos wykorzystuje znacznie silniejsze mechanizmy kryptograficzne niż LM.  Dodatkowo, wykorzystuje dynamicznie tworzone klucze sesyjne, które są ważne tylko w określonym czasie, co ogranicza potencjalne straty w przypadku złamania klucza sesyjnego. Uwierzytelnianie odbywa się poprzez użycie biletów i nie wymaga każdorazowej transmisji hasła, co stanowi dodatkową ochronę. Protokół LM, z uwagi na swoje słabości, nie jest w ogóle zalecany do użytku, a protokół Kerberos ma znacznie większe zastosowanie w obecnych rozwiązaniach.\n\n**\"Kerberos jest dostępny tylko w środowisku domenowym\"** - To stwierdzenie jest **poprawne**. Kerberos jest protokołem zaprojektowanym do pracy w scentralizowanych środowiskach, takich jak domeny Windows. Wymaga specjalnej infrastruktury (kontroler domeny), w którym przechowywana jest baza użytkowników, ich haseł oraz zasobów sieciowych.  W środowisku bezdomenowym stosowanie Kerberosa nie ma sensu i zazwyczaj jest zastępowane przez NTLM.\n\n**\"LM jest bezpieczniejszy niż NTLM\"** - To stwierdzenie jest **niepoprawne**.  LM jest zdecydowanie mniej bezpieczny niż NTLM. Zastosowana funkcja skrótu jest prosta i szybka do złamania. Dodatkowo często hasła ograniczone są do 14 znaków co dodatkowo ułatwia kryptoanalizę.  Z tego powodu, zawsze gdy to możliwe, protokół LM powinien być wyłączony na wszystkich komputerach w sieci."
    },
    {
        "questionId": 107,
        "title": "Wskaz wlasnosci protokolu RADIUS:",
        "answers": [
            {
                "text": "zabezpiecza poczte elektroniczna wraz z zalacznikami",
                "isCorrect": false
            },
            {
                "text": "moga go wykorzystywac np. serwery dostepowe",
                "isCorrect": true
            },
            {
                "text": "jest realizacja koncepcji AAA",
                "isCorrect": true
            },
            {
                "text": "pozwala na centralizacje zarzadzania danymi, ktore dystrybuuje",
                "isCorrect": true
            },
            {
                "text": "wspomaga uwierzytelnianie",
                "isCorrect": true
            },
            {
                "text": "pracuje w architekturze klient-serwer",
                "isCorrect": true
            }
        ],
        "clue": 5,
        "isStarred": false,
        "explanation": "Protokół RADIUS (Remote Authentication Dial-In User Service) jest protokołem sieciowym działającym w architekturze klient-serwer. Umożliwia on centralne zarządzanie uwierzytelnianiem, autoryzacją i rozliczaniem (AAA) użytkowników, którzy chcą uzyskać dostęp do sieci. Protokół RADIUS najczęściej stosowany jest w sieciach, gdzie wielu użytkowników chce uzyskać dostęp do różnych usług i zasobów sieciowych.\n\n*   **\"zabezpiecza poczte elektroniczna wraz z zalacznikami\"** - Jest to **niepoprawna** odpowiedź. RADIUS nie ma nic wspólnego z zabezpieczaniem poczty elektronicznej. Do tego celu używa się innych protokołów i technologii takich jak np. S/MIME lub PGP. Zabezpieczanie poczty elektronicznej to zupełnie inny problem. S/MIME i PGP wykorzystują kryptografie do szyfrowania i podpisywania wiadomości, czego RADIUS nie robi. Przykładowo, S/MIME używa certyfikatów X.509 do weryfikacji tożsamości nadawcy i odbiorcy wiadomości e-mail, a PGP używa kombinacji kluczy publicznych i prywatnych. RADIUS jest protokołem *dostępu do sieci*, a nie protokołem *komunikacji* pocztowej.\n\n*   **\"moga go wykorzystywac np. serwery dostepowe\"** - Jest to **poprawna** odpowiedź. Serwery dostępowe (np. RAS, _Remote Access Server_) używają RADIUS do weryfikowania tożsamości użytkowników próbujących uzyskać dostęp do sieci. Kiedy użytkownik próbuje połączyć się zdalnie z siecią, serwer dostępowy wysyła dane uwierzytelniające użytkownika do serwera RADIUS. Serwer RADIUS decyduje czy użytkownik ma prawo dostępu do sieci i odsyła stosowną decyzję do serwera dostępowego. Przykładowo, administrator sieci może skonfigurować serwer VPN do korzystania z serwera RADIUS, aby wszyscy użytkownicy logujący się do VPN byli weryfikowani centralnie.\n\n*   **\"jest realizacja koncepcji AAA\"** - Jest to **poprawna** odpowiedź. RADIUS jest implementacją koncepcji AAA, która obejmuje trzy aspekty bezpieczeństwa:  **Uwierzytelnianie** (ang. _Authentication_) - weryfikacja tożsamości użytkownika, na przykład poprzez login i hasło, **Autoryzację** (ang. _Authorization_) - przydzielanie użytkownikowi praw dostępu do zasobów sieciowych, oraz **Rozliczanie** (ang. _Accounting_) - rejestrowanie czasu i rodzaju wykorzystanych zasobów. Przykładem z życia może być publiczny punkt dostępu do sieci WiFi, gdzie RADIUS weryfikuje czy użytkownik w ogóle ma prawo skorzystać z usługi, do jakich zasobów ma dostęp oraz jak długo korzystał z połączenia.\n\n*   **\"pozwala na centralizacje zarzadzania danymi, ktore dystrybuuje\"** - Jest to **poprawna** odpowiedź. RADIUS centralizuje zarządzanie danymi uwierzytelniającymi (np. hasłami). Zamiast konfigurować każdego serwera dostępowego oddzielnie, cała konfiguracja znajduje się w centralnym serwerze RADIUS. Ułatwia to administrowanie siecią. Na przykład duża firma może mieć wiele serwerów dostępowych (np. VPN, Wi-Fi), ale dzięki RADIUS wszystkie konta użytkowników są w jednym miejscu. To upraszcza zarządzanie dostępem do sieci.\n\n*   **\"wspomaga uwierzytelnianie\"** - Jest to **poprawna** odpowiedź. RADIUS jest protokołem wykorzystywanym do uwierzytelniania użytkowników. Serwer RADIUS weryfikuje czy dane uwierzytelniające (na przykład hasło) przekazane przez użytkownika są poprawne. Jeżeli są, to serwer dostępowy zezwala użytkownikowi na dalszy dostęp. Praktyczny przykład to serwer poczty elektronicznej, który może korzystać z protokołu RADIUS do weryfikacji loginu i hasła użytkownika, który chce pobrać wiadomości e-mail.\n\n*   **\"pracuje w architekturze klient-serwer\"** - Jest to **poprawna** odpowiedź. RADIUS działa w architekturze klient-serwer. Serwer RADIUS obsługuje żądania uwierzytelnienia od klientów (serwerów dostępowych). Serwer dostępowy przesyła zapytanie do serwera RADIUS, ten weryfikuje uprawnienia użytkownika i odsyła informację do serwera dostępowego czy użytkownik powinien uzyskać dostęp. Przykładowo, urządzenie brzegowe sieci(router) jest klientem protokołu RADIUS w systemie informatycznym danej organizacji."
    },
    {
        "questionId": 108,
        "title": "Nastepujaca regula filtracji zapory sieciowej od 1.1.1.1 do x.x.x.x:",
        "answers": [
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwera www o dowolnym adresie",
                "isCorrect": false
            },
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwera www o adresie 1.1.1.1",
                "isCorrect": true
            },
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwerem www o adresie 1.1.1.1",
                "isCorrect": false
            },
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwerem www o dowolnym adresie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Reguła filtrowania zapory sieciowej analizuje pakiety na podstawie adresu źródłowego i docelowego, a także protokołu i portów. Zapora sieciowa(_ang. firewall_) jest mechanizmem zabezpieczającym, który na podstawie zestawu reguł podejmuje decyzje odnośnie pakietów, które przez nią przechodzą. Najczęściej używanymi akcjami są przepuszczanie(ang. ACCEPT) pakietu lub odrzucenie (ang. DROP) pakietu. \nAdres źródłowy (_ang. source address_) to adres IP urządzenia, które inicjuje połączenie. Adres docelowy (_ang. destination address_) to adres IP urządzenia docelowego, do którego połączenie jest kierowane. Numer portu, jest to numer jednoznacznie identyfikujący usługę sieciową. Usługa sieciowa _serwer www_, najczęściej jest dostępna pod portem 80(HTTP) lub 443 (HTTPS). Słowo _any_ , oznacza dowolny adres IP lub dowolny numer portu. W regułach zapory sieciowej występują adresy IP i numery portów lub słowo any. \nRozpatrzmy teraz poszczególne odpowiedzi:\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwera www o dowolnym adresie\"** - Ta odpowiedź jest **niepoprawna**. Reguła, o której mowa w pytaniu, określa konkretny adres IP (1.1.1.1) jako źródło połączenia (czyli ten, który inicjuje połączenie, czyli pakiet jest wysyłany z tego adresu), a nie jak sugeruje odpowiedź dowolny adres. Adres \"x.x.x.x\" nie jest rozpatrywany. Ta odpowiedź myli kierunek ruchu, wskazując że to serwer www nawiązuje połączenie, co przy zablokowaniu takiego ruchu uniemożliwiłoby prawidłowe działanie serwera. W rzeczywistości ta reguła blokuje pakiety wysłane z adresu 1.1.1.1, co w tym wypadku oznacza, że blokuje połączenia przychodzące z tego adresu, a nie z dowolnego.\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwera www o adresie 1.1.1.1\"** - Ta odpowiedź jest **poprawna**. Reguła odnosi się do połączeń nawiązywanych z adresu IP 1.1.1.1. Sformułowanie „z serwera www” jest tutaj pewnym uproszczeniem ponieważ faktycznie ta reguła blokuje wszystkie połączenia z tego adresu niezależnie od usługi(np. serwera poczty, ssh, ftp), jednak z uwagi że pytanie jest zdefiniowane jako dotyczące serwera www odpowiedź ta jest poprawna. W praktyce oznacza to, że jeśli serwer WWW ma adres IP 1.1.1.1, ta reguła uniemożliwi połączenie z tym serwerem. W takim przypadku wszelkie prośby o załadowanie strony internetowej z danego serwera www kończyłyby się niepowodzeniem z uwagi na blokadę na zaporze.\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwerem www o adresie 1.1.1.1\"** - Ta odpowiedź jest **niepoprawna**. Odpowiedź ta pomija fakt, że reguła tyczy się wszystkich usług a nie tylko serwera www. Sformułowanie „z serwera www” jest tutaj pewnym uproszczeniem ponieważ faktycznie ta reguła blokuje wszystkie połączenia z tego adresu niezależnie od usługi, jeśli w danej regule nie mamy określonego konkretnego numeru portu, a wszystkie usługi mają przypisane porty (np. www port 80). W praktyce oznacza to, że jeśli serwer WWW ma adres IP 1.1.1.1, to ta reguła uniemożliwi połączenie z tym serwerem (poprzez port 80), ale również uniemożliwi np. pobranie poczty elektronicznej(np. port 110 lub 143). W rzeczywistości ta reguła blokuje wszystkie połączenia inicjowane z tego adresu IP 1.1.1.1.\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwera www o dowolnym adresie\"** - Ta odpowiedź jest **niepoprawna**. Adres 1.1.1.1 wskazuje konkretny adres ip a nie dowolny. Po drugie kierunek połączenia jest inicjowany z adresu źródłowego(czyli z adresu 1.1.1.1) a nie do niego. Odpowiedź ta myli kierunek ruchu, wskazując że to serwer www nawiązuje połączenie, co przy zablokowaniu takiego ruchu uniemożliwiłoby prawidłowe działanie serwera. W rzeczywistości ta reguła blokuje pakiety wysłane z adresu 1.1.1.1, a nie z dowolnego.\n\nWnioskiem z powyższej analizy jest to, że reguła blokuje połączenia ze źródła 1.1.1.1, więc połączenie do serwera www o adresie 1.1.1.1 również będzie zablokowane(zakładając, że protokół http nie będzie wykorzystywał innego, rzadko stosowanego numeru portu)."
    },
    {
        "questionId": 109,
        "title": "Ktore z ponizszych protokolow sluza realizacji kryptograficznych tuneli wirtualnych z ochrona poufnosci?",
        "answers": [
            {
                "text": "PGP",
                "isCorrect": false
            },
            {
                "text": "ESP",
                "isCorrect": true
            },
            {
                "text": "X.400",
                "isCorrect": false
            },
            {
                "text": "AH",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół ESP (Encapsulating Security Payload) jest protokołem, który zapewnia poufność poprzez szyfrowanie danych. Umożliwia on również zapewnienie integralności danych. ESP jest używany w ramach protokołu IPsec, który służy do tworzenia bezpiecznych połączeń VPN. IPsec (Internet Protocol Security) jest zestawem protokołów zapewniających bezpieczną komunikację w sieciach IP poprzez uwierzytelnianie i szyfrowanie pakietów danych. ESP, opakowując dane w zaszyfrowaną kapsułę, uniemożliwia osobom nieupoważnionym odczytanie przesyłanych informacji.\n\n**Odpowiedź A: PGP**\nPGP (Pretty Good Privacy) to program komputerowy wykorzystywany do kryptograficznego zabezpieczania przesyłek poczty elektronicznej i plików. PGP przede wszystkim zapewnia ochronę integralności poprzez podpis cyfrowy oraz ochronę poufności poprzez szyfrowanie wiadomości i plików, PGP nie służy do tworzenia tuneli wirtualnych, a raczej zabezpieczanie indywidualnej poczty.\n\n**Odpowiedź B: ESP**\nESP (Encapsulating Security Payload) jest protokołem z rodziny IPsec i jest odpowiedzialny za zapewnienie poufności poprzez szyfrowanie przesyłanych danych. ESP tworzy tunel, w którym dane są zaszyfrowane. Umożliwia także zapewnienie integralności danych, jednak głównym jego celem jest ochrona poufności.\nPrzykładowo, gdy dwa komputery w oddzielnych sieciach lokalnych chcą bezpiecznie komunikować się przez Internet, mogą ustanowić tunel VPN z wykorzystaniem protokołu IPsec i jego części składowej, protokołu ESP. Wówczas cała transmisja pomiędzy tymi sieciami lokalnymi jest szyfrowana, uniemożliwiając przechwycenie danych przez niepowołane osoby.\n\n**Odpowiedź C: X.400**\nX.400 jest standardem dotyczącym przesyłania wiadomości, szczególnie w komunikacji pocztowej. Definiuje format wiadomości i protokoły, natomiast nie ma wbudowanych mechanizmów kryptograficznych, które mogłyby służyć do tworzenia tuneli wirtualnych. Standard X.400 nie ma na celu ochronę przesyłanych wiadomości, dlatego jego zastosowanie nie pozwala na tworzenie bezpiecznych tuneli VPN.\n\n**Odpowiedź D: AH**\nAH (Authentication Header) jest również protokołem z rodziny IPsec, jednakże jego zadaniem jest ochrona integralności oraz uwierzytelnienie przesyłanych danych poprzez użycie algorytmów kryptograficznych generujących skrót wiadomości. AH nie oferuje szyfrowania, a tym samym nie chroni poufności. AH może zostać użyty do ochrony np. zapytań DNS."
    },
    {
        "questionId": 110,
        "title": "Wskaz protokoly wymagajace zabezpieczenia autentycznosci i integralnosci danych, ale niekoniecznie poufnosci:",
        "answers": [
            {
                "text": "DNS (Domain  Name Service)",
                "isCorrect": true
            },
            {
                "text": "ARP (Address Resolution Protocol)",
                "isCorrect": true
            },
            {
                "text": "STP (Spanning Tree Protocol)",
                "isCorrect": true
            },
            {
                "text": "rlogin (Remote Login)",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół DNS (Domain Name Service) służy do tłumaczenia nazw domenowych na adresy IP. Jego głównym celem jest zapewnienie dostępności tych informacji. Poufność danych w DNS nie jest kluczowa, gdyż  większość tych danych jest publiczna. Natomiast  autentyczność i integralność są niezwykle ważne, gdyż  fałszywe informacje DNS mogą przekierować użytkownika na  nieprawdziwą stronę, a tym samym narazić go na kradzież danych, ataki phishingowe.\n\nProtokół ARP (Address Resolution Protocol) umożliwia odwzorowanie adresu IP na adres MAC w sieci lokalnej. ARP jest protokołem bezstanowym i nie zapewnia szyfrowania danych. Celem ARP jest dostarczenie poprawnego adresu MAC dla urządzenia o znanym adresie IP, w obrębie lokalnej sieci. Poufność w tym protokole nie jest istotna, gdyż przesyłane dane nie są tajne. Jednakże, zapewnienie autentyczności i integralności protokołu ARP jest niezwykle ważne. Atakujący, podszywając się pod urządzenie, może przesłać fałszywe informacje ARP, przez co może podsłuchiwać komunikację, lub spowodować, że ruch w sieci będzie przekierowany na nieprawidłowy adres MAC i zablokować połączenie. Z tego powodu wymagana jest ochrona przed modyfikacją danych w protokole ARP, czyli integralność i potwierdzenie, że dane są poprawne czyli autentyczność.\n\nProtokół STP (Spanning Tree Protocol) jest protokołem umożliwiającym budowanie bezpętlowych topologii w sieciach z przełącznikami. Jego zadaniem jest zapobieganie powstawania pętli w sieci i zapewnienie dostępu do wszystkich przełączników w sieci. Wymiana informacji między przełącznikami nie wymaga zachowania poufności, gdyż nie przenoszą one tajnych danych. Natomiast integralność danych jest ważna, gdyż fałszywe informacje w protokole STP mogą spowodować utworzenie pętli w sieci, a w rezultacie zablokowanie komunikacji, lub spowodować niepotrzebne zablokowanie łącza. Zatem autentyczność i integralność są niezbędne w tym protokole, aby nie dochodziło do modyfikacji komunikatów przez niepowołane osoby.\n\nProtokół rlogin (Remote Login) jest protokołem umożliwiającym zdalny dostęp do systemu operacyjnego. Podczas procesu uwierzytelniania przesyłane są nazwa użytkownika oraz hasło dostępu, które, jeżeli nie są szyfrowane, mogą zostać przechwycone przez osoby niepowołane i wykorzystane do nieautoryzowanego logowania się do systemu operacyjnego. Dlatego też protokół ten wymaga ochrony wszystkich trzech własności: poufności, integralności i autentyczności. Poufność jest niezbędna w tym przypadku gdyż użytkownik, a szczególnie jego hasło jest traktowane jako informacja poufna, integralność zapewnia, że dane nie zostaną zmodyfikowane a autentyczność potwierdza tożsamość serwera i użytkownika."
    },
    {
        "questionId": 111,
        "title": "Ktore nazwy atakow dotycza zalewania uzytkownikow niepozadana informacja:",
        "answers": [
            {
                "text": "spam",
                "isCorrect": true
            },
            {
                "text": "pharming",
                "isCorrect": false
            },
            {
                "text": "scam",
                "isCorrect": false
            },
            {
                "text": "spim",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Pojęcie \"spam\" w kontekście bezpieczeństwa komputerowego odnosi się do niechcianych i nieproszonych wiadomości elektronicznych, rozsyłanych masowo. Spam jest formą cyberprzestępczości, która polega na rozsyłaniu niechcianej korespondencji, zazwyczaj w celach reklamowych, ale może również zawierać linki do złośliwego oprogramowania lub próby wyłudzenia informacji.\n\n*   **spam:** Jest to poprawna odpowiedź. Termin \"spam\" jest używany do opisania masowego rozsyłania niechcianych wiadomości, najczęściej e-mailowych. Przykładowo, każdego dnia miliony użytkowników Internetu otrzymują e-maile reklamujące nieznane produkty lub oferujące \"okazje\", na które nikt się nie zapisywał. Te e-maile są typowym przykładem spamu. Spam nie jest ograniczony tylko do poczty email, występuje on w komentarzach blogów, forach internetowych i serwisach społecznościowych.  W kontekście bezpieczeństwa, spam to poważne zagrożenie, ponieważ wiadomości te mogą zawierać złośliwe oprogramowanie, służące do kradzieży danych lub przejęcia kontroli nad komputerem użytkownika. Zazwyczaj użytkownik ma bardzo mało kontroli nad pojawianiem się spamu w jego systemie.\n\n*   **pharming:** Jest to niepoprawna odpowiedź. \"Pharming\" to rodzaj ataku, który polega na przekierowaniu użytkownika do fałszywej strony internetowej, która na pierwszy rzut oka wygląda identycznie jak oryginalna. Zazwyczaj atak tego typu uzyskuje się modyfikując wpisy DNS. Celem ataku pharming jest przejęcie poufnych danych użytkownika(np. haseł czy danych logowania). Pharming nie polega na zalewaniu użytkownika niechcianymi informacjami, ale na kierowaniu go na fałszywe strony internetowe. Przykładem ataku pharming może być modyfikacja pliku hosts lub serwera DNS, co powoduje, że przy próbie otwarcia strony banku, użytkownik jest przekierowywany na stronę łudząco podobną, ale należącą do przestępców, a nie do banku.\n\n*   **scam:** Jest to niepoprawna odpowiedź. \"Scam\" to oszustwo, najczęściej w formie finansowej, ale też celem scam mogą być dane użytkownika, np. dane osobowe czy numery kart kredytowych. Scamy często wykorzystują mechanizm spamu jako narzędzie, ale nie są tym samym co spam. Scam opiera się na psychologicznym triku wykorzystującym ufność, strach, chęć zysku. Przykładem takiego działania jest wysyłanie e-maila rzekomo od banku z informacją o potrzebie natychmiastowego zalogowania się do systemu w celu weryfikacji konta.\n\n*   **spim:** Jest to poprawna odpowiedź. \"Spim\" to odmiana spamu, który rozsyłany jest za pomocą komunikatorów internetowych (instant messaging). Podobnie jak e-mailowy spam, spim jest niechciany i często zawiera niebezpieczne linki, ale dotyczy głównie komunikatorów internetowych. Przykładem jest rozsyłanie wiadomości z losowych kont na komunikatorze, np. Skype, reklamujące zakup tabletek na odchudzanie."
    },
    {
        "questionId": 112,
        "title": "Do szyfrow asymetrycznych zaliczamy:",
        "answers": [
            {
                "text": "SHA",
                "isCorrect": false
            },
            {
                "text": "SSH",
                "isCorrect": false
            },
            {
                "text": "AES",
                "isCorrect": false
            },
            {
                "text": "zadne z powyzszych",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie asymetryczne, znane również jako kryptografia klucza publicznego, charakteryzuje się użyciem dwóch kluczy – klucza publicznego i klucza prywatnego. Klucz publiczny jest dostępny dla wszystkich i służy do szyfrowania danych, natomiast klucz prywatny jest znany tylko właścicielowi i służy do deszyfrowania. Ten mechanizm umożliwia bezpieczną komunikację bez konieczności wcześniejszej wymiany tajnych kluczy. Przykłady algorytmów asymetrycznych to RSA, DSA i ElGamal.\n\nOpcja **SHA** odnosi się do rodziny kryptograficznych funkcji skrótu. SHA (Secure Hash Algorithm) jest algorytmem jednokierunkowym, który przekształca dowolnej długości dane wejściowe na wyjściową wartość o stałej długości, zwaną skrótem. Funkcje skrótu używane są do weryfikacji integralności danych oraz w podpisach cyfrowych. SHA nie służy do szyfrowania danych, więc nie jest algorytmem szyfrowania asymetrycznego. Przykładowo, hasło użytkownika może być przekształcone za pomocą algorytmu SHA i zapisane w postaci skrótu, a nie w postaci jawnego tekstu w bazie danych.\n\nOpcja **SSH** (Secure Shell) jest protokołem sieciowym służącym do bezpiecznego połączenia z serwerem. SSH wykorzystuje kryptografię symetryczną do szyfrowania przesyłanych danych, a kryptografię asymetryczną, np. RSA do wymiany kluczy i uwierzytelniania stron. SSH sam w sobie nie jest algorytmem szyfrowania, asymetrycznym, tylko protokołem bezpieczeństwa wykorzystującym różne metody szyfrowania. Wykorzystując SSH, możemy bezpiecznie zalogować się do zdalnego serwera lub przesłać pliki.\n\nOpcja **AES** (Advanced Encryption Standard) to algorytm symetrycznego szyfrowania blokowego. Oznacza to, że do szyfrowania i deszyfrowania tych samych danych używany jest ten sam tajny klucz. AES jest powszechnie stosowany ze względu na swoją szybkość i bezpieczeństwo, jednak nie jest on szyfrem asymetrycznym. Przykładowo, AES może być stosowany do szyfrowania dysków twardych lub tunelowania połączeń w protokole VPN.\n\nPrawidłową odpowiedzią jest **żadne z powyższych**, ponieważ SHA jest algorytmem haszującym, SSH protokołem, a AES algorytmem szyfrowania symetrycznego.  Żaden z nich nie jest algorytmem szyfrowania asymetrycznego, które wykorzystuje parę kluczy – publiczny i prywatny."
    },
    {
        "questionId": 113,
        "title": "W metodzie uzgadniania klucza Diffiego-Hellmana system moze zostac skompromitowany poprzez:",
        "answers": [
            {
                "text": "przechwycenie jednego z wymienianych kluczy",
                "isCorrect": false
            },
            {
                "text": "przechwycenie obu wymienianych klucz",
                "isCorrect": false
            },
            {
                "text": "postawienie falszywego klucza w miejsce kazdego z wymienianych",
                "isCorrect": true
            },
            {
                "text": "postawienie falszywego klucza w miejsce dowolnego z wymienianych",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół Diffiego-Hellmana to metoda uzgadniania tajnego klucza między dwiema stronami za pośrednictwem niezabezpieczonego kanału. Działa on w oparciu o matematyczne własności grup cyklicznych. Uczestnicy komunikacji, nazywani powszechnie Alicją i Bolkiem, wymieniają się informacjami w następujący sposób:\n1. Alicja wybiera losową liczbę _a_ i oblicza wartość _A = g^a mod p_, gdzie _g_ to generator grupy a _p_ to duża liczba pierwsza publicznie znana. Następnie wysyła _A_ do Bolka.\n2. Bolek wybiera losową liczbę _b_ i oblicza wartość _B = g^b mod p_,  a następnie wysyła _B_ do Alicji.\n3. Alicja oblicza tajny klucz: _s = B^a mod p_\n4. Bolek oblicza tajny klucz: _s = A^b mod p_\n\nZ matematycznych własności operacji na grupach cyklicznych wynika, że obie wartości _s_ obliczone przez obie strony są sobie równe i stają się tajnym kluczem symetrycznym, który znają tylko obie strony. \nZabezpieczenie Diffiego-Hellmana opiera się na trudności obliczeniowej wyznaczenia wartości _a_ lub _b_ znając _A_, _B_, _g_ oraz _p_. W szczególności wartość klucza _s_ jest również trudna do obliczenia nie znając _a_ lub _b_. Zatem podsłuchanie wymienianych wartości _A_ i _B_ nie pozwala na proste obliczenie klucza _s_.  Jednak protokół ten jest podatny na atak typu _Man-in-the-Middle (MitM)_.\nW tym ataku napastnik (nazwijmy go Edziu) umiejscawia się w kanale komunikacyjnym pomiędzy Alicją i Bolkiem i  modyfikuje przesyłane dane w następujący sposób:\n1. Alicja wysyła _A_ do Bolka. Edziu przechwytuje wartość A i wysyła do Bolka fałszywą wartość _E1_.\n2. Bolek wysyła _B_ do Alicji. Edziu przechwytuje wartość _B_ i wysyła do Alicji fałszywą wartość _E2_.\n3.  Alicja wykonuje obliczenia, ale używa podstawionej wartości _E2_ do obliczenia klucza, który nie jest tym kluczem, którego oczekuje Bolek, tak naprawdę ma klucz, który współdzieli z Edziem. \n4. Bolek wykonuje obliczenia, ale używa podstawionej wartości _E1_ do obliczenia klucza, który nie jest tym kluczem, którego oczekuje Alicja, tak naprawdę ma klucz, który współdzieli z Edziem. \nW takim przypadku i mimo prawidłowego wyliczenia kluczy po obu stronach, żaden z nich nie jest współdzielony z zamierzoną stroną. \n\n*   **\"przechwycenie jednego z wymienianych kluczy\"** - *Niepoprawna*. Samo przechwycenie pojedynczej wartości _A_ lub _B_  nie umożliwia obliczenia tajnego klucza. Włamywacz nie może wyznaczyć  _a_ lub _b_ na podstawie tych informacji. Ochrona opiera się na trudności rozwiązania problemu logarytmu dyskretnego.\n*   **\"przechwycenie obu wymienianych kluczy\"** - *Niepoprawna*. Nawet przechwycenie obu wartości _A_ i _B_ nie pozwala włamywaczowi na proste obliczenie tajnego klucza _s_. Włamywacz musiałby złamać zabezpieczenia klucza prywatnego w protokole Diffiego-Hellmana lub wykorzystać jakieś słabości algorytmu, które nie zostały wykryte, aby w ogóle pozyskać taką informację.  Samo przechwycenie danych w czasie transmisji nie ma znaczenia.\n*   **\"postawienie fałszywego klucza w miejsce każdego z wymienianych\"** - *Poprawna*.  To jest istota ataku Man-in-the-Middle. Edziu aktywnie wchodzi w proces wymiany kluczy i podstawia swoje fałszywe wartości ( _E1_ i _E2_),  uniemożliwiając stronom ustalenie wspólnego tajnego klucza. Alicja myśli, że dzieli klucz z Bolkiem, a Bolek, że dzieli klucz z Alicją - w rzeczywistości obaj współdzielą osobne klucze z Edziem. Ten atak pozwala  Edziowi czytać i modyfikować całą komunikację.\n*   **\"postawienie fałszywego klucza w miejsce dowolnego z wymienianych\"** - *Poprawna*.  Podobnie jak w poprzednim przypadku, samo podstawienie fałszywej wartości w miejsce _A_ lub _B_ wystarczy, aby doprowadzić do sytuacji, w której klucz tajny nie jest współdzielony między Alicją i Bolkiem,  ponieważ tylko jedna strona obliczy fałszywy klucz wspólnie z Edziem. Atak nie powiedzie się, jeżeli obie strony nie będą miały podstawionego fałszywego klucza i nie uzgodnią klucza z włamywaczem."
    },
    {
        "questionId": 114,
        "title": "Algorytm SHA-256 i SHA-512 roznia sie wzajemnie:",
        "answers": [
            {
                "text": "odpornoscia na ataki Length extension",
                "isCorrect": false
            },
            {
                "text": "podatnoscia na kolizje",
                "isCorrect": true
            },
            {
                "text": "wielkosci wynikowego skrotu",
                "isCorrect": true
            },
            {
                "text": "zadne z powyzszych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Funkcje skrótu kryptograficznego, takie jak SHA-256 i SHA-512,  przetwarzają dane wejściowe o dowolnej długości na wyjście o ustalonej długości, zwane również skrótem (ang. _hash_, _message digest_, _fingerprint_). Kluczowymi cechami funkcji skrótu są jednokierunkowość (trudność odwrócenia procesu), determinizm (to samo wejście daje zawsze to samo wyjście) oraz odporność na kolizje. Odporność na kolizje oznacza, że znalezienie dwóch różnych danych wejściowych, które dają ten sam skrót, jest obliczeniowo trudne.\n\n**odpornoscia na ataki Length extension** - Jest to **niepoprawna** odpowiedź. Ataki typu length extension są ogólnym problemem funkcji skrótu i nie są specyficzne dla algorytmów z rodziny SHA-2, czyli SHA-256 i SHA-512. Ataki te wykorzystują znajomość skrótu pewnych danych oraz ich długości do utworzenia skrótu dla danych poszerzonych o dodatkowe informacje bez znajomości oryginalnych danych. Ataki te zostały wykorzystane np. do stworzenia fałszywego klucza uwierzytelniającego dla serwera Yandex.\n\n**podatnoscia na kolizje** - Jest to **poprawna** odpowiedź. Pomimo, że zarówno SHA-256 i SHA-512 są projektowane tak aby były odporne na kolizje, to w teorii algorytmy te będą w różnym stopniu na nie podatne. Praktycznie, kolizje dla obu algorytmów są obliczeniowo bardzo kosztowne i nadal w praktyce są nieznane. Algorytm SHA-512 jest mniej podatny na tego typu ataki ze względu na dużo większą długość produkowanego skrótu.\n\n**wielkosci wynikowego skrotu** - Jest to **poprawna** odpowiedź. Algorytm SHA-256 produkuje skrót o długości 256 bitów, natomiast algorytm SHA-512 produkuje skrót o długości 512 bitów. To zasadnicza różnica między tymi algorytmami. Dłuższy skrót oferuje teoretycznie większą odporność na ataki siłowe metodą przeszukiwania wyczerpującego(_ang. brute force attack_).\n\n**zadne z powyzszych** - Jest to **niepoprawna** odpowiedź, ponieważ dwa z powyższych stwierdzeń są prawidłowe."
    },
    {
        "questionId": 115,
        "title": "Wskaz cechy zapory sieciowej zrealizowanej poprzez Komputer-Twierdze (Bastion Host):",
        "answers": [
            {
                "text": "dla ruchu z zewnatrz zapora ,,przykrywa\" soba cala siec wewnetrzna",
                "isCorrect": true
            },
            {
                "text": "dla ruchu od wewnatrz zapora ,,przykrywa\" soba caly swiat zewnetrzny",
                "isCorrect": true
            },
            {
                "text": "w zaporze nie jest realizowany routing",
                "isCorrect": true
            },
            {
                "text": "komunikacja zachodzi wylacznie przez uslugi proxy",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Komputer-Twierdza, znany również jako Bastion Host, to specjalnie zabezpieczony komputer w sieci, który służy jako jedyny punkt styku między siecią wewnętrzną a światem zewnętrznym, takim jak internet. Charakteryzuje się on brakiem funkcji routingu, realizując komunikację wyłącznie poprzez usługi pośredniczące (proxy), a z perspektywy sieci zewnętrznej, sieć wewnętrzna jest \"ukryta\".\n\n*   **\"dla ruchu z zewnatrz zapora ,,przykrywa\" soba cala siec wewnetrzna\"** - Jest to **poprawna** odpowiedź. Bastion Host, jako jedyny punkt styku, przyjmuje cały ruch przychodzący z zewnątrz. Z perspektywy sieci zewnętrznej, systemy wewnętrzne pozostają niewidoczne, gdyż jedyny widoczny adres IP to adres IP interfejsu sieciowego bastion hosta. Bastion Host działa jako rodzaj maski, ukrywając całą sieć wewnętrzną. Przykładowo, jeśli atakujący chce dostać się do serwera bazy danych w sieci wewnętrznej, to najpierw będzie musiał sforsować zabezpieczenia bastion hosta, a dopiero potem, jeśli w ogóle, będzie mógł spróbować dostać się do serwera bazy danych.\n\n*   **\"dla ruchu od wewnatrz zapora ,,przykrywa\" soba caly swiat zewnetrzny\"** - Jest to **poprawna** odpowiedź. Bastion Host działa również jako pośrednik dla ruchu wychodzącego z sieci wewnętrznej. Pakiety z sieci wewnętrznej, które są przeznaczone dla serwerów w Internecie, są kierowane najpierw do Bastion Hosta. Z punktu widzenia serwerów internetowych, cała sieć wewnętrzna reprezentowana jest przez adres IP Bastion Hosta. Przykładowo, jeśli komputer w sieci wewnętrznej ma pobrać aktualizacje systemu, to będzie wysyłał zapytanie do Bastion Hosta, a ten będzie kontaktował się ze stroną producenta oprogramowania i odebrana aktualizacja będzie zwrócona do komputera w sieci wewnętrznej.\n\n*   **\"w zaporze nie jest realizowany routing\"** - Jest to **poprawna** odpowiedź. Bastion Host nie działa jako ruter, czyli nie przekazuje pakietów między sieciami na poziomie warstwy sieciowej. Zamiast tego, działa jako „brama” na poziomie warstwy aplikacyjnej. Oznacza to, że zamiast przekazywać surowe pakiety, analizuje je, a następnie, na podstawie zdefiniowanych reguł, samodzielnie zestawia połączenie z serwerem po stronie zewnętrznej, zachowując się jak klient. Dla porównania, router przesyła pakiety na podstawie adresów IP warstwy trzeciej OSI a Bastion Host pośredniczy w sesji na poziomie warstwy siódmej OSI.\n\n*  **\"komunikacja zachodzi wylacznie przez uslugi proxy\"** - Jest to **poprawna** odpowiedź. Bastion Host nie pozwala na bezpośrednie łączenie się z serwerami w sieci wewnętrznej. W celu komunikacji z serwerem w sieci wewnętrznej, pakiet jest przejmowany przez zaporę, która sama nawiązuje komunikację z serwerem. W ten sposób nie ujawniamy struktury sieci wewnętrznej. Zatem, zamiast bezpośredniego połączenia, cała komunikacja odbywa się poprzez usługi pośredniczące, tzw. proxy. Przykładowo, zamiast łączenia się bezpośrednio z serwerem FTP, klient kontaktuje się z serwerem proxy FTP, który dopiero nawiązuje właściwe połączenie z serwerem wewnątrz sieci.\n\nPodsumowując, Bastion Host to specjalnie skonfigurowany komputer, będący jedynym punktem styku między siecią wewnętrzną a zewnętrzną. Nie realizuje funkcji routingu, a komunikacja odbywa się jedynie poprzez usługi proxy. Tworzy on barierę ochronną, maskując jednocześnie wewnętrzną strukturę sieci."
    },
    {
        "questionId": 116,
        "title": "Funkcja systemowa chroot()",
        "answers": [
            {
                "text": "oferuje kontrole nad komunikacja sieciowa",
                "isCorrect": false
            },
            {
                "text": "nie oferuje kontroli nad komunikacja sieciowa",
                "isCorrect": true
            },
            {
                "text": "jest wykorzystywana przez narzedzie sudo do zmiany aktualnych uprawnien procesu",
                "isCorrect": false
            },
            {
                "text": "sluzy do chwilowego przeniesienia administratora na wybranego uzytkownika",
                "isCorrect": false
            },
            {
                "text": "ogranicza aplikacji dostep do systemu plikow",
                "isCorrect": true
            },
            {
                "text": "chroni system przed atakami DoS",
                "isCorrect": false
            },
            {
                "text": "jest jednym z mechanizmow tworzenia piaskownicy",
                "isCorrect": true
            },
            {
                "text": "pozwala wykonac pojedyncze polecenia administracyjne administracyjne bez weryfikacji hasla",
                "isCorrect": false
            },
            {
                "text": "wymaga powielania plikow niezbednych dla poprawnego dzialania aplikacji",
                "isCorrect": true
            },
            {
                "text": "pozwala wielokrotnie skorzystac z uprawnien administratora bez weryfikacji hasla przez ustalony czas",
                "isCorrect": false
            },
            {
                "text": "ogranicza procesom dostepnosc systemu plikow",
                "isCorrect": true
            }
        ],
        "clue": 5,
        "isStarred": false,
        "explanation": "Funkcja systemowa `chroot()` jest mechanizmem systemowym, który zmienia katalog główny dla wywołującego procesu i jego potomnych. Oznacza to, że po wywołaniu `chroot()`, proces będzie widział system plików tak, jakby nowy katalog, który został podany w wywołaniu funkcji był jego korzeniem. Proces nie będzie miał dostępu do plików i katalogów znajdujących się poza tym nowym korzeniem, co tworzy tzw. \"piaskownicę\" (_ang. sandbox_). Mechanizm ten służy do ograniczenia wpływu na system potencjalnie niebezpiecznych programów, poprzez ograniczanie do jakich plików i katalogów programy mają dostęp. Funkcja ta jest często wykorzystywana w serwerach z usługą www, gdzie serwer www ma dostęp tylko do plików stron internetowych, bez dostępu do plikow systemowych. \n\n*   **\"oferuje kontrole nad komunikacja sieciowa\"** -  To nieprawda. Funkcja `chroot()` nie ma wpływu na komunikację sieciową. Ogranicza jedynie dostęp do systemu plików. Proces uwięziony w piaskownicy może komunikować się z siecią, tak jak każdy inny proces. Przykładowo, serwer WWW działający w \"chroot\" nadal może nasłuchiwać na portach TCP, nawiązywać i obsługiwać połączenia.\n*   **\"nie oferuje kontroli nad komunikacja sieciowa\"** - To jest poprawne. Jak wspomniano powyżej, `chroot()` nie ma wpływu na komunikację sieciową. Proces może nadal komunikować się z siecią, o ile ma do tego odpowiednie uprawnienia i połączenia nie są blokowane przez inny mechanizm (np. firewall).\n*   **\"jest wykorzystywana przez narzedzie sudo do zmiany aktualnych uprawnien procesu\"** - To nieprawda. Narzędzie `sudo` służy do wykonywania poleceń z uprawnieniami innego użytkownika (np. administratora), ale nie korzysta z `chroot()` do ograniczenia dostępu do systemu plików. Używa ono mechanizmów kontroli dostępu do poszczególnych poleceń, a nie modyfikuje katalogu głównego procesu.\n*   **\"sluzy do chwilowego przeniesienia administratora na wybranego uzytkownika\"** - To nieprawda. Funkcja `chroot()` nie zmienia tożsamości użytkownika procesu, tylko ogranicza jego dostęp do systemu plików. Jest to mechanizm kontroli dostępu do systemu plików a nie użytkowników. Do zmiany użytkownika wykorzystywane są np. polecenia `su`, `sudo` i mechanizmy PAM.\n*  **\"ogranicza aplikacji dostep do systemu plikow\"** - To jest poprawne. Funkcja `chroot()` została zaprojektowana specjalnie w tym celu – do ograniczenia dostępu aplikacji do plików i katalogów w systemie operacyjnym.\n*   **\"chroni system przed atakami DoS\"** - To nieprawda. `chroot()` nie chroni przed atakami DoS. Ataki DoS zazwyczaj opierają się na przeciążeniu zasobów (np. sieciowych), co `chroot()` nie adresuje. Owszem, możemy ograniczyć wpływ ataku na system plików, ale nie przed samym atakiem. Do ochrony przed atakami DoS wykorzystuje się na ogół firewalle i inne systemy ochrony przed atakami sieciowymi.\n*   **\"jest jednym z mechanizmow tworzenia piaskownicy\"** - To jest poprawne. `chroot()` jest podstawowym mechanizmem, który pozwala utworzyć piaskownicę. Polega to na tym, że proces działający w środowisku utworzonym przez chroot, nie jest w stanie wyjść z przydzielonego mu środowiska (ograniczenia systemu plików) i nie ma możliwości dostępu do zasobów spoza piaskownicy.\n*   **\"pozwala wykonac pojedyncze polecenia administracyjne administracyjne bez weryfikacji hasla\"** - To nieprawda. `chroot()` nie ma nic wspólnego z wykonywaniem pojedynczych poleceń administracyjnych bez weryfikacji hasła. Służy jedynie do ograniczenia dostępu do systemu plików. Mechanizmy pozwalające na wykonywanie poleceń administracyjnych to np. `sudo`, do których konfiguracji musimy podać hasło administratora.\n*   **\"wymaga powielania plikow niezbednych dla poprawnego dzialania aplikacji\"** - To jest poprawne. Implementacja mechanizmu `chroot()` wymaga fizycznego skopiowania wszystkich potrzebnych do działania aplikacji bibliotek i innych plików do piaskownicy. Należy pamiętać, że programy do poprawnego działania wymagają, oprócz bibliotek, plików konfiguracyjnych, które należy odpowiednio przygotować, aby program działał w piaskownicy.\n*   **\"pozwala wielokrotnie skorzystac z uprawnien administratora bez weryfikacji hasla przez ustalony czas\"** - To nieprawda. Funkcja `chroot()` nie ma nic wspólnego z wielokrotnym korzystaniem z uprawnień administracyjnych. `chroot()` ogranicza jedynie dostęp do systemu plików. Do zarządzania uprawnieniami użytkownika można wykorzystywać np. narzędzie `sudo` do którego konfiguracji należy ustalić okres ważności uprawnień.\n*  **\"ogranicza procesom dostepnosc systemu plikow\"** - To jest poprawne. Istotą `chroot()` jest ograniczenie dostępu do systemu plików i utworzenie \"piaskownicy\" dla procesu.\n\nPodsumowując, `chroot()` jest mechanizmem do tworzenia \"piaskownicy\", czyli środowiska z ograniczonym dostępem do systemu plików, przez co zwiększa się bezpieczeństwo systemu operacyjnego, na którym działa aplikacja."
    },
    {
        "questionId": 117,
        "title": "Ktore z ponizszych technologii sprzetowych umozliwiaja separacje srodowiska wykonawczego aplikacji poprzez wirtualizacje calosci badz czesci systemu operacyjnego (np. jadra systemu):",
        "answers": [
            {
                "text": "TEE (Trusted Execution Environment)",
                "isCorrect": true
            },
            {
                "text": "VBS (Virtualization-Based Security)",
                "isCorrect": true
            },
            {
                "text": "ARM TrustZone",
                "isCorrect": true
            },
            {
                "text": "SSL (Secure Socket Layer)",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Separacja środowiska wykonawczego polega na stworzeniu izolowanego środowiska, w którym aplikacja lub system operacyjny działają niezależnie od reszty systemu. Oznacza to, że awaria lub naruszenie bezpieczeństwa w takim izolowanym środowisku nie wpłynie na integralność pozostałych części systemu. Wirtualizacja to technika pozwalająca na uruchomienie wielu systemów operacyjnych lub aplikacji w odizolowany od siebie sposób. Wykorzystanie wirtualizacji do separacji środowiska wykonawczego zwiększa poziom bezpieczeństwa. Istnieją dwie koncepcje wirtualizacji: klasyczna, która opiera się o hiperwizora i uruchamianie wirtualnych maszyn na warstwie programowej oraz wirtualizacja opierająca się o wsparcie sprzętowe. Wirtualizacja z pomocą sprzętu jest dużo bardziej wydajna i ma większe możliwości, szczególnie jeśli chodzi o separację środowiska wykonawczego.\n\n**TEE (Trusted Execution Environment)** to sprzętowo-programowe środowisko wykonawcze, które oferuje bezpieczną przestrzeń do wykonywania wrażliwego kodu, niezależnie od działającego systemu operacyjnego. TEE jest zazwyczaj implementowane jako oddzielny procesor lub logiczna jednostka przetwarzania w głównym procesorze. TEE zapewnia **izolację pamięci** oraz **bezpieczny start**, co oznacza że kod uruchamiany w TEE jest chroniony przed nieautoryzowanym dostępem oraz modyfikacją. TEE jest wykorzystywane w wielu zastosowaniach, np. do przechowywania kluczy kryptograficznych lub ochrony danych biometrycznych.  Systemy TEE są powszechnie stosowane w telefonach komórkowych oraz innych urządzeniach mobilnych. Przykładem może być system **ARM TrustZone**.\n\n**VBS (Virtualization-Based Security)** to technologia firmy Microsoft wprowadzona w systemach Windows 10 i nowszych. VBS wykorzystuje funkcje wirtualizacji wspomaganej sprzętowo do stworzenia **bezpiecznego rdzenia** (_ang. secure kernel_) , w którym działają procesy odpowiedzialne za bezpieczeństwo systemu. Działanie VBS opiera się o warstwę **hypervisora**, która separuje rdzeń bezpieczeństwa od reszty systemu operacyjnego. Dzięki temu uszkodzenie rdzenia bezpieczeństwa jest o wiele trudniejsze. System VBS umożliwia również **ochronę danych poufnych**, na przykład poprzez stworzenie wirtualnego kontenera w którym przechowujemy klucze kryptograficzne.\n\n**ARM TrustZone** to technologia wirtualizacji implementowana w procesorach ARM. TrustZone dzieli system na dwie części: „secure world” oraz „normal world”. „Secure world” jest przeznaczona dla procesów odpowiedzialnych za bezpieczeństwo. System TrustZone umożliwia m.in. wykonywanie kodu systemu operacyjnego w bezpiecznym środowisku. Jest to również przykład implementacji TEE. TrustZone jest powszechnie wykorzystywana w telefonach komórkowych oraz innych urządzeniach mobilnych.\n\n**SSL (Secure Sockets Layer)** jest protokołem sieciowym, który służy do szyfrowania komunikacji pomiędzy klientem a serwerem. Protokół SSL zapewnia ochronę poufności oraz integralności przesyłanych danych. Protokół SSL nie służy do izolacji środowiska wykonawczego i nie jest technologią sprzętową. SSL wykorzystuje szyfrowanie symetryczne do szyfrowania danych oraz szyfrowanie asymetryczne do uwierzytelniania. SSL jest mechanizmem warstwy aplikacyjnej i transportowej, gdzie odbywa się faktyczne przesyłanie pakietów."
    },
    {
        "questionId": 118,
        "title": "Ktory z wymienionych protokolow chroni klienta przed przypadkiem podszywania sie pod zaufany serwer?",
        "answers": [
            {
                "text": "IPsec + PSK(Pre shared key)",
                "isCorrect": true
            },
            {
                "text": "HTTP/1.1",
                "isCorrect": false
            },
            {
                "text": "SSH",
                "isCorrect": true
            },
            {
                "text": "HTTP/1.0",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół IPsec (Internet Protocol Security) z PSK (Pre-Shared Key) wykorzystuje współdzielony tajny klucz do uwierzytelniania i szyfrowania komunikacji między dwiema stronami. Przed rozpoczęciem bezpiecznej komunikacji, obie strony muszą mieć ten sam, wcześniej ustalony klucz. Klucz ten służy do wygenerowania kluczy sesyjnych wykorzystywanych podczas szyfrowania przesyłanych danych. Chociaż dane są chronione przed podsłuchem, sam protokół IPsec z PSK nie weryfikuje autentyczności serwera za pomocą certyfikatu klucza publicznego, przez co nie chroni przed podszywaniem. Mimo wszystko, ze względu na silne szyfrowanie asymetryczne sesji, atakujący nie ma możliwości podszywania się bez znajomości klucza PSK, co powoduje, że ten mechanizm jest uważany za bezpieczny.\n\nProtokół HTTP/1.1 jest protokołem warstwy aplikacyjnej służącym do przesyłania dokumentów hipertekstowych (HTML). Sam w sobie nie zawiera żadnych mechanizmów chroniących przed podszywaniem się pod serwer. W praktyce jest stosowany z protokołem SSL/TLS jako HTTPS.\n\nProtokół SSH (Secure Shell) jest protokołem warstwy aplikacyjnej do bezpiecznego dostępu zdalnego do systemów operacyjnych. Umożliwia uwierzytelnienie serwera oraz klienta, w zależności od konfiguracji. SSH oferuje kilka metod uwierzytelniania, w tym najczęściej spotykane oparcie uwierzytelniania na hasłach lub na kluczach kryptograficznych, gdzie serwer przedstawia klientowi certyfikat klucza publicznego, który klient może zweryfikować. Ta metoda chroni klienta przed podszywaniem. Poza tym, samo szyfrowanie danych również chroni połączenie przed podsłuchem i ewentualną podmianą pakietów.\n\nProtokół HTTP/1.0 jest starszą, niebezpieczną wersją protokołu HTTP, nie posiadającą mechanizmów bezpieczeństwa. Podobnie jak HTTP/1.1 nie chroni przed podszywaniem się pod serwer.\n\nPodsumowując, tylko IPsec z PSK i SSH oferują mechanizmy kryptograficznej ochrony przed podszywaniem się pod zaufany serwer. IPsec z PSK oferuje ochronę poprzez silne szyfrowanie asymetryczne połączenia jednak nie daje ochrony przed podszywaniem opartym na weryfikacji certyfikatu. SSH natomiast chroni klienta poprzez weryfikację autentyczności serwera za pomocą certyfikatu lub klucza publicznego. Natomiast w protokołach HTTP/1.0 i HTTP/1.1 nie ma mechanizmów do tego."
    },
    {
        "questionId": 119,
        "title": "Ktory angielski termin okresla wykorzystanie do ataku znanych luk w systemie atakowanym:",
        "answers": [
            {
                "text": "exploiting",
                "isCorrect": true
            },
            {
                "text": "eavesdropping",
                "isCorrect": false
            },
            {
                "text": "masquerading",
                "isCorrect": false
            },
            {
                "text": "tampering",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "**Exploiting**, w kontekście bezpieczeństwa komputerowego, to proces wykorzystywania znanych luk bezpieczeństwa, błędów konfiguracyjnych lub słabości w oprogramowaniu lub systemie komputerowym do przeprowadzenia nieautoryzowanych działań. Luki te mogą wynikać z niedopatrzeń programistów, nieaktualnego oprogramowania lub błędnej konfiguracji systemów. Atakujący, wykorzystując exploit, czyli konkretny program lub kod, który wykorzystuje te luki, mogą uzyskać dostęp do systemu, przejąć kontrolę nad nim, kraść dane, lub zainstalować złośliwe oprogramowanie. Praktyczny przykład to wykorzystanie luki w serwerze WWW do uzyskania dostępu do plików konfiguracyjnych, które pozwolą na dalszą penetrację systemu.\n\nOpcja **eavesdropping**, czyli podsłuchiwanie, odnosi się do pasywnego przechwytywania komunikacji sieciowej w celu uzyskania nieautoryzowanego dostępu do przesyłanych danych. Atakujący nie modyfikuje danych, a jedynie je odczytuje. Przykładem jest przechwytywanie haseł lub innych wrażliwych informacji przesyłanych w sieci. Ten atak nie ma związku z wykorzystaniem luk w systemie tylko z przechwytywaniem danych.\n\n**Masquerading** czyli podszywanie się, polega na udawaniu innej, zazwyczaj zaufanej, osoby lub systemu w celu uzyskania nieautoryzowanego dostępu do zasobów lub informacji. Przykładowo, atakujący może utworzyć fałszywy serwer WWW udający popularny serwis logowania, w celu przechwycenia danych uwierzytelniających od nieświadomych użytkowników. Ten atak również nie wykorzystuje konkretnych luk w systemie a opiera się na oszustwie.\n\nOpcja **tampering**, czyli manipulacja, dotyczy nieautoryzowanej modyfikacji danych lub systemów. Celem jest naruszenie integralności systemu lub danych, np. poprzez zmianę konfiguracji, dodanie złośliwego kodu, czy modyfikację treści plików. Manipulacja nie musi od razu wykorzystywać znanych luk bezpieczeństwa, choć może do nich prowadzić lub je wykorzystywać."
    },
    {
        "questionId": 120,
        "title": "Metoda Diffiego-Hellmana:",
        "answers": [
            {
                "text": "generuje programowo hasla SSO",
                "isCorrect": false
            },
            {
                "text": "realizuje uwierzytelnianie metoda hasel jednorazowych",
                "isCorrect": false
            },
            {
                "text": "wykorzystuje idee asymetrycznej pary kluczy (prywatny - publiczny)",
                "isCorrect": true
            },
            {
                "text": "pozwala wygenerowac symetryczny klucz sesji",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Metoda Diffiego-Hellmana (DH), to algorytm wymiany kluczy, który umożliwia dwóm stronom (nawet jeśli wcześniej się nie komunikowały i nie wymieniały żadnych haseł) ustanowienie współdzielonego klucza tajnego (sekretnego) poprzez niezabezpieczony kanał komunikacyjny. Klucz ten może być potem użyty w symetrycznych algorytmach szyfrowania do bezpiecznej komunikacji. Protokół Diffiego-Hellmana nie służy bezpośrednio do szyfrowania danych, a jedynie do uzgodnienia wspólnego klucza. W protokole Diffiego-Hellmana wykorzystuje się własność jednokierunkowości pewnych operacji matematycznych (operacji na grupach skończonych), co sprawia, że poznanie wartości pośrednich podczas wymiany informacji o kluczu nie pozwala przeciwnikowi na poznanie samego klucza.\n\n**\"generuje programowo hasla SSO\"** - Jest to odpowiedź **niepoprawna**. Mechanizm Diffiego-Hellmana nie generuje haseł używanych w SSO (_Single Sign-On_). SSO to mechanizm, który umożliwia użytkownikowi jednokrotne logowanie do wielu aplikacji lub usług (autentykacja tylko raz) na przykład poprzez system operacyjny. Metoda Diffiego-Hellmana jest metodą kryptograficzną służącą do wymiany kluczy, a nie do przechowywania haseł SSO, które są generowane przez system SSO.\n\n**\"realizuje uwierzytelnianie metoda hasel jednorazowych\"** - Jest to odpowiedź **niepoprawna**. Algorytm Diffiego-Hellmana nie służy do generowania i wymiany haseł jednorazowych (OTP – _One-Time Password_). Hasła jednorazowe są generowane algorytmicznie na podstawie jakiegoś klucza (może być symetryczny) oraz licznika czasu lub zdarzeń. Mechanizm DH natomiast,  pozwala na utworzenie współdzielonego klucza sesji dla szyfrowania symetrycznego, a nie generowania haseł.\n\n**\"wykorzystuje idee asymetrycznej pary kluczy (prywatny - publiczny)\"** - Jest to odpowiedź **poprawna**. Protokół Diffiego-Hellmana nie używa asymetrycznej pary kluczy do szyfrowania tak, jak np. RSA, ale wykorzystuje publicznie dostępne parametry oraz losowo generowane wartości prywatne do utworzenia tajnego klucza, który jest  identyczny dla obu stron. Klucze asymetryczne w tym algorytmie nie służą do bezpośredniego szyfrowania wiadomości, a jedynie do utworzenia tajnego klucza. Podobnie jak w kryptografii asymetrycznej, DH operuje na koncepcji klucza publicznego i klucza prywatnego ale one nie służą tutaj bezpośrednio do szyfrowania danych, tylko do wzajemnego uzgodnienia klucza symetrycznego.\n\n**\"pozwala wygenerowac symetryczny klucz sesji\"** - Jest to odpowiedź **poprawna**. Algorytm Diffiego-Hellmana generuje właśnie symetryczny klucz, który następnie będzie wykorzystywany do szyfrowania symetrycznego. W praktyce klucz taki tworzony jest na nowo przy każdym nawiązaniu połączenia (przy każdej sesji), dlatego też jest określany mianem klucza sesji. Zastosowanie klucza symetrycznego po wymianie DH pozwala obniżyć koszty obliczeniowe, które są znacznie wyższe przy stosowaniu algorytmów asymetrycznych. Przykładowo, algorytm AES, będący algorytmem symetrycznym wykorzystywanym w protokole TLS/SSL, jest algorytmem szybszym od algorytmu RSA, będącego popularnym algorytmem kryptografii asymetrycznej."
    },
    {
        "questionId": 121,
        "title": "Ktore ataki sieciowe mozna wyeliminowac stosujac ochrone autentycznosci komunikacji?",
        "answers": [
            {
                "text": "ARP cache poisoning",
                "isCorrect": true
            },
            {
                "text": "DNS cache poisoning",
                "isCorrect": false
            },
            {
                "text": "ARP spoofing",
                "isCorrect": true
            },
            {
                "text": "DNS spoofing",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Autentyczność komunikacji, w kontekście bezpieczeństwa sieci komputerowych, odnosi się do procesu weryfikacji tożsamości komunikujących się stron. Jej celem jest upewnienie się, że dane pochodzą od deklarowanego nadawcy i nie zostały zmodyfikowane.  W przeciwieństwie do poufności, która chroni dane przed nieautoryzowanym odczytem, autentyczność chroni przed podszywaniem się i fałszowaniem informacji. \n\n**ARP cache poisoning** i **ARP spoofing** to ataki, które bezpośrednio wykorzystują brak mechanizmów autentyczności w protokole ARP (Address Resolution Protocol). ARP jest protokołem warstwy łącza danych, który służy do mapowania adresów IP na adresy MAC w sieciach lokalnych. Atak polega na wysyłaniu fałszywych odpowiedzi ARP, które mogą doprowadzić do nieprawidłowego mapowania adresów i w konsekwencji do przejęcia ruchu sieciowego przez atakującego (w przypadku ARP spoofingu, który może mieć szersze zastosowanie, w tym man in the middle) lub  przekierowania go na fałszywy adres MAC (w przypadku ARP cache poisoning, który dotyczy tylko zmiany w tablicy ARP). Zastosowanie mechanizmów autentyczności, np. kryptograficznie podpisywanych odpowiedzi ARP, uniemożliwiłoby atakującemu modyfikację wpisów w tablicy ARP. Uwierzytelnienie w protokole ARP zapewniłoby, że tylko zaufane urządzenia z sieci mogą wysyłać odpowiedzi ARP,  potwierdzające swoją tożsamość, i w ten sposób obroniłoby przed atakami typu \"man-in-the-middle\" lub atakami polegającymi na przekierowywaniu ruchu sieciowego.\n\n**DNS cache poisoning** i **DNS spoofing**, choć wykorzystują ataki związane z systemem DNS, nie są wprost powiązane z brakiem autentyczności hostów w sieci. Są to ataki, które polegają na manipulowaniu odpowiedziami DNS, celem skierowania żądań do fałszywych serwerów. DNS spoofing jest nieco szerszym pojęciem i odnosi się nie tylko do ataku na _cache_, lecz do ataku na wszelki mechanizm związany z działaniem DNS. DNS cache poisoning ma na celu zanieczyszczenie pamięci podręcznej serwerów DNS, co skutkuje przekierowaniem ruchu na złośliwe serwery. DNS spoofing polega często na podszywaniu się pod zaufany serwer DNS.  Zabezpieczenia przed tego typu atakami polegają na  weryfikacji integralności  i autentyczności danych DNS (np.  protokół DNSSEC) a nie autentyczności hostów. W praktyce, klient wysyłając zapytanie DNS do swojego serwera DNS nie weryfikuje czy serwer jest autentyczny, a bardziej czy serwer DNS przesyła wiarygodne informacje. Mechanizm uwierzytelniania hosta nie zabezpiecza zatem przed atakami DNS cache poisoning i DNS spoofing, ponieważ serwery DNS i tak wymagają od podmiotów, którym rozsyłają informację DNS o potwierdzenie ich autentyczności, poprzez podpis kluczem prywatnym powiązanym z certyfikatem ich hostów. \n\nPodsumowując, ochrona autentyczności komunikacji w kontekście tych ataków, jest kluczowa w przypadku ataków na ARP, ponieważ pozwala wyeliminować ataki oparte na braku potwierdzania wiarygodności hostów, które podają się za poprawne adresy. Natomiast ataki na DNS wymagają zabezpieczeń powiązanych z certyfikacją odpowiedzi DNS (DNSSEC). Przykładowo, jeśli serwer  pobierający adresy ze zdalnego serwera DNS weryfikowałby autentyczność serwera na podstawie jego certyfikatu i klucza prywatnego powiązanego z certyfikatem, wówczas nie byłoby możliwe wykonanie ataków opartych na podszywaniu się pod serwer DNS."
    },
    {
        "questionId": 122,
        "title": "Wskaz cechy PKI:",
        "answers": [
            {
                "text": "certyfikaty kluczy prywatnych sa skladowane w repozytoriach takich jak np. DNSsec",
                "isCorrect": false
            },
            {
                "text": "certyfikaty kluczy sa wzajemnie wystawiane przez innych uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "uniewaznienia certyfikatu klucza ma rowniez postac certyfikatu",
                "isCorrect": true
            },
            {
                "text": "do zweryfikowania certyfikatu klucza publicznego uzytkownika potrzebny jest certyfikat glownego urzedu (RootCA)",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Infrastruktura klucza publicznego (PKI) to system, który umożliwia bezpieczne zarządzanie kluczami publicznymi i certyfikatami cyfrowymi. Certyfikaty cyfrowe w PKI są dokumentami elektronicznymi, które potwierdzają tożsamość podmiotu (osoby, urządzenia, organizacji) i wiążą ją z jego kluczem publicznym. PKI to przede wszystkim hierarchiczny system zaufania oparty na zaufanych urzędach certyfikacji.\n\nPierwsza odpowiedź jest **niepoprawna**, ponieważ certyfikaty kluczy *publicznych*, a nie prywatnych, są przechowywane w repozytoriach. DNSsec (Domain Name System Security Extensions) jest rozszerzeniem protokołu DNS, które umożliwia weryfikację autentyczności odpowiedzi serwerów DNS. DNSsec, podobnie jak PKI, też może wykorzystywać certyfikaty w tym klucze publiczne, ale *nie prywatne*. DNSsec zabezpiecza integralność odpowiedzi serwerów DNS, natomiast certyfikaty w PKI zabezpieczają tożsamość i klucze publiczne podmiotów. Certyfikaty kluczy prywatnych nie są jawne. Klucze prywatne muszą pozostać tajne i są przechowywane w systemach komputerowych swoich właścicieli(użytkowników), nie zaś w publicznych repozytoriach.\n\nDruga odpowiedź jest **niepoprawna**, ponieważ w poprawnie skonfigurowanym systemie PKI certyfikaty kluczy *nie są* wystawiane przez innych użytkowników, a przez zaufane urzędy certyfikacji (CA). Użytkownicy mogą poświadczać certyfikaty, jednak ostateczną weryfikację podejmuje sam klient poprzez sprawdzenie czy certyfikat jest wystawiony przez zaufany dla niego urząd certyfikacji. PKI buduje hierarchie zaufania. Zaufanie w tym systemie jest przenoszone na inne podmioty przez urzędy certyfikacji. Bez tej hierarchi nie byłby możliwa do zrealizowania idea zaufania w sieci Internet. Gdyby każdy użytkownik mógł wystawiać sobie certyfikaty oraz tym samym decydować komu ufa to taki system nie miał by sensu.\n\nTrzecia odpowiedź jest **poprawna**, ponieważ unieważnienie certyfikatu klucza jest *również* publikowane w formie certyfikatu, a dokładniej *listy odwołanych certyfikatów* (ang. CRL, Certificate Revocation List). Unieważnienie certyfikatu nie powoduje fizycznego usunięcia wydanego certyfikatu. Urząd certyfikacji wydając certyfikat na określony okres (np. rok) poświadcza, że certyfikat użytkownika jest poprawny, jednak z różnych przyczyn (np. wyciek klucza prywatnego, rozwiązanie umowy z użytkownikiem) zachodzi konieczność unieważnienia takiego certyfikatu jeszcze przed upływem tego terminu. Ponieważ nie można cofnąć certyfikatu(fizycznie usunąć certyfikatu u klienta), urząd certyfikacji wydaje nowy certyfikat informujący o unieważnieniu poprzedniego certyfikatu. Taka lista (CRL) jest udostępniana publicznie, tak, aby wszyscy użytkownicy sieci posiadający infrastrukturę klucza publicznego mogli sprawdzać ważność certyfikatów swoich partnerów do komunikacji. Jest to kluczowy element utrzymywania zaufania w systemie PKI.\n\nCzwarta odpowiedź jest **niepoprawna**, ponieważ do zweryfikowania certyfikatu klucza publicznego użytkownika potrzebny jest certyfikat *wystawcy* tego certyfikatu, a niekoniecznie głównego urzędu certyfikacji (RootCA). Proces weryfikacji certyfikatu może być wieloetapowy. Użytkownik może weryfikować czy wystawca jego certyfikatu posiada z kolei certyfikat od innego zaufanego wystawcy, i tak dalej, aż do głównego urzędu certyfikacji (RootCA). Innymi słowy weryfikacja zależy od poprawności całego łańcucha zaufania, począwszy od weryfikowanego certyfikatu aż do zaufanego urzędu certyfikacji (RootCA). Certyfikat RootCA jest niezbędny do zweryfikowania poprawności certyfikatu innego urzędu (pośredniczącego), które w rzeczywistości wydało certyfikat dla danego użytkownika."
    },
    {
        "questionId": 123,
        "title": "Atak typu TCP spoofing wymaga:",
        "answers": [
            {
                "text": "intensywnego zalewania segmentami SYN",
                "isCorrect": false
            },
            {
                "text": "odgadniecia numeru ISN strony odbierajacej zadanie nawiazania polaczenia",
                "isCorrect": true
            },
            {
                "text": "odgadniecia numeru sekwencyjnego pierwszego segmentu strony zadajacej nawiazania polaczenia",
                "isCorrect": false
            },
            {
                "text": "zalewania zadaniami nawiazania polaczenia TCP w trybie rozgloszeniowym",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Atak typu TCP spoofing polega na podszywaniu się pod inny komputer w sieci poprzez manipulację nagłówkami pakietów TCP, tak aby wyglądały one jakby pochodziły od zaufanej strony. Najczęściej dotyczy to sytuacji, w której atakujący próbuje nawiązać połączenie z serwerem podszywając się pod zaufanego klienta lub inny serwer. Podstawą ataku TCP spoofing jest znajomość mechanizmu nawiązywania połączenia TCP (ang. _three-way handshake_) oraz znajomość numeru sekwencyjnego, który jest niezbędny do nawiązania poprawnej sesji.  \nProtokół TCP, wykorzystywany do przesyłania danych w sposób zorientowany połączeniowo, wymaga aby przed rozpoczęciem wymiany danych ustalić z wyprzedzeniem parametry tego połączenia. Realizowane jest to poprzez procedurę _three-way handshake_, w której dwie strony (klient i serwer) wymieniają między sobą trzy segmenty TCP. Klient na początku wysyła segment SYN zawierający w nagłówku flagę SYN(synchronizację), która informuje serwer, że klient chce nawiązać nowe połączenie. Dodatkowo segment ten zawiera inicjalny numer sekwencyjny (ang. Initial Sequence Number, ISN), który jest pierwszym numerem w strumieniu danych klienta i pozwala na ich uporządkowanie w kolejności w jakiej zostały wysłane. Serwer w odpowiedzi wysyła segment SYN+ACK z ustawioną flaga SYN oraz ACK(potwierdzenie) i jednocześnie przesyła swój ISN, różny od ISN klienta. Trzecim segmentem w sekwencji jest segment ACK przesyłany przez klienta do serwera, który potwierdza odebranie od serwera segmentu SYN+ACK oraz zawiera informację o poprawnym ustawieniu ISN serwera. Po tej sekwencji następuje dopiero faza przesyłania danych między stronami. \nDo ataku TCP spoofing jest konieczne odgadnięcie numeru ISN, który zostanie wysłany przez serwer, gdyż bez tego nie da się poprawnie dokończyć fazy ustanawiania połączenia z serwerem. Adres IP nadawcy w segmencie SYN jest łatwy do sfałszowania, tak aby serwer myślał, że segment SYN przyszedł od kogoś innego. Jednak aby serwer zaakceptował trzeci segment ACK i nie odrzucił połączenia, atakujący musi wiedzieć jaki ISN ma ustawić w polu potwierdzenia w tym segmencie, który musi być identyczny jak wartość ISN w segmencie SYN+ACK wysłanego wcześniej przez serwer do potencjalnej ofiary.\n\n*   **\"intensywnego zalewania segmentami SYN\"** - Ta odpowiedź jest **niepoprawna**. Zalewanie segmentami SYN jest charakterystyczne dla ataku typu SYN flood, gdzie celem jest wyczerpanie zasobów serwera poprzez dużą liczbę niedokończonych połączeń TCP. W TCP spoofing celem jest udawanie konkretnej sesji, a nie próba zablokowania zasobów.\n*   **\"odgadniecia numeru ISN strony odbierajacej zadanie nawiazania polaczenia\"** - Ta odpowiedź jest **poprawna**. Jak wyjaśniono powyżej, atakujący musi odgadnąć, a właściwie przewidzieć, ISN serwera zawarty w segmencie SYN+ACK, gdyż bez tego nie będzie w stanie poprawnie ukończyć trójstopniowego uzgadniania połączenia (_three-way handshake_) i tym samym skutecznie podszyć się pod zaufanego klienta.\n*   **\"odgadniecia numeru sekwencyjnego pierwszego segmentu strony zadajacej nawiazania polaczenia\"** - Ta odpowiedź jest **niepoprawna**. Atakujący musi ustalić numer ISN serwera, a nie klienta, gdyż to serwer jest potencjalną ofiarą ataku i to do niego jest adresowany sfałszowany segment SYN. To numer ISN serwera stanowi podstawę do zbudowania poprawnego segmentu ACK wysłanego przez klienta do serwera. Atakujący podszywa się pod klienta i musi podać odpowiedni numer ISN serwera, aby ten zaakceptował połączenie.\n*  **\"zalewania zadaniami nawiazania polaczenia TCP w trybie rozgloszeniowym\"** - Ta odpowiedź jest **niepoprawna**. Zalewanie zadaniami połączenia w trybie rozgłoszeniowym nie jest charakterystyczne dla ataku typu TCP spoofing. Ten typ ataku nie wykorzystuje rozgłaszania pakietów. Taki rodzaj zachowania jest charakterystyczny dla ataku typu Smurf, który wykorzystuje rozgłoszeniowe pakietów ICMP, a nie TCP. Atakujący nie chce ujawnić swojego położenia w sieci poprzez rozsyłanie pakietów, atak TCP spoofing następuje z jednego konkretnego adresu IP.\n\nPodsumowując, kluczowym elementem ataku TCP spoofing jest nie tylko zmiana adresu IP źródła, ale również odgadnięcie numeru ISN strony odbierającej zadanie nawiązania połączenia (serwera) w trójstopniowej procedurze uzgadniania połączenia, gdyż bez tego nie można poprawnie ustanowić połączenia i podszyć się pod zaufaną stronę."
    },
    {
        "questionId": 124,
        "title": "W protokole HTTP/2:",
        "answers": [
            {
                "text": "uwierzytelnianie klienta jest obowiazkowe",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie serwera jest opcjonalne",
                "isCorrect": true
            },
            {
                "text": "uwierzytelnianie serwera jest obowiazkowe",
                "isCorrect": false
            },
            {
                "text": "szyfrowanie calej komunikacji jest obowiazkowe",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół HTTP/2 nie wymaga obowiązkowego uwierzytelniania klienta, natomiast uwierzytelnianie serwera jest opcjonalne, a szyfrowanie całej komunikacji nie jest obligatoryjne. Uwierzytelnianie w kontekście HTTP/2 dotyczy potwierdzania tożsamości komunikujących się stron, a szyfrowanie zapewnia ochronę poufności przesyłanych danych. W HTTP/2, podobnie jak w HTTP/1.1, nie ma wbudowanego mechanizmu wymuszania uwierzytelniania serwera ani klienta, a decyzja o jego implementacji leży po stronie serwera. W praktyce, przeglądarki (klienty) zazwyczaj wymagają uwierzytelnienia serwera przez certyfikat SSL/TLS, ale jest to implementacja na poziomie przeglądarki, a nie wymóg samego protokołu HTTP/2. Podobnie, samo szyfrowanie transmisji danych również jest opcjonalne, choć w praktyce rzadko stosuje się połączenia HTTP/2 bez SSL/TLS, z powodu obaw o bezpieczeństwo przesyłanych informacji.\n\n*   **\"uwierzytelnianie klienta jest obowiazkowe\"** - To zdanie jest **niepoprawne**. Protokół HTTP/2 nie wymusza uwierzytelniania klienta. Jest to opcjonalna funkcjonalność, która może zostać zaimplementowana w zależności od potrzeb danej aplikacji lub serwera. W praktyce uwierzytelnienie klienta jest rzadziej spotykane w porównaniu z uwierzytelnieniem serwera. Przykładowo, przeglądając większość stron internetowych, nie musisz uwierzytelniać się certyfikatem.\n*   **\"uwierzytelnianie serwera jest opcjonalne\"** - To zdanie jest **poprawne**. W specyfikacji HTTP/2, serwer nie jest zobowiązany do uwierzytelnienia się przed klientem, ale w praktyce przeglądarki akceptują serwery posiadające certyfikat SSL/TLS. Jest to częsty wybór w konfiguracji serwera. W HTTP/2 serwer nie ma obowiązku przedstawienia certyfikatu, jednak dla większości użytkowników HTTP/2 jest używane w protokole HTTPS, w którym to protokole (HTTPS) serwer ma obowiązek przedstawić certyfikat, w przeciwnym razie przeglądarka poinformuje użytkownika o braku poprawnego certyfikatu.\n*   **\"uwierzytelnianie serwera jest obowiazkowe\"** - To zdanie jest **niepoprawne**. Mimo że większość serwerów korzysta z certyfikatów SSL/TLS w HTTP/2 (a konkretniej HTTPS), sam protokół HTTP/2 nie wymusza uwierzytelniania serwera. Serwer może działać bez certyfikatu, ale nie będzie on poprawnie obsługiwany przez większość przeglądarek internetowych. Uwierzytelnienie serwera jest realizowane opcjonalnie poprzez połączenie protokołu HTTP/2 z SSL/TLS.\n*   **\"szyfrowanie calej komunikacji jest obowiazkowe\"** - To zdanie jest **niepoprawne**. Szyfrowanie całej komunikacji w HTTP/2 jest opcjonalne, a nie obligatoryjne, chociaż jest silnie rekomendowane z uwagi na bezpieczeństwo. W praktyce dla większości implementacji połączeń HTTP/2 najczęściej jest realizowane połączenie szyfrowane (HTTPS) z użyciem protokołu SSL/TLS, lecz to HTTPS a nie samo HTTP/2 wymusza szyfrowanie połączenia. Zwykle połączenie HTTP/2 z szyfrowaniem jest określane mianem połączenia HTTPS."
    },
    {
        "questionId": 125,
        "title": "Ktore z ponizszych protokolow sluza realizacji kryptograficznych tuneli wirtualnych z ochrona integralnosci?",
        "answers": [
            {
                "text": "TLS",
                "isCorrect": true
            },
            {
                "text": "S/MIME",
                "isCorrect": false
            },
            {
                "text": "AH",
                "isCorrect": true
            },
            {
                "text": "ESP",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół TLS (Transport Layer Security), będący następcą protokołu SSL, jest protokołem kryptograficznym, który zapewnia zarówno poufność, jak i integralność przesyłanych danych. Działa on na warstwie transportowej modelu OSI, co oznacza, że może być wykorzystywany do zabezpieczania różnych protokołów warstwy aplikacji, takich jak HTTP (HTTPS), SMTP czy POP3. Integralność danych w TLS jest osiągana poprzez wykorzystanie funkcji skrótu kryptograficznego, która pozwala wykryć ewentualne zmiany w treści przesyłanej informacji. \n\nProtokół S/MIME (Secure/Multipurpose Internet Mail Extensions) jest standardem służącym do zabezpieczania poczty elektronicznej. Obejmuje on zarówno mechanizmy szyfrowania, zapewniając poufność wiadomości, jak i podpisywania, gwarantując integralność i autentyczność. Choć S/MIME zapewnia integralność wiadomości e-mail, nie służy on do tworzenia tuneli wirtualnych. Jego zastosowanie ogranicza się do zabezpieczenia zawartości przesyłanych wiadomości i nie chroni on transmisji między serwerami pocztowymi. \n\nProtokół AH (Authentication Header), należący do rodziny protokołów IPsec, zapewnia uwierzytelnianie i integralność przesyłanych pakietów IP. Oznacza to, że AH gwarantuje, że dane nie zostały zmienione w trakcie transmisji i że pochodzą z zaufanego źródła. Protokół AH nie zapewnia jednak poufności, czyli nie szyfruje przesyłanych danych. Jest to protokół działający na poziomie sieciowym i może być stosowany np. do ochrony połączeń VPN.\n\nProtokół ESP (Encapsulating Security Payload), również należący do rodziny protokołów IPsec, zapewnia zarówno integralność, autentyczność jak i poufność przesyłanych pakietów IP. ESP, oprócz mechanizmów wykorzystywanych w AH, dołącza dodatkowo szyfrowanie danych, zapewniając poufność przesyłanych informacji. Tak jak AH, ESP operuje na poziomie sieciowym i często jest wykorzystywany w połączeniach VPN do tworzenia bezpiecznego kanału transmisji danych.\n\nW praktyce oznacza to, że dla zabezpieczenia połączenia HTTP wykorzystamy TLS w celu zapewnienia integralności jak i poufności przesyłanych danych np przy dostępie do strony bankowej. W celu ochrony poczty elektronicznej wykorzystamy S/MIME do podpisania i zaszyfrowania listu, jednak ten protokół sam w sobie nie tworzy tunelu do bezpiecznej transmisji danych. W przypadku budowy tunelu VPN do zdalnej sieci wykorzystamy protokół IPsec (AH i/lub ESP) co nam da poufność oraz integralność przesyłanych danych między dwoma zdalnymi lokalizacjami."
    },
    {
        "questionId": 126,
        "title": "Standard IEEE 802.1X:",
        "answers": [
            {
                "text": "pozwala na wykorzystanie certyfikatów X.509 do realizacji swoich zadań",
                "isCorrect": true
            },
            {
                "text": "pozwala uwierzytelniać stanowiska sieciowe przy dostępie do sieci lokalnej",
                "isCorrect": true
            },
            {
                "text": "oferuje wymianę kluczy w sieci WiFi przy wykorzystaniu zarówno haseł jak i certyfikatów",
                "isCorrect": true
            },
            {
                "text": "umożliwia scentralizowane uwierzytelnianie wielu punktów zdalnego dostępu",
                "isCorrect": true
            },
            {
                "text": "podnosi dostępność poprzez redundantne rozproszenie danych uwierzytelniających do wielu punktów dostępowych",
                "isCorrect": false
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "IEEE 802.1X jest standardem dla kontroli dostępu do sieci opartej na portach. Działa na warstwie łącza danych i wymusza proces uwierzytelniania, zanim urządzenie uzyska pełny dostęp do sieci. W praktyce uniemożliwia to urządzeniom, które nie przeszły pomyślnie procesu uwierzytelniania, na przykład komputerom z nieznanymi użytkownikami lub urządzeniami bez poprawnej konfiguracji, uzyskanie dostępu do sieci.\n\n**Odpowiedź 1:** \"pozwala na wykorzystanie certyfikatów X.509 do realizacji swoich zadań\" jest **poprawna**. Standard IEEE 802.1X obsługuje różne protokoły uwierzytelniania, w tym EAP-TLS, który wykorzystuje certyfikaty X.509 do weryfikacji tożsamości. Certyfikaty te są ważne dla zapewnienia silnego uwierzytelniania, ponieważ potwierdzają tożsamość urządzenia, a nie tylko użytkownika. Na przykład w firmie każdy laptop może posiadać certyfikat z informacją o właścicielu (pracowniku) i w chwili dołączania do sieci w biurze następuje proces uwierzytelniania na podstawie tego certyfikatu.\n\n**Odpowiedź 2:** \"pozwala uwierzytelniać stanowiska sieciowe przy dostępie do sieci lokalnej\" jest **poprawna**. To jest podstawowa funkcja 802.1X. Standard ten jest wykorzystywany aby zweryfikować, czy stacja podłączająca się do sieci jest uprawniona do uzyskania dostępu. Przykładowo, podłączenie komputera do sieci biurowej nie spowoduje automatycznie uzyskania dostępu do zasobów sieciowych. Najpierw należy przejść pomyślnie proces uwierzytelniania. Do chwili zakończenia tego procesu dostęp do sieci jest zablokowany.\n\n**Odpowiedź 3:** \"oferuje wymianę kluczy w sieci WiFi przy wykorzystaniu zarówno haseł jak i certyfikatów\" jest **poprawna**. Chociaż 802.1X jest często kojarzony z sieciami przewodowymi, jest również szeroko stosowany w sieciach bezprzewodowych (WiFi), np. w połączeniu z protokołem EAP-TLS (wykorzystując certyfikaty X.509) lub EAP-PEAP i EAP-TTLS (bazującymi na hasłach). Wiele hotspotów WiFi (w hotelach, kawiarniach) korzysta z tego mechanizmu aby ograniczyć dostęp do sieci tylko dla uprawnionych użytkowników.\n\n**Odpowiedź 4:** \"umożliwia scentralizowane uwierzytelnianie wielu punktów zdalnego dostępu\" jest **poprawna**. Protokół 802.1X często wykorzystuje serwery RADIUS lub TACACS+ do scentralizowanego zarządzania uwierzytelnianiem. Pozwala to zarządzać wszystkimi punktami dostępowymi z jednego miejsca i zapewnia spójność zasad bezpieczeństwa.\n\n**Odpowiedź 5:** \"podnosi dostępność poprzez redundantne rozproszenie danych uwierzytelniających do wielu punktów dostępowych\" jest **niepoprawna**. 802.1X samo w sobie nie zapewnia rozproszenia danych uwierzytelniających w celu zapewnienia redundancji. Chociaż można w połączeniu z 802.1X wykorzystać kilka serwerów uwierzytelniających (np. RADIUS) dla zwiększenia dostępności, to jednak sama funkcjonalność ta nie jest zawarta w standardzie 802.1X. Redundancja jest mechanizmem, który ma za zadanie podnieść dostępność usług w przypadku wystąpienia awarii, czego 802.1X nie robi."
    },
    {
        "questionId": 127,
        "title": "Wskaz rodzaje adresow, ktore zapora sieciowa dokonujaca translacji NAT powinna filtrowac w pakietach przychodzacych od strony zewnetrznej sieci publicznej:",
        "answers": [
            {
                "text": "dowolne prywatne IP, w polu zrodlowym",
                "isCorrect": true
            },
            {
                "text": "dowolne prywatne IP, w polu docelowym",
                "isCorrect": true
            },
            {
                "text": "adresy wykorzystywane wewnatrz, w polu zrodlowym",
                "isCorrect": true
            },
            {
                "text": "adresy wykorzystywane wewnatrz, w polu docelowym",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Translacja Adresów Sieciowych (NAT) to technika, w której urządzenia sieciowe, takie jak routery, modyfikują adresy IP w nagłówkach pakietów. Ma to na celu ukrycie struktury sieci prywatnej oraz umożliwienie urządzeniom w sieci prywatnej komunikacji z Internetem, poprzez użycie ograniczonej puli adresów publicznych. Zapora sieciowa (firewall) wykorzystująca NAT, umieszczona na styku sieci prywatnej i publicznej, musi filtrować adresy IP w pakietach przychodzących z sieci zewnętrznej, aby zapobiec potencjalnym atakom i nieprawidłowemu przekierowaniu ruchu sieciowego.\n\n**Dowolne prywatne IP, w polu źródłowym:**  To odpowiedź **poprawna**. Zapora sieciowa powinna odrzucać pakiety, których źródłem są prywatne adresy IP (np. z zakresów 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16), ponieważ te adresy powinny być używane tylko wewnątrz sieci prywatnych. Jeśli taki pakiet pojawi się z zewnątrz, może świadczyć o próbie ataku typu IP spoofing. W praktyce, atakujący próbuje sfałszować adres IP źródła pakietu, aby podszyć się pod wiarygodny host wewnątrz sieci.\n\n**Dowolne prywatne IP, w polu docelowym:** To odpowiedź **poprawna**. Pakiety z prywatnymi adresami IP w polu docelowym, przychodzące z zewnętrznej sieci, oznaczają niepoprawne routowanie pakietów, lub są próbą zaadresowania pakietów do serwera sieci prywatnej. Te pakiety powinny być odrzucane gdyż nie powinny nigdy dotrzeć do firewalla. Oznacza to również, że próba ich nadania z zewnątrz powinna być traktowana jako potencjalny atak.\n\n**Adresy wykorzystywane wewnątrz, w polu źródłowym:** To odpowiedź **poprawna**. Adresy te są zdefiniowane wewnętrznie w danej sieci. W zależności od wdrożonej polityki bezpieczeństwa, takie pakiety powinny być odrzucane z uwagi na to, że nie powinny nigdy zostać wysłane z zewnętrznej sieci publicznej. Sytuacja taka podobnie jak w punkcie pierwszym jest nadużyciem pakietu IP. Zastosowanie takiej filtracji jest kluczowe, gdy adresacja wewnątrz sieci publicznej pokrywa się z adresacją sieci prywatnej. Zastosowanie tej opcji ochroni sieć przed atakiem w którym intruz będzie próbował podszyć się pod użytkownika sieci prywatnej.\nPraktyczny przykład: W firmie o adresach prywatnych z zakresu 10.0.0.0/24, jeśli na zaporę sieciową przyjdzie pakiet z adresem źródłowym 10.0.0.100,  z sieci zewnętrznej, to zapora sieciowa powinna go zablokować, gdyż taki adres źródłowy nie powinien nigdy pojawić się w ruchu sieciowym ze strony sieci publicznej.\n\n**Adresy wykorzystywane wewnątrz, w polu docelowym:** To odpowiedź **poprawna**. Podobnie jak w punkcie drugim pakiet adresowany do adresów wewnątrz sieci prywatnej nie powinien nigdy dotrzeć do firewalla ze strony sieci zewnętrznej. Sytuacja taka oznacza, że ktoś próbuje zaadresować pakiet do wewnętrznych serwerów pomijając zaporę, co stanowi poważne naruszenie polityki bezpieczeństwa.\nPraktyczny przykład: Jeżeli w sieci wewnętrznej istnieje serwer o adresie 192.168.0.10, to pakiet z tym adresem docelowym przychodzący z sieci zewnętrznej powinien być zablokowany, gdyż komunikacja z serwerem powinna być realizowana przez zaporę i jej adres publiczny.\n\nPodsumowując, zapora sieciowa implementująca NAT powinna odrzucać pakiety z nieprawidłowym adresem źródłowym i docelowym z zewnątrz, gdzie te adresy należą do przestrzeni adresowej chronionej sieci. Filtracja ma chronić przed atakami podszywania się oraz nieuprawnionym dostępem do serwerów wewnątrz sieci prywatnej."
    },
    {
        "questionId": 128,
        "title": "Do przechowywania danych uwierzytelniajacych w systemie MS Windows aplikacje moga skorzystac z:",
        "answers": [
            {
                "text": "Winlog API",
                "isCorrect": false
            },
            {
                "text": "Data Protection API (DPAPI)",
                "isCorrect": false
            },
            {
                "text": "Credential Manager API",
                "isCorrect": true
            },
            {
                "text": "Generic Security Service API (GSSAPI)",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "W systemie MS Windows, aplikacje, które wymagają przechowywania i dostępu do danych uwierzytelniających, takich jak hasła, klucze lub certyfikaty, powinny korzystać z dedykowanych interfejsów programowania aplikacji (API) w celu zapewnienia bezpieczeństwa. Jednym z kluczowych API do tego celu jest **Credential Manager API**.\n\n**Credential Manager API** to zestaw funkcji dostępnych w systemie Windows, zaprojektowanych do bezpiecznego przechowywania i pobierania danych uwierzytelniających. Aplikacje wykorzystujące ten API, mogą bezpiecznie przechowywać poświadczenia użytkowników bez konieczności bezpośredniego zarządzania danymi logowania, co zmniejsza ryzyko narażenia poufnych informacji na ataki. Mechanizm ten umożliwia zarządzanie listą poświadczeń i ich właściwościami takimi jak nazwa użytkownika, hasło, klucz publiczny. Aplikacja korzystająca z tego API, wysyła prośbę do menadżera poświadczeń o udostępnienie poświadczenia dla określonego identyfikatora. Jeżeli takie poświadczenie istnieje, menadżer poświadczeń zweryfikuje czy aktualny użytkownik ma prawo do odczytania danych i zwróci je do aplikacji. Najważniejszą cechą tego mechanizmu jest fakt, że w systemie operacyjnym nie są w ogóle przechowywane klucze szyfrujące danych logowania. Klucze do szyfrowania poświadczeń generowane są na podstawie informacji, do których ma dostęp tylko dany użytkownik i system operacyjny, w związku z tym nawet z poziomu administratora nie można odczytać danych logowania innych użytkowników.  \nNa przykład, aplikacja pocztowa może użyć Credential Manager API, aby bezpiecznie przechowywać hasła do serwerów pocztowych. Użytkownik podaje hasło tylko raz, a następnie aplikacja automatycznie pobiera je z Credential Manager API przy każdym uruchomieniu.\n\nOpcje odpowiedzi:\n*   **\"Winlog API\"** jest **nieprawidłowa**. Winlog API, to interfejs programowania do obsługi dziennika zdarzeń systemowych w systemie Windows. Jest on używany przez aplikacje, które chcą zapisywać logi związane z działaniem systemu, w tym również logi związane z działaniami użytkowników (np. logowanie, wylogowywanie itp). Nie ma on jednak możliwości bezpiecznego przechowywania haseł i innych danych uwierzytelniających. Zatem, aplikacje **nie powinny** go wykorzystywać do tego celu. Przykładowo, aplikacja monitorująca aktywność użytkowników może wykorzystać Winlog API do rejestrowania nieudanych prób logowania, ale nie wykorzysta go do przechowywania danych uwierzytelniających.\n*   **\"Data Protection API (DPAPI)\"** jest **nieprawidłowa**. DPAPI (ang. *Data Protection API*) służy do szyfrowania danych użytkownika, jednak nie jest dedykowany do przechowywania danych uwierzytelniających. DPAPI, jest bardziej ogólnego przeznaczenia i może zostać wykorzystany do szyfrowania dowolnej treści danych, które zależą od danych uwierzytelniających użytkownika, ale nie jest menadżerem danych uwierzytelniających. Przykładowo, aplikacja może wykorzystać DPAPI do szyfrowania plików użytkownika, jednak dane logowania powinien pobierać z Credential Manager API.\n*   **\"Credential Manager API\"** jest **poprawna**. Jak wyjaśniono powyżej, jest to właściwy interfejs programowania aplikacji w systemie Windows do bezpiecznego przechowywania i zarządzania informacjami uwierzytelniającymi. Jest on przeznaczony do przechowywania i udostępniania danych uwierzytelniających, w odróżnieniu od DPAPI, służącego do ochrony danych ogólnego przeznaczenia. Aplikacja bankowa powinna używać Credential Manager API, do przechowywania danych logowania do banku, a nie DPAPI, które jest bardziej uniwersalnym mechanizmem.\n*   **\"Generic Security Service API (GSSAPI)\"** jest **nieprawidłowa**. GSSAPI (ang. *Generic Security Service API*) to standard interfejsu umożliwiający aplikacjom wykorzystanie różnych mechanizmów uwierzytelniania w sieci. Najczęściej używany jest w protokołach wykorzystujących Kerberos(przykładowo w protokole SSH). Nie służy natomiast do bezpiecznego przechowywania informacji o uwierzytelnieniu, dlatego nie można go wykorzystać do tego celu. Przykładowo, klient SSH może użyć GSSAPI do uwierzytelnienia się w sieci za pomocą Kerberosa, ale dane uwierzytelniające nie są przetrzymywane przez ten API."
    },
    {
        "questionId": 129,
        "title": "Nastepujaca regula filtracji zapory sieciowej od ",
        "answers": [
            {
                "text": ".",
                "isCorrect": false
            },
            {
                "text": ".",
                "isCorrect": false
            },
            {
                "text": ".",
                "isCorrect": false
            },
            {
                "text": "do 1.1.1.1:",
                "isCorrect": false
            },
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwera www o dowolnym adresie",
                "isCorrect": false
            },
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwerem www o dowolnym adresie",
                "isCorrect": false
            },
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwerem www o adresie 1.1.1.1",
                "isCorrect": true
            },
            {
                "text": "blokuje wszelkie połączenia nawiązywane z serwera www o adresie 1.1.1.1",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Reguła zapory sieciowej, o której mowa w pytaniu, której dokładnej składni nie podano (jedynie efekt działania), służy do blokowania komunikacji w sieci, konkretnie połączeń nawiązywanych z serwerem. Zapora sieciowa, działając na zasadzie filtra, bada pakiety danych przepływające przez sieć i na podstawie zdefiniowanych reguł decyduje o ich przepuszczeniu bądź zablokowaniu. Kluczowym elementem reguły jest w tym przypadku adres źródłowy.\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwera www o adresie 1.1.1.1\"** - **PRAWIDŁOWA**\n    *   Ta odpowiedź jest poprawna, ponieważ reguła, o której mowa w zadaniu blokuje *połączenia przychodzące* z serwera www, którego adres źródłowy to 1.1.1.1. Z punktu widzenia zapory sieciowej, połączenie nawiązywane z serwera, czyli serwer jest źródłem pakietów. Reguła \"blokuje\", oznacza to, że pakiety mające taki adres źródłowy nie są przepuszczane przez zaporę. W praktyce oznacza to, że wszelkie próby inicjowania połączeń z zewnątrz do zasobów chronionych zaporą, z serwera o adresie 1.1.1.1 zostaną odrzucone. Serwer o adresie 1.1.1.1 będzie mógł nawiązywać połączenia ale nie będzie mógł odbierać połączeń nawiązanych z jego strony.\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwera www o dowolnym adresie\"** - **NIEPRAWIDŁOWA**\n    *   Ta odpowiedź jest nieprawidłowa, ponieważ reguła w pytaniu blokuje połączenia tylko z serwera o adresie 1.1.1.1. Reguła nie blokuje wszelkich połączeń nawiązywanych z serwerem www tylko te połączenia, w których serwer o adresie 1.1.1.1 jest źródłem.\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwera www o dowolnym adresie\"** - **NIEPRAWIDŁOWA**\n    *   Ta odpowiedź jest nieprawidłowa, ponieważ reguła w pytaniu blokuje połączenia tylko z serwera o adresie 1.1.1.1. Reguła nie blokuje wszelkich połączeń nawiązywanych z serwerem www tylko te połączenia, w których serwer o adresie 1.1.1.1 jest źródłem.\n\n*   **\"blokuje wszelkie połączenia nawiązywane z serwerem www o adresie 1.1.1.1\"** - **NIEPRAWIDŁOWA**\n    *   Ta odpowiedź jest nieprawidłowa, ponieważ reguła w pytaniu blokuje połączenia tylko z serwera o adresie 1.1.1.1. Reguła nie blokuje wszelkich połączeń nawiązywanych z serwerem www tylko te połączenia, w których serwer o adresie 1.1.1.1 jest źródłem.\n\n*   **\"do 1.1.1.1\"** - **NIEPRAWIDŁOWA**\n    *  Ta odpowiedź jest nieprawidłowa, gdyż brakuje kontekstu który implikuje działanie tej reguły i to jaka ma być akcja.\n\n*   **\".\"** - **NIEPRAWIDŁOWA**\n    *   Ta odpowiedź jest nieprawidłowa, gdyż brakuje kontekstu, który implikuje działanie tej reguły.\n\n*   **\".\"** - **NIEPRAWIDŁOWA**\n    *   Ta odpowiedź jest nieprawidłowa, gdyż brakuje kontekstu, który implikuje działanie tej reguły.\n\n*   **\".\"** - **NIEPRAWIDŁOWA**\n    *   Ta odpowiedź jest nieprawidłowa, gdyż brakuje kontekstu, który implikuje działanie tej reguły.\n\n**Przykład praktyczny:**\nZałóżmy, że chcemy zabezpieczyć serwer www w naszej sieci lokalnej, którego adres IP to 192.168.1.10 przed próbami ataku ze strony serwera który jest również serwerem www(np. potencjalnie przejęty serwer www). W tym celu konfigurujemy zaporę, dodając do niej regułę blokującą wszelkie próby połączenia z adresie 1.1.1.1. Takie połączenia będą odrzucane, więc nasz serwer www 192.168.1.10 nie będzie mógł odebrać pakietów wysyłanych przez serwer 1.1.1.1. Natomiast serwer o adresie 1.1.1.1 może nawiązywać połączenia do innych serwerów, ale w ten sposób nie może nawiązać połączenia z serwerem 192.168.1.10."
    },
    {
        "questionId": 130,
        "title": "Ktore operacje moga byc wykorzystywane do realizacji ataku DoS (Denial of Service):",
        "answers": [
            {
                "text": "intensywny strumien segmentow FIN z adresem docelowym ofiary",
                "isCorrect": true
            },
            {
                "text": "fragmentacja datagramu o sumarycznej wielkosci ponad 64kB",
                "isCorrect": true
            },
            {
                "text": "intensywny strumien pakietow UDP echo z adresem docelowym ofiary",
                "isCorrect": true
            },
            {
                "text": "intensywny strumien rozgloszeniowym segmentow SYN z adresem zrodlowym ofiary",
                "isCorrect": false
            },
            {
                "text": "intensywny strumien segmentow SYN z adresem docelowym ofiary",
                "isCorrect": true
            },
            {
                "text": "intensywny strumien rozgloszeniowych pakietow ICMP echo z adresem zrodlowym ofiary",
                "isCorrect": true
            },
            {
                "text": "fragmentacja datagramu o sumarycznej wielkosci ponad 16 kB",
                "isCorrect": false
            }
        ],
        "clue": 5,
        "isStarred": false,
        "explanation": "Atak typu Odmowa Usługi (DoS, Denial of Service) ma na celu uniemożliwienie dostępu do zasobów systemu, serwera lub sieci komputerowej przez uprawnionych użytkowników. Ataki te wykorzystują różne techniki, z których większość polega na przeciążeniu atakowanego systemu, przez wysłanie dużej ilości danych, w tym pakietów o specjalnych parametrach. Częstym skutkiem ataku DoS jest niemożliwość prawidłowego działania serwera, zablokowanie usługi lub w skrajnych przypadkach uszkodzenie, awaria systemu.\n\n**Intensywny strumień segmentów FIN z adresem docelowym ofiary:** Jest to **prawidłowa odpowiedź**. Segment FIN jest wykorzystywany w protokole TCP do zakończenia połączenia. Strumień wielu segmentów FIN, kierowanych do ofiary, może w efekcie przeciążyć zasoby serwera odpowiedzialne za zarządzanie połączeniami TCP, powodując odmowę usługi. Przykładem jest sytuacja, gdy atakujący wysyła wiele pakietów FIN do serwera, który nie jest w stanie zamknąć tak szybko wszystkich połączeń i w efekcie przestaje reagować na nowe pakiety.\n\n**Fragmentacja datagramu o sumarycznej wielkości ponad 64kB:** Jest to **prawidłowa odpowiedź**. Fragmentacja datagramów IP to proces dzielenia pakietu danych na mniejsze części. Atakujący może celowo stworzyć wiele fragmentów datagramu IP w taki sposób, że ich sumaryczna wielkość przekroczy dopuszczalną wartość, 64kB. Niektóre systemy operacyjne przy scalaniu tak nieprawidłowo sfragmentowanych pakietów mogą ulec awarii lub mogą zużywać dużo zasobów na ich scalanie. Zatem celowe wysłanie dużej liczby tak nieprawidłowych fragmentów może doprowadzić do przeciążenia serwera i odmowy usługi.\n\n**Intensywny strumień pakietów UDP echo z adresem docelowym ofiary:** Jest to **prawidłowa odpowiedź**. Protokoł UDP, w odróżnieniu od TCP, nie posiada mechanizmu uzgadniania połączenia, ani sprawdzania dostarczenia pakietu. Serwer, który odbiera pakiet UDP jest zobowiązany do przetworzenia go, nawet jeśli pakiet ten jest częścią ataku. Usługa UDP Echo jest z definicji bardzo prosta, odbiera dany pakiet i odsyła go z powrotem, zatem nie jest potrzebna żadna dodatkowa interpretacja treści pakietu, z tych powodów usługa ta doskonale nadaje się do ataku DoS. Intensywny strumień tych pakietów (tzw. _UDP flood_) kierowanych do ofiary zmusza ją do ciągłego wysyłania odpowiedzi i może doprowadzić do wyczerpania jej zasobów sieciowych i procesorowych. Atak taki nie wymaga wysyłania dużej ilości danych, a jedynie dużą ilość pakietów.\n\n**Intensywny strumień rozgłoszeniowym segmentów SYN z adresem źródłowym ofiary:** Jest to **nieprawidłowa odpowiedź**. Atakujący wysyłając segmenty SYN z adresem źródłowym ofiary kieruje strumień odpowiedzi do ofiary. Atakujący ma pod tym względem ograniczony zysk z takiego ataku ponieważ to ofiara ma być przeciążana a nie inni. Atakujący natomiast przy dobrze spreparowanym ataku typu SYN flood, wykorzystuje adres IP który nie istnieje w sieci, w celu wyczerpania zasobów systemu odpowiedzialnego za obsługę niepełnych połączeń TCP. W przypadku adresowania rozgłoszeniowego żaden z systemów w sieci nie wyśle odpowiedzi na adres rozgłoszeniowy, gdyż pakiety kierowane do adresów rozgłoszeniowych nie są pakietami zwrotnymi(nie zawierają adresu IP nadawcy).\n\n**Intensywny strumień segmentów SYN z adresem docelowym ofiary:** Jest to **prawidłowa odpowiedź**. Segment SYN jest wykorzystywany w protokole TCP do inicjowania połączenia. Atakujący może wysłać wiele segmentów SYN do serwera, podszywając się pod różne adresy IP. Serwer odpowiada na każdy taki segment wysyłając segment SYN/ACK. W ten sposób serwer przeznacza zasoby na obsługę nie do końca zestawionych połączeń, licząc na nadejście segmentu ACK. Jeśli atakujący wyśle bardzo dużą ilość SYN, to serwer może zostać przeciążony nie zakończonymi połączeniami. Taki atak nazywany jest atakiem SYN flood.\n\n**Intensywny strumień rozgłoszeniowych pakietów ICMP echo z adresem źródłowym ofiary:** Jest to **prawidłowa odpowiedź**. Protokół ICMP echo (_ping_) służy do testowania dostępności hostów w sieci. Polega na wysłaniu komunikatu ICMP echo i oczekiwaniu na odpowiedź ICMP echo reply. Pakiet rozgłoszeniowy ma adres docelowy który umożliwia dotarcie pakietu do wszystkich hostów w podsieci. Jeśli pakiety ICMP echo będą wysyłane na adres rozgłoszeniowy, a jako adres źródłowy będzie podany adres ofiary to spowoduje, że wszystkie komputery w danej podsieci odpowiedzą do komputera ofiary, co jest równoznaczne ze atakiem typu DoS, tzw. atak Smurf. Atakujący wysyła wiele pakietów ICMP echo z ustawionym adresem źródłowym ofiary.\n\n**Fragmentacja datagramu o sumarycznej wielkości ponad 16kB:** Jest to **nieprawidłowa odpowiedź**. Ataki bazujące na niepoprawnej fragmentacji pakietów powodujące awarie systemów bazują na pakietach o rozmiarze powyżej 64 kB.  Ataki bazujące na mniejszym rozmiarze pakietów nie są w obecnych systemach operacyjnych już tak skuteczne i raczej nie doprowadzą do awarii serwera."
    },
    {
        "questionId": 131,
        "title": "Elementem ochrony przed zlosliwym wykorzystaniem przepelnienia bufora moze byc:",
        "answers": [
            {
                "text": "remapowanie adresu 0 (dereferencja stala)",
                "isCorrect": false
            },
            {
                "text": "randomizacja przydzialu przestrzeni adresowej procesu",
                "isCorrect": true
            },
            {
                "text": "remapowanie adresu obslugi przerwania/wyjatku (dereferencja zmienna)",
                "isCorrect": false
            },
            {
                "text": "wstawienie ,,kanarka\" bezposrednio po wskazniku poprzedniej ramki",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Przepełnienie bufora (_buffer overflow_) to podatność, która powstaje gdy program zapisuje dane poza wyznaczonym obszarem pamięci - buforem. W przypadku przepełnienia bufora opartego o stos (_stack buffer overflow_) atakujący może nadpisać adres powrotu funkcji na stosie, co umożliwia mu przejęcie kontroli nad wykonywanym kodem.\n\n**Randomizacja przydziału przestrzeni adresowej procesu** (_Address Space Layout Randomization_ - ASLR) jest mechanizmem obronnym, który utrudnia wykorzystanie przepełnienia bufora poprzez losowe rozmieszczanie w pamięci kluczowych elementów przestrzeni adresowej procesu. Oznacza to, że adresy bibliotek, stosu i sterty zmieniają się przy każdym uruchomieniu procesu. W efekcie, atakujący nie jest w stanie przewidzieć, gdzie w pamięci znajdują się kluczowe dane, np. adresy funkcji wykorzystywanych podczas ataku, co utrudnia wstrzyknięcie i wykonanie złośliwego kodu. Realnym scenariuszem jest serwer działający w oparciu o system operacyjny, w którym ASLR chroni go przed wieloma próbami przejęcia kontroli przez atakującego. \n\n**Wstawienie „kanarka” bezpośrednio po wskaźniku poprzedniej ramki** polega na umieszczeniu specjalnej wartości kontrolnej (tzw. kanarka) na stosie pomiędzy buforem a adresem powrotu funkcji. Przed powrotem z funkcji sprawdzana jest wartość kanarka. W przypadku przepełnienia bufora kanarek zostaje nadpisany, a ochrona wywoła wyjątek, który nie pozwoli na poprawny powrót z funkcji, a tym samym - nie pozwoli na wykonanie złośliwego kodu wstrzykniętego do bufora. Mechanizm ten nie uniemożliwia samego przepełnienia, ale uniemożliwia jego wykorzystanie, przerywając proces z chwilą wykrycia modyfikacji kanarka. Na przykład biblioteki C++ (w systemach Linux z biblioteką glibc) z opcją `-fstack-protector-all` stosują właśnie mechanizm kanarków (ang. stack canaries). \n\n**Remapowanie adresu 0 (dereferencja stała)** nie jest skuteczną ochroną przed przepełnieniem bufora. Adres 0 to NULL. Próba dereferencji (odczytania/zapisu w pamięci wskazywanej przez) wskaźnika o wartości NULL generuje błąd dostępu do pamięci. Jednak taka sytuacja nie jest charakterystyczna tylko i wyłącznie dla przepełnienia bufora opartego o stos i nie utrudnia w żaden sposób wykonania prawidłowego ataku. Przykładowo atakujący może podać poprawną wartość adresu na stosie, a nie adres 0, tym samym obchodząc mechanizm sprawdzający adres 0.\n\n**Remapowanie adresu obsługi przerwania/wyjątku (dereferencja zmienna)** również nie jest skuteczną ochroną przeciwko przepełnieniu bufora, aczkolwiek może chronić przed wykorzystaniem bardziej zaawansowanego ataku. Atakujący może nadpisać na stosie adres powrotu, ale również, adres obsługi przerwania lub wyjątku, a następnie spróbować wymusić takie zdarzenie, co spowoduje przejście do złośliwego kodu umieszczonego w pamięci pod adresem wskazanym przez nadpisany adres obsługi przerwania. Jedynie ochrona mechanizmami takimi jak np. ASLR może utrudnić takie zaawansowane ataki."
    },
    {
        "questionId": 132,
        "title": "Wskaz cechy DNAT:",
        "answers": [
            {
                "text": "pozwala uniknac powtornego sprawdzania regul filtracji dla ruchu zweryfikowanego uprzednio",
                "isCorrect": false
            },
            {
                "text": "ukrywa rzeczywisty adres odbiorcy pakietu",
                "isCorrect": true
            },
            {
                "text": "moze byc pomyslnie wykonanie posrodku tunelu VPN tylko w trybie transportowym // w tunelowym",
                "isCorrect": false
            },
            {
                "text": "ukrywa rzeczywisty adres nadawcy pakietu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Translacja Adresów Sieciowych (ang. Network Address Translation, NAT) to technika modyfikacji adresów IP w nagłówkach pakietów danych podczas ich przesyłania przez urządzenie sieciowe, takie jak router. Wyróżniamy translację adresów źródłowych (ang. Source NAT, SNAT) i docelowych (ang. Destination NAT, DNAT). DNAT służy do ukrywania rzeczywistego adresu odbiorcy pakietu, pozwalając na przekierowanie ruchu z publicznego adresu IP na prywatny adres IP w sieci wewnętrznej.\n\n**Odpowiedź 1: \"pozwala uniknac powtornego sprawdzania regul filtracji dla ruchu zweryfikowanego uprzednio\"**\n\nTa odpowiedź jest **niepoprawna**. Opisana cecha dotyczy tzw. filtrowania pakietów kontekstowego (ang. stateful firewalling), które śledzi stan połączenia. Dzięki temu mechanizmowi zapora sieciowa pamięta, że pakiet należy do wcześniej nawiązanego połączenia i nie musi ponownie sprawdzać reguł filtracji. Natomiast DNAT dotyczy wyłącznie modyfikacji adresów, a nie optymalizacji reguł filtracji.\n\n**Odpowiedź 2: \"ukrywa rzeczywisty adres odbiorcy pakietu\"**\n\nTa odpowiedź jest **poprawna**. DNAT modyfikuje adres IP docelowy w nagłówku pakietu. Pakiet wysłany z Internetu na publiczny adres IP routera jest przekierowywany (poprzez DNAT) na serwer w sieci lokalnej, który posiada adres prywatny.  W ten sposób rzeczywisty adres serwera sieci lokalnej jest ukryty przed osobami w sieci zewnętrznej.  Przykładowo, jeśli serwer WWW w sieci lokalnej ma adres 192.168.1.100, a adres publiczny routera to 203.0.113.5, DNAT przekieruje ruch z portu 80 na adresie publicznym na port 80 na adresie 192.168.1.100, ukrywając tym samym adres serwera WWW.\n\n**Odpowiedź 3: \"moze byc pomyslnie wykonanie posrodku tunelu VPN tylko w trybie transportowym // w tunelowym\"**\n\nTa odpowiedź jest **niepoprawna**. DNAT jest procesem translacji adresów na poziomie warstwy sieciowej (modelu OSI) i nie jest specyficzny dla tuneli VPN, ani konkretnych trybów protokołu IPsec.  DNAT może być wykonywany zarówno w środowisku bez VPN, w tunelu VPN w trybie transportowym (gdzie oryginalne nagłówki IP są zachowane), jak i w tunelu VPN w trybie tunelowym (gdzie tworzony jest nowy nagłówek IP). DNAT jest niezależny od rodzaju tunelu VPN.\n\n**Odpowiedź 4: \"ukrywa rzeczywisty adres nadawcy pakietu\"**\n\nTa odpowiedź jest **niepoprawna**. Ukrywanie rzeczywistego adresu nadawcy pakietu jest charakterystyczne dla mechanizmu translacji adresów źródłowych, czyli SNAT (ang. Source NAT). SNAT zmienia adres IP źródłowy w nagłówku pakietu, dzięki czemu pakiety, które są wysyłane z sieci lokalnej posiadającej adresy prywatne (niewidoczne w Internecie) są przekształcane w pakiety posiadające publiczny adres routera oraz odpowiedni numer portu, który umożliwia odbiór odpowiedzi zwrotnej. DNAT ukrywa natomiast adres *odbiorcy*, umożliwiając przekierowanie ruchu do serwerów w sieci prywatnej."
    },
    {
        "questionId": 133,
        "title": "Wskaz cechy filtracji bezstanowej realizowanej przez zapory sieciowe:",
        "answers": [
            {
                "text": "zapora utrzymuje liste aktywnych polaczen",
                "isCorrect": false
            },
            {
                "text": "pozwala uniknac niepotrzebnego sprawdzania regul dla pakietow powracajacych w ruchu zweryfikowanym w strone przeciwna",
                "isCorrect": false
            },
            {
                "text": "dopasowuje pakiety do zapamietanej historii komunikacji",
                "isCorrect": false
            },
            {
                "text": "historia komunikacja nie ma wplywu na decyzje zapory",
                "isCorrect": true
            },
            {
                "text": "wymaga sprawdzania regul dla kazdego pakietu",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Filtrowanie bezstanowe, w kontekście zapór sieciowych, to technika analizowania pakietów sieciowych, w której każdy pakiet jest oceniany niezależnie, bez odniesienia do wcześniejszych pakietów czy stanu istniejących połączeń. Oznacza to, że zapora nie utrzymuje żadnej historii sesji czy połączeń - podejmuje decyzję na podstawie zawartości bieżącego pakietu i zdefiniowanych reguł.\n\n**Odpowiedź 1: \"zapora utrzymuje liste aktywnych polaczen\"**\nTo stwierdzenie jest **niepoprawne**, ponieważ opisuje cechę filtrowania *stanowego*, a nie bezstanowego. Zapora *stanowa* (stateful firewall) śledzi aktywne połączenia, przechowując informacje o etapach nawiązywania sesji, numerach portów i sekwencyjnych, adresach IP i innych atrybutach, pozwalając na podejmowanie decyzji na podstawie tych informacji a nie tylko pojedynczego pakietu. Przykładem jest TCP, gdzie zapora stanowa wie, czy pakiet jest częścią nawiązywania połączenia, przesyłania danych, czy zamykania sesji.\n\n**Odpowiedź 2: \"pozwala uniknac niepotrzebnego sprawdzania regul dla pakietow powracajacych w ruchu zweryfikowanym w strone przeciwna\"**\nTo stwierdzenie jest **niepoprawne**. Unikanie ponownego sprawdzania reguł dla pakietów zwrotnych to cecha zapory *stanowej*, która na podstawie zapisanej historii wie o istnieniu powiązania dwóch pakietów. Zapora bezstanowa musi analizować *każdy* pakiet z osobna.\n\n**Odpowiedź 3: \"dopasowuje pakiety do zapamietanej historii komunikacji\"**\nTo stwierdzenie jest **niepoprawne** i odnosi się do zapory *stanowej*. Zapora bezstanowa nie przechowuje żadnej historii komunikacji, a każda decyzja podejmowana jest w oderwaniu od poprzednich pakietów.\n\n**Odpowiedź 4: \"historia komunikacja nie ma wplywu na decyzje zapory\"**\nTo stwierdzenie jest **poprawne**. W filtracji bezstanowej zapora analizuje jedynie bieżący pakiet, nie biorąc pod uwagę wcześniejszych pakietów i stanu połączeń. Oznacza to, że każdy pakiet jest traktowany jako nowy i jest analizowany pod kątem zdefiniowanych reguł, bez odniesienia do historii transmisji.\n\n**Odpowiedź 5: \"wymaga sprawdzania regul dla kazdego pakietu\"**\nTo stwierdzenie jest **poprawne**. Zapora bezstanowa nie ma mechanizmu zapamiętywania nawiązanych połączeń dlatego każdy pakiet jest poddawany analizie pod kątem zdefiniowanych reguł. Reguły są sprawdzane sekwencyjnie do czasu pierwszego dopasowania.\n\n**Przykład:**\nWyobraźmy sobie prostą zaporę, która przepuszcza pakiety na port 80 (HTTP) z dowolnego miejsca, ale do hosta o adresie 192.168.1.100. Bezstanowo, zapora będzie sprawdzać każdy pakiet. Jeśli przyjdzie pakiet z portu 80 do 192.168.1.100, to zostanie przepuszczony, ale jeżeli będzie z innego portu, to zostanie zablokowany. Zapora *nie będzie pamiętać*, że ten pakiet był częścią połączenia zainicjowanego wcześniej. Bezstanowość pozwala więc na bardzo szybkie podejmowanie decyzji z punktu widzenia pojedynczego pakietu ale sprawia, że zapora nie może reagować elastycznie w sposób charakterystyczny dla zapory stanowej."
    },
    {
        "questionId": 134,
        "title": "Jakie metody uwierzytelniania oferuje protokol HTTP?",
        "answers": [
            {
                "text": "obustronne uwierzytelnianie metoda Diffiego-Hellmana",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie serwera poprzez certyfikat X.509",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie klienta poprzez username token (username + password)",
                "isCorrect": true
            },
            {
                "text": "uwierzytelnianie klienta metoda digest (z uzyciem funkcji skrotu)",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół HTTP, będący fundamentem komunikacji w Internecie, oferuje kilka mechanizmów uwierzytelniania, mających na celu weryfikację tożsamości użytkownika próbującego uzyskać dostęp do zasobów serwera.\n\n**Uwierzytelnianie klienta poprzez username token (username + password):** Jest to podstawowy mechanizm uwierzytelniania w HTTP.  Klient, chcąc uzyskać dostęp do chronionego zasobu, przesyła do serwera nagłówek `Authorization` zawierający nazwę użytkownika i hasło zakodowane w formacie Base64.  Serwer, po otrzymaniu takich danych, weryfikuje je w swojej bazie użytkowników. Przykładowo, przeglądarka internetowa, chcąc uzyskać dostęp do chronionej strony internetowej, wyświetli użytkownikowi okno dialogowe, w którym użytkownik wpisze nazwę użytkownika i hasło. Dane te zostaną przekonwertowane na format base64 i umieszczone w nagłówku HTTP. Przykładowy nagłówek żądania HTTP:  `Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=` gdzie `dXNlcm5hbWU6cGFzc3dvcmQ` jest zakodowaną w base64 postacią `username:password`. Ten mechanizm, mimo swojej prostoty, jest **niezalecany** w przypadku przesyłania poufnych danych, ponieważ hasło jest przesyłane w postaci odkodowanej przez base64, którą łatwo odszyfrować. Jest podatne na przechwycenie. \n\n**Uwierzytelnianie klienta metodą digest (z użyciem funkcji skrótu):** Jest to bardziej zaawansowany i bezpieczniejszy mechanizm uwierzytelniania niż poprzedni. Zamiast przesyłać hasło w formie zakodowanej, klient przesyła do serwera skrót (hash) hasła, oraz inne dane. Serwer na podstawie danych skrótu jest w stanie zweryfikować czy autoryzacja następuje z właściwego konta. Cały proces przebiega w kilku etapach: najpierw serwer informuje klienta o chęci uwierzytelnienia się (401 Unauthorized) i przesyła wygenerowany przez siebie identyfikator (nonce). Następnie klient przesyła swoją nazwę użytkownika, oraz skrót obliczony na podstawie hasła, identyfikatora (nonce) i innych danych. Serwer posiada skrót oryginalnego hasła i może go porównać z otrzymanym. Ten mechanizm chroni hasło przed wyciekiem z nagłówka HTTP, gdyż nie jest przesyłane w postaci jawnej. \n\n**Obustronne uwierzytelnianie metodą Diffiego-Hellmana:** Metoda Diffiego-Hellmana jest algorytmem uzgadniania kluczy, a nie metodą uwierzytelniania w HTTP.  Służy do bezpiecznego uzgodnienia klucza symetrycznego między dwoma stronami, które nie wymieniały wcześniej żadnych poufnych informacji. Ten klucz może być wykorzystany w późniejszym procesie szyfrowania, np. w protokole HTTPS (SSL/TLS). Diffie-Hellman sam w sobie nie umożliwia zweryfikowania tożsamości, jedynie uzgodnienie wspólnego sekretu. W kontekście HTTP, Diffie-Hellman nie jest protokołem uwierzytelniania, lecz mechanizmem pomocniczym który może być stosowany jako element w innych mechanizmach uwierzytelniania. \n\n**Uwierzytelnianie serwera poprzez certyfikat X.509:** Certyfikat X.509 jest używany w protokole HTTPS (SSL/TLS) do uwierzytelniania serwera, a nie w samym HTTP. Przeglądarka internetowa, łącząc się z serwerem https, w pierwszej kolejności pobiera i weryfikuje certyfikat X.509. Weryfikacja certyfikatu (w tym sprawdzenie ważności podpisu, listy CRL i ścieżki zaufania) pozwala na potwierdzenie, że serwer jest tym, za kogo się podaje. W ten sposób ochrania się przed atakiem „man in the middle”, gdzie podszywający się napastnik prezentuje fałszywy certyfikat aby podszyć się pod serwer. Certyfikat nie jest używany w mechanizmie uwierzytelniania oferowanym przez samo HTTP."
    },
    {
        "questionId": 135,
        "title": "Wskaz funkcje biblioteczne odpowiedzialne za podatnosc na atak przepelnienia bufora",
        "answers": [
            {
                "text": "strcpy()",
                "isCorrect": true
            },
            {
                "text": "strncpy()",
                "isCorrect": false
            },
            {
                "text": "execv()",
                "isCorrect": false
            },
            {
                "text": "shellcode()",
                "isCorrect": false
            },
            {
                "text": "gets()",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Przepelnienie bufora to luka bezpieczeństwa, która występuje, gdy program zapisuje dane poza przydzielony bufor pamięci, nadpisując sąsiadujące obszary. Może to prowadzić do uszkodzenia danych, awarii programu, a nawet przejęcia kontroli nad systemem przez intruza, jeśli nadpisze on adresy powrotu funkcji w stosie. Funkcje, które nie sprawdzają długości wprowadzanych danych, są szczególnie podatne na ten rodzaj ataku.\n\n`strcpy()` – jest to funkcja biblioteczna języka C, służąca do kopiowania łańcucha znaków z jednego miejsca w pamięci do drugiego. Funkcja ta, nie sprawdza, czy docelowy bufor jest wystarczająco duży, aby pomieścić kopiowany łańcuch. Dlatego też, jeśli źródłowy łańcuch jest większy niż rozmiar docelowego bufora, funkcja `strcpy()` nadpisze kolejne obszary pamięci, prowadząc do przepełnienia bufora. Przykładowo, jeśli bufor ma 10 bajtów, a `strcpy()` skopiuje do niego 20 bajtowy łańcuch, to 10 bajtów nadpisze dane w pamięci przylegającej do bufora. Ta podatność sprawia, że `strcpy()` jest często wykorzystywana przez atakujących w exploitach, by nadpisać w pamięci adresy powrotu funkcji, tym samym powodując wykonanie dowolnego kodu. **Dlatego ta odpowiedź jest poprawna.**\n\n`strncpy()` – to funkcja z biblioteki C, która podobnie jak `strcpy()` służy do kopiowania łańcuchów znaków, ale różnica między nimi polega na tym, że `strncpy()` dodatkowo przyjmuje jako argument maksymalną liczbę znaków do skopiowania. Ta dodatkowa informacja umożliwia na zabezpieczenie się przed przepełnieniem bufora. W tym wypadku programista ma możliwość samodzielnie określić jak dużo pamięci ma być przeznaczone na dany łańcuch znaków. Poprawnie używana funkcja `strncpy()` nie prowadzi do przepełnienia bufora, dlatego **ta odpowiedź jest niepoprawna.**\n\n`execv()` – to funkcja biblioteczna języka C, służąca do wykonywania programu, którego ścieżka dostępu jest przekazana jako argument funkcji. Nie ma bezpośredniego związku z przepełnieniem bufora, choć może być wykorzystana w exploitach. `execv()` sama w sobie nie tworzy warunków do powstania przepełnienia bufora, dlatego **ta odpowiedź jest niepoprawna.**\n\n`shellcode()` – nie jest to standardowa funkcja biblioteczna, lecz nazwa na fragment programu wykonywalnego napisanego zazwyczaj w asemblerze, który ma za zadanie stworzenie powłoki systemu operacyjnego. Shellcode to w istocie złośliwy kod, stanowiący ładunek, często umieszczany w obszarze pamięci, w której wcześniej doszło do przepełnienia bufora, aby go wykonać. `shellcode()` nie jest funkcją biblioteczną, a koncepcją wykorzystywaną w atakach, dlatego **ta odpowiedź jest niepoprawna.**\n\n`gets()` – to funkcja biblioteczna języka C, która odczytuje linię znaków ze standardowego wejścia. Funkcja `gets()` podobnie jak `strcpy()` nie posiada żadnych mechanizmów kontroli rozmiaru bufora docelowego i jest bardzo podatna na przepełnienie bufora, bo gdy użytkownik poda za dużo danych, to `gets()` zapisze je w pamięci poza buforem. Funkcja `gets()` jest tak niebezpieczna, że jej używanie jest w obecnej chwili wysoce nie rekomendowane. **Dlatego ta odpowiedź jest poprawna.**\n\nPodsumowując, funkcje `strcpy()` i `gets()` są szczególnie niebezpieczne z punktu widzenia bezpieczeństwa, ponieważ pozwalają na łatwe spowodowanie przepełnienia bufora przez nadpisanie pamięci, a przez to umożliwienie intruzowi wykonanie złośliwego kodu, lub chociażby do spowodowania nie prawidłowego działania programu. Z kolei `strncpy()` jest bezpieczniejsza, gdy jej argument określający długość docelowego bufora jest w prawidłowy sposób obsługiwany przez programistę, a `execv` jest po prostu funkcją systemową i nie ma związku z przepełnieniem bufora. `shellcode` nie jest funkcją, tylko złośliwym kodem."
    },
    {
        "questionId": 136,
        "title": "Niezaprzeczalnosc to wlasnosc potwierdzajaca iz:",
        "answers": [
            {
                "text": "odbiorca wiadomosci nie sfalszowal jej tresci po odebraniu",
                "isCorrect": false
            },
            {
                "text": "nadawca wiadomosci jest rzeczywiscie tym za kogo sie podaje",
                "isCorrect": false
            },
            {
                "text": "nadawca wiadomosci faktycznie ja wyslal",
                "isCorrect": true
            },
            {
                "text": "doszlo do ataku aktywnego MiM",
                "isCorrect": false
            },
            {
                "text": "odbiorca wiadomosci faktycznie ja odebral",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Niezaprzeczalność (_ang. non-repudiation_) to właściwość systemu bezpieczeństwa, która uniemożliwia nadawcy wiadomości wyparcie się faktu wysłania tej wiadomości lub odbiorcy wyparcie się faktu otrzymania tej wiadomości. Celem niezaprzeczalności jest zapewnienie wiarygodnego dowodu, że dana akcja (wysłanie lub otrzymanie wiadomości) miała miejsce i z pewnością została wykonana przez daną stronę (nadawcę lub odbiorcę). Niezaprzeczalność zapewnia integralność danych, a pośrednio również ich poufność.\n\n**Pierwsza odpowiedź: \"odbiorca wiadomosci nie sfalszowal jej tresci po odebraniu\" jest niepoprawna**, ponieważ opisuje integralność danych, a nie niezaprzeczalność. Integralność danych oznacza, że wiadomość nie została zmodyfikowana w trakcie transmisji. Choć powiązane, integralność różni się od niezaprzeczalności. Integralność można osiągnąć przy pomocy skrótów kryptograficznych oraz sum kontrolnych. \n\n**Druga odpowiedź: \"nadawca wiadomosci jest rzeczywiscie tym za kogo sie podaje\" jest niepoprawna**, gdyż opisuje uwierzytelnianie (autentyczność) a nie niezaprzeczalność. Uwierzytelnianie potwierdza tożsamość nadawcy, ale nie wyklucza możliwości, że ten nadawca później zaprzeczy wysłaniu wiadomości. Do uwierzytelnienia można wykorzystać hasła i klucze kryptograficzne. \n\n**Trzecia odpowiedź: \"nadawca wiadomosci faktycznie ja wyslal\" jest poprawna**, ponieważ stanowi definicję niezaprzeczalności. Mechanizmy niezaprzeczalności zapobiegają sytuacji, w której nadawca może twierdzić, że nigdy nie wysłał danej wiadomości. W praktyce osiąga się to poprzez zastosowanie podpisów cyfrowych. Wykorzystując asymetryczny algorytm kryptograficzny, nadawca szyfruje wiadomość swoim kluczem prywatnym, co jest dowodem wysłania wiadomości.\n\n**Czwarta odpowiedź: \"doszlo do ataku aktywnego MiM\" jest niepoprawna**, ponieważ  odnosi się do _Man-in-the-Middle_ ataku. MiM to atak, w którym osoba trzecia przechwytuje i potencjalnie modyfikuje przesyłane dane. Atak ten nie jest bezpośrednio związany z niezaprzeczalnością. MiM narusza integralność i poufność danych. \n\n**Piąta odpowiedź: \"odbiorca wiadomosci faktycznie ja odebral\" jest poprawna**, bo również wchodzi w zakres niezaprzeczalności. Mechanizmy niezaprzeczalności uniemożliwiają odbiorcy twierdzić, że nigdy nie otrzymał danej wiadomości. Podobnie jak w przypadku nadawcy, wykorzystuje się tu potwierdzenie otrzymania wiadomości za pomocą podpisu cyfrowego. Odbiorca po otrzymaniu wiadomości, generuje podpis cyfrowy i wysyła go do nadawcy, jako potwierdzenie, że wiadomość faktycznie dotarła.\n\nPodsumowując, niezaprzeczalność to nie tylko potwierdzenie tożsamości nadawcy (autentyczność) czy nienaruszalności danych (integralność), lecz także ochrona przed tym, aby strony komunikacji nie mogły wyprzeć się udziału w niej. Niezaprzeczalność jest szczególnie ważna w sytuacjach, gdzie istotne są dowody wykonania akcji, np. transakcje finansowe czy umowy prawne. Do osiągnięcia niezaprzeczalności wykorzystuje się mechanizmy podpisu cyfrowego."
    },
    {
        "questionId": 137,
        "title": "Termin two-factor authentication (2FA) dotyczy:",
        "answers": [
            {
                "text": "procesu potwierdzania tozsamosci przy uzyciu dwoch oddzielnych procedur lub skladnikow sprzetowych",
                "isCorrect": true
            },
            {
                "text": "uzycia w protokole HTTP/2 obustronnego uwierzytelniania",
                "isCorrect": false
            },
            {
                "text": "wykorzystania do kontroli integralnosci danych algorytmow kryptografii asymetrycznej bazujacych na zlozonosci rozkladu duzych liczb na czynniki (faktoryzacji)",
                "isCorrect": false
            },
            {
                "text": "uwierzytelniania metoda zawolanie-odzew",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Two-factor authentication (2FA), znane również jako uwierzytelnianie dwuskładnikowe, to metoda weryfikacji tożsamości użytkownika, która wymaga użycia dwóch różnych i niezależnych od siebie czynników. Czynniki te należą do różnych kategorii, które tradycyjnie dzielimy na: „coś, co wiesz” (np. hasło, PIN), „coś, co masz” (np. karta chipowa, token sprzętowy, telefon komórkowy), oraz „coś, czym jesteś” (np. cechy biometryczne). 2FA ma na celu zwiększenie bezpieczeństwa konta poprzez utrudnienie dostępu nieuprawnionym osobom, nawet jeśli zdobędą one hasło użytkownika.\n\n*   **\"procesu potwierdzania tozsamosci przy uzyciu dwoch oddzielnych procedur lub skladnikow sprzetowych\"** - **Prawidłowa odpowiedź**. Ta definicja wprost opisuje istotę 2FA. Użytkownik musi przedstawić dowód tożsamości z dwóch różnych kategorii, na przykład hasło (coś, co wiesz) i kod SMS (coś, co masz), aby uzyskać dostęp do konta. Przykładowo, logując się do banku internetowego, możemy być poproszeni o podanie hasła, a następnie kodu przesłanego na nasz telefon. Oba te kroki są konieczne, aby proces uwierzytelniania był kompletny.\n\n*   **\"uzycia w protokole HTTP/2 obustronnego uwierzytelniania\"** - **Nieprawidłowa odpowiedź.** Obustronne uwierzytelnianie (mutual authentication) w HTTP/2, choć podnosi bezpieczeństwo, to nie jest tożsame z 2FA. Obustronne uwierzytelnianie oznacza, że zarówno klient, jak i serwer muszą nawzajem potwierdzić swoją tożsamość, często za pomocą certyfikatów. Jest to pojedynczy, choć wzajemny, proces uwierzytelnienia, a nie uwierzytelnienie wykorzystujące dwa różne czynniki. Przykładowo, systemy korporacyjne mogą wymagać uwierzytelniania certyfikatem serwera i użytkownika, ale nadal może być to jednofaktorowe uwierzytelnienie.\n\n*   **\"wykorzystania do kontroli integralnosci danych algorytmow kryptografii asymetrycznej bazujacych na zlozonosci rozkladu duzych liczb na czynniki (faktoryzacji)\"** - **Nieprawidłowa odpowiedź.** Ta opcja opisuje mechanizm kontroli integralności danych (zapewniający, że dane nie zostały zmienione) za pomocą kryptografii asymetrycznej, takiej jak algorytm RSA. Ten mechanizm używany jest np. w podpisie cyfrowym, który pozwala weryfikować integralność i autentyczność dokumentu, ale nie ma związku z samą ideą dwuskładnikowego uwierzytelniania. Przykładem jest podpis elektroniczny który pozwala stwierdzić, że wysłany email nie został zmieniony w trakcie transferu, ale nie służy do weryfikowania tożsamości użytkownika.\n\n*   **\"uwierzytelniania metoda zawolanie-odzew\"** - **Nieprawidłowa odpowiedź.** Metoda \"zawołanie-odzew\" (challenge-response) jest sposobem uwierzytelniania, w którym serwer wysyła losowe wyzwanie do klienta, a klient odpowiada, używając do tego jakiejś formy klucza, hasła, lub innego \"sekretu\". Takie uwierzytelnianie chroni przed niektórymi atakami, jednak wciąż bazuje tylko na jednym czynniku, zazwyczaj \"coś co wiesz\" i nie jest tożsame z 2FA, które wymaga niezależnych od siebie czynników. Przykładowo, protokół CHAP używa tego mechanizmu, gdzie serwer wysyła losowy ciąg, a klient szyfruje go i odsyła, jednak sam CHAP nie jest przykładem 2FA."
    },
    {
        "questionId": 138,
        "title": "Wskaż cechy poprawnie opisujące DNSsec:",
        "answers": [
            {
                "text": "umożliwia przechowywanie kluczy publicznych podmiotów z domeny",
                "isCorrect": true
            },
            {
                "text": "stosuje kryptografię asymetryczną do podpisywania rekordów",
                "isCorrect": true
            },
            {
                "text": "przesyła zapytania i odpowiedzi w tunelu IPsec",
                "isCorrect": false
            },
            {
                "text": "stosuje kryptografię symetryczna do szyfrowania rekordów",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "DNSSEC (Domain Name System Security Extensions) rozszerza standardowy protokół DNS (Domain Name System) o mechanizmy kryptograficzne. Celem DNSSEC jest ochrona integralności i autentyczności danych DNS, nie zapewnia poufności, czyli nie szyfruje transferu zapytań i odpowiedzi. DNSSEC wykorzystuje kryptografię asymetryczną, aby umożliwić weryfikację autentyczności danych DNS. Oznacza to, że wykorzystywane są pary kluczy - publiczny i prywatny. Właściciel domeny publikuje swój klucz publiczny w specjalnym rekordzie DNS, natomiast kluczem prywatnym podpisuje inne rekordy związane z daną domeną. Klient DNS, który korzysta z DNSSEC jest w stanie zweryfikować, czy otrzymane dane DNS (np. adres IP powiązany z nazwą domeny) pochodzą z zaufanego źródła i nie zostały zmienione.\n\n*   **\"umożliwia przechowywanie kluczy publicznych podmiotów z domeny\"** Jest to **poprawna** odpowiedź. DNSSEC wykorzystuje rozszerzone rekordy DNS do przechowywania kluczy publicznych należących do danej domeny i jej poddomen. Te klucze publiczne są używane do weryfikacji podpisów cyfrowych w innych rekordach DNS. Na przykład, rekord DNSKEY zawiera klucz publiczny domeny, co pozwala weryfikować podpisy cyfrowe w rekordach tej domeny.\n\n*   **\"stosuje kryptografię asymetryczną do podpisywania rekordów\"** Jest to **poprawna** odpowiedź. DNSSEC używa kryptografii asymetrycznej do zapewnienia autentyczności i integralności rekordów. Rekordy są podpisywane kluczem prywatnym domeny i weryfikowane z użyciem klucza publicznego tej domeny. Podpis cyfrowy pozwala upewnić się, że rekord DNS nie został zmieniony przez nieautoryzowaną osobę w trakcie jego przesyłania. Przykładem mogą być rekordy RRSIG, które zawierają podpisy cyfrowe rekordów DNS.\n\n*   **\"przesyła zapytania i odpowiedzi w tunelu IPsec\"** Jest to **niepoprawna** odpowiedź. DNSSEC nie wykorzystuje protokołu IPsec. DNSSEC rozszerza protokół DNS o mechanizmy kryptograficzne, które zapewniają integralność i autentyczność danych. Nie ukrywa on jednak treści zapytań i odpowiedzi. IPsec jest protokołem warstwy sieciowej zapewniającym poufność i integralność transmisji pakietów IP poprzez tunelowanie, ale nie jest on używany w DNSSEC. DNSSEC działa na poziomie aplikacji.\n\n*   **\"stosuje kryptografię symetryczna do szyfrowania rekordów\"** Jest to **niepoprawna** odpowiedź. DNSSEC wykorzystuje kryptografię asymetryczną, a nie symetryczną. Kryptografia symetryczna, w której ten sam klucz jest używany do szyfrowania i deszyfrowania, jest szybsza, ale ma problem z dystrybucją klucza, ponieważ trzeba go bezpiecznie przekazać drugiej stronie. DNSSEC potrzebuje klucza prywatnego i publicznego by móc podpisywać i weryfikować te podpisy, kryptografia symetryczna nie posiada tego mechanizmu."
    },
    {
        "questionId": 139,
        "title": "Klucze w szyfrowaniu symetrycznym:",
        "answers": [
            {
                "text": "moga byc publicznie dostepne pod warunkiem certyfikacji",
                "isCorrect": false
            },
            {
                "text": "zapewniaja autentycznosc i niezaprzeczalnosc pod warunkiem zachowania tajnosci klucza",
                "isCorrect": false
            },
            {
                "text": "zawsze powinny byc znane tylko komunikujacym sie stronom",
                "isCorrect": true
            },
            {
                "text": "wymagaja losowego wyboru duzych liczb pierwszych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie symetryczne to metoda szyfrowania, w której ten sam klucz jest używany zarówno do szyfrowania, jak i deszyfrowania danych. Klucz ten jest określany mianem tajnego klucza. Z uwagi, że do szyfrowania i deszyfrowania używamy tego samego klucza musi on być znany i tajny jedynie dla obu stron komunikacji. Celem tej metody jest ochrona poufności przesyłanych danych i utajnienie ich przed niepowołanym dostępem. Skuteczność szyfrowania symetrycznego w dużej mierze zależy od długości klucza oraz tajności tego klucza.\n\n**Odpowiedź a** jest niepoprawna ponieważ klucze w szyfrowaniu symetrycznym *nie* mogą być publicznie dostępne. Klucz symetryczny musi być znany tylko stronom komunikującym się, w przeciwnym razie cała komunikacja jest niebezpieczna. Mechanizmy certyfikacji są związane z kluczami publicznymi szyfrowania asymetrycznego, gdzie klucz publiczny jest udostępniany, a prywatny musi pozostać tajny.\n\n**Odpowiedź b** jest niepoprawna, ponieważ szyfrowanie symetryczne *nie* zapewnia autentyczności i niezaprzeczalności, nawet jeśli klucz jest utrzymany w tajemnicy. Klucz symetryczny jest współdzielony między komunikującymi się stronami, więc nie można jednoznacznie stwierdzić, która z nich jest nadawcą wiadomości. Autentyczność i niezaprzeczalność jest funkcjonalnością szyfrowania asymetrycznego, w którym strona posługuje się kluczem prywatnym do podpisu a kluczem publicznym innej strony do szyfrowania komunikacji.\n\n**Odpowiedź c** jest poprawna. Klucze w szyfrowaniu symetrycznym muszą być znane tylko i wyłącznie komunikującym się stronom. W przeciwnym wypadku osoba trzecia będzie w stanie odszyfrować przesyłane dane. Przykładem użycia szyfrowania symetrycznego jest szyfrowanie tuneli VPN z wykorzystaniem algorytmu blowfish. W przypadku, gdyby klucz, którym szyfrowany jest tunel VPN, został ujawniony osobom trzecim, to cała komunikacja w obrębie sieci VPN byłaby niebezpieczna. \n\n**Odpowiedź d** jest niepoprawna, ponieważ losowy wybór dużych liczb pierwszych jest związany z generacją kluczy asymetrycznych, np. RSA, a *nie* symetrycznych. Klucze symetryczne są na ogół generowane pseudolosowo jako ciągi bitów o odpowiedniej długości (np. 128, 256). Choć kryptograficznie silny generator liczb pseudolosowych jest oczywiście istotny, to nie ma to bezpośredniego związku z użyciem liczb pierwszych. Przykładem może być algorytm AES, który wykorzystuje klucze symetryczne."
    },
    {
        "questionId": 140,
        "title": "Ktore z ponizszych protokolow sluza realizacji kryptograficznych tuneli wirtualnych:",
        "answers": [
            {
                "text": "TLS",
                "isCorrect": true
            },
            {
                "text": "LDAP",
                "isCorrect": false
            },
            {
                "text": "X.400",
                "isCorrect": false
            },
            {
                "text": "L2TP",
                "isCorrect": false
            },
            {
                "text": "IPsec",
                "isCorrect": true
            },
            {
                "text": "SSL",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół kryptograficznego tunelowania tworzy bezpieczny, zaszyfrowany kanał komunikacyjny między dwoma punktami w sieci, umożliwiając poufną i integralną transmisję danych. W praktyce, umożliwia to tworzenie wirtualnych sieci prywatnych (VPN). Wykorzystuje się w tym celu techniki kryptograficzne, aby zapewnić, że dane są chronione przed nieautoryzowanym dostępem i modyfikacją podczas przesyłania przez potencjalnie niezaufane sieci, takie jak Internet.\n\n**TLS (Transport Layer Security)**, a właściwie jego poprzednik SSL (Secure Sockets Layer), to protokół kryptograficzny, który zapewnia bezpieczne połączenie w warstwie transportowej, czyli powyżej protokołów takich jak TCP i UDP. Jest najczęściej stosowany do ochrony komunikacji w przeglądarkach internetowych (HTTPS) lub w programach poczty elektronicznej, gdzie kluczowe jest poufność przesyłanych danych. SSL/TLS wykorzystuje algorytmy szyfrowania symetrycznego do szyfrowania przesyłanych danych i algorytmy kryptografii asymetrycznej do wymiany kluczy szyfrowania i uwierzytelniania stron. Oznacza to, że dane są szyfrowane w locie przed ich wysłaniem i deszyfrowane po ich otrzymaniu. Uwierzytelnianie najczęściej odbywa się poprzez weryfikację certyfikatu cyfrowego serwera, który potwierdza jego tożsamość.\n\n**LDAP (Lightweight Directory Access Protocol)** to protokół warstwy aplikacyjnej używany do zarządzania informacjami o użytkownikach i zasobach w katalogach. Jest wykorzystywany do dostępu do informacji o użytkownikach, ale nie jest protokołem tunelującym i nie zapewnia sam w sobie szyfrowanej komunikacji, dlatego odpowiedź ta jest niepoprawna. LDAP często używany jest w połączeniu z innymi mechanizmami bezpieczeństwa, ale nie jest on odpowiedzialny za tworzenie szyfrowanego kanału wymiany danych.\n\n**X.400** to historyczny standard przesyłania wiadomości, w tym poczty elektronicznej. Był popularny w latach 80 i 90 ale nie zapewnia kryptograficznego tunelowania, dlatego nie jest to poprawna odpowiedź. Podobnie jak LDAP nie ma wbudowanych mechanizmów szyfrowania, tylko jest wykorzystywany do przesyłania wiadomości.\n\n**L2TP (Layer Two Tunneling Protocol)** jest protokołem tunelowania warstwy łącza danych. Sam w sobie nie zapewnia on szyfrowania ani ochrony danych, ale często używany jest w połączeniu z IPsec (Layer 3), aby stworzyć w pełni bezpieczny tunel. Sam protokół L2TP jedynie umożliwia tunelowanie i nie ma funkcji kryptograficznych, dlatego ta odpowiedź jest niepoprawna.\n\n**IPsec (Internet Protocol Security)** jest zbiorem protokołów zapewniających bezpieczeństwo w warstwie sieciowej (IP). IPsec oferuje mechanizmy szyfrowania i uwierzytelniania każdego pakietu IP, co daje kompleksową ochronę komunikacji. Protokół IPsec stosuje algorytmy kryptografii symetrycznej do szyfrowania przesyłanych danych, a algorytmy kryptografii asymetrycznej do wymiany kluczy szyfrowania i uwierzytelniania stron. Dzięki temu, że IPsec jest protokołem działającym w warstwie sieciowej, może być używany do ochrony dowolnych protokołów transportowych i aplikacyjnych. Najczęściej stosowany jest do budowy sieci VPN typu site-to-site gdzie wymagane jest szyfrowanie przesyłanych danych i ukrycie adresów sieci wewnętrznych przed niepowołanym okiem.\n\n**SSL (Secure Sockets Layer)**, jak wspomniano wcześniej, to protokół kryptograficzny, który zapewnia bezpieczne połączenie, wykorzystywany m.in. w HTTPS. Choć technicznie nieco starszy niż TLS, oba terminy są często używane zamiennie, a TLS jest jego następną generacją. SSL tworzy tunel kryptograficzny dla protokołów warstwy aplikacji, co pozwala przesyłać dane w sposób poufny i integralny oraz uwierzytelnić serwer przed klientem. Umożliwia stworzenie logicznego szyfrowanego kanału wymiany danych między dwiema aplikacjami. Typowe zastosowanie to przeglądanie bezpiecznych stron www (protokół HTTPS)."
    },
    {
        "questionId": 141,
        "title": "Mechanizm ochrony antyspamowej o nazwie ,,szare listy\" opera sie na:",
        "answers": [
            {
                "text": "automatycznym weryfikowaniu listy zabronionych adresow nadawcow przez MTA",
                "isCorrect": false
            },
            {
                "text": "odeslaniu komunikatu SMTP o czasowej niedostepnosci uslugi",
                "isCorrect": true
            },
            {
                "text": "analizie heurystycznej naglowka SMTP przez MUA",
                "isCorrect": false
            },
            {
                "text": "dynamicznym weryfikowaniu listy podejrzanych adresow nadawcow przez uzytkownika",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Technika \"szare listy\" (greylisting) jest metodą walki ze spamem wykorzystującą cechy protokołu SMTP (Simple Mail Transfer Protocol), który jest wykorzystywany przy przesyłaniu poczty elektronicznej. Protokołem tym posługują się serwery poczty elektronicznej MTA (Mail Transfer Agent), a nie klienci poczty MUA (Mail User Agent). Mechanizm ten polega na czasowym odrzuceniu połączenia od nieznanego nadawcy.\n\n**Mechanizm „szarych list” działa następująco:**\nGdy serwer poczty MTA (odbierający) otrzymuje połączenie od serwera poczty MTA (nadającego) z którym wcześniej nie miał do czynienia lub od nieznanego nadawcy, wysyła do nadawcy kod 452 oznaczający: \"czasowa niedostępność\". Prawidłowo działający serwer poczty elektronicznej (MTA) odczekuje pewien okres czasu i ponawia transmisje. Serwery, z których jest przesyłany spam, w przeważającej większości nie ponawiają transmisji. Dzięki tej właściwości \"szare listy\" pozwalają na eliminowanie z poczty potencjalnego SPAMu. \n\n*   **\"automatycznym weryfikowaniu listy zabronionych adresow nadawcow przez MTA\"** - Ta odpowiedź opisuje mechanizm wykorzystujący tzw. czarne listy(ang. blacklist), które wykorzystują adresy znanych spamowych serwerów. Mechanizm ten polega na sprawdzeniu adresu nadawcy i porównaniu go z listą adresów znanych nadawców spamu, jeśli adres znajduje się na czarnej liście, serwer poczty elektronicznej odbiera od razu połączenie i odrzuca wiadomość. Jest to inna metoda niż \"szare listy\" i w praktyce często jest stosowana jako uzupełnienie dla \"szarych list\".\n\n*   **\"odeslaniu komunikatu SMTP o czasowej niedostepnosci uslugi\"** - Ta odpowiedź jest **poprawna**.  Istotą \"szarych list\" jest wysyłanie kodu błędu 452 \"czasowa niedostępność\", który jest tymczasowy i informuje nadawcę o chwilowej niemożności dostarczenia poczty. Prawidłowo działający serwer MTA ponownie spróbuje dostarczyć wiadomość po upływie pewnego okresu czasu. Spamer z reguły nie przesyła ponownie tej samej wiadomości, dlatego mechanizm \"szarych list\" pozwala na eliminację spamu.\n\n*   **\"analizie heurystycznej naglowka SMTP przez MUA\"** - Analiza heurystyczna nagłówka SMTP, to metoda, w której specjalnie przygotowane moduły potrafią znaleźć w nagłówku cechy wspólne dla wiadomości spamowych.  Zazwyczaj analiza taka nie jest wykonywana na poziomie serwera MTA a na poziomie klienta pocztowego MUA. Jest to więc poprawna, ale inna technika walki ze spamem, a nie „szare listy”.\n\n*   **\"dynamicznym weryfikowaniu listy podejrzanych adresow nadawcow przez uzytkownika\"** - Ta odpowiedź opisuje mechanizm wykorzystujący dane o podejrzanych nadawcach, które to dane są podawane przez użytkownika. W ten sposób tworzy się listę adresów z których poczta powinna być odrzucana na podstawie działań podejmowanych przez użytkownika (np. poprzez zgłaszanie wiadomości jako spam). Jest to kolejna z wielu technik walki ze spamem, ale nie ma nic wspólnego z \"szarymi listami\".\n\n**Podsumowując:** \"Szare listy\" to technika, która tymczasowo blokuje połączenia od nieznanych serwerów MTA i oczekuje na ponowienie próby transmisji, wykorzystując fakt, że serwery spamerskie z reguły nie ponawiają prób dostarczenia poczty. Jest to metoda działająca na poziomie serwera MTA i wykorzystuje protokół SMTP. Nie jest ona realizowana ani na poziomie klientów poczty MUA, ani za pomocą ręcznie budowanych list."
    },
    {
        "questionId": 142,
        "title": "Wskaz zagrozenie bezpieczenstwa zwiazane z fragmentacja datagramow w protokole IP?",
        "answers": [
            {
                "text": "scalanie fragmentow perfidnie przygotowanych moze powodowac nieprzewidziane efekty",
                "isCorrect": true
            },
            {
                "text": "fragmentacja uniemozliwia stosowanie AH IPsec",
                "isCorrect": false
            },
            {
                "text": "fragmentacja uniemozliwia stosowanie ESP IPsec",
                "isCorrect": false
            },
            {
                "text": "fragmentacja utrudnia skuteczna filtracje pakietow",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Fragmentacja datagramów IP jest mechanizmem pozwalającym na dzielenie dużych pakietów danych na mniejsze fragmenty. Dzieje się tak, gdy pakiet, przekraczając maksymalną jednostkę transferową (MTU) na trasie, musi zostać podzielony. Każdy fragment otrzymuje nagłówek IP, w tym pole identyfikacyjne i przesunięcie fragmentu (fragment offset), które pozwalają na ponowne scalenie pakietu na docelowym hoście.\n\n**Odpowiedź 1: \"scalanie fragmentow perfidnie przygotowanych moze powodowac nieprzewidziane efekty\"** jest **poprawna**.\n  *   Ten punkt odnosi się do luk implementacyjnych w procesie ponownego składania fragmentów. Jeżeli złośliwy napastnik przygotuje fragmenty pakietów z nieprawidłowymi przesunięciami (fragment offset), może to spowodować, że system docelowy będzie miał problemy z poprawnym scalaniem. Ta sytuacja może doprowadzić do nieprzewidzianych zachowań, takich jak zawieszenie systemu czy przepełnienie bufora, co z kolei może być wykorzystane do przeprowadzenia ataku typu *Denial of Service (DoS)* lub do nieautoryzowanego wykonywania kodu. Przykładem takiego ataku jest *Teardrop attack*, w którym wysyłane są fragmenty z nałożonymi na siebie przesunięciami, powodując zakłócenia w procesie składania i błędy w systemie docelowym.\n\n**Odpowiedź 2: \"fragmentacja uniemozliwia stosowanie AH IPsec\"** jest **niepoprawna**.\n  *   Protokół IPsec AH (*Authentication Header*) chroni integralność pakietu poprzez dodanie do niego nagłówka uwierzytelniającego. Chociaż fragmentacja może utrudnić weryfikację integralności na pewnym etapie, to nie uniemożliwia całkowicie stosowania AH. Każdy fragment jest niezależnie zabezpieczany nagłówkiem AH. To stwierdzenie jest błędne, ponieważ AH jest zaprojektowane do pracy z fragmentacją.\n\n**Odpowiedź 3: \"fragmentacja uniemozliwia stosowanie ESP IPsec\"** jest **niepoprawna**.\n  * Protokół IPsec ESP (*Encapsulating Security Payload*) zapewnia poufność i (opcjonalnie) integralność poprzez szyfrowanie i (opcjonalne) dodanie nagłówka autentykującego. ESP może być wykorzystane wraz z fragmentacją IP, podobnie jak AH. Każdy fragment pakietu jest niezależnie szyfrowany i uwierzytelniany. Fragmentacja nie uniemożliwia stosowania protokołu ESP.\n\n**Odpowiedź 4: \"fragmentacja utrudnia skuteczna filtracje pakietow\"** jest **poprawna**.\n  *   Wiele zapór ogniowych analizuje tylko nagłówek pierwszego fragmentu pakietu, aby uniknąć zbyt dużej liczby obliczeń i zasobów. Jeżeli w pierwszym fragmencie pakietu nie znajdą się niebezpieczne dane, które spowodowałyby odrzucenie pakietu, to kolejne fragmenty pakietu są przepuszczane przez zaporę sieciową. Złośliwy napastnik może celowo umieścić całą treść ataku w kolejnych fragmentach pakietu, które nie są już analizowane przez zaporę. Dlatego też mechanizm fragmentacji jest często wykorzystywany w atakach na zapory sieciowe. Skuteczna filtracja pakietów pofragmentowanych wymaga często zaawansowanych mechanizmów i jest kosztowna zasobowo, przez co w wielu zaporach sieciowych jest ona ograniczana."
    },
    {
        "questionId": 143,
        "title": "Atak na usluge www realizowany poprzez wymuszenie wykonania w przegladarce kodu pochodzacego z lokalizacji innej niz pobrana strona to:",
        "answers": [
            {
                "text": "same origin forgery",
                "isCorrect": false
            },
            {
                "text": "command injection",
                "isCorrect": false
            },
            {
                "text": "SQL injection",
                "isCorrect": false
            },
            {
                "text": "cross site scripting",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Atak typu Cross-Site Scripting (XSS) polega na wstrzyknięciu złośliwego kodu (zazwyczaj JavaScript) do strony internetowej, który następnie jest wykonywany w przeglądarce ofiary. To kluczowe, że kod nie pochodzi bezpośrednio z serwera, który pierwotnie wyświetlił stronę, lecz z innego źródła – na przykład z bazy danych serwera, która została wcześniej poddana atakowi. Złośliwy kod wstrzyknięty do strony jest wykonywany w kontekście (domenie) ofiary, czyli przeglądarka uważa ten kod za zaufany, bo „widzi”, że jest wykonywany w kontekście strony na której ofiara przebywa. Umożliwia to atakującemu wykonanie szerokiego wachlarza złośliwych działań takich jak kradzież ciasteczek sesyjnych, przekierowanie na złośliwą stronę, czy wykonanie innych akcji w imieniu ofiary.\n\n*   **same origin forgery:** Ta odpowiedź jest niepoprawna. Nie jest to znany termin z dziedziny bezpieczeństwa systemów komputerowych. „Same origin policy” jest koncepcją bezpieczeństwa w przeglądarkach internetowych, która ma za zadanie zapobiegać wykonywania skryptów pochodzących z różnych domen w tej samej przeglądarce i w kontekście innej domeny. Atak XSS łamie tę zasadę, a więc fałszerstwo w tym przypadku odnosi się do „obejścia” polityki bezpieczeństwa a nie do „podrobienia” tożsamości.\n*   **command injection:** Ta odpowiedź jest niepoprawna. Atak command injection polega na wstrzykiwaniu złośliwych poleceń do systemów operacyjnych (na przykład poprzez niedopracowaną aplikację webową, która wprost wykorzystuje dane wprowadzone przez użytkownika, w celu wykonania polecenia w systemie operacyjnym), a nie kodu wykonywanego w przeglądarce. Polecenia te są wykonywane na serwerze, a nie w przeglądarce użytkownika. Przykładowo, aplikacja webowa może wykonywać polecenie systemowe z danymi, które użytkownik wprowadził w formularzu. Atakujący może podmienić te dane na takie, które zawierają złośliwe polecenia dla systemu operacyjnego.  \n*  **SQL injection:** Ta odpowiedź jest niepoprawna. Atak SQL injection polega na wstrzykiwaniu złośliwego kodu SQL do bazy danych poprzez niedopracowaną aplikację, np. webową. Atakujący wstrzykuje do zapytania SQL złośliwy fragment SQL, co może prowadzić do modyfikacji, wykasowania lub ujawnienia danych z bazy danych. Podstawowym celem tego ataku jest wykorzystanie luki w aplikacji, w komunikacji z bazą danych na serwerze. Atak nie jest bezpośrednio związany z wykonywaniem skryptów w przeglądarce ofiary.\n*   **cross site scripting:** Ta odpowiedź jest poprawna. Cross-Site Scripting (XSS) dokładnie opisuje sytuację przedstawioną w pytaniu. Atak XSS wykorzystuje zaufanie przeglądarki do pochodzenia skryptu i wstrzykuje kod klienta z jednej domeny (domeny zaufanej) na inną domenę (domenę ofiary). Kod ten wykonywany jest następnie przez przeglądarkę w zaufanym kontekście domeny ofiary. Zastosowań XSS jest wiele, od próby przejęcia sesji użytkownika, poprzez tworzenie fałszywych formularzy aż do całkowitego zablokowania poprawnego działania strony WWW. Przykładowo strona z komentarzami, która pozwala umieszczać HTML oraz JavaScript, może stać się ofiarą XSS. Jeżeli komentarz zostanie zapisany do bazy danych, a następnie poprawnie odtworzony na stronie. W tym przypadku JavaScript z komentarza zostanie wykonany za każdym razem gdy ktoś wywoła tą stronę z widokiem wszystkich komentarzy, na przykład zliczając kliknięcia lub przekierowując do innej strony."
    },
    {
        "questionId": 144,
        "title": "Wskaz wsrod wymienionych jeden standard bezpieczenstwa, ktorego nalezy najbardziej unikac w zabezpieczaniu sieci WiFi:",
        "answers": [
            {
                "text": "WEP",
                "isCorrect": true
            },
            {
                "text": "WPA2",
                "isCorrect": false
            },
            {
                "text": "WPA",
                "isCorrect": false
            },
            {
                "text": "802.11i",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół WEP (Wired Equivalent Privacy) jest najmniej bezpiecznym spośród wymienionych standardów zabezpieczeń sieci bezprzewodowych Wi-Fi i należy go unikać. WEP został zaprojektowany jako pierwszy protokół bezpieczeństwa dla sieci Wi-Fi, jednak szybko okazało się, że posiada szereg słabości.  WEP jest podatny na ataki wykorzystujące słabości algorytmu RC4, którym szyfrowane są ramki danych. Te słabości pozwalają na stosunkowo szybkie złamanie zabezpieczeń WEP. W praktyce, z użyciem odpowiedniego oprogramowania (np. Aircrack-ng),  szyfrowanie WEP można złamać w ciągu kilku minut. W konsekwencji, dane przesyłane w sieci WEP są bardzo podatne na przechwycenie i odszyfrowanie.\n\nWPA (Wi-Fi Protected Access) jest ulepszeniem względem WEP i wprowadził nowe, silniejsze mechanizmy szyfrowania, wykorzystujące algorytm TKIP (Temporal Key Integrity Protocol). TKIP posiada dynamicznie zmieniający się klucz szyfrowania, przez co trudniejsze jest jego złamanie niż w przypadku WEP. Mimo tego, WPA również posiada luki, na które podatne są algorytmy TKIP (np. atak Michael).  WPA jest bardziej bezpieczne niż WEP, jednak obecnie nie jest zalecane, gdyż nowszy standard WPA2 jest o wiele bardziej odporny na ataki.\n\nWPA2 (Wi-Fi Protected Access 2) to aktualnie najbardziej zalecany standard bezpieczeństwa dla sieci Wi-Fi. WPA2 jest z kolei implementacją specyfikacji 802.11i. WPA2, w odróżnieniu od poprzednika, wykorzystuje mechanizmy szyfrowania wykorzystujące protokół CCMP (_ang. Counter Cipher Mode with Block Chaining Message Authentication Code Protocol_), który korzysta z silnego szyfru blokowego AES (Advanced Encryption Standard). Długość klucza stosowana w tym algorytmie utrudnia kryptoanalizę z użyciem metody siłowej (tzw. atak brute-force). WPA2 ma również inne ulepszenia związane z weryfikacją integralności przesyłanych danych i silniejszymi mechanizmami uwierzytelniania stron. W związku z tym WPA2 nie jest standardem, którego należy unikać. \n\n802.11i to standard IEEE, który definiuje rozszerzenia protokołu 802.11 (Wi-Fi) w zakresie bezpieczeństwa. W szczególności opisuje mechanizmy szyfrowania i uwierzytelniania takie jak CCMP oraz silniejszy algorytm AES. 802.11i stanowi podstawę dla protokołu WPA2, a więc jest standardem, który należy stosować, nie unikać. \n\nPodsumowując, WEP, z powodu swoich licznych słabości,  jest najmniej bezpiecznym z wymienionych standardów i należy go unikać. WPA jest ulepszeniem, ale nadal ma wady, zaś WPA2/802.11i stanowią obecnie standard w zabezpieczaniu sieci Wi-Fi. W realnym scenariuszu ataku, użycie WEP umożliwia intruzowi łatwe przechwycenie i odszyfrowanie danych, natomiast użycie WPA2 drastycznie utrudnia takie działanie, pod warunkiem jednakże zastosowania odpowiednio skomplikowanych haseł."
    },
    {
        "questionId": 145,
        "title": "Wskaz ktore z ponizszych technik moga byc wykorzystywane do tzw. wzmacniania DDoS:",
        "answers": [
            {
                "text": "SYN cookies",
                "isCorrect": false
            },
            {
                "text": "protokol DNSsec",
                "isCorrect": false
            },
            {
                "text": "rozgloszenie",
                "isCorrect": true
            },
            {
                "text": "protokol DNS",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Techniki wzmacniania DDoS (Distributed Denial of Service) polegają na wykorzystaniu pośredników, aby wysłać do ofiary dużą ilość danych. Działania te wykorzystują infrastrukturę sieciową w taki sposób, aby stosunkowo niewielkim wysiłkiem ze strony atakującego, wygenerować bardzo duży ruch sieciowy i unieruchomić serwer ofiary poprzez wyczerpanie jego zasobów. Atak wzmacniania DDoS wykorzystuje fakt, że odpowiedź serwera jest wielokrotnie większa niż zapytanie klienta. \n\n**SYN cookies** są mechanizmem obronnym, a nie techniką wzmacniania. Stosuje się je w celu obrony przed atakami typu SYN flood. SYN cookies działają w ten sposób, że serwer, gdy odbiera pakiet SYN z prośbą o nawiązanie połączenia TCP, nie rezerwuje zasobów od razu, tylko na podstawie odebranych danych tworzy specjalny znacznik (cookie) i odsyła w pakiecie SYN-ACK. Serwer zapamiętuje tylko parametry cookie, ale nie przydziela zasobów dla nowego połączenia. Dopiero gdy otrzyma pakiet ACK, serwer analizuje otrzymany znacznik i jeśli znacznik jest poprawny (spełnia wymagania algorytmu na podstawie którego został wygenerowany), to rezerwowane są zasoby dla połączenia. Dzięki takiemu podejściu unika się sytuacji w której serwer zostaje zalany pakietami SYN, co prowadzi do wyczerpania jego zasobów. SYN cookies są mechanizmem obronnym a nie techniką wykorzystywaną do ataków.\n\n**Protokół DNSsec** (Domain Name System Security Extensions) to rozszerzenie protokołu DNS, które dodaje do niego mechanizmy kryptograficzne. DNSsec zabezpiecza DNS przed atakami typu DNS spoofing, które polegają na fałszowaniu informacji o mapowaniu nazw domenowych na adresy IP. DNSsec wykorzystuje mechanizmy kryptografii klucza publicznego do podpisywania informacji zwracanych w odpowiedziach serwera DNS. Dzięki czemu klient wie, że informacja odnośnie mapowania nazwy domenowej na adres IP pochodzi z wiarygodnego serwera. DNSsec jest protokołem poprawiającym bezpieczeństwo DNS, a nie techniką wzmacniania DDoS.\n\n**Rozgłoszenie** (ang. broadcast) jest techniką, która może być wykorzystana do wzmacniania ataków DDoS. W sieci lokalnej, jeśli wyślemy do wszystkich komputerów zapytanie, komputery odbierając to zapytanie są zobligowane do wygenerowania odpowiedzi. Wykorzystując tą cechę protokołu warstwy łącza danych, atakujący mogą wysyłać zapytania do komputerów na adres rozgłoszeniowy, podając adres IP ofiary jako adres źródłowy. Wszystkie komputery w tej sieci lokalnej będą odbierać to zapytanie i wysyłać odpowiedzi na adres IP ofiary. Skutkuje to natężeniem ruchu sieciowego, który kierowany jest na serwer ofiary. Prowadzi to do przeciążenia serwera i ostatecznie do jego unieruchomienia. Technika ta może być rozszerzona również na poziomie protokołu IP, jeśli router brzegowy nie będzie blokował pakietów broadcast. Rozgłoszenie jest techniką wzmacniania DDoS.\n\n**Protokół DNS** może zostać wykorzystany do wzmacniania ataków DDoS, poprzez wysyłanie do serwera DNS zapytań o dużą liczbę rekordów DNS (np. polecenie dig z opcją ANY) z adresem IP ofiary jako źródłowym. Serwer DNS jest zmuszony do wygenerowania bardzo dużej odpowiedzi, która jest kierowana na serwer ofiary. Atakujący najczęściej wykorzystują serwery DNS, które nie zostały poprawnie skonfigurowane lub serwery które nie przeszły aktualizacji bezpieczeństwa. Dzięki temu uzyskują serwer który w sposób bezwiedny bierze udział w ataku DDoS. Protokół DNS jest techniką wzmacniania DDoS."
    },
    {
        "questionId": 146,
        "title": "Ktora z ponizszych cech poprawnie opisuje mechanizm SYN cookies:",
        "answers": [
            {
                "text": "chroni przed atakami buffer overflow",
                "isCorrect": false
            },
            {
                "text": "jest jedna z technik wzmacniania atakow DDos",
                "isCorrect": false
            },
            {
                "text": "chroni przed atakami SYN flood",
                "isCorrect": true
            },
            {
                "text": "po wyslaniu segmentu SYN/ACK nadawca zapomina o polaczeniu",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm SYN cookies jest metodą obrony przed atakami typu SYN flood. Atak SYN flood to atak typu DoS (Denial of Service), który wykorzystuje proces nawiązywania połączenia TCP. Proces nawiązywania połączenia TCP wymaga 3 etapów. Najpierw klient wysyła pakiet SYN do serwera. Serwer odsyła do klienta pakiet SYN/ACK. A na koniec klient odsyła do serwera pakiet ACK. W tym momencie połączenie jest nawiązane i serwer może wymieniać dane z klientem. Atakujący, w ataku SYN flood, wysyła dużą liczbę pakietów SYN do serwera, ale nie odsyła nigdy pakietu ACK. W efekcie serwer przetrzymuje pakiety SYN/ACK, w oczekiwaniu na nadejście pakietów ACK. Jeżeli do serwera dociera duża liczba pakietów SYN, to serwer może stracić wszystkie dostępne zasoby na obsługę tych otwartych na pół połączeń TCP. Powoduje to niedostępność serwera dla prawidłowych użytkowników, którzy zechcą się z nim połączyć. \n\nOdpowiedź \"chroni przed atakami buffer overflow\" jest **niepoprawna**. Atak buffer overflow (przepełnienie bufora) to atak na aplikację, która nie sprawdza długości wprowadzanych danych. Ataki te są powiązane z błędami programistów. Natomiast SYN cookies, są elementem obrony przed atakami typu DoS i wykorzystują działanie protokołu TCP. \nOdpowiedź \"jest jedną z technik wzmacniania ataków DDos\" jest **niepoprawna**. SYN cookies jest metodą obrony przed atakami DoS a nie ich wzmacniania. Ataki DDos(Distributed Denial of Service) to ataki typu DoS, które są przeprowadzone z wielu źródeł równocześnie, wzmacniając tym samym jego siłę. \nOdpowiedź \"chroni przed atakami SYN flood\" jest **poprawna**. SYN cookies zabezpieczają przed atakami typu SYN flood wykorzystując fakt, że klient nigdy nie wysyła pakietu ACK. Dzięki SYN cookies, serwer nie przetrzymuje informacji o połączeniu. Miast tego wysyła kod-ciasteczko (ang. SYN cookie) zawierające informacje o tym połączeniu do klienta. Odbierając od klienta pakiet ACK serwer sprawdza czy przesłany kod-ciasteczko jest poprawny, jeśli tak to dane połączenie zostaje utworzone. \nOdpowiedź \"po wysłaniu segmentu SYN/ACK nadawca zapomina o połączeniu\" jest **poprawna**. SYN cookies to technika, która nie wymaga od serwera utrzymywania stanu połączenia po wysłaniu SYN/ACK, serwer „zapomina” o połączeniu po wysłaniu SYN/ACK. Serwer tworzy kod-ciasteczko(SYN cookie), w którym zawarte są informacje o połączeniu, kod ten zostaje odesłany do klienta w pakiecie SYN/ACK. Potem kod-ciasteczko jest przesyłany w pakiecie ACK od klienta do serwera. Dzięki temu serwer może odtworzyć informacje o połączeniu i go sfinalizować. \n\nW praktyce, serwer otrzymujący pakiet SYN, generuje specjalną wartość SYN cookie, która jest obliczona na podstawie danych pakietu SYN oraz tajnego klucza serwera. Ta wartość jest odesyłana do klienta w pakiecie SYN/ACK. Gdy serwer odbierze pakiet ACK od klienta, sprawdza poprawność kodu-ciasteczka, czy zawarte w nim informacje są zgodne z informacjami o połączeniu zawartymi w pakiecie. Jeśli tak to połączenie jest tworzone. Kod ciasteczko ma za zadanie ochrona przed atakami typu SYN flood, gdyż na serwerze nie jest przechowywany żaden stan połączenia, nie są przetrzymywane w pamięci numery sekwencyjne jak ma to miejsce w standardowej implementacji protokołu TCP. \n\nZastosowanie SYN cookies ma istotne znaczenie w realnych środowiskach. Systemy, które są publicznie dostępne dla Internautów mogą być potencjalnie narażone na ataki typu SYN flood, przez co ich prawidłowa praca może być utrudniona lub nawet całkowicie zablokowana. Dlatego technika SYN cookies jest bardzo popularna i stosowana w większości aktualnie wykorzystywanych systemów operacyjnych."
    },
    {
        "questionId": 147,
        "title": "Mechanizm ACL:",
        "answers": [
            {
                "text": "oferuje niezaprzeczalnosc nadania wiadomosci",
                "isCorrect": false
            },
            {
                "text": "jest narzedziem kontroli dostepu do zasobow",
                "isCorrect": true
            },
            {
                "text": "oferuje niezaprzeczalnosc odbioru wiadomosci",
                "isCorrect": false
            },
            {
                "text": "wyroznia systemy MAC od DAC",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Listy kontroli dostępu (ACL, *ang. Access Control Lists*) to mechanizmy systemowe służące do zarządzania uprawnieniami dostępu do zasobów, takich jak pliki, katalogi, urządzenia czy usługi. Definiują one, kto (użytkownik lub grupa użytkowników) ma jakie prawa (np. odczyt, zapis, wykonywanie) do danego zasobu. Każdy wpis w ACL określa uprawnienia dostępu dla konkretnego użytkownika lub grupy.\n\n*   **\"oferuje niezaprzeczalnosc nadania wiadomosci\"**: Jest to **niepoprawna** odpowiedź. Niezaprzeczalność nadania (ang. *non-repudiation of origin*) to właściwość systemu, która zapobiega wyparciu się przez nadawcę faktu wysłania wiadomości. Mechanizmy ACL nie są do tego przeznaczone i nie posiadają takiej funkcjonalności. Niezaprzeczalność osiąga się za pomocą podpisów cyfrowych, a nie poprzez mechanizmy kontroli dostępu. Wyobraźmy sobie, że pracownik wysyła umowę do klienta i chce mieć pewność, że klient nie wyprze się, iż ją otrzymał. W tym przypadku, użycie podpisu cyfrowego na umowie gwarantuje niezaprzeczalność wysłania i otrzymania dokumentu. ACL nie ma w sobie takich mechanizmów.\n\n*   **\"jest narzedziem kontroli dostepu do zasobow\"**: Jest to **poprawna** odpowiedź. Mechanizmy ACL są podstawowym narzędziem do kontrolowania dostępu do zasobów w systemie operacyjnym. Każdy obiekt(np. plik lub katalog) ma powiązaną z nim listę kontroli dostępu. Wpisy na liście ACL definiują komu i jakie prawa(np. odczytu, zapisu, wykonywania) są przyznane dla danego obiektu. Przykładem może być sytuacja, w której administrator systemu chce udostępnić plik z umową jedynie dla konkretnych działów w firmie. Dzięki ACL może ustawić dostęp do pliku tylko dla użytkowników z działu handlowego oraz działu prawnego. Inne działy nie będą miały możliwości odczytania tego pliku.\n\n*   **\"oferuje niezaprzeczalnosc odbioru wiadomosci\"**: Jest to **niepoprawna** odpowiedź. Podobnie jak w przypadku odpowiedzi pierwszej, mechanizm ACL nie jest do tego przeznaczony. ACL to mechanizm kontroli dostępu a nie mechanizm niezaprzeczalności. Mechanizm niezaprzeczalności odbioru jest w praktyce trudny do realizacji(w odróżnieniu od niezaprzeczalności wysłania), a mechanizmy wykorzystywane w tym celu nie są realizowane w listach kontroli dostępu. \n\n*   **\"wyroznia systemy MAC od DAC\"**: Jest to **niepoprawna** odpowiedź. Listy ACL są obecne zarówno w systemach DAC (*ang. Discretionary Access Control*, Uznaniowa Kontrola Dostępu), jak i MAC (*ang. Mandatory Access Control*, Ścisła Kontrola Dostępu). Choć ACL mogą być implementowane inaczej w systemach MAC i DAC, to sama obecność ACL nie jest elementem różnicującym te dwa systemy. Systemy DAC pozwalają na samodzielne zarządzanie uprawnieniami do własnych zasobów dla właściciela obiektu(np. pliku). W systemie MAC, system sam ustala uprawnienia do zasobów i często ani użytkownik, ani administrator nie ma możliwości zmiany tych ustawień. ACL są w obu systemach używane do specyfikacji tych uprawnień. ACL są narzędziem wykorzystywanym w obu modelach kontroli dostępu ale nie są wyznacznikiem, który model jest MAC a który DAC."
    },
    {
        "questionId": 148,
        "title": "Wskaz cechy scislej kontroli dostepu (MAC):",
        "answers": [
            {
                "text": "podatna na bledy samodzielnej konfiguracji przez uzytkownika",
                "isCorrect": false
            },
            {
                "text": "wymaga kosztownej globalne konfiguracji systemu",
                "isCorrect": true
            },
            {
                "text": "nie pozwala uzytkownikowi sterowac uprawnieniami do jego wlasnych zasobow",
                "isCorrect": true
            },
            {
                "text": "trudna do nadzorowania przez system",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Ścisła kontrola dostępu (MAC) to model bezpieczeństwa, w którym dostęp do zasobów jest regulowany przez centralną politykę bezpieczeństwa, a nie przez decyzje właścicieli zasobów. Oznacza to, że nawet właściciel pliku lub innego zasobu nie może dowolnie zmieniać uprawnień dostępu do niego. Polityka MAC jest narzucana przez administratora i w sposób automatyczny wymuszana przez system. W przeciwieństwie do uznaniowej kontroli dostępu (DAC), gdzie użytkownicy mogą samodzielnie decydować, kto ma dostęp do ich zasobów, MAC centralizuje zarządzanie dostępem, co jest bardziej bezpieczne, ale zarazem bardziej restrykcyjne dla użytkowników.\n\n**Odpowiedź 1: \"podatna na bledy samodzielnej konfiguracji przez uzytkownika\"**\n\nTa odpowiedź jest **niepoprawna**.  MAC z założenia *nie* jest podatna na błędy samodzielnej konfiguracji przez użytkownika. Użytkownicy nie mają w ogóle uprawnień do konfigurowania zasad kontroli dostępu.  To centralny administrator, a nie użytkownik, definiuje i implementuje politykę bezpieczeństwa, która determinuje dostęp do zasobów. Celem MAC jest wyeliminowanie możliwości popełniania błędów konfiguracyjnych przez użytkowników.\n\n**Odpowiedź 2: \"wymaga kosztownej globalnej konfiguracji systemu\"**\n\nTa odpowiedź jest **poprawna**. Implementacja MAC wiąże się z narzuceniem rygorystycznej polityki bezpieczeństwa na poziomie całego systemu.  W praktyce oznacza to konieczność precyzyjnego zdefiniowania etykiet poufności dla wszystkich zasobów, użytkowników i procesów. To pociąga za sobą duży nakład pracy związany z analizą potrzeb bezpieczeństwa systemu oraz implementacją zdefiniowanej polityki bezpieczeństwa i wymaga wiedzy eksperckiej i zasobów, co przekłada się na wysokie koszty. Przykładowo, w systemach z MAC, każde tworzenie nowego pliku, użytkownika lub procesu musi być zgodne z precyzyjnie określonymi regułami, co nie jest proste i jest czasochłonne.\n\n**Odpowiedź 3: \"nie pozwala uzytkownikowi sterowac uprawnieniami do jego wlasnych zasobow\"**\n\nTa odpowiedź jest **poprawna**. Jest to wręcz podstawowa cecha MAC. W przeciwieństwie do DAC, gdzie właściciel pliku decyduje, kto i w jaki sposób ma do niego dostęp, w MAC uprawnienia dostępu są determinowane przez centralnie narzuconą politykę. Użytkownik nie może, zgodnie z polityką MAC, zmienić poziomu dostępu, nawet do swoich własnych zasobów. Na przykład, użytkownik który utworzył plik z danymi oznaczonymi jako \"tajne\" nie może sam zadecydować o zmianie poziomu poufności danych na \"poufne\" lub \"publiczne\".\n\n**Odpowiedź 4: \"trudna do nadzorowania przez system\"**\n\nTa odpowiedź jest **niepoprawna**. System MAC charakteryzuje się wręcz wysoką łatwością nadzorowania. Cała polityka bezpieczeństwa jest zdefiniowana centralnie i automatycznie wymuszana przez system, co ułatwia kontrolę nad prawidłowym działaniem mechanizmów kontroli dostępu. Centralizacja polityki bezpieczeństwa ułatwia analizę i wykrywanie potencjalnych problemów. W systemach MAC nadzór jest zaimplementowany bezpośrednio w systemie operacyjnym, co sprawia, że mechanizmy kontroli dostępu są bardzo silne."
    },
    {
        "questionId": 149,
        "title": "Jaki rodzaj filtracji umozliwia podejmowanie decyzji o filtracji pakietow z uwzglednieniem stanu sesji do  ktorej przynaleza?",
        "answers": [
            {
                "text": "filtry bezstanowe",
                "isCorrect": false
            },
            {
                "text": "filtry statyczne",
                "isCorrect": false
            },
            {
                "text": "filtry kontekstowe",
                "isCorrect": true
            },
            {
                "text": "Stateful Packet Filtering",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Filtry kontekstowe, znane również jako filtry stanowe (ang. *stateful packet filtering*), pozwalają zaporom sieciowym na podejmowanie decyzji o przepuszczaniu lub blokowaniu pakietów na podstawie aktualnego stanu połączenia, do którego pakiet ten należy. Oznacza to, że zapora nie analizuje pakietu w oderwaniu od kontekstu komunikacji, ale śledzi poszczególne etapy nawiązywania i przesyłania danych w ramach danego połączenia.\n\n**Filtry bezstanowe** analizują pakiety niezależnie, na podstawie nagłówków (np. adres źródłowy, docelowy, porty). Nie pamiętają one, czy pakiet jest częścią aktywnego połączenia. W praktyce oznacza to, że reguła pozwalająca na ruch inicjowany z wewnątrz sieci (np. zapytanie HTTP z twojego komputera do serwera) wymaga dodatkowej reguły zezwalającej na ruch zwrotny, ponieważ filtr bezstanowy nie \"pamięta\" że te dwa pakiety tworzą jedno połączenie. \n\n**Filtry statyczne** to rodzaj filtrów bezstanowych, gdzie reguły filtracji są definiowane z góry i nie zmieniają się w zależności od okoliczności. Przykładowo, reguła \"blokuj pakiety z adresu X\" będzie zawsze działać niezależnie od tego, czy dany adres jest obecnie częścią aktywnego połączenia. Z tego powodu reguły takie są mało elastyczne i wymagają dużej liczby reguł aby zapewnić bezpieczeństwo, np. połączenie do serwera HTTP (port 80 TCP) wymaga reguły zezwalającej na wychodzący ruch na port 80 TCP i kolejnej reguły na wchodzący ruch na port TCP losowy(powyżej 1024).\n\n**Filtry kontekstowe (stateful packet filtering)** działają inaczej. Analizują one pakiety w kontekście całego połączenia i są wykorzystywane na przykład w zaporach typu firewall. Posiadają mechanizm, który \"pamięta\" etapy zestawiania połączenia TCP. Przykładowo, typowe połączenie TCP (np. przy wejściu na stronę WWW) składa się z trzech kroków: pakiet SYN od klienta do serwera, pakiet SYN+ACK od serwera do klienta i na końcu pakiet ACK od klienta do serwera. Filtr kontekstowy po odebraniu segmentu SYN rejestruje te informacje w tabeli stanów, dzięki temu następne segmenty w ramach tego połączenia(ACK, dane) są z automatu uznawane za poprawny ruch. Rejestr połączeń umożliwia na podejmowanie dynamicznych decyzji o blokowaniu lub przepuszczaniu pakietów (bez potrzeby ręcznego dopisywania reguły). Do tej grupy filtrów należą również rozwiązania bazujące na tzw. inspekcji protokołów (_ang. protocol inspection_), które analizują na przykład treść nagłówków protokołu w wyższych warstwach modelu OSI (np. HTTP), aby podejmować bardziej wyrafinowane decyzje o filtracji.\n\nPraktycznym przykładem różnicy jest atak SYN flood. Zapora bezstanowa widzi pakiet SYN jako nowy, niezależny pakiet i działa zgodnie z ustawionymi regułami przepuszczając taki pakiet. Natomiast zapora stanowa widzi, że pakiet SYN nie jest częścią zdefiniowanego, prawidłowego połączenia i blokuje go. Podobnie, jeśli ustawiona jest reguła pozwalająca na połączenie z serwerem WWW, ale tylko z sieci lokalnej, filtr bezstanowy wymaga osobnej reguły dla odpowiedzi z serwera (która może posiadać nieznany port docelowy). Filtr stanowy zapamiętuje kierunek ruchu i automatycznie pozwala na przepływ odpowiedzi."
    },
    {
        "questionId": 150,
        "title": "Ktore z ponizszych cech poprawnie opisuja standard IEEE 802.1X:",
        "answers": [
            {
                "text": "umozliwia scentralizowane zarzadzanie kluczami publicznymi uzytkownikow PKI/X",
                "isCorrect": false
            },
            {
                "text": "moze wykorzystywac certyfikaty X.509 do kontroli dostepu w sieciach WiFi",
                "isCorrect": true
            },
            {
                "text": "chroni przed atakami IP spoofing",
                "isCorrect": true
            },
            {
                "text": "umozliwia uwierzytelnianie stanowisk sieci LAN",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "IEEE 802.1X jest standardem kontroli dostępu do sieci, który zapewnia scentralizowane uwierzytelnianie na poziomie portu sieciowego. Oznacza to, że zanim urządzenie uzyska dostęp do sieci (na przykład Internetu, serwera plików), musi przejść proces uwierzytelnienia. Standard ten jest niezależny od technologii łącza (przewodowe, bezprzewodowe) czy protokołów (IP), ale najczęściej stosowany jest w sieciach Ethernet (przewodowych LAN) i WiFi (bezprzewodowych WLAN). 802.1X definiuje architekturę, w której urządzenia działają jako „Supplicants” (uwierzytelniane), urządzenia pośredniczące jako „Authenticators” (przełączniki/routery), oraz centralny serwer uwierzytelniający jako „Authentication Server” (np. RADIUS).\n\n*   **\"umozliwia scentralizowane zarzadzanie kluczami publicznymi uzytkownikow PKI/X\"** - Ta odpowiedź jest **niepoprawna**. Chociaż 802.1X może *używać* certyfikatów X.509 (które zawierają klucze publiczne) do uwierzytelniania, sam standard nie zarządza kluczami publicznymi użytkowników w ramach PKI. Zarządzanie PKI jest osobnym problemem i realizowane jest przez inne systemy, w których klucze 802.1X są tylko jednymi z wielu komponentów. Mechanizmy PKI obejmują urzędy certyfikacji(CA), które generują i podpisują certyfikaty X.509, a standard 802.1X *korzysta* z tych certyfikatów, lecz sam nie jest odpowiedzialny za zarządzanie cyklem ich życia.\n\n*   **\"moze wykorzystywac certyfikaty X.509 do kontroli dostepu w sieciach WiFi\"** - Ta odpowiedź jest **poprawna**. Standard 802.1X może wykorzystywać certyfikaty X.509 do uwierzytelniania użytkowników i urządzeń w sieciach Wi-Fi (WLAN). W takim scenariuszu, użytkownik lub urządzenie przedstawia certyfikat X.509 jako dowód swojej tożsamości. Mechanizm ten znany jest jako EAP-TLS (Extensible Authentication Protocol-Transport Layer Security) i jest jedną z najbezpieczniejszych metod uwierzytelniania bezprzewodowego. Przykładowo, w środowisku korporacyjnym, aby uzyskać dostęp do firmowej sieci Wi-Fi, pracownik musi uwierzytelnić się przedstawiając ważny certyfikat X.509 wydany przez centralny urząd certyfikacji firmy. To chroni sieć przed dostępem nieuprawnionych osób, nawet jeśli znają nazwę sieci Wi-Fi.\n\n*   **\"chroni przed atakami IP spoofing\"** - Ta odpowiedź jest **poprawna**. Uwierzytelnianie 802.1X na poziomie portu sieciowego sprawia, że osoba atakująca nie może przesyłać pakietów z sfałszowanym adresem IP, gdyż aby w ogóle zostać wpuszczonym do sieci najpierw trzeba się poprawnie uwierzytelnić. Bez poprawnego uwierzytelnienia port przełącznika jest zablokowany i odrzuca wszystkie nadchodzące pakiety od atakującego, nawet gdy pakiety te mają sfałszowany nagłówek IP. Atak IP spoofing często polega na podszywaniu się pod zaufanego użytkownika, w 802.1X to podszywanie jest niemożliwe do przeprowadzenia.\n\n*   **\"umozliwia uwierzytelnianie stanowisk sieci LAN\"** - Ta odpowiedź jest **poprawna**. Standard 802.1X stosuje się nie tylko do sieci bezprzewodowych (Wi-Fi).  Może być używany również do zabezpieczania dostępu w sieciach lokalnych (LAN) - na przykład, w sieciach ethernetowych. W tym scenariuszu, przed uzyskaniem dostępu do sieci (łącza fizycznego - portu przełącznika), komputery użytkowników muszą  się uwierzytelnić, najczęściej za pomocą kombinacji nazwy użytkownika i hasła, lub też za pomocą certyfikatu X.509. Często spotykany sposób uwierzytelniania w sieciach lokalnych to EAP-MD5, w którym przesyłane są skróty MD5 haseł, a nie hasła w postaci jawnej, ale też spotykane jest EAP-TLS z użyciem certyfikatów, gdy wymagane jest podwyższone bezpieczeństwo.\n\nPytanie to pomaga uświadomić sobie, że 802.1X to uniwersalny mechanizm kontroli dostępu, a nie tylko zabezpieczenie sieci Wi-Fi. Podkreśla też, że bezpieczeństwo sieci opiera się na wielu mechanizmach, które uzupełniają się wzajemnie."
    },
    {
        "questionId": 151,
        "title": "Algorytm 3DES to:",
        "answers": [
            {
                "text": "zastosowanie skrotu qubicznego Extended Signature",
                "isCorrect": false
            },
            {
                "text": "pseudolosowy generator 3D cube",
                "isCorrect": false
            },
            {
                "text": "trzykrotne uzycie algorytmu DES",
                "isCorrect": true
            },
            {
                "text": "podzial szyfrogramu na 3 porcje roznej dlugosci wg Disturb-Extraction Split",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Algorytm 3DES, czyli Triple DES, to metoda symetrycznego szyfrowania, która polega na trzykrotnym zastosowaniu algorytmu DES (Data Encryption Standard) na jednym bloku danych. DES jest symetrycznym algorytmem blokowym, który operuje na 64-bitowych blokach danych i wykorzystuje klucz o długości 56 bitów. Chociaż DES był szeroko stosowany, jego stosunkowo krótki klucz stał się podatny na ataki brute-force. Algorytm 3DES powstał jako odpowiedź na tę słabość.\n\n*   **\"zastosowanie skrotu qubicznego Extended Signature\"** - Jest to niepoprawna odpowiedź. Skrót (ang. hash) to funkcja matematyczna, która przekształca dane wejściowe o dowolnej długości w wyjściowe o stałej długości. Skrót (hash) jest funkcją jednokierunkową, co oznacza że nie ma możliwości na podstawie skrótu odtworzyć danych wejściowych. Funkcje skrótu wykorzystywane są do tworzenia sum kontrolnych, podpisu elektronicznego, czy w protokołach uwierzytelniania. Pojęcie \"skrót kubiczny\" czy \"Extended Signature\" nie są terminami używanymi w kryptografii. \n    *   **Praktyczne implikacje:** Funkcje skrótu nie są algorytmami szyfrowania, więc nie można używać ich do szyfrowania danych.\n\n*   **\"pseudolosowy generator 3D cube\"** - Jest to niepoprawna odpowiedź. Generator pseudolosowy (ang. pseudorandom generator) to algorytm, który tworzy ciąg liczb wyglądających losowo. Pseudolosowość jest wykorzystywana w kryptografii do tworzenia kluczy szyfrujących, wektorów inicjujących, danych uwierzytelniających. Termin \"generator 3D cube\" nie ma żadnego zastosowania w kryptografii. \n    *   **Praktyczne implikacje:** Pseudolosowe generatory liczb nie szyfrują danych; generują jedynie sekwencje liczb, które są wykorzystywane jako dane wejściowe w algorytmach szyfrowania.\n\n*   **\"trzykrotne uzycie algorytmu DES\"** - Jest to poprawna odpowiedź. W 3DES, algorytm DES jest używany trzykrotnie w operacji szyfrowania i deszyfrowania. Najczęściej spotykanym trybem jest DES-EDE (encrypt-decrypt-encrypt), gdzie szyfrowanie odbywa się za pomocą klucza K1, deszyfrowanie z użyciem klucza K2, a ponownie szyfrowanie z użyciem klucza K1. Zatem zamiast pojedynczego klucza DES, 3DES używa dwóch kluczy 56 bitowych (razem 112 bitów klucza) lub trzech (168 bitów klucza) co znacznie podnosi poziom bezpieczeństwa. \n    *   **Praktyczne implikacje:** 3DES, mimo że nie jest już uważany za najbezpieczniejszy algorytm, wciąż jest stosowany w niektórych systemach, zwłaszcza w starszych urządzeniach i aplikacjach, gdzie zmiana implementacji algorytmu szyfrowania nie jest łatwa.\n\n*   **\"podzial szyfrogramu na 3 porcje roznej dlugosci wg Disturb-Extraction Split\"** - Jest to niepoprawna odpowiedź. Technika ta, jeśli jest w ogóle używana w kryptologii, to w zupełnie innym kontekście niż algorytmy szyfrowania, i dotyczy zazwyczaj podziału danych wejściowych lub danych wykorzystywanych w algorytmach kryptograficznych. Nie jest to związane z algorytmem 3DES.\n    *   **Praktyczne implikacje:** Algorytmy szyfrowania nie dzielą szyfrogramu w taki sposób."
    },
    {
        "questionId": 152,
        "title": "Ktora z ponizszych cech poprawnie opisuje protokol RADIUS:",
        "answers": [
            {
                "text": "wspiera realizacje kontroli dostepu do zasobow sieciowych",
                "isCorrect": false
            },
            {
                "text": "umozliwia rejestrowanie dostepu do zasobow sieciowych",
                "isCorrect": false
            },
            {
                "text": "chroni przed atakami DNS spoofing",
                "isCorrect": false
            },
            {
                "text": "umozliwia scentralizowane uwierzytelnianie podmiotow",
                "isCorrect": true
            },
            {
                "text": "oferuje wymiane kluczy protokołu IPsec przy wykorzystaniu zarówno haseł jak i certyfikatów PKI",
                "isCorrect": false
            },
            {
                "text": ") podnosi dostępność poprzez redundantne rozproszenie danych uwierzytelniających do wielu punktów dostępowych",
                "isCorrect": false
            },
            {
                "text": ") udostępnia informacje niezbędne do kontroli uprawnień zdalnego dostępu (np. restrykcje czasowe)",
                "isCorrect": true
            },
            {
                "text": "pozwala na scentralizowane przechowywanie danych uwierzytelniających dla wielu punktów dostępowych",
                "isCorrect": true
            },
            {
                "text": "podnosi dostepnosc poprzez redundantne rozproszenie danych uwierzytelniajacych do wielu punktow dostepowych",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół RADIUS (Remote Authentication Dial-In User Service) jest protokołem sieciowym, który centralizuje uwierzytelnianie, autoryzację i rozliczanie (AAA) dostępu do sieci. W typowym scenariuszu, użytkownik chcący uzyskać dostęp do sieci, np. poprzez Wi-Fi lub VPN, wysyła żądanie uwierzytelnienia do punktu dostępowego. Ten punkt dostępowy, zamiast samodzielnie sprawdzać dane logowania, przekazuje je do serwera RADIUS. Serwer RADIUS weryfikuje tożsamość użytkownika, określa, do jakich zasobów użytkownik ma dostęp (autoryzacja) i może rejestrować czas trwania sesji (rozliczanie).\n\n**\"wspiera realizacje kontroli dostepu do zasobow sieciowych\"** -  Ta odpowiedź jest *nieprawidłowa*, ponieważ RADIUS sam w sobie nie realizuje kontroli dostępu do zasobów sieciowych. RADIUS jest serwerem uwierzytelniającym, który po pozytywnej weryfikacji tożsamości użytkownika zwraca informacje o tym czy może on uzyskać dostęp. Natomiast za kontrolę dostępu do zasobów odpowiedzialny jest punkt dostępowy, który otrzymuje informacje od serwera RADIUS. Przykładowo, po uwierzytelnieniu użytkownika, serwer RADIUS może zwrócić informację, że użytkownik ma prawo korzystać z określonego segmentu sieci lub konkretnych usług, zaś punkt dostępowy wdraża te ograniczenia.\n\n**\"umozliwia rejestrowanie dostepu do zasobow sieciowych\"** - Ta odpowiedź jest *nieprawidłowa*, gdyż RADIUS owszem potrafi rejestrować informacje o procesie uwierzytelniania, sesji połączenia, adresie IP klienta, ilości przesłanych danych i czasie sesji, ale nie rejestruje dostępu do konkretnych zasobów. Przykładowo, serwer RADIUS może zarejestrować, że użytkownik zalogował się o godzinie 10:00 i wylogował o godzinie 11:00, ale nie zarejestruje, do których plików czy baz danych użytkownik miał dostęp.\n\n**\"chroni przed atakami DNS spoofing\"** - Ta odpowiedź jest *nieprawidłowa*, ponieważ RADIUS w żaden sposób nie chroni przed atakami DNS spoofing. DNS spoofing jest atakiem na warstwę sieciową, która wykorzystuje lukę w protokole DNS. Natomiast RADIUS działa na warstwie aplikacyjnej. Ochrona przed atakami DNS spoofing wymaga stosowania mechanizmów takich jak DNSSEC.\n\n**\"umozliwia scentralizowane uwierzytelnianie podmiotow\"** - Ta odpowiedź jest *prawidłowa*. Jedną z kluczowych zalet RADIUS jest scentralizowane uwierzytelnianie. Wszystkie punkty dostępu do sieci (np. wiele routerów WiFi) korzystają z jednego serwera RADIUS, co upraszcza zarządzanie kontami użytkowników. Zamiast konfigurować uwierzytelnianie na każdym urządzeniu osobno, wystarczy skonfigurować je tylko na serwerze RADIUS. Przykładowo, w dużej firmie wszystkie punkty dostępowe Wi-Fi mogą odpytywać ten sam serwer RADIUS o dane logowania użytkowników.\n\n**\"oferuje wymiane kluczy protokołu IPsec przy wykorzystaniu zarówno haseł jak i certyfikatów PKI\"** - Ta odpowiedź jest *nieprawidłowa*. Protokół RADIUS nie jest odpowiedzialny za wymianę kluczy protokołu IPsec. RADIUS może być używany do uwierzytelniania podmiotów w procesie negocjacji IPsec, ale sama wymiana kluczy, np. metodą IKE (Internet Key Exchange), odbywa się niezależnie od RADIUSa. Przykładowo, serwer VPN może używać RADIUSa do uwierzytelnienia użytkownika, ale wymiana kluczy szyfrujących jest obsługiwana przez protokół IKE.\n\n**\"podnosi dostępność poprzez redundantne rozproszenie danych uwierzytelniających do wielu punktów dostępowych\"** - Ta odpowiedź jest *nieprawidłowa*. RADIUS sam w sobie nie rozprasza danych uwierzytelniających, co mogłoby podnieść dostępność. Scentralizowane podejście oznacza, że wszystkie dane są przechowywane na jednym lub kilku serwerach RADIUS. Rozproszenie danych na wiele serwerów wymaga konfiguracji dodatkowych mechanizmów, takich jak replikacja bazy danych RADIUS, które to rozwiązanie nie jest integralną częścią samego RADIUSA. Co więcej jeśli system autoryzacyjny RADIUS jest niedostępny, nie można się w ogóle dołączyć do sieci. Rozwiązaniem są tutaj dodatkowe konfiguracje z zapasowym serwerem RADIUS (backup).\n\n**\"udostępnia informacje niezbędne do kontroli uprawnień zdalnego dostępu (np. restrykcje czasowe)\"** - Ta odpowiedź jest *prawidłowa*. RADIUS, w procesie autoryzacji, przekazuje do punktu dostępowego informacje o uprawnieniach użytkownika, w tym np. o ograniczeniach czasowych. Dzięki temu można np. ustalić, że dany użytkownik może uzyskiwać dostęp do sieci tylko w określonych godzinach.\n\n**\"pozwala na scentralizowane przechowywanie danych uwierzytelniających dla wielu punktów dostępowych\"** - Ta odpowiedź jest *prawidłowa*. Serwer RADIUS jest centralnym magazynem danych uwierzytelniających, z którego korzystają wszystkie punkty dostępowe sieci. Ułatwia to zarządzanie użytkownikami oraz ich uprawnieniami. Przykładowo, dodanie lub usunięcie użytkownika, zmiana hasła wykonywane są tylko w jednej centralnej lokalizacji i są automatycznie dostępne dla wszystkich punktów dostępowych, w tym np. punktów Wi-Fi, serwerów VPN itp. \n\n**\"podnosi dostepnosc poprzez redundantne rozproszenie danych uwierzytelniajacych do wielu punktow dostepowych\"**- Ta odpowiedź jest *nieprawidłowa*, jak już wspomniano wcześniej RADIUS sam w sobie nie zapewnia redundantnego rozproszenia danych, co mogłoby podnieść dostępność. Zastosowanie redundancji wymaga dodatkowej konfiguracji, replikacji baz danych."
    },
    {
        "questionId": 152,
        "title": "Ktora z ponizszych cech poprawnie opisuje protokol RADIUS:",
        "answers": [
            {
                "text": "oferuje wymiane kluczy protokolu IPsec przy wykorzystaniu zarowno hasel jak i certyfikatow PKI",
                "isCorrect": false
            },
            {
                "text": "podnosi dostepnosc poprzez redundantne rozproszenie danych uwierzytelniajacych do wielu punktow dostepowych",
                "isCorrect": false
            },
            {
                "text": "udostepnia informacje niezbedne do kontroli uprawnien zdalnego dostepu (np. restrykcje czasowe)",
                "isCorrect": false
            },
            {
                "text": "pozwala na scentralizowane przechowywanie danych uwierzytelniajacych dla wielu punktow dostepowych",
                "isCorrect": true
            },
            {
                "text": "podnosi dostepnosc poprzez redundantne rozproszenie danych uwierzytelniajacych do wielu punktow dostepowych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół RADIUS (Remote Authentication Dial-In User Service) to protokół sieciowy, który służy do centralnego uwierzytelniania, autoryzacji i monitorowania (AAA, *Authentication, Authorization, and Accounting*) dostępu do sieci. Działa on w architekturze klient-serwer. Serwer RADIUS to centralna baza danych, która przechowuje informacje o użytkownikach, ich hasłach i uprawnieniach. Klienci RADIUS, np. routery, punkty dostępowe Wi-Fi lub serwery VPN, przesyłają zapytania o uwierzytelnienie do serwera RADIUS. Serwer RADIUS weryfikuje tożsamość użytkownika i przekazuje klientowi informację o tym, czy dostęp powinien zostać przyznany.\n\n**Odpowiedź 1: \"oferuje wymiane kluczy protokolu IPsec przy wykorzystaniu zarowno hasel jak i certyfikatow PKI\"**\nTa odpowiedź jest niepoprawna. RADIUS nie zajmuje się bezpośrednio wymianą kluczy dla protokołu IPsec. Wymiana kluczy dla IPsec odbywa się zazwyczaj przy użyciu protokołu IKE (*Internet Key Exchange*) i, choć RADIUS może *autentykować* użytkowników w konfiguracjach VPN wykorzystujących IPsec, nie bierze bezpośredniego udziału w wymianie kluczy IPsec. IPsec to mechanizm ochrony komunikacji warstwy sieciowej a RADIUS to usługa centralnego uwierzytelniania.\n\n**Odpowiedź 2: \"podnosi dostepnosc poprzez redundantne rozproszenie danych uwierzytelniajacych do wielu punktow dostepowych\"**\nTa odpowiedź jest niepoprawna. RADIUS nie podnosi dostępności poprzez rozproszenie danych. Wręcz przeciwnie, RADIUS *centralizuje* dane uwierzytelniające, tzn. są one przechowywane w jednym centralnym miejscu. Dostępność systemu można podnieść stosując wiele serwerów RADIUS, ale samo RADIUS nie zapewnia redundancji danych poprzez ich rozproszenie, to użytkownik lub administrator systemu musi zadbać o to. Chociaż RADIUS może obsługiwać wiele punktów dostępowych, to dane o autoryzacji są przechowywane w centralnej bazie.\n\n**Odpowiedź 3: \"udostepnia informacje niezbedne do kontroli uprawnien zdalnego dostepu (np. restrykcje czasowe)\"**\nTa odpowiedź jest niepoprawna. Chociaż RADIUS bierze udział w procesie *autoryzacji*, to nie definiuje sam, *jakie* uprawnienia ma dany użytkownik, na przykład o ograniczeniach czasowych.  RADIUS, jako mechanizm AAA, *udostępnia* informacje o uprawnieniach użytkownika, ale *nie zarządza* tymi uprawnieniami w sposób elastyczny, na przykład oferując ograniczenia czasowe; uprawnienia użytkownika są zarządzane gdzie indziej w systemie i RADIUS jedynie pobiera informacje o nich. \n\n**Odpowiedź 4: \"pozwala na scentralizowane przechowywanie danych uwierzytelniajacych dla wielu punktow dostepowych\"**\nTa odpowiedź jest poprawna. To jest główną funkcją protokołu RADIUS. Dzięki scentralizowanej bazie danych, administrator może w jednym miejscu zarządzać informacjami o użytkownikach, hasłach oraz uprawnieniach. Przykładowo, firma posiadająca wiele biur (punktów dostępowych) może zarządzać wszystkimi hasłami pracowników za pomocą jednego serwera RADIUS.\n\n**Odpowiedź 5: \"podnosi dostepnosc poprzez redundantne rozproszenie danych uwierzytelniajacych do wielu punktow dostepowych\"**\nTa odpowiedź jest niepoprawna. Dokładnie tak samo jak odpowiedź nr 2, mechanizm RADIUS nie zapewnia redundancji danych uwierzytelniających, a centralizuje je. Oczywiście można podnieść dostępność poprzez użycie kilku serwerów RADIUS w jednej strukturze sieciowej, ale sama koncepcja RADIUS nie zapewnia tej funkcji.\n\n**Podsumowanie:**\nRADIUS centralizuje uwierzytelnianie, co jest przydatne w dużych sieciach. Nie zarządza sam uprawnieniami (poza kontrolą autoryzacji), nie rozprasza danych w celu podniesienia dostępności oraz nie bierze udziału w wymianie kluczy IPsec. Kluczową funkcją RADIUS jest scentralizowane przechowywanie danych uwierzytelniających dla wielu punktów dostępowych, co sprawia, że odpowiedź nr 4 jest poprawna."
    },
    {
        "questionId": 153,
        "title": "Ktore okreslenie poprawnie opisuje protokol IKE?",
        "answers": [
            {
                "text": "oferuje uwierzytelnianie stron",
                "isCorrect": true
            },
            {
                "text": "korzysta z ICMP",
                "isCorrect": false
            },
            {
                "text": "korzysta z UDP",
                "isCorrect": true
            },
            {
                "text": "oferuje negocjacje algorytmow szyfrujacych",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół IKE (Internet Key Exchange) jest kluczowym elementem w ramach IPsec (Internet Protocol Security). Jego głównym zadaniem jest bezpieczne uzgodnienie parametrów ochrony (takich jak algorytmy szyfrowania i skrótu, oraz klucze sesyjne) pomiędzy dwoma urządzeniami chcącymi ustanowić zabezpieczone połączenie VPN. IKE nie przesyła samych danych użytkownika, lecz tworzy kanał komunikacyjny, który zapewnia bezpieczeństwo dla danych przesyłanych przez IPsec. Protokół IKE nie jest sam w sobie mechanizmem szyfrowania danych użytkownika, lecz jedynie mechanizmem umożliwiającym ustanowienie warunków, aby taki mechanizm szyfrowania mógł zostać wykorzystany.\n\n*   **\"oferuje uwierzytelnianie stron\" - PRAWDA.** IKE zapewnia uwierzytelnianie, co oznacza, że pozwala obu stronom (np. klientowi i serwerowi VPN) na wzajemną weryfikację tożsamości. Wykorzystuje do tego celu mechanizmy kryptografii asymetrycznej, gdzie strony wymieniają między sobą certyfikaty X.509 i potwierdzają swoją tożsamość poprzez sprawdzenie czy klucz publiczny zgadza się z podpisem z certyfikatu. Jest to fundamentalna funkcja protokołu IKE - bez uwierzytelnienia nie ma mowy o bezpiecznym uzgodnieniu parametrów połączenia. W praktyce, bez tego etapu, z dużą dozą prawdopodobieństwa nie bylibyśmy w stanie stwierdzić, czy nie łączymy się z podstawionym (podrobionym) serwerem, przez który nasz ruch byłby rejestrowany.\n\n*   **\"korzysta z ICMP\" - FAŁSZ.** Protokół IKE nie korzysta z ICMP (Internet Control Message Protocol). ICMP to protokół warstwy sieciowej służący do przesyłania komunikatów diagnostycznych i informacyjnych, np. o niedostępności hosta docelowego (komunikaty *Destination Unreachable*) czy żądania echa (*ping*). IKE działa na poziomie warstwy transportowej i używa głównie UDP, z rzadka TCP, do przesyłania swoich komunikatów kontrolnych związanych z nawiązywaniem połączenia. W praktyce, jeśli zablokujemy ruch ICMP, komunikacja z wykorzystaniem IKE nie ulegnie zakłóceniu.\n\n*   **\"korzysta z UDP\" - PRAWDA.** Protokół IKE do przesyłania swoich komunikatów, w których negocjuje parametry połączenia, wykorzystuje przede wszystkim protokół UDP (User Datagram Protocol). UDP jest protokołem bezpołączeniowym, co oznacza, że komunikacja nie wymaga nawiązania uprzedniego połączenia, jak to ma miejsce w TCP. Jest to szybsze rozwiązanie niż TCP. Mimo stosowania UDP, mechanizm IKE zapewnia wiarygodność i uporządkowanie przesyłanych komunikatów poprzez swoje własne mechanizmy (np. mechanizmy numerowania sekwencyjnego i przesyłania potwierdzeń). W praktyce, gdy mamy problemy z ustanowieniem tunelu IPsec, powinniśmy w pierwszej kolejności sprawdzić, czy na firewallu nie jest blokowany ruch UDP na porcie 500 (domyślny port IKE)\n\n*  **\"oferuje negocjacje algorytmow szyfrujacych\" - PRAWDA.** IKE jest odpowiedzialny za negocjację algorytmów szyfrujących, uwierzytelniających i skrótu. W praktyce, to dzięki temu etapowi uzgadniana jest wersja protokołu (np. SSL/TLS), konkretne algorytmy szyfrowania (np. AES, 3DES) oraz skrótu (np. SHA1, MD5). Każda ze stron proponuje swoje ustawienia, następnie dochodzi do uzgodnienia używanych algorytmów poprzez negocjację, gdzie obie strony wykorzystują najbezpieczniejsze mechanizmy, które są dostępne dla obu stron połączenia.  Jest to element kluczowy, umożliwiający dopasowanie poziomu bezpieczeństwa do możliwości obu stron połączenia. Dzięki temu, protokół IPsec może działać w różnorodnych środowiskach."
    },
    {
        "questionId": 154,
        "title": "Przed ktorymi atakami chroni poprawnie nawiazana sesja VPN (IPsec lub TLS):",
        "answers": [
            {
                "text": "TCP spoofing",
                "isCorrect": true
            },
            {
                "text": "SQLi",
                "isCorrect": false
            },
            {
                "text": "DNS spoofing",
                "isCorrect": true
            },
            {
                "text": "ARP spoofing",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół IPsec (Internet Protocol Security) i TLS (Transport Layer Security) to mechanizmy zapewniające poufność, integralność i autentyczność komunikacji w sieci. Ustanowienie sesji VPN za pomocą IPsec lub TLS tworzy zaszyfrowany tunel między dwoma punktami, chroniąc przesyłane dane przed podsłuchem i modyfikacją w trakcie transmisji. Jednakże, ochrona ta nie jest uniwersalna i nie obejmuje wszystkich rodzajów ataków.\n\n**TCP spoofing**, polega na podszywaniu się pod inny komputer poprzez sfałszowanie adresu IP źródłowego w nagłówku pakietu TCP i przejęciu kontroli nad sesją TCP. IPsec i TLS skutecznie chronią przed tym atakiem. Ustanowienie sesji VPN wymaga uzgodnienia kluczy kryptograficznych, co uniemożliwia napastnikowi z zewnątrz podszycie się pod jedną ze stron i wstrzyknięcie do legalnej sesji złośliwych pakietów TCP. Dodatkowo, dzięki szyfrowaniu zawartości pakietów TCP uniemożliwia się napastnikowi wyciąganie potrzebnych informacji np. numeru sesyjnego.\n\n**SQLi (SQL Injection)** to rodzaj ataku na aplikacje, w szczególności na systemy baz danych. Polega na wstrzykiwaniu złośliwego kodu SQL do zapytań bazodanowych, co może skutkować pozyskaniem lub zniszczeniem danych. VPN nie chroni przed SQLi. Jest to problem na poziomie aplikacji a nie sieci. Sesja VPN zapewnia ochronę na poziomie warstwy sieciowej, podczas gdy SQLi wykorzystuje lukę w kodzie aplikacji. Aplikacja podatna na SQLi będzie tak samo podatna niezależnie od tego czy ruch sieciowy do niej będzie przesyłany przez VPN czy też nie. Przykład: atakujący poprzez pole formularza strony www dodaje znak apostrofu(') przed tekstem i wysyła w ten sposób zmodyfikowane zapytanie do bazy danych. Zapytanie jest przesyłane poprzez VPN ale to nie niweluje w żaden sposób zagrożenia w postaci SQLi.\n\n**DNS spoofing**, zwane też zatruwaniem DNS (_ang. DNS cache poisoning_), to atak, w którym napastnik podmienia adres IP przypisany do danej nazwy domenowej w lokalnym cache serwera DNS lub klienta DNS. Sesja VPN chroni przed DNS spoofing. Dane, które przesyłane są między serwerami DNS mogą być fałszowane gdy nie są przesyłane przez chroniony kanał komunikacji VPN. Dzięki kryptograficznym mechanizmom IPsec/TLS napastnikowi nie uda się podmienić pakietów z informacjami o mapowaniu nazwy domenowej do adresu IP. \n\n**ARP spoofing**, to atak, w którym napastnik wysyła sfałszowane pakiety ARP, w celu powiązania swojego adresu MAC z adresem IP ofiary.  VPN nie chroni przed ARP spoofing. Atak ten działa w warstwie łącza danych, a IPsec i TLS działają na wyższych warstwach sieciowych. W sieci lokalnej można sfałszować tablicę ARP dowolnej stacji, niezależnie od tego czy komunikacja jest tunelowana czy nie. Mechanizmy IPsec/TLS zapewniają ochronę na warstwie sieciowej i wyższych. Mechanizmy protokołu ARP nie wykorzystują kryptografii do potwierdzenia wiarygodności odpowiedzi ARP. Przykład: w sieci lokalnej atakujący wysyła pakiety ARP podszywając się pod router (default gateway), a następnie przechwytuje ruch generowany przez stacje, które wysłały do niego pakiet ARP z zapytaniem o adres MAC routera. Stacja podłączona do sieci VPN jest narażona na ten atak w dokładnie taki sam sposób jak stacja, która nie używa VPN."
    },
    {
        "questionId": 155,
        "title": "Do zrealizowania zamaskowanego kanalu komunikacyjnego moze potencjalnie posluzyc:",
        "answers": [
            {
                "text": "metoda challenge-response na poziomie warstwy 2 OSI",
                "isCorrect": false
            },
            {
                "text": "port szeregowy",
                "isCorrect": false
            },
            {
                "text": "obciazenie systemu",
                "isCorrect": true
            },
            {
                "text": "kolejka wydruku",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Zamaskowany kanał komunikacyjny, inaczej kanał ukryty (ang. *covert channel*), to sposób przekazywania informacji wykorzystujący mechanizmy systemu komputerowego, które nie są do tego przeznaczone. Celem jest ukrycie faktu, że jakaś komunikacja w ogóle ma miejsce. Nie chodzi o ukrycie treści (jak w szyfrowaniu), ale o ukrycie samego kanału. Wykorzystuje się do tego nieoczywiste elementy systemu, na przykład obciążenie procesora lub kolejkę zadań do drukarki.\n\n*   **metoda challenge-response na poziomie warstwy 2 OSI:** Ta metoda jest mechanizmem uwierzytelniania w sieciach komputerowych, a w szczególności na poziomie warstwy 2 modelu OSI (warstwa łącza danych). Uwierzytelnianie *challenge-response* polega na tym, że strona inicjująca połączenie wysyła losowe wyzwanie (ang. *challenge*), na które druga strona musi odpowiedzieć w prawidłowy sposób(ang. *response*), aby potwierdzić swoją tożsamość.  Mimo, że nie jest to otwarta komunikacja, nie jest to mechanizm zamaskowany. Metoda ta nie nadaje się na ukryty kanał komunikacyjny, gdyż jest to jawna, znana i dobrze udokumentowana metoda uwierzytelniania.\n\n*   **port szeregowy:** Port szeregowy, np. RS-232, jest fizycznym interfejsem komunikacyjnym w komputerze.  Wykorzystanie portu szeregowego jako kanału komunikacyjnego jest ewidentne, gdyż sam fakt jego wykorzystania jest jawny. Do komunikacji tym kanałem potrzebny jest dedykowany program który wysyłałby dane, więc tak utworzona komunikacja nie jest zamaskowana. Nie można tego kanału wykorzystać do zamaskowania faktu komunikacji.\n\n*   **obciążenie systemu:**  Obciążenie systemu (np. procesora lub pamięci) jest parametrem, który może być zmieniany. Na przykład, proces może celowo zużywać więcej zasobów procesora aby przesłać bit \"1\", a mniej aby przesłać bit \"0\". Zmiany obciążenia systemu są bardzo trudne do zauważenia przez użytkownika, czy nawet przez monitor systemowy.  Można w ten sposób utworzyć wolny i bardzo nieefektywny kanał komunikacyjny, wykorzystujący \"normalne\" zmiany obciążenia systemu. Jest to przykład wykorzystania parametrów systemu do stworzenia zamaskowanego kanału komunikacyjnego.\n\n*   **kolejka wydruku:** Kolejka wydruku jest mechanizmem służącym do zarządzania zadaniami drukowania w systemie operacyjnym. Proces, który chce przesłać informacje może tworzyć lub usuwać zadania w kolejce drukarki, w taki sposób można przedstawić informacje binarne np: stworzenie zadania w kolejce to \"1\", brak nowego zadania w kolejce to \"0\",  lub tworzenie zadań o określonej wielkości (np. liczba bajtów na rozmiar danego bitu). Mechanizm kolejki wydruku jest jawnym kanałem, ale samo wykorzystanie tego mechanizmu do przekazywania poufnych danych jest niewidoczne. Użytkownik z zewnątrz nie ma możliwości wywnioskowania, iż kanał jest wykorzystywany do komunikacji. W ten sposób powstaje nieoczywisty, zamaskowany kanał komunikacyjny.\n\nW praktyce, ataki wykorzystujące zamaskowane kanały komunikacyjne są bardzo trudne do wykrycia.  Na przykład, złośliwe oprogramowanie może wykorzystać zmiany obciążenia procesora do przesyłania skradzionych informacji, a te zmiany, z punktu widzenia zwykłego użytkownika, nie będą się niczym wyróżniały od \"normalnego\" zużycia zasobów przez system. Albo malware może  ukrywać komunikację w plikach tymczasowych lub w kolejkach drukowania, gdzie są tworzone zadania wydruku o pozornie losowym rozmiarze i nazwie w celu przesłania ukrytej wiadomości."
    },
    {
        "questionId": 156,
        "title": "Wskaz kto moze rozszyfrowac plik zaszyfrowany mechanizmem EFS:",
        "answers": [
            {
                "text": "kazdy agent DRA istniejacy w momencie deszyfrowania pliku",
                "isCorrect": false
            },
            {
                "text": "wlasciciel pliku",
                "isCorrect": true
            },
            {
                "text": "administrator",
                "isCorrect": false
            },
            {
                "text": "kazdy DRA istniejacy w momencie szyfrowania pliku",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm EFS (Encrypting File System) w systemie Windows służy do szyfrowania plików i folderów na poziomie systemu plików. Używa on kombinacji szyfrowania symetrycznego i asymetrycznego. Gdy użytkownik szyfruje plik, system generuje losowy klucz symetryczny, który służy do szyfrowania danych pliku. Ten klucz symetryczny jest następnie szyfrowany kluczem publicznym właściciela pliku, a zaszyfrowany klucz symetryczny jest przechowywany wraz z plikiem.\n\n**Odpowiedź 1: \"kazdy agent DRA istniejacy w momencie deszyfrowania pliku\" - NIEPOPRAWNA.** Agenci odzyskiwania danych (DRA) są specjalnie wyznaczeni użytkownicy (często administratorzy), którym przypisuje się certyfikaty umożliwiające odzyskiwanie plików zaszyfrowanych przy pomocy EFS. DRA mają dostęp do danych, gdy wystąpi problem z dostępem właściciela pliku. Jednakże, aby DRA mógł odszyfrować plik, musi posiadać certyfikat ważny w momencie szyfrowania pliku. DRA dodany po zaszyfrowaniu pliku nie będzie posiadał odpowiedniego certyfikatu i nie będzie mógł odszyfrować danych.\n\n**Odpowiedź 2: \"wlasciciel pliku\" - POPRAWNA.** Właściciel pliku ma przypisany do certyfikatu swój klucz prywatny, który wykorzystywany jest do odszyfrowania klucza symetrycznego. Klucz symetryczny jest wykorzystywany do rozszyfrowania danych pliku. Właściciel pliku jest główną osobą uprawnioną do rozszyfrowania pliku, a DRA jest mechanizmem awaryjnym, gdy właściciel utraci dostęp do swoich kluczy.\n\n**Odpowiedź 3: \"administrator\" - NIEPOPRAWNA.** Administrator sam w sobie nie ma automatycznego dostępu do plików zaszyfrowanych mechanizmem EFS. Aby móc odszyfrować zaszyfrowane pliki administrator musi być ustanowiony jako DRA, musi być aktywny jako DRA w momencie szyfrowania pliku oraz posiadać certyfikat powiązany z certyfikatem użytkownika zaszyfrowującego plik. W przeciwnym wypadku administrator nie posiada dostępu do zaszyfrowanych danych.\n\n**Odpowiedź 4: \"kazdy DRA istniejacy w momencie szyfrowania pliku\" - POPRAWNA.** Każdy agent DRA, który był zdefiniowany w momencie zaszyfrowania pliku, posiada klucz prywatny, który odpowiada kluczowi publicznemu użytemu do zaszyfrowania pliku. Dzięki temu DRA może rozszyfrować klucz symetryczny i odzyskać dane pliku. Klucz DRA który był ważny w momencie zaszyfrowania pliku jest przechowywany w nagłówku pliku co umożliwia odzyskiwanie danych.\n\n**Przykład praktyczny:**\nUżytkownik \"Jan\" szyfruje plik za pomocą EFS. W tym czasie zdefiniowany jest administrator jako DRA. Użytkownik \"Jan\" traci swój klucz prywatny i nie może odczytać pliku. Używając mechanizmu DRA administrator może odszyfrować plik gdyż posiada klucz do niego. Teraz jeżeli dodamy użytkownika \"Piotr\" jako DRA po zaszyfrowaniu pliku, to Piotr nie będzie mógł odczytać tego pliku, gdyż nie istniał on jako DRA w momencie szyfrowania tego pliku i nie posiada certyfikatu umożliwiającego odzyskanie klucza.\n\nPodsumowując, tylko właściciel pliku (posiadający klucz prywatny) i agenci DRA, którzy istnieli w momencie szyfrowania pliku, mogą rozszyfrować plik zaszyfrowany mechanizmem EFS. Użycie DRA jest mechanizmem odzyskiwania danych w sytuacjach awaryjnych, kiedy właściciel pliku utraci swój klucz prywatny, a jego głównym zadaniem jest ochrona przed utratą danych i nie umożliwia uzyskania dostępu osobom niepowołanym do zaszyfrowanych danych."
    },
    {
        "questionId": 157,
        "title": "Mechanizm Lock-and-Key:",
        "answers": [
            {
                "text": "wymaga uwierzytelnienia uzytkownika, np. za pomoca RADIUS-a",
                "isCorrect": true
            },
            {
                "text": "automatycznie blokuje stacje niespelniajace wymagan polityki bezpieczenstwa",
                "isCorrect": false
            },
            {
                "text": "moze byc wykorzystywany do tymczasowego uzyskania uprzywilejowanego dostepu do sieci wewnetrznej z zewnatrz",
                "isCorrect": true
            },
            {
                "text": "sluzy do translacji regul filtracji z jednej zapory na inna",
                "isCorrect": false
            },
            {
                "text": "jest podatny na IP spoofing",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Mechanizm \"lock-and-key\" w kontekście bezpieczeństwa systemów komputerowych odnosi się do podstawowej metody kontroli dostępu, gdzie identyfikacja podmiotu(np. użytkownika lub urządzenia) jest weryfikowana przed przyznaniem dostępu do zasobów.  W przypadku systemów komputerowych najczęściej przybiera to postać uwierzytelniania za pomocą hasła, certyfikatu lub innego tokena (klucza), który ma być zgodny z zapisanym w systemie odpowiednikiem (zamkiem). Ta koncepcja ma swoje ograniczenia, które należy uwzględnić przy budowie systemów bezpieczeństwa. \n\n*   **\"wymaga uwierzytelnienia uzytkownika, np. za pomoca RADIUS-a\"** - **PRAWDA.** Mechanizm \"lock-and-key\" zawsze wymaga uwierzytelnienia, aby zweryfikować tożsamość podmiotu. Protokół RADIUS (Remote Authentication Dial-In User Service) jest jednym z wielu, który może być wykorzystany do tej weryfikacji.  RADIUS to centralny system uwierzytelniania i autoryzacji używany w sieciach, gdzie użytkownicy zdalnie logują się do zasobów sieciowych.  Klient RADIUS(np. Serwer VPN) przekazuje dane logowania użytkownika do serwera RADIUS, który weryfikuje te dane i odsyła odpowiedź czy zezwolić na dostęp. Jest to praktyczny przykład metody \"lock-and-key\", gdzie hasło lub certyfikat jest \"kluczem\" pasującym do \"zamka\", którym jest weryfikacja tożsamości użytkownika.\n\n*   **\"automatycznie blokuje stacje niespelniajace wymagan polityki bezpieczenstwa\"** - **FAŁSZ.** Mechanizm \"lock-and-key\" sam w sobie nie realizuje automatycznego blokowania stacji. Blokowanie hostów, które nie spełniają określonych kryteriów bezpieczeństwa, jest charakterystyczne dla systemów IPS (Intrusion Prevention Systems) lub mechanizmów bazujących na zaporach sieciowych, które mogą wykorzystywać różne metody filtrowania ruchu, w tym sprawdzenie źródłowego adresu IP. \"Lock-and-key\" skupia się głównie na uwierzytelnieniu i autoryzacji użytkownika, a nie na automatycznym egzekwowaniu polityk na poziomie stacji.\n\n*   **\"moze byc wykorzystywany do tymczasowego uzyskania uprzywilejowanego dostepu do sieci wewnetrznej z zewnatrz\"** - **PRAWDA.** Mechanizm \"lock-and-key\" może być wykorzystywany do uwierzytelniania użytkowników VPN, umożliwiając tym samym uzyskanie zdalnego dostępu do zasobów wewnętrznej sieci. Użytkownik podający odpowiedni klucz ma dostęp do autoryzowanej sieci. W przypadku VPN mechanizm \"lock-and-key\" z wykorzystaniem certyfikatu lub hasła, pozwala uprawnionemu użytkownikowi na uzyskanie dostępu do sieci firmowej z zewnątrz przez tunel VPN. W systemach operacyjnych opartych na Linux można wykorzystać do tego protokół OpenVPN z wykorzystaniem np. pliku z tajnym kluczem. \n\n*   **\"sluzy do translacji regul filtracji z jednej zapory na inna\"** - **FAŁSZ**. Mechanizm \"lock-and-key\" nie jest związany z translacją reguł filtracji pomiędzy różnymi zaporami ogniowymi.  Translacja reguł filtracji to konwersja reguł z jednej konfiguracji zapory do konfiguracji innej zapory. Proces ten wymaga precyzyjnego przełożenia reguł, aby zachować zamierzone bezpieczeństwo. Nie ma on nic wspólnego z \"lock-and-key\".\n\n*    **\"jest podatny na IP spoofing\"** - **PRAWDA.** Mechanizm \"lock-and-key\" bazujący wyłącznie na adresach IP jako identyfikatorze jest podatny na IP spoofing. IP spoofing to technika, w której atakujący fałszuje adres IP źródła w pakietach sieciowych, podszywając się pod zaufany komputer. Jeśli system uwierzytelnia się tylko na podstawie adresów IP(uważając je za element identyfikujący \"klucz\") to atakujący, podszywając się pod dozwolony adres IP, może ominąć ten system kontroli dostępu i w ten sposób uzyskać nieautoryzowany dostęp. Dodatkowe mechanizmy takie jak uwierzytelnienie hasłem czy certyfikatem mogą w znaczny sposób utrudnić atak, lecz w konfiguracji, w której liczy się tylko IP nadal jest ten atak możliwy. \n\nPodsumowując, mechanizm \"lock-and-key\", choć użyteczny w kontrolowaniu dostępu, nie jest idealnym zabezpieczeniem i może być elementem bardziej złożonych metod kontroli dostępu, ale zawsze wymaga dodatkowej ochrony przed niebezpieczeństwami pochodzącymi z zewnątrz (np. IP spoofing)."
    },
    {
        "questionId": 158,
        "title": "Protokol SSL/TLS oferuje:",
        "answers": [
            {
                "text": "uwierzytelnianie obustronne uczestnikow komunikacji",
                "isCorrect": true
            },
            {
                "text": "szyfrowanie transmisji na poziomie warstwy sesji OSI",
                "isCorrect": true
            },
            {
                "text": "uwierzytelnianie SSO",
                "isCorrect": false
            },
            {
                "text": "szyfrowanie transmisji na poziomie warstwy transportowej OSI",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSL/TLS (Secure Sockets Layer/Transport Layer Security) zapewnia bezpieczną komunikację, obejmującą uwierzytelnianie i szyfrowanie. Działa w warstwie sesji modelu OSI, czyli warstwie, która zajmuje się ustanawianiem, zarządzaniem i zamykaniem sesji między aplikacjami, a nie bezpośrednio z transportem danych.\n\n**Odpowiedź 1: \"uwierzytelnianie obustronne uczestników komunikacji\"**\nJest to **poprawna odpowiedź**. SSL/TLS oferuje możliwość uwierzytelniania zarówno serwera, jak i klienta. Oznacza to, że zarówno serwer, jak i klient mogą zweryfikować tożsamość drugiej strony przed rozpoczęciem właściwej komunikacji. Serwer przedstawia klientowi certyfikat, który poświadcza jego tożsamość. Klient może (opcjonalnie) przedstawić swój certyfikat, aby serwer mógł go uwierzytelnić. W praktyce, serwery zazwyczaj wymagają uwierzytelnienia tylko od klientów, gdy wchodzą w interakcję z poufnymi zasobami.\n\n**Odpowiedź 2: \"szyfrowanie transmisji na poziomie warstwy sesji OSI\"**\nJest to **poprawna odpowiedź**. SSL/TLS działa na poziomie warstwy sesji (ang. _session layer_). Warstwa sesji jest warstwą powyżej warstwy transportowej (TCP/UDP), a poniżej warstwy aplikacji. To właśnie w tej warstwie ustalane są parametry szyfrowania i klucze, a same dane (pakiety z warstwy aplikacji) są szyfrowane przed ich przekazaniem warstwie transportowej. Typowym przykładem jest HTTPS, które używa protokołu HTTP w warstwie aplikacji i protokołu SSL/TLS w warstwie sesji. To SSL/TLS szyfruje dane zanim protokół transportowy (TCP) prześle je przez sieć.\n\n**Odpowiedź 3: \"uwierzytelnianie SSO\"**\nJest to **niepoprawna odpowiedź**. SSO (Single Sign-On), czyli \"logowanie jednokrotne\", to mechanizm, który pozwala użytkownikowi zalogować się raz i uzyskać dostęp do wielu różnych zasobów lub aplikacji, które bazują na systemie zaufania. Chociaż SSL/TLS może być elementem systemów SSO, to sam w sobie nie jest mechanizmem SSO. SSL/TLS zapewnia uwierzytelnianie i szyfrowanie połączenia, a nie logowanie jednokrotne. System SSO może używać SSL/TLS do ochrony swojej komunikacji, ale to są dwie odrębne koncepcje.\n\n**Odpowiedź 4: \"szyfrowanie transmisji na poziomie warstwy transportowej OSI\"**\nJest to **niepoprawna odpowiedź**. Protokół SSL/TLS zapewnia szyfrowanie na poziomie warstwy sesji OSI. Warstwa transportowa (TCP/UDP) zapewnia transport danych, a SSL/TLS szyfruje te dane pomiędzy aplikacjami w warstwie sesji. SSL/TLS jest warstwą pośrednią (protokołem sesji) między warstwą aplikacji (HTTP, SMTP) a transportu (TCP), i to na tym etapie szyfrowanie jest wykonywane."
    },
    {
        "questionId": 159,
        "title": "Wyobrazmy sobie serwer udostepniajacy wybranym podsieciom dwie uslugi: www i ftp. Zapewnienie kontroli dostepu, np. za pomoca narzedzia personal firewall (lub wrappera polaczen) tylko do jednej z tych uslug stanowi:",
        "answers": [
            {
                "text": "realizacje predykatu ograniczonej kontroli dostepu (MAC)",
                "isCorrect": false
            },
            {
                "text": "naruszenie warunku spojnosci pionowej zabezpieczen",
                "isCorrect": false
            },
            {
                "text": "naruszenie warunku spojnosci poziomej zabezpieczen",
                "isCorrect": true
            },
            {
                "text": "naruszenie zasad poziomu B1/TCSEC i EAL4/CC",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Podstawową koncepcją testowaną w tym pytaniu jest **spójność pozioma zabezpieczeń**. Spójność pozioma zabezpieczeń oznacza, że wszystkie elementy systemu informatycznego znajdujące się na tym samym poziomie (warstwie, posiadające ten sam rodzaj funkcjonalności) powinny być zabezpieczone z podobnym stopniem staranności. Chodzi o to, że w systemie, w którym występują elementy o podobnym charakterze nie powinny być stosowane różne mechanizmy bezpieczeństwa. Niezastosowanie spójności poziomej stwarza słabość całego systemu. W pytaniu chodzi o to, że dwie podobne usługi sieciowe, na przykład www i ftp, powinny być zabezpieczone w podobny sposób. Zabezpieczenie tylko jednej z nich stwarza zagrożenie ominięcia zabezpieczeń przez potencjalnego intruza.\n\n*   **\"realizacje predykatu ograniczonej kontroli dostępu (MAC)\"** - Ta odpowiedź jest niepoprawna, ponieważ **MAC** (Mandatory Access Control) to model kontroli dostępu, w którym uprawnienia są narzucane przez system, a nie przyznawane przez właściciela. Chociaż zapora sieciowa i _wrapper_ połączeń to narzędzia związane z kontrolą dostępu, pytanie skupia się na *niespójności* zabezpieczeń, a nie na samym fakcie ich istnienia czy na typie użytego mechanizmu kontroli dostępu. Wybór mechanizmu MAC nie zmienia faktu, że nie wszystkie usługi są zabezpieczone w odpowiedni sposób.\n\n*   **\"naruszenie warunku spójności pionowej zabezpieczeń\"** - Ta odpowiedź jest niepoprawna, ponieważ **spójność pionowa** odnosi się do ochrony ścieżki komunikacyjnej między punktami komunikacyjnymi (np. aplikacja-system operacyjny-warstwa sieciowa). Chodzi o to, by cała ścieżka komunikacyjna była chroniona przed nieuprawnionym dostępem. W tym pytaniu nie mamy do czynienia z taką sytuacją, tylko z niejednorodnym zastosowaniem zabezpieczeń dla różnych usług pracujących na tym samym poziomie.\n\n*   **\"naruszenie warunku spójności poziomej zabezpieczeń\"** - Ta odpowiedź jest poprawna. Jak zostało wyjaśnione na początku, **spójność pozioma** oznacza stosowanie jednolitych zabezpieczeń dla elementów tego samego rodzaju. Zabezpieczenie tylko jednej z dwóch usług, www i ftp, narusza zasadę spójności poziomej zabezpieczeń, ponieważ pozostawia drugą z tych usług niechronioną i potencjalnie otwartą na ataki. Przykładowo, jeśli serwer WWW jest chroniony zapora, ale serwer FTP nie, intruz może wykorzystać niechroniony protokół FTP, aby dostać się do systemu, a następnie - może potencjalnie wykorzystać ten dostęp do ataku na siec wewnętrzną.\n\n*  **\"naruszenie zasad poziomu B1/TCSEC i EAL4/CC\"** - Ta odpowiedź jest niepoprawna. **TCSEC** (Trusted Computer System Evaluation Criteria) i **CC** (Common Criteria) to standardy bezpieczeństwa systemów komputerowych, określające *poziom zaufania* do danego systemu, a nie odnoszą się one bezpośrednio do kwestii poziomej spójności zabezpieczeń. Zdefiniowane klasy bezpieczeństwa, jak np. B1/TCSEC czy EAL4/CC określają szereg wytycznych w celu uzyskania wysokiego stopnia ochrony. Niemniej jednak, pominięcie jakiegokolwiek elementu w zabezpieczeniach sprawi, że nawet jeśli system spełnia wymogi poziomu B1, to nie będzie spełniał wymagań spójności poziomej. \n\nPodsumowując, odpowiedź podkreśla, że ochrona systemu wymaga spójnego podejścia, gdzie elementy tego samego rodzaju (np. różne usługi sieciowe) otrzymują taki sam poziom ochrony. Seletywne stosowanie zapory (lub _wrappera_) do tylko jednej usługi tworzy luki bezpieczeństwa."
    },
    {
        "questionId": 160,
        "title": "Ktory termin okresla ochrone informacji przed nieautoryzowanym jej zmodyfikowaniem:",
        "answers": [
            {
                "text": "autoryzacja",
                "isCorrect": false
            },
            {
                "text": "niezaprzeczalnosc",
                "isCorrect": false
            },
            {
                "text": "spojnosc",
                "isCorrect": false
            },
            {
                "text": "integralnosc",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "**Integralność** (ang. *integrity*) w kontekście bezpieczeństwa systemów komputerowych oznacza ochronę danych przed nieautoryzowaną modyfikacją lub zniszczeniem. Chodzi o to, by dane przechowywane i przesyłane były dokładne, kompletne i niezmienione przez niepowołane osoby czy oprogramowanie. Integralność jest jedną z trzech podstawowych cech bezpieczeństwa informacji, obok poufności (ang. *confidentiality*) i dostępności (ang. *availability*), tworzących tzw. triadę CIA. Przykładowo, system bazodanowy, który przechowuje informacje finansowe firmy, musi zapewniać integralność danych – zmiany danych powinny być dokonywane tylko przez uprawnionych użytkowników i powinny być dokładne, aby uniknąć strat finansowych i utraty zaufania klientów. \n\n*   **autoryzacja** -  (ang. *authorization*) to proces nadawania użytkownikom odpowiednich uprawnień dostępu do zasobów systemu (np. danych, plików, usług).  Autoryzacja nie chroni bezpośrednio przed zmianą danych, a jedynie kontroluje, kto może w ogóle podejmować próby dostępu, w tym modyfikacji. Przykładowo, system operacyjny pozwala administratorowi na zmianę konfiguracji, zwykły użytkownik ma do tego ograniczone uprawnienia. Autoryzacja jest ważnym elementem bezpieczeństwa, ale nie odnosi się wprost do ochrony przed modyfikacją, którą zapewnia integralność. \n*   **niezaprzeczalność** - (ang. *non-repudiation*) zapewnia, że nadawca danych nie może zaprzeczyć, że te dane wysłał, a odbiorca nie może zaprzeczyć, że te dane otrzymał.  Niezaprzeczalność jest potrzebna w systemach, gdzie ważna jest odpowiedzialność za wykonane akcje. Mechanizm ten nie ma bezpośredniego wpływu na ochronę samych danych, tylko na pewność co do pochodzenia i otrzymania informacji. Na przykład w transakcjach handlowych gdzie obie strony powinny mieć pewność, że operacja została faktycznie wykonana i nikt się tego nie wyprze.\n*   **spójność** - w tym kontekście jest pojęciem bardziej ogólnym, nie odnosi się bezpośrednio do bezpieczeństwa, ale jest ogólnym pojęciem, które może być utożsamiane z integralnością. W informatyce spójność odnosi się do stanu systemu lub zbioru danych, w którym elementy są ze sobą powiązane w logiczny i poprawny sposób, czyli nie ma niespójnych danych. Spójność nie definiuje sposobu ochrony przed modyfikacją, chociaż ma podobne cele. Na przykład system plików w systemie operacyjnym musi być spójny, czyli struktura danych w systemie plików nie może być uszkodzona ani niekompletna.\n\n*   **integralność** - (ang. *data integrity*) jest kluczowym elementem w ochronie danych przed nieautoryzowanymi zmianami. Mechanizmy zapewniające integralność mogą obejmować sumy kontrolne, algorytmy skrótu, podpisy cyfrowe czy systemy kontroli dostępu. Dla przykładu, jeśli plik wykonywalny systemu operacyjnego, zostanie zmieniony przez złośliwe oprogramowanie, mechanizmy ochrony integralności powinny wykryć to naruszenie, co pozwoli uniknąć przejęcia kontroli nad systemem."
    },
    {
        "questionId": 161,
        "title": "Ktore z ponizszych okreslen opisuja mechanizm CAP (capabilities):",
        "answers": [
            {
                "text": "opisuje prawa uwierzytelnionego uzytkownika w bilecie systemu Kerberos",
                "isCorrect": false
            },
            {
                "text": "specyfikuje w certyfikacie klucza publicznego mozliwosci wykorzystania danego klucza",
                "isCorrect": false
            },
            {
                "text": "pozwala na rozdzielenie uprawnien ogolno administracyjnych na szczegolowe podzbiory",
                "isCorrect": true
            },
            {
                "text": "przydziela uzytkownikowi pewne informacje uwierzytelniajace przedstawiane nastepnie podczas dostepu do poszczegolnych uslug",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm *capabilities* (CAP) jest rozszerzeniem standardowych uprawnień w systemach Linux, które pozwala na rozdzielenie uprawnień ogólnoadministracyjnych (takich jak uprawnienia *super-użytkownika*, czyli *root*) na zbiór mniejszych, szczegółowych uprawnień, które mogą być nadawane konkretnym procesom lub użytkownikom. W tradycyjnym systemie uprawnień, proces, który musi wykonać operację wymagającą uprawnień administratora, musi działać z pełnymi uprawnieniami *root*. Natomiast mechanizm *capabilities* pozwala procesowi uzyskać dostęp tylko do tych uprawnień, które są niezbędne do wykonania konkretnej operacji, a nie wszystkich. \n\n* **Odpowiedź: \"opisuje prawa uwierzytelnionego uzytkownika w bilecie systemu Kerberos\"**\n  - Jest to **niepoprawna** odpowiedź. System Kerberos zajmuje się *uwierzytelnianiem*, czyli weryfikacją tożsamości użytkownika, a nie *autoryzacją*, czyli przydzielaniem uprawnień. Kerberos wydaje bilety (_tickets_), które umożliwiają dostęp do usług, ale sam bilet nie opisuje *capabilities* ani uprawnień użytkownika w systemie operacyjnym.  Bilet Kerberosa pozwala w danym czasie korzystać z określonej usługi, ale system operacyjny musi mieć inne mechanizmy do kontroli tego co dany użytkownik z danym biletem może zrobić w systemie plików i innymi obiektami.\n\n* **Odpowiedź: \"specyfikuje w certyfikacie klucza publicznego mozliwosci wykorzystania danego klucza\"**\n   - Jest to **niepoprawna** odpowiedź. Certyfikat klucza publicznego, w standardzie X.509, opisuje klucz publiczny i dane jego właściciela oraz zawiera informacje o zastosowaniu klucza, np. czy jest to klucz do podpisywania cyfrowego, czy szyfrowania. Informacje zawarte w certyfikacie nie określają możliwości, czy szczegółowych *capabilities*, w kontekście systemu operacyjnego. Zastosowanie certyfikatu jest określone w dodatkowej sekcji w certyfikacie (np. Certificate Key Usage) - nie ma to jednak nic wspólnego z uprawnieniami w systemie operacyjnym.\n\n*   **Odpowiedź: \"pozwala na rozdzielenie uprawnien ogolno administracyjnych na szczegolowe podzbiory\"**\n    - Jest to **poprawna** odpowiedź. Mechanizm *capabilities* właśnie to robi. Zamiast przypisywać uprawnienia *root* do procesu, można przypisać do niego jedynie uprawnienie do wykonywania konkretnej operacji np. wiązania gniazda do portu o numerze mniejszym niż 1024 (wymagane przez serwery nasłuchujące), czy odczytywania/zapisu konkretnych plików. Przykładowo, serwer www, normalnie musiałby działać pod kontrolą *root*, ale dzięki capabilities może tylko wykonywać powiązanie portu 80 i czytać pliki html z danego katalogu, bez możliwości wykonywania poleceń systemowych, co znacząco zwiększa bezpieczeństwo systemu.\n\n*   **Odpowiedź: \"przydziela uzytkownikowi pewne informacje uwierzytelniajace przedstawiane nastepnie podczas dostepu do poszczegolnych uslug\"**\n    - Jest to **niepoprawna** odpowiedź. *Capabilities* są mechanizmem *autoryzacji*, czyli przydzielania uprawnień, a nie *uwierzytelniania*, czyli weryfikacji tożsamości.  Proces uwierzytelniania dostarcza informacje o użytkowniku, a mechanizm *capabilities* określa, jakie ten użytkownik lub proces ma uprawnienia. Przykładowo użytkownik loguje się w systemie, dostaje informacje uwierzytelniające, które są używane przy wykonywaniu czynności, ale za te czynności uprawnienia daje mechanizm *capabilities*."
    },
    {
        "questionId": 162,
        "title": "Ktorego typu ataku dotyczy nastepujacy opis: Atak ten przeprowadza osoba, ktora wobec kazdej z dwoch uprawnionych stron komunikacji podszywa sie za przeciwna strone, posredniczac w przesylaniu danych:",
        "answers": [
            {
                "text": "aktywny",
                "isCorrect": true
            },
            {
                "text": "zdalny",
                "isCorrect": false
            },
            {
                "text": "pasywny",
                "isCorrect": false
            },
            {
                "text": "lokalny",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Atak aktywny to rodzaj ataku w bezpieczeństwie komputerowym, w którym atakujący nie tylko obserwuje przesyłane dane, ale również aktywnie wchodzi w interakcję z komunikacją, modyfikując ją lub generując własne dane. W przeciwieństwie do ataku pasywnego, który skupia się jedynie na podsłuchiwaniu, atak aktywny bezpośrednio ingeruje w proces wymiany informacji. Przykładem ataku aktywnego jest atak \"man-in-the-middle\", gdzie napastnik podszywa się pod każdą z komunikujących się stron, przejmując i modyfikując przesyłane wiadomości.\n\n*   **aktywny**: Jest to **poprawna** odpowiedź. Opis w pytaniu idealnie charakteryzuje atak aktywny. Atakujący nie tylko obserwuje komunikację, ale aktywnie w niej uczestniczy, podszywając się pod obie strony i modyfikując przesyłane dane. Wyobraźmy sobie transakcję bankową online. Atakujący, stosując atak man-in-the-middle, przechwytuje informacje przesyłane między klientem a bankiem, np. numery konta i hasła, następnie zmienia numer konta na swój, a resztę informacji przesyła dalej do banku. W taki sposób klient myśli, że zlecił przelew na właściwe konto.\n\n*   **zdalny**: Jest to **niepoprawna** odpowiedź. Atak zdalny odnosi się do miejsca, z którego przeprowadzany jest atak - czyli spoza systemu. Natomiast, w pytaniu opisany jest charakter ataku (ingerencja w komunikację), a nie jego lokalizacja. Atakujący w scenariuszu opisanym w pytaniu, może przeprowadzić atak zdalny, będąc poza siecią atakowanego, ale również lokalny - jeśli w sieci działa jako jeden z użytkowników.\n\n*   **pasywny**: Jest to **niepoprawna** odpowiedź. Atak pasywny polega na monitorowaniu komunikacji bez jej modyfikowania. Atakujący jedynie podsłuchuje dane, nie ingerując w ich przesyłanie. Przykładem może być przechwytywanie nieszyfrowanych haseł w sieci bezprzewodowej. Opis w pytaniu jednoznacznie wskazuje, że atakujący modyfikuje przesyłane dane, a nie tylko je przechwytuje.\n\n*   **lokalny**: Jest to **niepoprawna** odpowiedź. Atak lokalny oznacza, że napastnik ma już dostęp do systemu i próbuje zwiększyć swoje uprawnienia, a nie jak w pytaniu manipuluje komunikacją między dwiema stronami. Atak lokalny może przykładowo wystąpić, jeśli programista złośliwego oprogramowania wykorzysta lukę w kodzie aplikacji, która działa w systemie ofiary w celu zwiększenia uprawnień do poziomu administracyjnego, umożliwiającego dostęp do danych, których normalny użytkownik nie powinien zobaczyć."
    },
    {
        "questionId": 163,
        "title": "Co zapewnia uwierzytelnianie przez posiadanie?",
        "answers": [
            {
                "text": "poufnosc",
                "isCorrect": false
            },
            {
                "text": "integralnosc poufnosc i integralnosc",
                "isCorrect": false
            },
            {
                "text": "integralnosc",
                "isCorrect": false
            },
            {
                "text": "zadne z powyzszych",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Uwierzytelnianie przez posiadanie, znane również jako \"proof by possession\", polega na weryfikacji tożsamości użytkownika poprzez sprawdzenie, czy posiada on dany obiekt, na przykład kartę elektroniczną, token sprzętowy, lub klucz kryptograficzny. Ten sposób uwierzytelniania koncentruje się na *tym, co użytkownik ma*, aby potwierdzić jego tożsamość.\n\n**Odpowiedź \"poufnosc\" jest niepoprawna**, ponieważ samo posiadanie elementu uwierzytelniającego nie zapewnia poufności danych. Poufność, czyli ochrona informacji przed nieautoryzowanym ujawnieniem, wymaga dodatkowych mechanizmów takich jak szyfrowanie danych. Na przykład karta dostępu do budynku nie gwarantuje, że nikt inny nie zobaczy, jakie dokumenty użytkownik przenosi w teczce.\n\n**Odpowiedź \"integralnosc poufnosc i integralnosc\" jest niepoprawna**, z tych samych powodów co \"poufnosc\". Integralnosc, czyli ochrona danych przed nieautoryzowaną modyfikacją lub zniszczeniem, wymaga zastosowania dodatkowych mechanizmów takich jak podpisy cyfrowe czy sumy kontrolne, niezależnie od tego jak użytkownik się uwierzytelnił. Przykładowo, token jednorazowych haseł pozwala użytkownikowi uzyskać dostęp do systemu, ale nie chroni danych, które użytkownik przetwarza w systemie.\n\n**Odpowiedź \"integralnosc\" jest niepoprawna**, z tych samych powodów co \"poufnosc\". Mechanizm uwierzytelniania *tym co użytkownik ma* nie chroni integralności danych.\n\n**Odpowiedź \"zadne z powyzszych\" jest poprawna**.  Uwierzytelnianie przez posiadanie jedynie potwierdza tożsamość użytkownika, który posługuje się danym obiektem. Nie ma żadnego bezpośredniego związku z zapewnieniem poufności ani integralności danych. Realizacja tych cech wymaga innych, dodatkowych mechanizmów bezpieczeństwa."
    },
    {
        "questionId": 164,
        "title": "Bezposrednim celem ataku metoda przepelnienia bufora jest:",
        "answers": [
            {
                "text": "wypchniecie wartosci zmiennych globalnych programu poza chroniony segment danych",
                "isCorrect": false
            },
            {
                "text": "uszkodzenie zawartosci segmentu danych i w efekcie zawieszenie procesu",
                "isCorrect": false
            },
            {
                "text": "uszkodzenie zawartosci segmentu kodu i w efekcie zawieszenie procesu",
                "isCorrect": false
            },
            {
                "text": "nadpisanie adresu powrotu na stosie",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Przepełnienie bufora to rodzaj ataku, który wykorzystuje błąd w oprogramowaniu, gdzie program zapisuje dane poza przydzielonym obszarem pamięci (buforem). Bufor to obszar pamięci o określonym rozmiarze. Do przepełnienia dochodzi, gdy ilość danych, które program próbuje zapisać, przekracza rozmiar tego bufora. Przepełnienia bufora są szczególnie niebezpieczne, ponieważ umożliwiają one atakującemu na przejęcie kontroli nad działającym programem lub wręcz całym systemem.\nDziałanie ataku opartego na przepełnieniu bufora polega przede wszystkim na manipulacji stosu. Stos to obszar pamięci, gdzie przechowywane są dane tymczasowe, takie jak zmienne lokalne i adres powrotu z funkcji. Adres powrotu to adres instrukcji, do której proces ma wrócić po wykonaniu danej funkcji.\nPodczas ataku przepełnienia bufora, napastnik wykorzystując wadliwe oprogramowanie może wprowadzić do bufora dane o rozmiarze większym niż przewidział to programista. Te dane „wychodzą” poza obszar bufora i mogą nadpisać inne elementy na stosie, w tym adres powrotu. Zmiana wartości adresu powrotu spowoduje, że proces, zamiast wrócić do swojej oryginalnej ścieżki wykonywania kodu, przeskoczy do adresu podanego przez napastnika, co daje napastnikowi możliwość wykonania dowolnego kodu, dając mu możliwość całkowitego przejęcia kontroli nad systemem.\n\n*   **wypchniecie wartosci zmiennych globalnych programu poza chroniony segment danych** - Ta odpowiedź jest niepoprawna. Choć zmienne globalne, przechowywane w segmencie danych, mogą zostać ostatecznie uszkodzone w wyniku nieprawidłowego działania programu, to *bezpośrednim* celem przepełnienia bufora jest nadpisanie adresu powrotu na stosie, a nie wypchnięcie danych poza segment. Przepełnienie bufora działa przede wszystkim na stosie, a nie w segmencie danych, w którym zmienne globalne są przechowywane.\n\n*  **uszkodzenie zawartosci segmentu danych i w efekcie zawieszenie procesu** - Ta odpowiedź jest niepoprawna. Uszkodzenie segmentu danych może być *pośrednim* skutkiem ataku, ale nie jego *bezpośrednim* celem. Przepełnienie bufora działa przede wszystkim na stosie, a nie w segmencie danych. Uszkodzenie segmentu danych może prowadzić do niestabilności procesu lub jego zawieszenia, ale nie jest to *bezpośredni* efekt ataku.\n\n*  **uszkodzenie zawartosci segmentu kodu i w efekcie zawieszenie procesu** - Ta odpowiedź jest niepoprawna. Uszkodzenie segmentu kodu jest *rzadkim* skutkiem przepełnienia bufora. Zwykle do uszkodzenia kodu może dojść podczas ataków typu format string. Segment kodu na ogół jest chroniony przed zapisem w systemach operacyjnych i bezpośrednie jego nadpisanie jest utrudnione lub wręcz niemożliwe. Przepełnienie bufora działa przede wszystkim na stosie, gdzie zapisywana jest zmienna adres powrotu z danej funkcji.\n\n*  **nadpisanie adresu powrotu na stosie** - Ta odpowiedź jest poprawna. Bezpośrednim celem ataku metodą przepełnienia bufora jest nadpisanie adresu powrotu na stosie, co pozwala na przekierowanie wykonywania programu do miejsca wskazanego przez atakującego. To nadpisanie jest pierwszym i najważniejszym krokiem w przejęciu kontroli nad procesem. Na przykład, atakujący może nadpisać adres powrotu na stosie adresem wskazującym na jego złośliwy kod, umieszczony wcześniej w przepełnionym buforze. Po wykonaniu funkcji proces zamiast wrócić do miejsca wywołania, przeskoczy do złośliwego kodu."
    },
    {
        "questionId": 165,
        "title": "Mechanizm hasel jednorazowych mozna zrealizowac poprzez:",
        "answers": [
            {
                "text": "listy hasel jednorazowych",
                "isCorrect": true
            },
            {
                "text": "generowanie hasla jednorazowego co staly czas",
                "isCorrect": true
            },
            {
                "text": "generowanie hasla jednorazowego w odpowiedzi na zadany kod",
                "isCorrect": true
            },
            {
                "text": "generowanie hasla jednorazowego na podstawie czasu i kodu",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Mechanizm haseł jednorazowych (OTP – One-Time Password) ma na celu ochronę przed atakami typu *replay attack*, w których przechwycone hasło może być użyte ponownie przez napastnika. Hasło jednorazowe, jak sama nazwa wskazuje, może być użyte tylko raz, a po wykorzystaniu traci ważność. Z tego powodu, przechwycenie takiego hasła przez napastnika jest bezużyteczne, gdyż nie można go użyć przy próbie uwierzytelnienia. Osiągnięcie tej właściwości jest realizowane poprzez generowanie kolejnych haseł w sposób nieprzewidywalny na podstawie wcześniej użytych haseł. Istnieje kilka metod generowania haseł jednorazowych.\n\n*   **listy haseł jednorazowych:** Jest to najprostsza forma OTP. Użytkownik otrzymuje listę haseł, które może wykorzystać po kolei.  System, przed udzieleniem dostępu, weryfikuje czy przesłane hasło jest kolejnym z listy. Lista ta, po wykorzystaniu wszystkich haseł musi być odnowiona.  Ta metoda jest podatna na przechwycenie całej listy, jeśli nie jest ona odpowiednio chroniona, ponadto sama lista jest statyczna i przy wielu uwierzytelnieniach można przewidzieć kolejne hasło. Jest to mało kosztowne rozwiązanie, dobre do prostych zastosowań i tylko wtedy gdy lista haseł jest nie jest przesłana niechronionym kanałem.\n\n*   **generowanie hasła jednorazowego co stały czas:** Hasło jest generowane na podstawie aktualnego czasu oraz tajnego klucza, znanego zarówno systemowi jak i użytkownikowi.  Synchronizacja czasu musi być zapewniona przez obie strony. Przykładem może być generator haseł w aplikacji Google Authenticator, który co określony interwał czasowy generuje nowe hasło. Minusem tego rozwiązania może być konieczność odpowiedniej synchronizacji czasu obu stron oraz potencjalne zagrożenie związane z ciągłą dostępnością tajnego klucza w generatorze. Z drugiej jednak strony, jeśli hasło nie jest użyte natychmiast traci ono ważność wraz z upływem czasu.\n\n*   **generowanie hasła jednorazowego w odpowiedzi na zadany kod:** W tym przypadku system wysyła do użytkownika losowy ciąg znaków nazywany również zawołaniem (ang. challenge). Użytkownik przetwarza ten ciąg, np. używając swojego tajnego klucza, i przesyła jako odpowiedź (ang. response). System przelicza zawołanie stosując ten sam klucz i porównuje wynik z otrzymaną odpowiedzią.  Przykładem może być algorytm zawołanie-odzew. W tym rozwiązaniu napastnik nie może użyć ponownie przechwyconego odzewu do ponownego uwierzytelnienia. Z tego powodu ta metoda jest uważana za bardziej bezpieczną niż metoda oparta o listę haseł jednorazowych. Ochrona opiera się tu na trudności w odgadnięciu tajnego klucza na podstawie przechwyconego zawołania i odzewu.\n\n*   **generowanie hasła jednorazowego na podstawie czasu i kodu:**  Jest to kombinacja dwóch poprzednich metod. Hasło jest generowane na podstawie aktualnego czasu oraz unikalnego kodu użytkownika. Zazwyczaj tajny kod użytkownika jest generowany na początku procesu uwierzytelniania i przechowywany na urządzeniu użytkownika np. na telefonie. Ta metoda jest spotykana często w aplikacjach oferujących uwierzytelnianie wieloskładnikowe. Z uwagi na trudność w odgadnięciu następnego hasła na podstawie poprzedniego metoda ta uważana jest za jedną z najbezpieczniejszych do uwierzytelniania użytkownika."
    },
    {
        "questionId": 166,
        "title": "W RSBAC, czy kazdy program moze zmienic uprawnienia na inne niz te, na ktorych zostal uruchomiony?",
        "answers": [
            {
                "text": "zgode wydaje oficer bezpieczenstwa modyfikujac odpowiednio polityke bezpieczenstwa",
                "isCorrect": false
            },
            {
                "text": "tak",
                "isCorrect": true
            },
            {
                "text": "kazdorazowo musi otrzymac zgode oficera bezpieczenstwa",
                "isCorrect": false
            },
            {
                "text": "bezwzglednie nie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "W systemie RSBAC (Rule Set Based Access Control), mechanizmie kontroli dostępu typu MAC (Mandatory Access Control), programy nie mogą swobodnie zmieniać uprawnień, z jakimi zostały uruchomione. W przeciwieństwie do systemów z kontrolą dostępu typu DAC (Discretionary Access Control) gdzie programy mogą eskalować swoje uprawnienia, tutaj wszelkie działania w tym zakresie podlegają polityce bezpieczeństwa. Domyślnie w systemie RSBAC, każdy program działa w tak zwanej piaskownicy(_ang. sandbox_), która ma ograniczone uprawnienia. \n\n**Odpowiedź a (\"zgode wydaje oficer bezpieczenstwa modyfikujac odpowiednio polityke bezpieczenstwa\") jest niepoprawna**, ponieważ choć jest bliska prawdzie to nie jest poprawna z punktu widzenia bezpośredniej zmiany uprawnień przez program. Uprawnienia faktycznie nadaje się poprzez modyfikację polityki bezpieczeństwa, ale  nie oznacza to, że każdy program musi każdorazowo ubiegać się o zgodę. Zamiast tego, oficer bezpieczeństwa (lub administrator systemu) konfiguruje politykę, która pozwala _konkretnym_ programom na wykonywanie określonych operacji z ustalonymi uprawnieniami.  Przykładem może być polecenie `/bin/login`, które musi mieć uprawnienia do zmiany uprawnień, aby można było na jego podstawie zalogować się do systemu. \nW takim wypadku w  polityce bezpieczeństwa RSBAC, to oficer bezpieczeństwa definiuje, że program `/bin/login` ma uprawnienie do zmiany użytkownika na żądanego.\n\n**Odpowiedź b (\"tak\") jest poprawna**, ponieważ w systemie RSBAC, można ustawić politykę, która **umożliwi** konkretnym programom zmianę uprawnień, z jakimi zostały uruchomione. Oczywiście domyślnie taki mechanizm jest wyłączony, jednak dzięki RSBAC administrator ma możliwość ustawiania takich reguł. Przykładowo, skrypt startowy serwera WWW, uruchamiany początkowo z uprawnieniami administratora (_root_), może zostać uprawniony do zmiany uprawnień na użytkownika _wwwrun_ używanego standardowo do uruchamiania tego serwera, a to w konsekwencji daje serwerowi WWW uprawnienia do działania tylko na danych dostępnych dla tego użytkownika. \n\n**Odpowiedź c (\"kazdorazowo musi otrzymac zgode oficera bezpieczenstwa\") jest niepoprawna**, ponieważ w systemie RSBAC procesy nie muszą każdorazowo zwracać się do oficera bezpieczeństwa o nadanie potrzebnych uprawnień. Uprawnienia są przyznawane na podstawie polityki bezpieczeństwa. Oficer bezpieczeństwa konfiguruje system raz, a potem w normalnym toku działania programy nie kontaktują się już z nim. Jest to istotne z punktu widzenia wydajności systemu, bo zapobiega nadmiernemu obciążeniu systemu wielokrotnymi procedurami uwierzytelniania.\n\n**Odpowiedź d (\"bezwzglednie nie\") jest niepoprawna**, ponieważ mechanizmy systemu RSBAC, choć z założenia ograniczają możliwość dowolnej zmiany uprawnień przez aplikacje, nie stanowią absolutnego ograniczenia dla wszystkich przypadków. Poprzez odpowiednie ustawienia administrator jest w stanie (w pewnym stopniu) dopuścić do zmiany uprawnień przez wybrane aplikacje. Nie jest to jednak proste w zastosowaniu i wymaga bardzo dobrej znajomości systemu RSBAC. Zatem kluczowe jest to, że to nie program sam o sobie decyduje o zmianie swoich uprawnień tylko decyduje o tym polityka bezpieczeństwa zdefiniowana przez oficera bezpieczeństwa."
    },
    {
        "questionId": 167,
        "title": "Skrot ACL oznacza:",
        "answers": [
            {
                "text": "Added Control List",
                "isCorrect": false
            },
            {
                "text": "Access Control List",
                "isCorrect": true
            },
            {
                "text": "Lista uprawnien nadanych",
                "isCorrect": false
            },
            {
                "text": "Lista kontroli dostepu",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "ACL, czyli Access Control List (lista kontroli dostępu), to podstawowy mechanizm w systemach komputerowych, służący do zarządzania uprawnieniami do zasobów. Zasoby te mogą obejmować pliki, katalogi, procesy, urządzenia i inne elementy systemu. ACL określa, którzy użytkownicy lub grupy użytkowników mają jakie prawa dostępu do danego zasobu.\n\n**Odpowiedź \"Added Control List\" jest niepoprawna.**  Choć brzmi podobnie do poprawnej odpowiedzi, nie jest to przyjęty i standardowy skrót. W informatyce i cyberbezpieczeństwie termin \"Access Control List\" ma jednoznaczne i powszechnie używane tłumaczenie na angielski oraz skrót ACL.\n\n**Odpowiedź \"Access Control List\" jest poprawna.** ACL jest powszechnie stosowanym terminem w systemach operacyjnych, bazach danych, sieciach komputerowych oraz innych systemach informatycznych.  Przykładowo, w systemie Linux, za pomocą poleceń `getfacl` i `setfacl` można zarządzać rozszerzonymi listami kontroli dostępu,  dzięki którym użytkownik lub grupa użytkowników mogą posiadać sprecyzowane uprawnienia, a nie tylko standardowe „właściciel-grupa-inni”. Przykładowo, możemy nadać prawa do odczytu danego pliku tylko określonemu użytkownikowi, niezależnie od tego, czy jest właścicielem pliku, czy nie. W systemie Windows w systemie plików NTFS, listy ACL są wykorzystywane do definiowania dostępu dla konkretnych użytkowników lub grup do plików i katalogów.\n\n**Odpowiedź \"Lista uprawnien nadanych\" jest niepoprawna,** chociaż jest to poprawny opis tego, co ACL *robi*. ACL zawiera listę uprawnień nadanych, ale to nie jest to tłumaczenie *akronimu* ACL. To próba opisania funkcjonalności a nie formalna nazwa. Przykładowo, jeśli chcemy aby dany użytkownik mógł czytać plik ale nie mógł go modyfikować to przypisujemy użytkownikowi prawo do odczytu pliku.\n\n**Odpowiedź \"Lista kontroli dostepu\" jest poprawna,**  gdyż to jest poprawne polskie tłumaczenie frazy \"Access Control List\", którą to akronim ACL reprezentuje. Choć nie jest to skrót, to jest to precyzyjne i poprawne tłumaczenie. Na przykład jeśli chcemy zablokować dostęp wszystkim użytkownikom spoza naszej firmy, wystarczy dodać do listy kontroli dostępu odpowiednią regułę.\n\nPodsumowując, ACL to nie tylko akronim ale również bardzo ważny element, którego znajomość jest konieczna w dziedzinie bezpieczeństwa systemów komputerowych."
    },
    {
        "questionId": 168,
        "title": "Czy RSBAC zapewnia:",
        "answers": [
            {
                "text": "wymuszanie stosowania skomplikowanych hasel",
                "isCorrect": false
            },
            {
                "text": "aktualizacje oprogramowania",
                "isCorrect": false
            },
            {
                "text": "stosowanie polityki MAC",
                "isCorrect": true
            },
            {
                "text": "system trudny do przechwycenia przez osobe niepowolana",
                "isCorrect": true
            },
            {
                "text": "poufnosc przechowywanych danych",
                "isCorrect": false
            },
            {
                "text": "stosowanie polityki DAC",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "RSBAC (Rule-Set Based Access Control) jest systemem kontroli dostępu, który implementuje podejście **MAC (Mandatory Access Control)**, czyli ścisłą, obowiązkową kontrolę dostępu. W podejściu tym uprawnienia nie są ustalane według uznania właściciela zasobu jak ma to miejsce w przypadku **DAC (Discretionary Access Control) - Uznaniowej Kontroli Dostępu**, lecz są narzucane przez centralnie definiowaną politykę bezpieczeństwa. Użytkownicy w systemach MAC nie mogą samodzielnie decydować o prawach dostępu do zasobów. RSBAC to rozszerzenie systemu Linux, które umożliwia narzucanie tego typu polityk bezpieczeństwa.\n\n*   **\"wymuszanie stosowania skomplikowanych haseł\"** - To nie jest bezpośrednia funkcja RSBAC. Wymuszanie skomplikowanych haseł to raczej element polityki bezpieczeństwa systemu operacyjnego, często realizowane przez wtyczki PAM (Pluggable Authentication Modules), lub niezależne narzędzia. RSBAC skupia się na kontroli dostępu do zasobów systemu, a nie na zarządzaniu hasłami.\n*   **\"aktualizacje oprogramowania\"** - RSBAC nie zajmuje się aktualizacjami oprogramowania. Aktualizacja systemu, w tym jądra oraz komponentów bezpieczeństwa jest osobnym zadaniem administratora, nie powiązanym bezpośrednio z mechanizmem kontroli dostępu. Choć sama aktualizacja jest bardzo ważna z punktu widzenia bezpieczeństwa, nie jest ona elementem systemu RSBAC.\n*   **\"stosowanie polityki MAC\"** - Ta odpowiedź jest **poprawna**. Głównym celem RSBAC jest zapewnienie polityki MAC. System RSBAC pozwala administratorowi na sztywne definiowanie reguł dostępu i narzucanie ich, bez możliwości modyfikacji przez poszczególnych użytkowników. W RSBAC administrator definiuje typy, role oraz prawa dostępu do zasobów a następnie przypisuje je wybranym użytkownikom i aplikacjom. Ustawienia te nie są modyfikowalne przez użytkownika i są niezmienne z poziomu użytkownika.\n*   **\"system trudny do przechwycenia przez osobe niepowolana\"** - Ta odpowiedź również jest **poprawna**. Choć nie istnieje absolutne bezpieczeństwo, systemy takie jak RSBAC utrudniają niepowołany dostęp, gdyż ataki oparte na wykorzystaniu luk w uprawnieniach lub omijaniu logiki dostępu nie mają zastosowania. Systemy z wdrożoną polityką MAC są bardziej odporne na próby przejęcia kontroli, gdyż ograniczają użytkownikom zakres działania do bardzo szczegółowo określonej puli zasobów i uprawnień. Nawet w przypadku przejęcia kontroli nad procesem(aplikacją), intruz może wykonać tylko operacje, na które zezwala nałożona polityka. To w praktyce minimalizuje ryzyko kompromitacji systemu.\n*   **\"poufnosc przechowywanych danych\"** - Ochrona poufności danych nie jest głównym zadaniem RSBAC. RSBAC reguluje dostęp do zasobów, jednak nie chroni samych danych przed dostępem osób uprawnionych. Ochronę poufności można osiągnąć poprzez szyfrowanie danych. RSBAC może być jednak wykorzystany w systemach, które mają na celu utajnianie danych. Polityka bezpieczeństwa, którą można zbudować w RSBAC może zakazać odczytu danych nieuprawnionym użytkownikom, czyli podnieść poufność.\n*   **\"stosowanie polityki DAC\"** - Ta odpowiedź jest **niepoprawna**. RSBAC nie stosuje polityki DAC, gdyż jego celem jest ochrona zasobów przed samowolą użytkowników. Systemy DAC oferują mechanizmy określania praw dostępu do zasobów, jednak umożliwiają zmianę tych praw właścicielom. Ustawienia w systemie DAC są zmienne przez właściciela zasobów i stanowią zagrożenie w wypadku przejęcia hasła lub konta. Systemy MAC takie jak RSBAC uniemożliwiają obejście polityki bezpieczeństwa przez użytkownika.\n\nPodsumowując, RSBAC to narzędzie, które ma na celu podniesienie poziomu bezpieczeństwa systemów Linux poprzez narzucenie ścisłej polityki kontroli dostępu opartej na zasadach MAC. Główne zadania RSBAC sprowadzają się do kontroli dostępu do zasobów, bez skupienia się na aspekcie zarządzania hasłami, aktualizacjami oprogramowania i samej poufności danych(choć może ją wspomagać)."
    },
    {
        "questionId": 169,
        "title": "Szyfrowanie asymetryczne:",
        "answers": [
            {
                "text": "to uzywanie dwoch matematycznie zaleznych kluczy",
                "isCorrect": true
            },
            {
                "text": "jest wykorzystane przy podpisywaniu wiadomosci",
                "isCorrect": true
            },
            {
                "text": "to uzywanie dwoch niezaleznych kluczy: jednego do szyfrowania, drugiego do deszyfrowania",
                "isCorrect": false
            },
            {
                "text": "nie jest wykorzystywane przez SSH",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Kryptografia asymetryczna wykorzystuje parę kluczy: klucz publiczny i klucz prywatny, które są ze sobą powiązane matematycznie, ale klucz prywatny nie może być w prosty sposób odtworzony z klucza publicznego. Klucz publiczny jest przeznaczony do rozpowszechniania i może być znany każdemu, natomiast klucz prywatny jest utrzymywany w tajemnicy i znany tylko właścicielowi. W kryptografii asymetrycznej klucze z pary mają różne zastosowania: klucz publiczny służy do szyfrowania danych, a klucz prywatny do ich deszyfrowania (lub odwrotnie, jak przy podpisie cyfrowym).\n\n*   **\"to uzywanie dwoch matematycznie zaleznych kluczy\"** - To stwierdzenie jest **poprawne**. Klucze w kryptografii asymetrycznej (klucz publiczny i klucz prywatny) są ze sobą matematycznie powiązane. Ta zależność jest kluczowa, ponieważ szyfrowanie kluczem publicznym wymaga deszyfrowania pasującym kluczem prywatnym. Bez tej zależności, system kryptografii asymetrycznej nie mógłby prawidłowo funkcjonować.\n\n*   **\"jest wykorzystane przy podpisywaniu wiadomosci\"** - To stwierdzenie również jest **poprawne**.  Podpis cyfrowy jest realizowany przy wykorzystaniu klucza prywatnego nadawcy do utworzenia podpisu, a klucza publicznego do zweryfikowania poprawności tego podpisu. Nadawca tworzy skrót (hash) z przesyłanych danych i szyfruje ten skrót swoim kluczem prywatnym, w ten sposób powstaje podpis cyfrowy. Odbiorca wiadomości do weryfikacji podpisu używa klucza publicznego nadawcy aby rozszyfrować skrót i porównuje go ze skrótem, który sam wyliczy z odebranych danych. Jeśli oba skróty są identyczne to wiadomość nie została zmieniona, dodatkowo wiemy na 100% od kogo pochodzi. Przykładem praktycznym są certyfikaty cyfrowe używane do weryfikacji stron internetowych lub poczty e-mail.\n\n*   **\"to uzywanie dwoch niezaleznych kluczy: jednego do szyfrowania, drugiego do deszyfrowania\"** - To stwierdzenie jest **niepoprawne**. W kryptografii asymetrycznej, choć używa się dwóch kluczy, są one matematycznie powiązane, a nie niezależne. Klucz użyty do szyfrowania nie może służyć do deszyfrowania danych, tak jak ma to miejsce w kryptografii symetrycznej, lecz powiązany z nim klucz z pary.\n\n*  **\"nie jest wykorzystywane przez SSH\"** - To stwierdzenie jest **niepoprawne**. Protokół SSH (Secure Shell) w celu bezpiecznego nawiązania połączenia wykorzystuje kryptografię asymetryczną, a konkretnie algorytm Diffie-Hellmana, który umożliwia stronom bezpieczną wymianę klucza sesyjnego, który później wykorzystany będzie w szyfrowaniu symetrycznym. Jest również używana do weryfikacji tożsamości serwera, do uwierzytelniania klienta poprzez klucze prywatne lub pośrednio jako wsparcie protokołu Kerberos. W rzeczywistym scenariuszu, gdy logujemy się zdalnie przez SSH po raz pierwszy, na ekranie pojawia się pytanie o zaufanie hostowi zdalnemu. Po podjęciu pozytywnej decyzji i pobraniu klucza publicznego serwera do pliku `~/.ssh/known_hosts` wszelka komunikacja jest już chroniona i uwierzytelniona kryptograficznie."
    },
    {
        "questionId": 170,
        "title": "TUN/TAP to:",
        "answers": [
            {
                "text": "rozszerzenie programu OpenVPN",
                "isCorrect": true
            },
            {
                "text": "sterownik dzialajacy tylko na systemach Windows",
                "isCorrect": false
            },
            {
                "text": "sterownik dzialajacy tylko na systemach Linux",
                "isCorrect": false
            },
            {
                "text": "cos takiego nie istnieje",
                "isCorrect": false
            },
            {
                "text": "komponent pozwalajacy tworzyc wirtualne interfejsy sieciowe",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Interfejsy wirtualne TUN/TAP to sterowniki systemowe, które umożliwiają tworzenie wirtualnych interfejsów sieciowych.  Różnica między TUN a TAP polega na warstwie modelu ISO/OSI, na której operują.  **TUN** (_network TUNnel_) operuje na warstwie sieciowej (warstwa 3),  czyli na poziomie pakietów IP (ang. Internet Protocol). Sterownik TUN odbiera pakiety IP z oprogramowania, do którego jest podłączony i wstawia je do stosu sieciowego systemu operacyjnego i analogicznie z drugiej strony.  Natomiast **TAP** (ang. _network TAP_) operuje na warstwie łącza danych (warstwa 2), czyli na poziomie ramek Ethernetu.  Sterownik TAP odbiera ramki Ethernet z oprogramowania, do którego jest podłączony i wstawia je do stosu sieciowego systemu operacyjnego i analogicznie z drugiej strony. Oba sterowniki emulują wirtualną kartę sieciową, jednak  działają na różnych poziomach modelu sieciowego ISO/OSI.  W systemach Linux aby używać sterowników TUN/TAP wymagany jest moduł jądra o nazwie tun.\n\n**Poprawna odpowiedź:**\n\n*   **\"rozszerzenie programu OpenVPN\"** jest **poprawna,** ponieważ  OpenVPN to popularne oprogramowanie VPN, które  wykorzystuje sterowniki TUN lub TAP do tworzenia wirtualnych interfejsów sieciowych.  OpenVPN nie jest sterownikiem sieciowym sam w sobie, tylko korzysta z istniejących do komunikacji sieciowej, wykorzystuje sterowniki TUN/TAP, do stworzenia tunelu komunikacyjnego przez który będzie przesyłany ruch.  Dzięki użyciu TUN/TAP, OpenVPN może przekierowywać ruch sieciowy przez tunel VPN, jak również ma dostęp do zasobów sieciowych, do których ma dostęp karta sieciowa.\n\n*   **\"komponent pozwalajacy tworzyc wirtualne interfejsy sieciowe\"** jest **poprawna,** ponieważ  sterowniki TUN/TAP są odpowiedzialne za tworzenie wirtualnych interfejsów sieciowych. To one, a nie samo oprogramowanie VPN, są odpowiedzialne za ich stworzenie.  Aplikacje takie jak OpenVPN i inne, po odpowiednim skonfigurowaniu sterownika TUN lub TAP są w stanie przesłać ruch wirtualną kartą sieciową do odpowiedniego odbiorcy. Wirtualne interfejsy sieciowe tworzone przez sterowniki TUN/TAP są traktowane przez system operacyjny jako normalne karty sieciowe.\n\n**Niepoprawne odpowiedzi:**\n\n*   **\"sterownik dzialajacy tylko na systemach Windows\"** jest **niepoprawna**, ponieważ sterowniki TUN/TAP są powszechnie wykorzystywane w systemach Linux/Unix. Chociaż istnieją implementacje tych sterowników dla systemów Windows to pierwotnie powstały one w systemach Linux/Unix. Sterowniki TUN/TAP nie są również wyłączną własnością firmy Microsoft.\n\n*   **\"sterownik dzialajacy tylko na systemach Linux\"** jest **niepoprawna**, ponieważ sterowniki TUN/TAP istnieją również w systemach Windows, a dzięki OpenVPN można w łatwy sposób z nich korzystać. Zasadą istnienia i działania sterowników TUN/TAP jest ich uniwersalność pod względem systemu operacyjnego.\n\n*   **\"cos takiego nie istnieje\"** jest **niepoprawna,** ponieważ sterowniki TUN/TAP są powszechnie stosowane w systemach Linux/Unix i Microsoft Windows w celu budowy sieci VPN, kontenerów i symulatorów sieciowych. Sterowniki TUN/TAP jak i samo pojęcie wirtualnych interfejsów sieciowych są bardzo ważne dla funkcjonowania dzisiejszego Internetu.\n\n**Praktyczne implikacje:**\n\n*   **Uwierzytelnianie VPN:** OpenVPN używa TUN/TAP do tworzenia bezpiecznego kanału między dwoma urządzeniami. Pakiety IP są przesyłane przez wirtualny interfejs sieciowy a ich zawartość jest szyfrowana i/lub podpisywana, aby uniemożliwić osobom trzecim ich podsłuchiwania. Do tego procesu niezbędne jest istnienie sterownika TUN/TAP w systemie operacyjnym.\n*   **Konteneryzacja:** Technologie konteneryzacji, takie jak Docker, również korzystają z interfejsów wirtualnych do izolowania poszczególnych kontenerów oraz komunikacji między nimi, co jest kluczowe dla bezpieczeństwa kontenerów.\n*   **Testowanie sieci:** Inżynierowie sieci mogą za pomocą wirtualnych interfejsów sieciowych budować symulatory sieciowe, które umożliwiają im testowanie konfiguracji bez posiadania fizycznych elementów sieciowych."
    },
    {
        "questionId": 171,
        "title": "Mozliwosci uwierzytelniania przy uzyciu SSH to:",
        "answers": [
            {
                "text": "certyfikaty SSL X.509",
                "isCorrect": false
            },
            {
                "text": "para login, haslo naszego konta na zdalnym hoscie",
                "isCorrect": true
            },
            {
                "text": "samo haslo naszego konta na zdalnym hoscie",
                "isCorrect": false
            },
            {
                "text": "klucz publiczny, uzywany przy szyfrowaniu symetrycznym",
                "isCorrect": false
            },
            {
                "text": "trojka login, klucz publiczny i klucz prywatny",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) to protokół służący do bezpiecznego, szyfrowanego połączenia z komputerem zdalnym. Uwierzytelnianie w SSH to proces potwierdzania tożsamości użytkownika, który próbuje uzyskać dostęp do zdalnego systemu. Oprócz tradycyjnej metody uwierzytelniania hasłem, SSH oferuje również silniejsze metody wykorzystujące kryptografię.\n\n*   **\"certyfikaty SSL X.509\"** - Odpowiedź **niepoprawna**. Certyfikaty SSL X.509 są używane do uwierzytelniania serwerów, na przykład serwerów WWW w protokole HTTPS, ale nie są typową metodą uwierzytelniania użytkowników w SSH. W SSH certyfikaty mogą być wykorzystywane w połączeniu z innymi mechanizmami uwierzytelniania np. IKE w IPsec, ale nie wprost. Uwierzytelnienie użytkownika za pomocą certyfikatów X.509 w SSH wymagałoby dodatkowych wtyczek.\n\n*   **\"para login, haslo naszego konta na zdalnym hoscie\"** - Odpowiedź **poprawna**. Jest to podstawowa i najczęściej spotykana metoda uwierzytelniania w SSH. Użytkownik podaje swój login i hasło, a SSH przesyła te dane do serwera, który weryfikuje je, sprawdzając, czy dane te odpowiadają zapisanym danym w pliku konfiguracyjnym w systemie zdalnym(np. w pliku /etc/passwd lub /etc/shadow). Należy jednak podkreślić, że chociaż hasło jest przesyłane poprzez SSH, to połączenie jest szyfrowane, więc hasło nie jest przekazywane tekstem jawnym. Jest to podstawowa metoda, którą wykorzystuje wiele osób przy codziennej pracy i łączeniu się z systemem zdalnym.\n\n*   **\"samo haslo naszego konta na zdalnym hoscie\"** - Odpowiedź **niepoprawna**. Samo hasło nie wystarcza do uwierzytelnienia, niezbędny jest również login użytkownika, który wskazuje na konto, z którym ma być zestawione połączenie. Ponadto logowanie za pomocą hasła nie jest zalecane, gdyż jest najsłabszym mechanizmem uwierzytelniania w protokole SSH.\n\n*   **\"klucz publiczny, uzywany przy szyfrowaniu symetrycznym\"** - Odpowiedź **niepoprawna**. Klucz publiczny sam w sobie nie służy do szyfrowania symetrycznego. W rzeczywistości klucz publiczny służy do uwierzytelniania użytkownika poprzez mechanizm wyzwanie-odpowiedź. W tym mechanizmie serwer generuje ciąg losowych znaków, które są podpisywane prywatnym kluczem użytkownika, a serwer weryfikuje podpis za pomocą klucza publicznego (znanego serwerowi). Szyfrowanie symetryczne w SSH jest wykorzystywane, ale odbywa się po etapie uzgodnienia parametrów połączenia i wynegocjowaniu tajnego klucza sesji. Klucz publiczny w SSH służy do bezpiecznej dystrybucji klucza tajnego. Klucz publiczny nie wystarcza również do uzyskania dostępu do serwera, gdyż do uwierzytelniania niezbędny jest klucz prywatny.\n\n*   **\"trojka login, klucz publiczny i klucz prywatny\"** - Odpowiedź **poprawna**. Uwierzytelnianie z użyciem kluczy opiera się na parze kluczy: publicznym i prywatnym. Klucz prywatny jest znany tylko użytkownikowi i umożliwia podpisanie wyzwania generowanego przez serwer. Klucz publiczny jest umieszczany na zdalnym serwerze, w pliku ~/.ssh/authorized_keys, i służy do zweryfikowania podpisu. Do tego mechanizmu należy również dołączyć informację o nazwie konta (login). A zatem trojka login, klucz publiczny i klucz prywatny jest jedną z metod uwierzytelniania w systemie SSH."
    },
    {
        "questionId": 172,
        "title": "Protokol SSH umozliwia:",
        "answers": [
            {
                "text": "pobieranie plikow",
                "isCorrect": true
            },
            {
                "text": "bezpolaczeniowa komunikacje ze zdalnym hostem, na ktorym uruchomiony jest serwer ssh",
                "isCorrect": false
            },
            {
                "text": "nawiazywanie polaczen ze zdalnymi terminalami",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) to kryptograficzny protokół sieciowy, który zapewnia bezpieczny zdalny dostęp do komputera, w tym wykonywanie poleceń i przesyłanie plików. Jest on zaprojektowany w taki sposób, aby zapewnić poufność, integralność i autentyczność danych wymienianych między klientem a serwerem. W przeciwieństwie do protokołów takich jak Telnet, SSH szyfruje całą komunikację, w tym hasła i przesyłane dane, co uniemożliwia ich przechwycenie i odczytanie przez nieuprawnione osoby.\n\n**Odpowiedź 1: \"pobieranie plikow\" - poprawna.** Protokół SSH umożliwia bezpieczne przesyłanie plików pomiędzy komputerami za pomocą protokołu SFTP (Secure File Transfer Protocol) lub SCP (Secure Copy Protocol), które są często integralną częścią implementacji SSH. Użytkownik może przesyłać pliki za pomocą komend takich jak `scp` lub poprzez klienta SFTP. Praktycznym przykładem jest przesyłanie plików konfiguracyjnych do serwera lub pobieranie wyników obliczeń z serwera na lokalny komputer. \n\n**Odpowiedź 2: \"bezpolaczeniowa komunikacje ze zdalnym hostem, na ktorym uruchomiony jest serwer ssh\" - niepoprawna.** SSH jest protokołem zorientowanym na połączenie (_ang. connection-oriented_), co oznacza, że przed rozpoczęciem przesyłania danych, ustanawiane jest dedykowane połączenie między klientem a serwerem. To połączenie jest utrzymywane przez cały czas trwania sesji. W przeciwieństwie do protokołów bezpołączeniowych (np. UDP), SSH gwarantuje, że pakiety zostaną dostarczone w poprawnej kolejności i bez utraty. Bezpołączeniowy przesył danych to sytuacja w której nie ma nawiązanego i utrzymywanego ciągłego połączenia między dwoma urządzeniami przesyłanie danych odbywa się z pojedynczego punktu i kierowane jest do punktu docelowego, który sam musi zadbać o to czy dane doszły w całości.\n\n**Odpowiedź 3: \"nawiazywanie polaczen ze zdalnymi terminalami\" - poprawna.** Jedną z głównych funkcji SSH jest zapewnienie bezpiecznego dostępu do zdalnej powłoki (_ang. remote shell_). Umożliwia to administratorom systemów zarządzanie serwerami, wykonywanie poleceń i konfigurację systemu z dowolnego miejsca na świecie pod warunkiem posiadania dostępu do internetu lub sieci lokalnej. Na przykład administrator może połączyć się z serwerem za pomocą klienta SSH (np. OpenSSH w Linux, PuTTY w Windows) i wykonywać polecenia tak, jakby pracował lokalnie przy serwerze. SSH jest bezpieczną alternatywą dla starszych, niezabezpieczonych protokołów takich jak Telnet."
    },
    {
        "questionId": 173,
        "title": "Jakie restrykcje wprowadza tryb Safe w konfiguracji modulu PHP serwera WWW?",
        "answers": [
            {
                "text": "blokowanie wybranych funkcji",
                "isCorrect": true
            },
            {
                "text": "ograniczenie dostepu do fragmentu systemu plikow SSL",
                "isCorrect": false
            },
            {
                "text": "dostep tylko do plikow o tym samym wlascicielu co skrypt",
                "isCorrect": true
            },
            {
                "text": "ograniczenie zakresu zmiennych modyfikowanych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Tryb Safe w konfiguracji PHP to mechanizm bezpieczeństwa, który ogranicza funkcjonalność skryptów PHP. Ma na celu zapobieganie wykorzystaniu potencjalnych luk w skryptach, które mogłyby prowadzić do przejęcia kontroli nad serwerem lub nieuprawnionego dostępu do systemu plików. Tryb Safe był szczególnie popularny w starszych wersjach PHP, chociaż obecnie jego stosowanie nie jest zalecane z uwagi na istnienie bardziej elastycznych i skutecznych metod ochrony. Mechanizm ten wywodzi się z zamierzeń utworzenia tzw.  _piaskownicy_, _ang. sandbox_, dla wykonywanego skryptu.\n* **\"blokowanie wybranych funkcji\"** - Odpowiedź jest poprawna, tryb Safe blokuje możliwość wykorzystania niebezpiecznych funkcji PHP. Na przykład w trybie Safe, funkcje służące do wykonywania operacji systemowych (np. `system()`, `exec()`, `passthru()`) lub manipulacji plikami na serwerze (`fopen()`, `mkdir()`, `unlink()`) są domyślnie wyłączone i skrypt PHP nie może ich wywołać. Blokowane funkcje ograniczają potencjalne ataki, takie jak wstrzykiwanie kodu lub wykonywanie dowolnych poleceń systemu operacyjnego. Wyobraźmy sobie sytuację, że nieznany atakujący chce wykonać polecenie _rm -rf /*_ na serwerze. W trybie _safe_ nie będzie mógł tego zrobić gdyż polecenie to będzie zablokowane. \n* **\"ograniczenie dostepu do fragmentu systemu plikow SSL\"** - Odpowiedź jest niepoprawna. Safe Mode nie wprowadza żadnych specjalnych ograniczeń dostępu do plików związanych z SSL. Zarówno certyfikaty SSL jak i klucze prywatne wykorzystywane przez SSL są chronione mechanizmami kontroli dostępu systemu plików i nie są przedmiotem działania Safe Mode.\n* **\"dostep tylko do plikow o tym samym wlascicielu co skrypt\"** - Odpowiedź jest poprawna. W trybie Safe, skrypt PHP może mieć dostęp tylko do tych plików, których właścicielem jest sam skrypt (a dokładniej użytkownik, pod którym wykonywany jest proces skryptu PHP). Ograniczenie to ma na celu uniemożliwić skryptom modyfikację plików do których nie powinny mieć dostępu, w tym szczególnie danych innych użytkowników systemu. Jeżeli w trybie safe chcemy aby dany skrypt miał dostęp do pliku do którego nie jest właścicielem musi mieć ustawione uprawnienia dla innych użytkowników, co naturalnie zwiększa ryzyko nadużycia.\n* **\"ograniczenie zakresu zmiennych modyfikowanych\"** - Odpowiedź jest niepoprawna. Tryb Safe nie ma bezpośredniego wpływu na zakres zmiennych, które mogą być modyfikowane wewnątrz skryptu. Mechanizm Safe Mode skupia się na ograniczeniu dostępu do plików oraz funkcji systemu, nie kontrolując typowych zmiennych aplikacji.\n\nPodsumowując, tryb Safe w PHP to mechanizm, który wprowadza konkretne ograniczenia w dostępie do funkcji oraz plików. Choć może zwiększyć bezpieczeństwo systemu, w praktyce okazuje się często zbyt mało elastyczny, a przy tym nie chroni przed zaawansowanymi atakami. Współcześnie, zamiast polegać na Safe Mode, zaleca się używanie bezpiecznej konfiguracji serwera, bieżące aktualizacje oraz stosowanie bardziej zaawansowanych rozwiązań (np. wirtualizację/konteneryzację)."
    },
    {
        "questionId": 174,
        "title": "Serwer KDC:",
        "answers": [
            {
                "text": "jest bardzo dobrze zabezpieczony",
                "isCorrect": false
            },
            {
                "text": "moze zapewnic bardzo dobre bezpieczenstwo w sieci",
                "isCorrect": true
            },
            {
                "text": "stosuje proste mechanizmy kryptograficzne, ktore sa proste do zlamania",
                "isCorrect": false
            },
            {
                "text": "mozna prosto oszukac podszywajac sie pod niego",
                "isCorrect": false
            },
            {
                "text": "ufa kazdej usludze",
                "isCorrect": false
            },
            {
                "text": "ufa uwiarygodnionym uzytkownikom",
                "isCorrect": true
            },
            {
                "text": "ufa każdemu komputerowi w domenie",
                "isCorrect": false
            },
            {
                "text": "działa jedynie w obrębie jednej sieci lokalnej",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Serwer KDC (Key Distribution Center) jest centralnym elementem protokołu Kerberos, który służy do uwierzytelniania i autoryzacji w sieci. Kerberos to protokół uwierzytelniania sieciowego, który korzysta z kryptografii symetrycznej i jest szeroko stosowany w środowiskach korporacyjnych i systemach operacyjnych, takich jak Windows Active Directory. KDC działa jako zaufana strona trzecia, która uwierzytelnia użytkowników i usługi w domenie. Domena to w tym kontekście jednostka administracyjna w sieci, w której KDC zarządza uwierzytelnianiem.\n\n**Odpowiedź: \"jest bardzo dobrze zabezpieczony\" jest niepoprawna.**  KDC, jako centralny punkt uwierzytelniania, musi być *bardzo dobrze zabezpieczony*, ale nie można założyć, że jest on z natury absolutnie bezpieczny. KDC podlega atakom jak każde inne urządzenie. W celu ochrony KDC stosuje się szereg środków, takich jak fizyczna ochrona serwera, ograniczanie zdalnego dostępu do serwera, odpowiednia konfiguracja systemu operacyjnego serwera oraz monitorowanie aktywności.\n\n**Odpowiedź: \"moze zapewnic bardzo dobre bezpieczenstwo w sieci\" jest poprawna.** KDC, o ile jest poprawnie skonfigurowany i chroniony, zapewnia bardzo dobre bezpieczeństwo w sieci. Polega to na tym, że tylko posiadanie odpowiednich biletów, które wystawia KDC, umożliwia dostęp do zasobów sieci. Bilety wydawane są tylko zweryfikowanym użytkownikom. Poprawnie wdrożone KDC uniemożliwia nieuprawnionemu użytkownikowi dostęp do zasobów sieciowych.\n\n**Odpowiedź: \"stosuje proste mechanizmy kryptograficzne, ktore sa proste do zlamania\" jest niepoprawna.** KDC wykorzystuje zaawansowane algorytmy kryptograficzne, a nie proste, które są łatwe do złamania. Klucze sesyjne są tworzone przy pomocy szyfrowania symetrycznego, ale tylko po wykonaniu procedury uwierzytelniania przy wykorzystaniu kryptografii asymetrycznej, protokołu Diffiego-Hellmana.\n\n**Odpowiedź: \"mozna prosto oszukac podszywajac sie pod niego\" jest niepoprawna.** Podszycie się pod serwer KDC jest bardzo trudne, o ile system operacyjny na którym uruchomiony jest KDC, jest prawidłowo skonfigurowany i chroniony. Aby zasymulować działanie KDC, napastnik musiał by skompromitować certyfikat i/lub klucz prywatny serwera.\n\n**Odpowiedź: \"ufa kazdej usludze\" jest niepoprawna.** KDC *nie ufa każdej usłudze*, ale tylko tym, które posiadają ważny bilet TGT (_ang. Ticket Granting Ticket_). KDC to zaufana strona trzecia w protokole Kerberos. Klient przy starcie kontaktuje się z KDC. KDC w zamian odsyła bilet TGT, który uprawnia do korzystania z zasobów domeny. Bilet TGT jest weryfikowany przy każdej próbie uzyskania dostępu do zasobów sieci.\n\n**Odpowiedź: \"ufa uwiarygodnionym uzytkownikom\" jest poprawna.** KDC działa na zasadzie zaufania do użytkowników, którzy zostali pozytywnie uwierzytelnieni. Potwierdzenie tożsamości użytkownika odbywa się poprzez weryfikację jego hasła w stosunku do skrótu kryptograficznego hasła zapisanego w bazie danych KDC. Użytkownikowi wydawane są wtedy bilety autoryzacyjne uprawniające go do korzystania z usług sieciowych, bez konieczności ponownego podawania hasła.\n\n**Odpowiedź: \"ufa każdemu komputerowi w domenie\" jest niepoprawna.** KDC nie ufa automatycznie każdemu komputerowi w domenie. Każdy komputer w domenie musi posiadać swój bilet. Identyfikacja tożsamości komputera opiera się na podobnej zasadzie, jak w przypadku użytkowników.\n\n**Odpowiedź: \"działa jedynie w obrębie jednej sieci lokalnej\" jest niepoprawna.**  KDC może działać w obrębie jednej sieci lokalnej lub rozległej. Może działać w pojedynczej domenie, jak i w hierarchii wielu domen powiązanych relacjami zaufania. Przykładowo, implementacja KDC w systemach Microsoft Active Directory obejmuje rozległe środowiska sieciowe w których poszczególne lokalizacje geograficzne mogą być oddalone o setki i tysiące kilometrów."
    },
    {
        "questionId": 175,
        "title": "Wektor inicjujacy w szyfrowaniu: ",
        "answers": [
            {
                "text": "musi byc tajny i znany tylko odbiorcy",
                "isCorrect": false
            },
            {
                "text": "musi byc tajny i znany obu stronom komunikacji",
                "isCorrect": false
            },
            {
                "text": "powinien miec losowa wartosc, za kazdym razem inna",
                "isCorrect": true
            },
            {
                "text": "wykorzystywany jest wylacznie w szyfrowaniu asymetrycznym",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Wektor inicjalizacyjny (ang. Initialization Vector, IV) jest wartością o ustalonej długości, która jest wykorzystywana w algorytmach szyfrowania symetrycznego, a w szczególności w trybach blokowych takich jak CBC (Cipher Block Chaining). Jego głównym celem jest zapewnienie, że nawet jeśli ten sam tekst jawny (ang. plaintext) zostanie zaszyfrowany wielokrotnie przy użyciu tego samego klucza, otrzymane teksty zaszyfrowane (ang. ciphertext) będą za każdym razem różne. IV działa jako swego rodzaju \"ziarno\" w procesie szyfrowania, wprowadzając losowość do działania algorytmu szyfrującego. IV nie jest kluczem szyfrującym i nie należy go mylić z kluczem.\n\n**Odpowiedź \"musi byc tajny i znany tylko odbiorcy\" jest niepoprawna**, ponieważ IV nie musi być tajny. W rzeczywistości często jest on przesyłany wraz z tekstem zaszyfrowanym (jako jawna część pakietu). Tajny jest natomiast klucz szyfrujący. IV nie jest tajny, ale ma być unikatowy, generowany losowo. Przesyłanie tego samego IV dla tego samego klucza i tekstu jest podatne na ataki.\n\n**Odpowiedź \"musi byc tajny i znany obu stronom komunikacji\" jest również niepoprawna**, ponieważ chociaż obie strony komunikacji potrzebują znać wartość IV (aby poprawnie odszyfrować wiadomość), to jego tajność nie jest wymagana. Klucz szyfrowania jest elementem, który musi pozostać tajny. IV natomiast generowany jest losowo, a jego unikatowość jest ważniejsza od zachowania go w tajemnicy.\n\n**Odpowiedź \"powinien miec losowa wartosc, za kazdym razem inna\" jest poprawna**, ponieważ to unikalność i losowość są kluczowe dla bezpieczeństwa szyfrowania. Jeżeli IV nie będzie losowy i za każdym razem generowany od nowa to powstanie schemat, który może być wykorzystany do złamania hasła. Wygenerowanie IV o losowej wartości i wysłanie go razem z zaszyfrowaną wiadomością jest popularnym schematem. Przykładowo w szyfrowaniu WPA2, mechanizm TKIP używa unikalnego IV (zwanego tutaj również wektorem inicjującym) który jest generowany na podstawie numeru pakietu, numeru klucza oraz nadawcy i odbiorcy. Ta losowość zapewnia, że nawet powtarzające się dane będą szyfrowane różnymi ciągami.\n\n**Odpowiedź \"wykorzystywany jest wylacznie w szyfrowaniu asymetrycznym\" jest niepoprawna**, ponieważ IV jest stosowany głównie w trybach blokowych algorytmów szyfrowania symetrycznego, np. AES w trybie CBC. Algorytmy asymetryczne nie wymagają stosowania wektora inicjalizacyjnego. Algorytmy asymetryczne opierają się na kluczu publicznym i prywatnym, a nie na symetrycznym kluczu i IV. Klucz publiczny jest jawny, klucz prywatny jest tajny."
    },
    {
        "questionId": 176,
        "title": "W uwierzytelnianiu z udzialem zaufanej trzeciej strony, do zadan tej trzeciej strony nalezy:",
        "answers": [
            {
                "text": "poswiadczenie uwierzytelnienia",
                "isCorrect": true
            },
            {
                "text": "pobranie listu uwierzytelniajacego od jednej ze stron",
                "isCorrect": false
            },
            {
                "text": "pobranie listu uwierzytelniajacego od obu stron",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnienie jednej ze stron",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "W uwierzytelnianiu z udziałem zaufanej trzeciej strony, kluczową rolę odgrywa zaufana strona trzecia, która pośredniczy w procesie weryfikacji tożsamości. Zasadniczo, strona trzecia nie weryfikuje, która strona ma dostęp do konkretnych zasobów, a raczej to, czy dana strona jest tym, za kogo się podaje. Jest to proces, który skupia się na sprawdzeniu poprawności tożsamości, a nie na przyznawaniu dostępu do jakichś obiektów. Strona trzecia musi być zaufana zarówno przez stronę weryfikowaną, jak i przez stronę weryfikującą. \n\n**Poswiadczenie uwierzytelnienia** jest jednym z kluczowych zadań zaufanej trzeciej strony. Po uwierzytelnieniu podmiotu, zaufana strona trzecia wydaje poświadczenie - formalny dokument cyfrowy, lub token, który poświadcza, że tożsamość podmiotu została zweryfikowana. Ten dowód uwierzytelnienia jest potem przedstawiany stronie, która wymaga od podmiotu jego tożsamości. Strona ufająca stronie trzeciej nie musi sama dokonywać procesu weryfikacji podmiotu, tylko polega na poświadczeniu podpisanym przez stronę trzecią. Użytkownik uwierzytelniony przez stronę trzecią, otrzymuje poświadczenie(ang. credential), które może używać do wielokrotnego logowania do różnych systemów(jeśli polityka bezpieczeństwa to dopuszcza) bez podawania hasła. \n\nOdpowiedź **pobranie listu uwierzytelniajacego od jednej ze stron** jest niepoprawna ponieważ zakłada, że strona trzecia uzależniona jest od jednej ze stron potrzebujących uwierzytelnienia. To z kolei tworzy zagrożenie oparte o atak _man in the middle_. W schemacie tym atakujący może fałszować wiadomość uwierzytelniającą i podmienić ją na fałszywą a zaufana strona trzecia nie będzie w stanie tego zweryfikować. \n\nOdpowiedź **pobranie listu uwierzytelniajacego od obu stron** jest niepoprawna ponieważ zakłada, że strona trzecia uzależniona jest od obu stron potrzebujących uwierzytelnienia. Powoduje to to samo zagrożenie, co w przypadku powyższej odpowiedzi. Zaufana strona trzecia, powinna sama z siebie podejmować decyzję o poprawności tożsamości podmiotu. \n\nOdpowiedź **uwierzytelnienie jednej ze stron**  jest poprawna, ale niepełna. Zaufana trzecia strona, nie jest odpowiedzialna tylko za uwierzytelnianie jednej ze stron. Uwierzytelnienie jest warunkiem koniecznym dla wydania poświadczenia o którym mowa powyżej, ale nie jest celem samym w sobie. Celem jest *poswiadczenie* a nie samo uwierzytelnienie.\n\nPrzykładowo, w protokole Kerberos, który szeroko wykorzystuje ideę zaufanej trzeciej strony, serwer uwierzytelniania (KDC) po zweryfikowaniu tożsamości użytkownika wystawia mu specjalny bilet(_ang. ticket_). Ten bilet, kryptograficznie podpisany przez KDC, poświadcza tożsamość użytkownika wobec innych serwerów w domenie Kerberos. Inne serwery, które ufają KDC nie weryfikują już bezpośrednio tożsamości użytkownika - ufają poświadczeniu KDC."
    },
    {
        "questionId": 177,
        "title": "W uwierzytelnianiu z udzialem zaufanej trzeciej strony, do zadan strony uwierzytelnianej nalezy:",
        "answers": [
            {
                "text": "przekazanie poswiadczenia uwierzytelnienia drugiej ze stron",
                "isCorrect": true
            },
            {
                "text": "pobranie poswiadczenie uwierzytelnienia od drugiej ze stron",
                "isCorrect": false
            },
            {
                "text": "przekazanie danych uwierzytelniajacych drugiej ze stron",
                "isCorrect": false
            },
            {
                "text": "przekazanie danych uwierzytelniajacych stronie trzeciej",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Uwierzytelnianie z udziałem zaufanej trzeciej strony (TTP) to proces, w którym podmiot, chcąc udowodnić swoją tożsamość innemu podmiotowi, korzysta z usług zaufanego pośrednika. Ten pośrednik potwierdza tożsamość podmiotu, wystawiając specjalne poświadczenie (token) i dopiero to poświadczenie, a nie bezpośrednio dane uwierzytelniające, przekazywane jest do podmiotu weryfikującego.  Proces ten różni się od bezpośredniego uwierzytelniania, gdzie podmiot udowadnia tożsamość bezpośrednio podmiotowi weryfikującemu. TTP wprowadza dodatkowy element zaufania i pośrednictwa, co ma na celu zwiększenie bezpieczeństwa i elastyczności uwierzytelniania.\n\n**Odpowiedź \"przekazanie poświadczenia uwierzytelnienia drugiej ze stron\" jest poprawna**. Uwierzytelniany podmiot, po otrzymaniu poświadczenia od zaufanej trzeciej strony, przekazuje to poświadczenie podmiotowi weryfikującemu. To poświadczenie (token) jest dowodem, że tożsamość podmiotu została zweryfikowana. Na przykład, w protokole Kerberos, klient po uwierzytelnieniu u centrum dystrybucji kluczy (KDC) otrzymuje bilet (token), który następnie przedstawia serwerowi, z którym chce się połączyć. Bilet zawiera informacje, które serwer może zweryfikować, potwierdzając tym samym tożsamość klienta.\n\n**Odpowiedź \"pobranie poświadczenia uwierzytelnienia od drugiej ze stron\" jest niepoprawna**.  W uwierzytelnianiu z TTP, to podmiot uwierzytelniany pobiera poświadczenie od zaufanej trzeciej strony, a nie od strony weryfikującej. Strona weryfikująca tożsamość nie ma podstawy do wygenerowania takiego poświadczenia, jest nią tylko TTP. W protokole OAuth, klient nie pobiera tokena od zasobu (druga strona), tylko od serwera autoryzacji, który jest zaufanym pośrednikiem.\n\n**Odpowiedź \"przekazanie danych uwierzytelniających drugiej ze stron\" jest niepoprawna**. W modelu TTP, podmiot uwierzytelniany nie przekazuje swoich danych uwierzytelniających, takich jak hasło, bezpośrednio podmiotowi weryfikującemu. Bezpieczeństwo takiego modelu opiera się na tym, że tożsamość podmiotu jest weryfikowana przez zaufaną stronę trzecią, a nie bezpośrednio przez potencjalnie niebezpieczną stronę weryfikującą. Przykładowo, jeśli użytkownik chce zalogować się do aplikacji przy pomocy \"Logowanie przez Google\", nie podaje swojego hasła bezpośrednio aplikacji, tylko uwierzytelnia się u Google, która przekazuje do aplikacji tylko token potwierdzający uwierzytelnienie.\n\n**Odpowiedź \"przekazanie danych uwierzytelniających stronie trzeciej\" jest poprawna**. Podmiot uwierzytelniany, w pierwszej kolejności, przekazuje swoje dane uwierzytelniające (np. hasło) do zaufanej trzeciej strony. To zaufana trzecia strona dokonuje weryfikacji tych danych i w przypadku sukcesu wystawia podmiotowi token/poświadczenie autentyczności. Przykładem jest protokół Kerberos, gdzie klient najpierw uwierzytelnia się do centrum dystrybucji kluczy (KDC), podając swoje hasło, a potem uzyskuje bilet, który służy do udowodnienia tożsamości serwerowi."
    },
    {
        "questionId": 178,
        "title": "Zastosowanie rozszerzenia Enigmail w kliencie poczty Thunderbird pozwala na:",
        "answers": [
            {
                "text": "uzywanie mechanizmu SSL do zapewniania bezpiecznych szyfrowanych kanalow komunikacyjnych z serwerem poczty POP",
                "isCorrect": false
            },
            {
                "text": "wykorzystywanie PGP do szyfrowania i podpisywania wiadomosci",
                "isCorrect": true
            },
            {
                "text": "ochrone przed atakami man-in-the-middle",
                "isCorrect": false
            },
            {
                "text": "uzywanie mechanizm SSL do zapewniania bezpiecznych szyfrowanych kanalow komunikacyjnych z serwerem poczty SMTP",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Enigmail jest rozszerzeniem do klienta poczty Thunderbird, które umożliwia stosowanie protokołu PGP (_Pretty Good Privacy_) do szyfrowania i podpisywania wiadomości e-mail. PGP to standard kryptograficzny służący do zapewniania poufności i integralności wiadomości, wykorzystujący kryptografię asymetryczną (klucze publiczne i prywatne) oraz symetryczną.\n\n* **\"uzywanie mechanizmu SSL do zapewniania bezpiecznych szyfrowanych kanalow komunikacyjnych z serwerem poczty POP\"** - Jest to odpowiedź niepoprawna. SSL (_Secure Sockets Layer_) jest protokołem służącym do zabezpieczenia kanału komunikacyjnego między klientem a serwerem na poziomie transportowym. Chociaż Thunderbird wspiera SSL do bezpiecznego łączenia się z serwerami POP3, to nie jest to funkcja rozszerzenia Enigmail, które koncentruje się na PGP. SSL chroni przed podsłuchem na trasie klient-serwer, nie zapewnia natomiast poufności wiadomości u źródła (w skrzynce nadawcy). Przykładem zastosowania SSL jest przesyłanie danych uwierzytelniających do serwera POP3, które zostają zabezpieczone za pomocą SSL na całej trasie przesyłu a nie na poziomie wiadomości e-mail.\n\n* **\"wykorzystywanie PGP do szyfrowania i podpisywania wiadomosci\"** - Jest to odpowiedź poprawna. Enigmail został zaprojektowany jako rozszerzenie, które integruje PGP z Thunderbirdem, umożliwiając użytkownikom szyfrowanie treści wiadomości tak, aby tylko odbiorca dysponujący odpowiednim kluczem prywatnym mógł je odczytać. Ponadto Enigmail pozwala na dodawanie do wiadomości podpisów cyfrowych, które potwierdzają integralność oraz autentyczność autora danej wiadomości. Praktyczne zastosowanie można zaobserwować, gdy dwie osoby (nadawca i odbiorca), wymieniające poufne informacje, używają Enigmaila do podpisywania wiadomości a nadawca szyfruje list kluczem publicznym odbiorcy, dzięki temu odbiorca na 100% jest pewny, że to nadawca wysłał wiadomość i żadna osoba trzecia nie była w stanie ingerować w treść tej wiadomości.\n\n* **\"ochrone przed atakami man-in-the-middle\"** - Jest to odpowiedź niepoprawna. Chociaż PGP w pewnym stopniu chroni przed atakami typu \"man-in-the-middle\" (ze względu na poufność i integralność przesyłanych danych), to Enigmail nie zapewnia takiej ochrony dla połączenia z serwerem poczty POP3 lub SMTP. Enigmail jest tylko narzędziem do obsługi PGP, natomiast protokół SSL/TLS (nie jest on funkcjonalnością enigmail) jest odpowiedni do ochrony przed atakami \"man-in-the-middle\". Przykładem takiego ataku może być przechwytywanie danych przesyłanych z hasłem przez serwer pop3, jeśli nie jest ono szyfrowane.\n\n* **\"uzywanie mechanizmu SSL do zapewniania bezpiecznych szyfrowanych kanalow komunikacyjnych z serwerem poczty SMTP\"** - Jest to odpowiedź niepoprawna. Analogicznie jak w przypadku protokołu POP, protokół SMTP również może używać protokołu SSL w celu nawiązania bezpiecznego połączenia, jednak to nie jest główna funkcja rozszerzenia Enigmail. Enigmail skupia się na szyfrowaniu i podpisywaniu wiadomości przy użyciu PGP, a nie na zabezpieczaniu samej sesji połączenia pomiędzy klientem poczty a serwerem. Praktycznie wygląda to tak, że Enigmail zapewnia podpisanie/zaszyfrowanie każdej wiadomości e-mail niezależnie od tego czy klient łączy się z serwerem SMTP przy użyciu bezpiecznego połączenia SSL czy nie."
    },
    {
        "questionId": 179,
        "title": "Szyfr, w ktorym poddawana szyfrowaniu zostaje tej samej wielkosci jednobajtowa porcja nieregularnie pojawiajacych sie danych, nazywamy:",
        "answers": [
            {
                "text": "strumieniowym",
                "isCorrect": true
            },
            {
                "text": "symetrycznym",
                "isCorrect": false
            },
            {
                "text": "blokowym",
                "isCorrect": false
            },
            {
                "text": "niesymetrycznym",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfry strumieniowe przetwarzają dane bit po bicie lub bajt po bajcie. Szyfrowanie w szyfrach strumieniowych odbywa się poprzez generowanie tzw. keystreamu, czyli strumienia klucza. Strumień klucza jest generowany za pomocą algorytmu na podstawie tajnego klucza. Keystream ten jest następnie wykorzystywany do szyfrowania strumienia danych jawnych poprzez operację XOR, która daje w wyniku strumień danych zaszyfrowanych. Tego typu szyfrowanie jest charakterystyczne dla danych, które pojawiają się nieregularnie np.  strumieni audio i video, w przeciwieństwie do szyfrów blokowych które przetwarzają większe bloki danych o stałej długości. \n\n**strumieniowym** - To jest poprawna odpowiedź. Szyfr strumieniowy (ang. stream cipher)  działa w taki sposób, że szyfruje dane bit po bicie lub bajt po bajcie. Idealnie nadaje się do przetwarzania danych pojawiających się w czasie rzeczywistym (strumieni) i nieregularnie, takich jak strumienie audio, video, czy dane przesyłane z klawiatury. Algorytm szyfrujący generuje ciąg klucza (ang. keystream), który następnie jest używany do szyfrowania danych wejściowych. Typowym przykładem szyfru strumieniowego jest RC4.\n\n**symetrycznym** - Ta odpowiedź jest niepoprawna. Szyfr symetryczny (ang. symmetric cipher) to ogólna kategoria szyfrów, gdzie ten sam klucz jest używany zarówno do szyfrowania, jak i deszyfrowania. Szyfry strumieniowe _zwykle_ należą do tej kategorii, jednak szyfry blokowe również są szyframi symetrycznymi. Stąd odpowiedź jest zbyt ogólna. Przykładem algorytmu symetrycznego jest AES (Advanced Encryption Standard).\n\n**blokowym** - Ta odpowiedź jest niepoprawna. Szyfr blokowy (ang. block cipher) operuje na danych dzieląc je na bloki o ustalonej długości np. 128 lub 256 bitów. Bloki danych są szyfrowane i deszyfrowane jako pojedyncze całości. Szyfry blokowe nadają się idealnie do szyfrowania danych o znanej długości.  Przykłady szyfrów blokowych to DES, AES, 3DES. \n\n**niesymetrycznym** - Ta odpowiedź jest niepoprawna. Szyfr niesymetryczny (ang. asymmetric cipher), zwany też szyfrem klucza publicznego, wykorzystuje parę kluczy: publiczny (do szyfrowania) i prywatny (do deszyfrowania). Ten typ szyfrowania jest mniej wydajny niż szyfrowanie symetryczne i stosuje się je głównie w celu dystrybucji tajnych kluczy szyfrowania symetrycznego lub tworzenia podpisu cyfrowego. Przykładem algorytmu asymetrycznego jest RSA."
    },
    {
        "questionId": 180,
        "title": "Istotna przewaga podpisu elektronicznego nad odrecznym polega m. in. na:",
        "answers": [
            {
                "text": "jest scisle powiazany z trescia podpisywanego dokumentu",
                "isCorrect": true
            },
            {
                "text": "weryfikacja podpisu wymaga tylko dostepu do certyfikatu klucza prywatnego podpisujacego, co wystarcza do sadowego uznania podpisu za autentyczny",
                "isCorrect": false
            },
            {
                "text": "autentycznosc podpisu mozna zweryfikowac poprzez prosta weryfikacje certyfikatu klucza publicznego podpisujacego",
                "isCorrect": true
            },
            {
                "text": "samo zlozenie podpisu umozliwia wyparcie sie tego przez podpisujacego",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Podpis elektroniczny, w przeciwieństwie do podpisu odręcznego, jest nierozłącznie związany z treścią podpisywanego dokumentu dzięki użyciu funkcji skrótu kryptograficznego. Funkcja skrótu, taka jak SHA-256, tworzy unikalny \"odcisk palca\" danych wejściowych (dokumentu). Podpis elektroniczny generowany jest poprzez zaszyfrowanie tego skrótu kluczem prywatnym nadawcy. Oznacza to, że każda nawet najmniejsza zmiana w dokumencie spowoduje powstanie innego skrótu a co za tym idzie unieważni podpis. Ta właściwość zapewnia integralność dokumentu.\n**Odpowiedź 1 (poprawna):** \"jest scisle powiazany z trescia podpisywanego dokumentu\". To jest kluczowa cecha podpisu elektronicznego. Użycie funkcji skrótu kryptograficznego gwarantuje, że nawet najmniejsza zmiana w dokumencie spowoduje, że weryfikacja podpisu nie powiedzie się. Dla przykładu, jeśli chcemy podpisać umowę zakupu, to podpisany zostanie skrót tej umowy. Zmiana chociażby jednego znaku w treści umowy spowoduje zmianę skrótu i tym samym podpisanie takiego dokumentu stanie się niemożliwe.\n**Odpowiedź 2 (niepoprawna):** \"weryfikacja podpisu wymaga tylko dostepu do certyfikatu klucza prywatnego podpisujacego, co wystarcza do sadowego uznania podpisu za autentyczny\". Jest to błędne stwierdzenie. Podpis elektroniczny weryfikowany jest kluczem publicznym, nie prywatnym. Klucz prywatny służy do utworzenia podpisu, natomiast klucz publiczny do jego weryfikacji. W postępowaniu sądowym, ważny jest cały proces weryfikacji podpisu elektronicznego począwszy od certyfikatu, którym jest podpisany klucz publiczny. Klucz prywatny powinien pozostawać zawsze w ukryciu i dostępny tylko dla właściciela. Wykorzystanie klucza prywatnego dla procesu weryfikacji podważyłby całkowicie bezpieczeństwo takiego rozwiązania.\n**Odpowiedź 3 (poprawna):** \"autentycznosc podpisu mozna zweryfikowac poprzez prosta weryfikacje certyfikatu klucza publicznego podpisujacego\". Autentyczność podpisu elektronicznego jest możliwa dzięki wykorzystaniu certyfikatu klucza publicznego podpisującego. Certyfikat (wystawiony np. przez urząd certyfikacji) potwierdza, że klucz publiczny należy do konkretnej osoby lub podmiotu. Mając certyfikat i publiczny klucz podpisującego, można jednoznacznie zweryfikować czy dany dokument został podpisany kluczem prywatnym, który odpowiada kluczowi publicznemu z certyfikatu i czy nie uległ zmianie. Dodatkowo, na wiarygodność certyfikatu ma wpływ hierarchia certyfikacji i zaufania do urzędów certyfikacji.\n**Odpowiedź 4 (niepoprawna):** \"samo zlozenie podpisu umozliwia wyparcie sie tego przez podpisujacego\". Podpis elektroniczny zapewnia niezaprzeczalność. Ponieważ klucz prywatny służący do utworzenia podpisu jest znany tylko podpisującemu, i nie ma możliwości podrobienia go, to podpisujący nie może zaprzeczyć, że to on podpisał dokument, chyba, że udowodni, że jego klucz prywatny został skompromitowany. Dzieje się tak, ponieważ podpisany skrót pliku(dokumentu) jest unikalny dla danego dokumentu i klucza prywatnego. W przypadku odręcznego podpisu udowodnienie autorstwa i zaprzeczenie jego jest znacznie prostsze i często niemożliwe do jednoznacznego udowodnienia."
    },
    {
        "questionId": 181,
        "title": "Prosze wskazac algorytmy wykorzystywane w HMAC:",
        "answers": [
            {
                "text": "AES",
                "isCorrect": false
            },
            {
                "text": "SHA-4",
                "isCorrect": false
            },
            {
                "text": "ElGamal",
                "isCorrect": false
            },
            {
                "text": "Blowfish",
                "isCorrect": false
            },
            {
                "text": "Rijndael",
                "isCorrect": false
            },
            {
                "text": "MD5",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "HMAC (Hash-based Message Authentication Code) to mechanizm uwierzytelniania wiadomości, który wykorzystuje funkcję skrótu kryptograficznego oraz tajny klucz. Klucz ten jest znany tylko stronom uczestniczącym w komunikacji. HMAC zapewnia zarówno integralność danych, czyli pewność, że dane nie zostały zmienione podczas transmisji, jak i autentyczność, czyli pewność, że wiadomość pochodzi od autoryzowanego nadawcy. HMAC działa w taki sposób, że generuje skrót z wiadomości (funkcją skrótu), do którego następnie dodaje tajny klucz.\nFunkcja skrótu kryptograficznego jest funkcją jednokierunkową, która z danych o dowolnej długości generuje wartość o stałym rozmiarze, zwaną skrótem lub haszem. Funkcje skrótu charakteryzują się kilkoma właściwościami: mają być proste obliczeniowo, odporne na kolizje (czyli bardzo trudno jest znaleźć dwie różne wiadomości, które dają ten sam skrót) oraz nieodwracalne (czyli bardzo trudno jest odtworzyć wiadomość mając tylko jej skrót).\nHMAC łączy tajny klucz z funkcją skrótu, co uniemożliwia atakującemu, nawet znającemu algorytm używanej funkcji skrótu, podrobienie skrótu z tajnym kluczem i tym samym wysłanie nieautentycznej wiadomości.\n\n**AES** (Advanced Encryption Standard) to symetryczny algorytm szyfrowania blokowego, służący do poufności danych (szyfrowania), a nie do tworzenia skrótów. W HMAC nie jest stosowany, ponieważ jego celem jest stworzenie kodu uwierzytelniającego wiadomości, a nie zaszyfrowanie ich treści. Przykładowo, AES jest używany w połączeniach SSL/TLS do szyfrowania wymienianych danych, a nie do ich uwierzytelniania za pomocą HMAC.\n\n**SHA-4** nie jest poprawną nazwą algorytmu. Chodzi zapewne o algorytmy z rodziny SHA (Secure Hash Algorithm) jak SHA-1, SHA-256, czy SHA-512. Algorytmy te są jednokierunkowymi funkcjami skrótu, generującymi skrót wiadomości o ustalonym rozmiarze. SHA-1, SHA-256 i SHA-512 są powszechnie stosowane w HMAC, np. w protokołach bezpieczeństwa internetowego takich jak IPSec, gdzie służą do obliczania skrótu, który jest następnie powiązany z tajnym kluczem i używany do uwierzytelniania przesyłanych pakietów. SHA-4 nie jest jednak prawidłową odpowiedzią, gdyż taki algorytm nie istnieje.\n\n**ElGamal** jest asymetrycznym algorytmem szyfrowania, który jest stosowany do poufności danych lub podpisywania wiadomości, ale nie jest stosowany wprost w HMAC. Klucz publiczny służy do szyfrowania, a klucz prywatny do deszyfrowania i składania podpisu. Przykładowo, algorytm ElGamal może być użyty w systemach poczty elektronicznej do szyfrowania wiadomości, a nie w algorytmie HMAC.\n\n**Blowfish** jest symetrycznym algorytmem szyfrowania blokowego. Podobnie jak AES, Blowfish służy do szyfrowania treści wiadomości, a nie do ich uwierzytelniania. Jest to algorytm alternatywny dla AES, i jest powszechnie wykorzystywany np. w aplikacjach bazodanowych.\n\n**Rijndael** jest algorytmem symetrycznym szyfrowania blokowego, który w zmodyfikowanej formie jest również algorytmem AES. Podobnie jak Blowfish, nie jest używany bezpośrednio w HMAC, a jedynie jako algorytm szyfrujący, gdzie celem jest utajnienie a nie uwierzytelnienie wiadomości.\n\n**MD5** (Message Digest 5) jest funkcją skrótu kryptograficznego, generującą 128-bitowy skrót, która może być użyta w algorytmie HMAC, ale nie tylko. Jest to algorytm jednokierunkowy, co oznacza, że ​​na podstawie skrótu nie można odtworzyć oryginalnej wiadomości, ale mając klucz tajny można uwierzytelnić przesyłane dane obliczając funkcję skrótu w połączeniu z kluczem tajnym. HMAC wykorzystujący MD5 to HMAC-MD5. Przykładowo, HMAC-MD5 jest często używany w protokołach sieciowych do zapewnienia integralności i autentyczności przesyłanych pakietów."
    },
    {
        "questionId": 182,
        "title": "System NAC (Network Admission Control):",
        "answers": [
            {
                "text": "oferuja filtracje poczty elektronicznej",
                "isCorrect": false
            },
            {
                "text": "sluza realizacji rozleglych korporacyjnych sieci VPN",
                "isCorrect": false
            },
            {
                "text": "to zapory sieciowe stosujace bezstanowe reguly filtracji",
                "isCorrect": false
            },
            {
                "text": "umozliwiaja blokowanie ruchu sieciowego ze stacji nie spelniajacych wymagan polityki bezpieczenstwa",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "System NAC (Network Admission Control) to mechanizm bezpieczeństwa sieciowego, który kontroluje dostęp urządzeń do sieci, opierając się na zdefiniowanej polityce bezpieczeństwa. NAC nie jest zaporą sieciową ani systemem VPN, chociaż może z nimi współpracować. Jego głównym celem jest weryfikacja, czy urządzenia próbujące połączyć się z siecią spełniają określone wymagania bezpieczeństwa (np. posiadają aktualne oprogramowanie antywirusowe, system operacyjny z zainstalowanymi łatkami, określoną konfigurację). Jeśli urządzenie nie spełnia tych wymagań, dostęp jest blokowany lub ograniczany do czasu spełnienia warunków. NAC jest więc rozwiązaniem *proaktywnym*, mającym zapobiegać, a nie tylko reagować na incydenty.\n\n**Odpowiedź 1: \"oferuja filtracje poczty elektronicznej\"** jest niepoprawna. Filtracja poczty elektronicznej to zadanie serwerów pocztowych, bramek antyspamowych czy specjalistycznego oprogramowania antyspamowego. NAC nie jest zaprojektowany do analizy i filtrowania zawartości e-maili.\n\n**Odpowiedź 2: \"sluza realizacji rozleglych korporacyjnych sieci VPN\"** jest niepoprawna. Sieci VPN (Virtual Private Networks) służą do tworzenia bezpiecznych, zaszyfrowanych połączeń między różnymi sieciami lub użytkownikami, często poprzez sieć publiczną, np. Internet. Mechanizmy VPN zapewniają poufność i integralność przesyłanych danych. NAC nie tworzy tuneli VPN, choć może współpracować z systemami VPN. Na przykład, urządzenie logujące się poprzez VPN może być poddane weryfikacji NAC przed uzyskaniem pełnego dostępu do sieci.\n\n**Odpowiedź 3: \"to zapory sieciowe stosujace bezstanowe reguly filtracji\"** jest niepoprawna. Zapory sieciowe, w przeciwieństwie do NAC, koncentrują się na kontrolowaniu przepływu pakietów sieciowych na podstawie zdefiniowanych reguł. Zapory, mogą być stanowe (analizują historię połączenia) lub bezstanowe (analizują każdy pakiet osobno). NAC nie analizuje każdego pakietu pod względem źródła i celu ruchu, a skupia się na weryfikacji stanu urządzenia z punktu widzenia polityki bezpieczeństwa. NAC może współpracować z zaporą sieciową, na przykład dynamicznie zmieniać reguły zapory w zależności od stanu urządzenia.\n\n**Odpowiedź 4: \"umozliwiaja blokowanie ruchu sieciowego ze stacji nie spelniajacych wymagan polityki bezpieczenstwa\"** jest poprawna. Jest to kluczowa funkcja systemu NAC. Przykładowo, w sieci firmowej, urządzenie pracownika, które nie posiada aktualnego oprogramowania antywirusowego, nie zostanie wpuszczone do sieci lub zostanie poddane kwarantannie, czyli zostanie umieszczone w wyodrębnionej sieci o ograniczonym dostępie do zasobów i Internetu. Dopiero po spełnieniu wymagań (zainstalowaniu poprawek, uruchomieniu programu antywirusowego), system NAC umożliwi pełny dostęp do zasobów sieci. Inny przykład to sytuacja, gdzie osoba z zewnątrz (np. kontrahent) loguje się do sieci firmowej poprzez sieć bezprzewodową. Urządzenie takiej osoby może zostać poddane kontroli NAC. Jeżeli np. system operacyjny na tym urządzeniu jest przestarzały lub nie posiada wymaganych zabezpieczeń – połączenie zostanie zablokowane."
    },
    {
        "questionId": 183,
        "title": "Metoda PING stosowana przez systemy IDS polega na wyslaniu:",
        "answers": [
            {
                "text": "zapytania ICMP echo request pod adres MAC niezgodny z odpytywanym IP i oczekiwaniu na odpowiedz",
                "isCorrect": true
            },
            {
                "text": "pakietow ICMP ping i porownaniu roznic w czasach odpowiedzi pomiedzy roznymi stanowiskami",
                "isCorrect": false
            },
            {
                "text": "zapytania ICMP echo request pod adres rozgloszeniowy i oczekiwaniu na odpowiedz",
                "isCorrect": false
            },
            {
                "text": "zapytania ICMP echo request pod adres MAC podejrzanej stacji i oczekiwaniu na odpowiedz",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Metoda PING, w kontekście systemów wykrywania włamań (IDS), nie polega na standardowym wysyłaniu zapytań ICMP Echo Request w celu sprawdzenia dostępności hosta. Zamiast tego, IDS może wykorzystać modyfikację tego zapytania w celu przeprowadzenia aktywnego sondowania sieci i ewentualnego wykrycia podejrzanych zachowań. W standardowej sytuacji polecenie `ping` wysyła żądanie ICMP Echo Request do docelowego adresu IP, a system docelowy odpowiada pakietem ICMP Echo Reply, jeśli jest aktywny. Systemy IDS mogą modyfikować standardową procedurę PING, manipulując adresem MAC aby wykryć anomalie sieciowe lub próbować zidentyfikować podatności systemu. Adres MAC (Media Access Control) jest adresem warstwy drugiej modelu OSI i jest unikalny dla każdej karty sieciowej. Z kolei adres IP jest adresem warstwy trzeciej i jest wykorzystywany do routingu pakietów w sieciach TCP/IP. Komputery w sieci lokalnej kontaktują się ze sobą za pomocą adresów MAC i odwzorowują IP na MAC za pomocą protokołu ARP (Address Resolution Protocol).\n\n**Opcja 1 (poprawna):** \"zapytania ICMP echo request pod adres MAC niezgodny z odpytywanym IP i oczekiwaniu na odpowiedz\". Ta odpowiedź jest poprawna. System IDS celowo wysyła pakiet ICMP Echo Request z poprawnym adresem IP, ale z adresem MAC, który nie jest powiązany z tym adresem IP. W normalnych warunkach, odpowiedź na takie zapytanie nie powinna nastąpić. Jeśli jednak system odpowie, może to wskazywać na niepoprawną konfigurację, atak typu ARP spoofing (gdzie tablica ARP została zmodyfikowana i odwzorowuje adres IP na niepoprawny adres MAC) lub inne nieprawidłowości w sieci. Na przykład, IDS może wysłać zapytanie ping do adresu IP 192.168.1.100, ale z adresem MAC przypisanym do 192.168.1.200. Reakcja systemu na tak spreparowany pakiet może ujawnić ataki podszywania lub błędy w konfiguracji.\n    \n**Opcja 2 (niepoprawna):** \"pakietow ICMP ping i porownaniu roznic w czasach odpowiedzi pomiedzy roznymi stanowiskami\". Ta odpowiedź jest niepoprawna. Porównywanie różnic w czasach odpowiedzi między różnymi stanowiskami może być elementem diagnostyki sieci lub wykrywania problemów z opóźnieniami, ale samo wysłanie standardowych pakietów ping nie jest typową metodą wykrywania włamań, a w szczególności nie manipuluje adresami MAC. Natomiast pomiar opóźnienia może ujawnić np. problemy ze spójnością danych przesyłanych przez połączenie VPN.\n\n**Opcja 3 (niepoprawna):** \"zapytania ICMP echo request pod adres rozgloszeniowy i oczekiwaniu na odpowiedz\". Ta odpowiedź jest niepoprawna. Wysyłanie zapytań ICMP echo request na adres rozgłoszeniowy jest metodą sondowania całej sieci, a nie konkretnego hosta i często wykorzystywane w atakach typu \"smurf\", gdzie pakiety ping są wysyłane na adresy rozgłoszeniowe z adresem IP ofiary jako adresem nadawcy, co powoduje wysłanie dużej ilości odpowiedzi na adres ofiary. System IDS używający tej metody również nie manipuluje w tym wypadku adresem MAC. Wysyłanie na adres rozgłoszeniowy ICMP jest niebezpieczne i często jest blokowane na firewallach.\n\n**Opcja 4 (niepoprawna):** \"zapytania ICMP echo request pod adres MAC podejrzanej stacji i oczekiwaniu na odpowiedz\". Ta odpowiedź jest niepoprawna. Standardowo, pakiet ICMP nie zawiera adresu MAC, tylko adres IP w nagłówku warstwy trzeciej i docelowy adres MAC w nagłówku warstwy drugiej. Wysyłając taki pakiet używamy protokołu ARP do ustalenia docelowego adresu MAC danego adresu IP. IDS wykonuje dodatkowo modyfikacje takie jak podmiana adresu MAC na niepoprawny. Wysłanie pakietu ping z poprawnym adresem IP, ale do konkretnego adresu MAC bez sprawdzenia czy jest on poprawny z punktu widzenia protokołu ARP nie przynosi żadnych pożądanych efektów z punktu widzenia IDS."
    },
    {
        "questionId": 184,
        "title": "Cechy charakterystyczne ataku SYN flood to:",
        "answers": [
            {
                "text": "intensywny strumien segmentow SYN skierowany na adres ofiary",
                "isCorrect": true
            },
            {
                "text": "intensywny strumien segmentow SYN/ACK skierowany na adres ofiary",
                "isCorrect": false
            },
            {
                "text": "brak segmentow SYN/ACK",
                "isCorrect": false
            },
            {
                "text": "brak segmentow ACK",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Atak SYN flood wykorzystuje protokół TCP i jego trójstopniowy proces nawiązywania połączenia (tzw. TCP handshake), aby przeciążyć serwer. TCP handshake to proces uzgadniania parametrów połączenia pomiędzy klientem a serwerem za pomocą trzech segmentów. Klient wysyła segment z ustawioną flagą SYN (synchronizacja), serwer odsyła segment z flagami SYN i ACK (potwierdzenie synchronizacji), a klient odsyła segment z ustawioną flagą ACK (potwierdzenie).\n\nAtak SYN flood polega na wysłaniu przez atakującego dużej liczby segmentów TCP z ustawioną flagą SYN na adres serwera. Kluczowe jest to, że atakujący nie wysyła ostatniego segmentu z ustawioną flagą ACK. W prawidłowym połączeniu po otrzymaniu segmentu SYN serwer przydziela zasoby oczekując na segment ACK. Ze względu na brak segmentów ACK serwer jest przeciążony dużą ilością otwartych niepełnych połączeń. W rzeczywistości, atakujący podszywa się pod adres IP, z którego wysyłane są segmenty SYN co powoduje przeciążenie serwera wielką ilością próśb o nawiązanie połączenia.\n\n**Poprawna odpowiedź pierwsza:** \"intensywny strumien segmentow SYN skierowany na adres ofiary\" - Jest to kluczowa cecha ataku. Celem ataku SYN flood jest przeciążenie serwera dużą ilością żądań nawiązania połączenia w postaci pakietów z ustawioną flagą SYN, a więc bez finalizacji połączenia poprzez pakiet ACK. Atakujący nie ma intencji nawiązania pełnego połączenia, a jedynie zużycia zasobów serwera.\n\n**Niepoprawna odpowiedź druga:** \"intensywny strumien segmentow SYN/ACK skierowany na adres ofiary\" - Odpowiedź ta jest błędna. Segmenty SYN/ACK są odpowiedzią serwera na segmenty SYN. To, że atakiujący w ogóle na nie nie czeka, jest częścią ataku, a nie charakteryzuje sam atak, a jego następstwo. Celem ataku jest przeciążenie serwera, a nie generowanie segmentów SYN/ACK.\n\n**Niepoprawna odpowiedź trzecia:** \"brak segmentow SYN/ACK\" - Ta odpowiedź jest niepoprawna. Segmenty SYN/ACK są generowane przez serwer w odpowiedzi na segmenty SYN wysłane przez atakującego. Brak segmentów SYN/ACK nie jest cechą ataku SYN flood.\n\n**Poprawna odpowiedź czwarta:** \"brak segmentow ACK\" - Jest to kluczowy element ataku. Atakujący wysyła segmenty SYN ale nie wysyła segmentu ACK. Zatem połączenie nigdy nie zostaje poprawnie nawiązane, a serwer pozostaje w stanie oczekiwania na ostatni segment TCP handshake. Brak segmentów ACK, czyli finalnego kroku w procesie trójstopniowego uzgadniania połączenia powoduje gromadzenie półotwartych połączeń i wyczerpanie zasobów serwera, prowadząc do jego niedostępności.\n\nPrzykład z życia wzięty. Wyobraźmy sobie, że serwer to restauracja, a klienci to programy próbujące się połączyć. W normalnej sytuacji klient dzwoni (SYN), restauracja potwierdza, że odebrała telefon (SYN/ACK) i klient mówi \"dobrze\" (ACK), na co restauracja rezerwuje stolik. W ataku klient dzwoni (SYN) i restauracja potwierdza, że odebrała telefon (SYN/ACK), ale klient nie mówi \"dobrze\" (brak ACK) i dzwoni kolejny. W ten sposób wszystkie linie są zajęte, a restauracja nie ma żadnych stolików dla prawdziwych klientów. Atak polega na ciągłym wysyłaniu zapytań bez finalizowania sesji, a nie na braku odpowiedzi (SYN/ACK), czy na tym że serwer w ogóle na nie nie czeka (ACK)."
    },
    {
        "questionId": 185,
        "title": "Do szyfrow symetrycznych zaliczamy:",
        "answers": [
            {
                "text": "IDEA",
                "isCorrect": true
            },
            {
                "text": "RSA",
                "isCorrect": false
            },
            {
                "text": "Rijndael",
                "isCorrect": true
            },
            {
                "text": "Blowfish",
                "isCorrect": true
            },
            {
                "text": "ElGamal",
                "isCorrect": false
            },
            {
                "text": "MD4",
                "isCorrect": false
            },
            {
                "text": "MD5",
                "isCorrect": false
            },
            {
                "text": "DES",
                "isCorrect": true
            },
            {
                "text": "RC4",
                "isCorrect": true
            },
            {
                "text": "RC2",
                "isCorrect": true
            },
            {
                "text": "AES",
                "isCorrect": true
            },
            {
                "text": "Żadne z powyższych",
                "isCorrect": false
            }
        ],
        "clue": 7,
        "isStarred": false,
        "explanation": "Szyfry symetryczne, w przeciwieństwie do asymetrycznych, wykorzystują ten sam klucz zarówno do szyfrowania, jak i deszyfrowania danych. Oznacza to, że obie strony komunikacji (nadawca i odbiorca) muszą znać ten sam tajny klucz. Zaletą szyfrów symetrycznych jest ich szybkość działania i efektywność w szyfrowaniu dużych ilości danych. Wadą zaś konieczność bezpiecznego przekazania klucza między stronami, a także trudność w skalowaniu systemu, gdy komunikować ma się więcej niż dwie strony.\n\n**IDEA** (International Data Encryption Algorithm) jest algorytmem symetrycznym blokowym, używającym 128-bitowego klucza do szyfrowania danych w 64-bitowych blokach. Jest on szybki i efektywny, co czyni go dobrym wyborem do szyfrowania dużych porcji danych. Zastosowanie można znaleźć w oprogramowaniu szyfrującym pliki.\n\n**RSA** (Rivest–Shamir–Adleman) to algorytm asymetryczny, opierający się na matematycznej trudności faktoryzacji dużych liczb. W RSA używa się pary kluczy: publicznego, służącego do szyfrowania, oraz prywatnego, przeznaczonego do odszyfrowania. RSA jest wolniejszy od algorytmów symetrycznych i dlatego częściej wykorzystuje się go do szyfrowania kluczy sesyjnych, a nie danych. Znajduje zastosowanie w infrastrukturze klucza publicznego (PKI).\n\n**Rijndael** to algorytm symetryczny, który został wybrany jako standard AES (Advanced Encryption Standard). Jest on blokowy i obsługuje różne długości kluczy i bloków. Jest on szybki i wszechstronny, znalazł zastosowanie w protokołach SSL/TLS i VPN.\n\n**Blowfish** jest symetrycznym algorytmem blokowym, używającym kluczy o zmiennej długości. Jest znany ze swojej szybkości i elastyczności, co czyni go użytecznym w różnych zastosowaniach, jak np. szyfrowanie plików.\n\n**ElGamal** to algorytm asymetryczny, wykorzystujący logarytm dyskretny. Używa się go do szyfrowania i generowania podpisów cyfrowych. Podobnie jak RSA, jest stosunkowo wolny i częściej używany do wymiany kluczy sesyjnych, niż szyfrowania dużych plików.\n\n**MD4** i **MD5** to funkcje skrótu (hash functions), a nie szyfry. Funkcje skrótu są jednokierunkowe, to znaczy, z wygenerowanego skrótu nie da się odtworzyć oryginalnych danych. Używane są do weryfikacji integralności danych, a nie do ich szyfrowania. MD5, mimo że kiedyś powszechny, jest obecnie uważany za niezbyt bezpieczny z powodu odkrytych kolizji. Znajdują zastosowanie w algorytmach podpisu cyfrowego, gdzie skrót wiadomości jest podpisywany kluczem prywatnym.\n\n**DES** (Data Encryption Standard) jest algorytmem symetrycznym blokowym. Działa na blokach 64-bitowych przy użyciu klucza 56-bitowego. Chociaż kiedyś szeroko stosowany, obecnie uważany jest za niezbyt bezpieczny ze względu na stosunkowo krótki klucz. Ze względu na swoją małą długość klucza (56bit) nie jest odporny na ataki brutalnej siły. \n\n**RC4** (Rivest Cipher 4) to symetryczny szyfr strumieniowy, znany ze swojej szybkości. Jest stosowany w protokołach SSL i WEP. Należy pamiętać, iż RC4 nie jest uważany za wystarczająco bezpieczny i należy stosować nowsze algorytmy.\n\n**RC2** jest algorytmem symetrycznym blokowym o zmiennej długości klucza. Jest używany głównie do szyfrowania danych.\n\n**AES** (Advanced Encryption Standard) to symetryczny algorytm blokowy, następca standardu DES. Charakteryzuje się wysokim poziomem bezpieczeństwa i wydajnością. Jest powszechnie stosowany w różnych aplikacjach i protokołach (np. IPsec, TLS). Jest on standardem ochrony danych w Stanach Zjednoczonych, jak i innych krajach.\n\n\"Żadne z powyższych\" jest niepoprawną odpowiedzią, ponieważ wiele z wymienionych algorytmów to szyfry symetryczne."
    },
    {
        "questionId": 185,
        "title": "Do szyfrow symetrycznych zaliczamy:",
        "answers": [
            {
                "text": "MD4",
                "isCorrect": false
            },
            {
                "text": "Rijnadael",
                "isCorrect": false
            },
            {
                "text": "Blowfish",
                "isCorrect": false
            },
            {
                "text": "ElGamal",
                "isCorrect": true
            },
            {
                "text": "MD5",
                "isCorrect": false
            },
            {
                "text": "DES",
                "isCorrect": false
            },
            {
                "text": "Żadne z powyższych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie symetryczne to metoda szyfrowania, w której ten sam klucz jest używany zarówno do szyfrowania, jak i deszyfrowania danych.  Oznacza to, że obie strony komunikacji muszą wcześniej ustalić tajny klucz, który będzie wykorzystywany w procesie szyfrowania. \n\n* **MD4** oraz **MD5** to *funkcje skrótu*, a nie *algorytmy szyfrowania*. Funkcje skrótu, takie jak MD4 i MD5, generują skrót o stałej długości (tzw. _hash_) z danych wejściowych o zmiennej długości. Są to funkcje jednokierunkowe, co oznacza, że na podstawie skrótu nie można odtworzyć oryginalnych danych. Używa się ich do weryfikacji integralności danych, a nie do szyfrowania. Przykładem jest ochrona haseł. Hash hasła pozwala przechowywać w systemie jego zaszyfrowaną formę, dzięki czemu nikt nie może poznać prawdziwej wartości hasła tylko jego reprezentację.\n* **Rijndael** jest *algorytmem szyfrowania symetrycznego*. Algorytm Rijndael jest też znany jako Advanced Encryption Standard (AES) i używany w wielu aplikacjach i protokołach do szyfrowania danych. AES występuje w trzech wersjach o kluczach 128bitowych, 192bitowych oraz 256bitowych. Przykładowym zastosowaniem jest szyfrowanie połączeń bezprzewodowych(WiFi), standard WPA2. \n* **Blowfish** jest *algorytmem szyfrowania symetrycznego*. Algorytm Blowfish jest algorytmem blokowym, co oznacza że szyfruje dane w blokach. Jest często używany, gdyż jest szybki, sprawny i bezpłatny. Przykładowym zastosowaniem jest szyfrowanie danych przechowywanych na dysku, szyfrowanie archiwów (np. format 7z).\n* **ElGamal** jest *algorytmem szyfrowania asymetrycznego*. W algorytmie asymetrycznym używa się pary kluczy: publicznego (do szyfrowania) i prywatnego (do deszyfrowania). Klucz publiczny może być udostępniany publicznie, klucz prywatny musi być tajny. Ten algorytm używany jest do uzgadniania tajnych kluczy sesyjnych w protokole SSL/TLS, przesyłania podpisów cyfrowych.\n* **DES** (Data Encryption Standard) jest *algorytmem szyfrowania symetrycznego*, który był szeroko używany, jednak w obecnej chwili ze względu na stosunkowo krótką długość klucza 56 bitów nie jest uważany za bezpieczny algorytm. W celu zwiększenia bezpieczeństwa opracowano wersję 3DES gdzie stosuje się trzykrotne szyfrowanie tym samym algorytmem DES. Algorytm DES lub 3DES często jest spotykany w mechanizmach ochrony komunikacji w kartach płatniczych, bankomatach. \n* \"Żadne z powyższych\" - jest niepoprawna z uwagi na poprawne umiejscowienie w tej liście Blowfish, a ta odpowiedź jest wykluczona."
    },
    {
        "questionId": 186,
        "title": "Do szyfrow niesymetrycznych zaliczamy:",
        "answers": [
            {
                "text": "MD4",
                "isCorrect": false
            },
            {
                "text": "Rijnadael",
                "isCorrect": false
            },
            {
                "text": "Blowfish",
                "isCorrect": false
            },
            {
                "text": "ElGamal",
                "isCorrect": true
            },
            {
                "text": "MD5",
                "isCorrect": false
            },
            {
                "text": "DES",
                "isCorrect": false
            },
            {
                "text": "zadne z powyzszych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie asymetryczne, zwane też szyfrowaniem z kluczem publicznym, wykorzystuje parę kluczy: klucz publiczny, który może być swobodnie udostępniany, oraz klucz prywatny, który musi pozostać tajny. Klucz publiczny służy do szyfrowania danych, a odpowiadający mu klucz prywatny do ich odszyfrowania. W przeciwieństwie do tego, szyfry symetryczne wykorzystują ten sam klucz zarówno do szyfrowania, jak i odszyfrowywania danych. Klucz ten musi być utrzymany w tajemnicy przez obie strony komunikacji. Zastosowanie szyfrowania asymetrycznego eliminuje problem dystrybucji klucza występujący w szyfrowaniu symetrycznym. \n\n*   **MD4:**  MD4 (Message Digest 4) to algorytm haszujący, a nie algorytm szyfrowania. Algorytmy haszujące tworzą skrót danych (wartość haszującą) o stałej długości, który jest unikalny dla danego wejścia.  Funkcja haszująca jest jednokierunkowa, tzn. na podstawie wartości haszującej nie można odtworzyć pierwotnych danych. Stąd, MD4 nie należy do szyfrów symetrycznych, ani asymetrycznych.  MD4 był używany do tworzenia podpisów cyfrowych, ale obecnie jest uważany za niebezpieczny i nie powinien być używany. \n*   **Rijndael:** Rijndael to algorytm szyfrowania symetrycznego blokowego.  Oznacza to, że używa tego samego klucza do szyfrowania i odszyfrowania danych. Rijndael został wybrany jako standard AES (Advanced Encryption Standard) w 2001 roku. Jest stosowany do szyfrowania danych w wielu różnych aplikacjach, np. przy ochronie plików, komunikacji sieciowej.\n*   **Blowfish:** Blowfish to algorytm szyfrowania symetrycznego blokowego, co oznacza, że wykorzystuje ten sam klucz do szyfrowania i odszyfrowania danych.  Jest to szybki i elastyczny algorytm, który można skonfigurować za pomocą kluczy o różnej długości.  Blowfish jest często używany do szyfrowania plików i komunikacji w internecie, ale nie jest algorytmem asymetrycznym.\n*   **ElGamal:** ElGamal to algorytm szyfrowania asymetrycznego, co oznacza, że wykorzystuje dwie pary kluczy: klucz publiczny służący do szyfrowania i klucz prywatny służący do deszyfrowania.  Algorytm ElGamal jest używany do przesyłania danych, które muszą być utrzymywane w tajemnicy, jak i do tworzenia podpisów cyfrowych. ElGamal jest przykładem algorytmu, w którym problem tajności wiadomości jest równoważny problemowi dyskretnego logarytmu.\n*   **MD5:** MD5 (Message Digest 5) jest algorytmem haszującym, podobnie jak MD4.  MD5 tworzy skrót o długości 128-bitów, jednak nie jest on algorytmem szyfrującym symetrycznym ani asymetrycznym. Tak jak MD4, MD5 był używany do tworzenia podpisów cyfrowych ale obecnie jest uważany za algorytm niebezpieczny i nie powinien być stosowany.\n*   **DES:** DES (Data Encryption Standard) to algorytm szyfrowania symetrycznego blokowego z kluczem 56-bitowym.  Algorytm DES był bardzo popularny w latach 70-tych, ale obecnie jest uważany za mało bezpieczny z powodu krótkiej długości klucza, którą można złamać stosunkowo niewielkim nakładem obliczeniowym.  Mimo tego algorytm DES jest często stosowany jako przykład algorytmu symetrycznego.\n*   **żadne z powyższych:**  Odpowiedź ta jest niepoprawna, ponieważ algorytm ElGamal jest algorytmem asymetrycznym.\n\nPodsumowując, poprawną odpowiedzią jest **ElGamal**, ponieważ jest to jedyny algorytm z podanych, który wykorzystuje parę kluczy (publiczny i prywatny) do szyfrowania i deszyfrowania, co jest definicją szyfrowania asymetrycznego. Wszystkie inne przykłady są symetrycznymi algorytmami szyfrowania, lub (MD4, MD5) algorytmami hashującymi i nie reprezentują algorytmów asymetrycznych."
    },
    {
        "questionId": 187,
        "title": "IPsec ESP umozliwia zapewnienie:",
        "answers": [
            {
                "text": "autentycznosci tresci datagramu przy wykorzystaniu algorytmu MD5",
                "isCorrect": true
            },
            {
                "text": "autentycznosci tresci datagramu przy wykorzystaniu algorytmu 3DES",
                "isCorrect": true
            },
            {
                "text": "poufnosci tresci datagramu w trybie tunelowym",
                "isCorrect": true
            },
            {
                "text": "poufnosci tresci datagramu w trybie transportowym",
                "isCorrect": true
            },
            {
                "text": "tylko autentycznosci tresci datagramu, nie poufnosci",
                "isCorrect": false
            },
            {
                "text": "tylko poufnosci tresci datagramu, nie autentycznosci",
                "isCorrect": false
            },
            {
                "text": "poufnosci i/lub autentycznosci tresci datagramu, w trybie synchronicznym",
                "isCorrect": true
            },
            {
                "text": "poufnosci i/lub autentycznosci tresci datagramu, w trybie tunelowym",
                "isCorrect": false
            },
            {
                "text": "poufności i/lub autentyczności treści datagramu, w trybie synchronicznym",
                "isCorrect": false
            }
        ],
        "clue": 5,
        "isStarred": false,
        "explanation": "Protokół IPsec ESP (Encapsulating Security Payload) jest jednym z dwóch głównych protokołów składowych IPsec. IPsec, to zbiór protokołów, które umożliwiają bezpieczne przesyłanie danych przez sieci IP. ESP zapewnia poufność i/lub autentyczność danych w datagramie IP, w przeciwieństwie do protokołu AH (Authentication Header), który zapewnia jedynie autentyczność. ESP działa w dwóch trybach: transportowym i tunelowym. W trybie transportowym chroniona jest tylko zawartość pakietu IP (dane warstwy wyższej), natomiast w trybie tunelowym, chroniony jest cały pakiet IP łącznie z nagłówkiem.\n\n**Odpowiedź 1: \"autentycznosci tresci datagramu przy wykorzystaniu algorytmu MD5\"** - Jest **poprawna**. ESP może używać algorytmu MD5 (Message Digest 5) do obliczenia skrótu kryptograficznego treści datagramu w celu zapewnienia autentyczności, czyli pewności, że dane nie zostały zmienione w trakcie transmisji.  MD5, jako funkcja skrótu, nie szyfruje danych, a jedynie generuje ich skrót, który służy do weryfikacji integralności.  Gdy dane zostaną zmienione, to wyliczony skrót nie będzie się zgadzać ze skrótem zawartym w pakiecie.\n\n**Odpowiedź 2: \"autentycznosci tresci datagramu przy wykorzystaniu algorytmu 3DES\"** - Jest **poprawna**.  Chociaż 3DES (Triple DES) jest algorytmem szyfrowania symetrycznego, to jest on używany w połączeniu z funkcją skrótu (np. MD5) w ESP do zapewnienia autentyczności, przez obliczenie skrótu kryptograficznego, który jest szyfrowany symetrycznie z wykorzystaniem algorytmu 3DES.  Zapewnia to pewność co do integralności i pochodzenia danych.\n\n**Odpowiedź 3: \"poufnosci tresci datagramu w trybie tunelowym\"** - Jest **poprawna**.  Tryb tunelowy ESP kapsułkuje cały oryginalny datagram IP, tworząc nowy datagram IP i szyfrując całość, w tym także nagłówek oryginalnego pakietu, zapewniając tym samym poufność przesyłanych danych.  W ten sposób, treść wiadomości oraz informacje o jej nadawcy i odbiorcy są ukryte przed osobami niepowołanymi.\n\n**Odpowiedź 4: \"poufnosci tresci datagramu w trybie transportowym\"** - Jest **poprawna**. W trybie transportowym ESP szyfruje zawartość pakietu IP, pozostawiając nagłówek IP bez zmian, zapewniając tym samym poufność przesyłanych danych ale nie ukrywając informacji o nadawcy i odbiorcy wiadomości.\n\n**Odpowiedź 5: \"tylko autentycznosci tresci datagramu, nie poufnosci\"** - Jest **niepoprawna**. ESP, w przeciwieństwie do AH, może zapewnić zarówno autentyczność (integralność) jak i poufność.  Wybór konkretnego algorytmu (szyfrowania czy skrótu) oraz trybu pracy (tunelowego lub transportowego) określa jakie zabezpieczenia (i w jakim stopniu) będą zastosowane.\n\n**Odpowiedź 6: \"tylko poufnosci tresci datagramu, nie autentycznosci\"** - Jest **niepoprawna**. ESP, domyślnie, w większości implementacji, stosuje mechanizmy podpisu cyfrowego (skrót kryptograficzny) i w rezultacie ESP oferuje oba zabezpieczenia poufność oraz autentyczność. \n\n**Odpowiedź 7: \"poufnosci i/lub autentycznosci tresci datagramu, w trybie synchronicznym\"** - Jest **poprawna**.  Chociaż najczęściej używa się algorytmów asymetrycznych (z kluczem publicznym) do uzgadniania kluczy szyfrowania (przed zaszyfrowaniem pakietu), to sam protokół ESP wykorzystuje algorytmy symetryczne do ochrony przesyłanych danych.  Określenie \"tryb synchroniczny\" jest jednak mylące i nie odnosi się do charakterystyki pracy ESP.  W IPsec rozróżnia się dwa tryby pracy (transportowy i tunelowy) a nie synchroniczny.\n\n**Odpowiedź 8: \"poufnosci i/lub autentycznosci tresci datagramu, w trybie tunelowym\"** - Jest **niepoprawna**. Chociaż tryb tunelowy jest częściej używany z poufnością i autentycznością, nie jest on jedynym trybem pracy ESP, w którym uzyskuje się poufność i/lub autentyczność. Tryb transportowy również daje możliwość wykorzystania tych dwóch mechanizmów bezpieczeństwa.\n\n**Odpowiedź 9: \"poufności i/lub autentyczności treści datagramu, w trybie synchronicznym\"** - Jest **niepoprawna**.  Podobnie jak w odpowiedzi 7, określenie \"tryb synchroniczny\" nie ma związku z działaniem ESP i jest nieprecyzyjne. ESP zapewnia poufność i/lub autentyczność, a \"tryb synchroniczny\" jest tu nieadekwatnym określeniem."
    },
    {
        "questionId": 188,
        "title": "Jaki mechanizm moze wykorzystac administrator do dynamicznego uaktywnienia specjalnie przygotowanych regul filtracji umozliwiajacych obejscie ograniczen narzuconych na normalny ruch sieciowy?",
        "answers": [
            {
                "text": "zamek-i-klucz",
                "isCorrect": true
            },
            {
                "text": "dynamiczny skaner portow",
                "isCorrect": false
            },
            {
                "text": "sniffer dynamiczny",
                "isCorrect": false
            },
            {
                "text": "NIDS lub HIPS",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm \"zamek-i-klucz\" odnosi się do dynamicznego uaktywniania reguł filtracji w zaporze sieciowej. W typowej zaporze sieciowej reguły filtracji, które określają jaki ruch jest dozwolony, a jaki zabroniony, są zdefiniowane statycznie. Oznacza to, że raz zdefiniowane reguły obowiązują nieprzerwanie, chyba że administrator je ręcznie zmodyfikuje. Jednak w niektórych przypadkach, administrator może chcieć tymczasowo obejść takie ograniczenia. Mechanizm \"zamek-i-klucz\" pozwala na dynamiczne aktywowanie specjalnie przygotowanej reguły (lub zestawu reguł) filtrujących, które pozwalają na przesyłanie danych, które w normalnej sytuacji zostałyby zablokowane przez zaporę. Mechanizm ten może działać w następujący sposób:\n  1.  **Zamek:** Specjalna, ukryta i wyłączona reguła jest zdefiniowana w konfiguracji zapory sieciowej. Reguła ta zawiera kryteria dopasowania do ruchu sieciowego który chcemy przepuścić.\n  2.  **Klucz:** Działaniem aktywującym regułę jest unikalny ciąg bitów (lub inny rodzaj sygnału), który ma na celu zainicjowanie czasowego udostępnienia zasobów systemu w sposób wyłączający lub modyfikujący standardowe filtry zapory sieciowej. Klucz ten może być wygenerowany na podstawie określonego wzoru (np. o określonej godzinie) lub może być wynikiem działania zewnętrznej aplikacji (np. systemu wykrywania włamań).\n  3.  **Uaktywnienie:** Po otrzymaniu sygnału – \"klucza\" – zapora dynamicznie włącza odpowiednią regułę (\"zamek\"), która tymczasowo pozwala na ruch sieciowy, który byłby normalnie odrzucony.\n  4.  **Wyłączenie:** Po określonym czasie, lub po zakończeniu transmisji, reguła tymczasowa jest automatycznie wyłączana, a zapora wraca do normalnej ochrony.\n\n**Przykłady:**\n  *   Administrator może stworzyć regułę w zaporze sieciowej, która blokuje cały ruch telnet. Ale, na czas wykonywania zdalnej diagnostyki, tworzy dodatkową regułę (wygaszaną po 15 minutach), która umożliwia dostęp telnet z określonego adresu IP. Reguła tymczasowa, wykorzystująca znany tylko administratorowi \"klucz\", aktywuje się tylko na czas diagnostyki, i potem wyłącza.\n  *   Atakujący może wykorzystać lukę w systemie, aby zdalnie uruchomić specjalny program, który tymczasowo wyłączy część ograniczeń w zaporze sieciowej i utworzy połączenie umożliwiające zdalny dostęp do systemu. \n\n**Opcje odpowiedzi:**\n\n*   **\"zamek-i-klucz\"**: To **poprawna** odpowiedź, ponieważ opisuje koncepcję dynamicznego aktywowania i dezaktywowania specjalnych reguł w zaporze sieciowej.\n*   **\"dynamiczny skaner portów\"**: Jest to **niepoprawna** odpowiedź. Skaner portów to narzędzie, które umożliwia analizę, które porty TCP i UDP na danym hoście są otwarte. Nie pozwala na dynamiczne zmienianie reguł filtracji. Skaner portów jest wykorzystywany do wykrywania otwartych usług w systemie.\n*   **\"sniffer dynamiczny\"**: Jest to **niepoprawna** odpowiedź. Sniffer to program który przechwytuje ruch sieciowy w celu dalszej analizy. Może się przydać administratorowi do wykrywania nieprawidłowości w systemie, jednak sam w sobie nie zmienia dynamicznie zasad filtrowania w zaporze.\n*   **\"NIDS lub HIPS\"**: Jest to **niepoprawna** odpowiedź. NIDS (ang. Network Intrusion Detection System) lub HIPS (ang. Host-based Intrusion Prevention System) to systemy wykrywania włamań, które mogą reagować na podejrzane aktywności, i ewentualnie modyfikować reguły zapory, jednak nie jest to główna zasada działania tych systemów. NIDS i HIPS ma na celu wykrywanie aktywności niezgodnych z ustalona polityką bezpieczeństwa w oparciu o sygnatury oraz wzorce."
    },
    {
        "questionId": 189,
        "title": "Do czego sluzy protokol SMTP?",
        "answers": [
            {
                "text": "pozwala na szyfrowania zalacznikow wiadomosci",
                "isCorrect": false
            },
            {
                "text": "pozwala na przesylanie grupowych wiadomosci w trybie multicast",
                "isCorrect": false
            },
            {
                "text": "pozwala na przeszukiwanie bazy uzytkownikow na serwerze smtp w celu okreslenia adresata wiadomosci",
                "isCorrect": false
            },
            {
                "text": "pozwala na wysylanie wiadomosci do innych uzytkownikow",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół SMTP (Simple Mail Transfer Protocol) jest standardowym protokołem internetowym wykorzystywanym do przesyłania wiadomości e-mail. Działa on na warstwie aplikacji modelu TCP/IP i jest odpowiedzialny wyłącznie za dostarczanie wiadomości od nadawcy do serwera poczty elektronicznej, skąd następnie wiadomość jest przekazywana dalej, aż do serwera poczty docelowego odbiorcy. SMTP nie definiuje formatu treści wiadomości e-mail ani sposobu jej przechowywania w skrzynce pocztowej odbiorcy.\n\n* **\"pozwala na szyfrowania załączników wiadomości\"** - To jest **niepoprawna** odpowiedź. Protokół SMTP samodzielnie nie zapewnia szyfrowania wiadomości, ani załączników. Szyfrowanie i zabezpieczenie przesyłanych treści jest realizowane za pomocą innych protokołów, takich jak S/MIME lub PGP, które działają w warstwie aplikacji ponad SMTP. W praktyce oznacza to, że jeśli wiadomość jest przesyłana za pomocą SMTP, to jej treść (w tym załączniki) jest przekazywana „jako tekst jawny” i może zostać odczytana przez osoby niepowołane, które mają dostęp do ruchu sieciowego pomiędzy serwerami poczty elektronicznej. \n\n* **\"pozwala na przesyłanie grupowych wiadomości w trybie multicast\"** - To jest **niepoprawna** odpowiedź. Protokół SMTP jest protokołem do przesyłania wiadomości w trybie unicast, czyli jeden-do-jednego. Multicast, czyli przesyłanie wiadomości do grupy odbiorców jednocześnie, nie jest obsługiwane przez SMTP. Do realizacji takiego przesyłania służą inne mechanizmy i protokoły, takie jak listy mailingowe. Przykładowo, serwer pocztowy może samodzielnie utworzyć kilka osobnych połączeń SMTP wysyłając wiadomość do kilku różnych odbiorców(z list mailingowych), ale nie używa w tym celu multicast.\n\n* **\"pozwala na przeszukiwanie bazy użytkowników na serwerze smtp w celu określenia adresata wiadomości\"** - To jest **niepoprawna** odpowiedź. Protokół SMTP nie ma wbudowanych funkcji do przeszukiwania bazy użytkowników.  Określenie adresata (czyli użytkownika z określoną nazwą użytkownika) następuje na podstawie adresu e-mail, który zawiera nazwę użytkownika. Przeszukiwanie bazy użytkowników może nastąpić na serwerze SMTP ale nie jest to funkcjonalność SMTP.  Mechanizmy przeszukiwania i uwierzytelniania użytkowników na serwerze pocztowym realizowane są przez inne protokoły i aplikacje, takie jak np. LDAP, SQL oraz różnorodne systemy baz danych które często działają równolegle z serwerami SMTP. Serwer SMTP nie jest z nimi bezpośrednio związany.\n\n* **\"pozwala na wysyłanie wiadomości do innych użytkowników\"** - To jest **poprawna** odpowiedź. Podstawową funkcją protokołu SMTP jest właśnie przesyłanie wiadomości e-mail od nadawcy do serwera poczty elektronicznej, skąd wiadomość jest następnie dostarczana do serwera poczty odbiorcy. SMTP określa sekwencję komend i odpowiedzi, które są używane w tym procesie. Przykładowo klient pocztowy (MUA – ang. Mail User Agent) używa protokołu SMTP, aby przekazać wiadomość do serwera poczty (MTA – ang. Mail Transfer Agent), a ten z kolei, korzystając z SMTP, przekazuje wiadomość do kolejnego serwera poczty, aż do serwera docelowego adresata. W praktyce większość klientów poczty elektronicznej nie korzysta bezpośrednio z protokołu SMTP tylko korzysta z biblioteki, która wykorzystuje SMTP."
    },
    {
        "questionId": 190,
        "title": "Do czego sluzy komenda rlogin?",
        "answers": [
            {
                "text": "pozwala tylko systemowym uzytkownikom zalogowac sie na lokalna maszyne",
                "isCorrect": false
            },
            {
                "text": "pozwala na zdalny dostep do hosta",
                "isCorrect": true
            },
            {
                "text": "pozwala zalogowac sie lokalnym uzytkownikom na zdalna maszyne tylko na konto o takiej samej nazwie",
                "isCorrect": false
            },
            {
                "text": "dostarcza zaawansowanego mechanizmu uwierzytelniania uzytkownikow logujacych sie na lokalna maszyne",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Komenda `rlogin` służy do zdalnego logowania do systemu operacyjnego. Używając `rlogin`, użytkownik może uzyskać dostęp do sesji terminalowej (wiersza poleceń) na zdalnym komputerze, tak jakby siedział przed jego konsolą. Ten proces wymaga, by na komputerze, z którego się logujemy oraz komputerze, do którego się logujemy działało oprogramowanie obsługujące ten protokół.\nNiestety ten sposób logowania, ma poważne braki w bezpieczeństwie - a dokładniej w tajności. Hasła oraz cała sesja przesyłana jest jawnym tekstem, bez żadnych zabezpieczeń w formie szyfrowania, przez co jest narażona na nieautoryzowany odczyt poprzez osoby trzecie mające dostęp do ruchu sieciowego. Z tego powodu komenda `rlogin` nie powinna być używana w żadnym środowisku narażonym na podsłuch.\n\n*   **\"pozwala tylko systemowym uzytkownikom zalogowac sie na lokalna maszyne\"** - Jest to **niepoprawna** odpowiedź. `rlogin` służy do uzyskania zdalnego dostępu, czyli logowania do **innej**, **zdalnej** maszyny (a nie tej lokalnej). Ponadto,  `rlogin` pozwala na logowanie nie tylko użytkownikom systemowym, ale wszystkim użytkownikom posiadającym konta w systemie zdalnym i dostęp sieciowy do niego. Użytkownik lokalny może użyć `rlogin`, aby połączyć się z innym zdalnym systemem (zdalnym komputerem)\n*   **\"pozwala na zdalny dostep do hosta\"** - Jest to **poprawna** odpowiedź. `rlogin` służy do uzyskania dostępu do zdalnego komputera.  Wykorzystując  `rlogin` użytkownik ma dostęp do terminala zdalnego komputera i może wykonywać na nim polecenia.\n*   **\"pozwala zalogowac sie lokalnym uzytkownikom na zdalna maszyne tylko na konto o takiej samej nazwie\"** - Jest to **niepoprawna** odpowiedź. `rlogin` domyślnie próbuje zalogować użytkownika na zdalny komputer używając tej samej nazwy użytkownika, jaką użytkownik posiada w systemie lokalnym. Jednak opcja -l `rlogin -l nazwa_uzytkownika zdalny_komputer`  umożliwia zalogowanie się do zdalnego komputera pod inną nazwą użytkownika.\n*   **\"dostarcza zaawansowanego mechanizmu uwierzytelniania uzytkownikow logujacych sie na lokalna maszyne\"** - Jest to **niepoprawna** odpowiedź. `rlogin` nie oferuje żadnych zaawansowanych mechanizmów uwierzytelniania. Wykorzystuje jedynie hasło, które przesyłane jest jawnym tekstem przez sieć. Hasło w tej sytuacji nie jest chronione przed podsłuchiwaniem. W istocie `rlogin` nie jest  żadnym mechanizmem uwierzytelniania, a aplikacją kliencką realizującą zdalny dostęp do sesji terminalowej na odległym systemie. Uwierzytelnianie wykonywane jest przez zdalny system operacyjny.\n\nPrzykład:\nUżytkownik `jan`  pracujący na komputerze lokalnym o adresie IP 192.168.1.100 , używa komendy `rlogin zdalny.serwer.pl`. Jeżeli konto `jan`  istnieje na serwerze zdalny.serwer.pl, to  użytkownik `jan` uzyska połączenie z systemem zdalnym, a jego hasło zostanie przesłane nie szyfrowanym protokołem, poprzez sieć do serwera. Jeśli natomiast użytkownik `jan` na lokalnym komputerze użyje polecenia `rlogin -l admin zdalny.serwer.pl`  to spróbuje zalogować się na serwerze zdalny.serwer.pl na konto administratora, pod warunkiem, że posiada takie konto."
    },
    {
        "questionId": 191,
        "title": "Co ma na celu publikowanie swojego klucza publicznego PGP?",
        "answers": [
            {
                "text": "nic nie daje, publikowanie klucza ma na celu tylko usprawnienie mechanizmu wymiany kluczy miedzy uzytkownikami",
                "isCorrect": false
            },
            {
                "text": "uniemozliwienie intruzowi podszycie sie pod nasz e-mail",
                "isCorrect": false
            },
            {
                "text": "umozliwienie zaszyfrowania wiadomosci adresowanej do wlasciciela klucza",
                "isCorrect": true
            },
            {
                "text": "umozliwienie sprawdzenia autentycznosci listu wyslanego przez wlasciciela klucza",
                "isCorrect": true
            },
            {
                "text": "umozliwienie odszyfrowania zawartosci email wyslanej przez wlasciciela klucza",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Klucz publiczny PGP jest podstawowym elementem kryptografii asymetrycznej, gdzie każda osoba posiada parę kluczy – publiczny i prywatny. Klucz publiczny, jak sama nazwa wskazuje, jest przeznaczony do publicznego udostępnienia i może go uzyskać każdy. Służy on do dwóch głównych celów: szyfrowania wiadomości oraz weryfikacji podpisu cyfrowego.\n\n*   **Odpowiedź 1: \"nic nie daje, publikowanie klucza ma na celu tylko usprawnienie mechanizmu wymiany kluczy miedzy uzytkownikami\"** - Jest to odpowiedź nieprawidłowa, ponieważ ignoruje podstawowe funkcje klucza publicznego. Publikacja klucza publicznego PGP nie jest jedynie usprawnieniem wymiany, ale elementem niezbędnym do szyfrowania korespondencji i weryfikacji podpisów.\n*   **Odpowiedź 2: \"uniemozliwienie intruzowi podszycie sie pod nasz e-mail\"** - Jest to odpowiedź nieprawidłowa. Użycie podpisu cyfrowego (który jest możliwy dzięki kluczowi publicznemu) daje odbiorcy pewność co do tożsamości nadawcy i integralności wiadomości (czyli, że nie została zmieniona po wysłaniu). Nie uniemożliwia jednak intruzowi podszycia się.\n*   **Odpowiedź 3: \"umozliwienie zaszyfrowania wiadomosci adresowanej do wlasciciela klucza\"** - Jest to **poprawna** odpowiedź. Klucz publiczny służy do szyfrowania wiadomości w taki sposób, że tylko posiadacz odpowiadającego klucza prywatnego może ją odszyfrować. Jeśli Alicja chce przesłać wiadomość do Bolka, szyfruje ją kluczem publicznym Bolka, a Bolek odszyfrowuje ją swoim kluczem prywatnym. Zapewnia to poufność wiadomości, gdyż wiadomość zaszyfrowana kluczem publicznym jest nieczytelna dla osób trzecich, nie posiadających klucza prywatnego Bolka. Jest to podstawowe działanie szyfrowania asymetrycznego.\n*   **Odpowiedź 4: \"umozliwienie sprawdzenia autentycznosci listu wyslanego przez wlasciciela klucza\"** - Jest to **poprawna** odpowiedź. Klucz publiczny służy do weryfikacji podpisu cyfrowego. Jeśli Bolek wysyła list podpisany swoim kluczem prywatnym, Alicja może zweryfikować podpis, używając publicznego klucza Bolka. To zapewnia integralność wiadomości (pewność, że wiadomość nie została zmieniona) oraz autentyczność nadawcy (pewność, że nadawcą jest Bolek). Bez klucza publicznego nie ma możliwości wykonania prawidłowej weryfikacji podpisu cyfrowego.\n*   **Odpowiedź 5: \"umozliwienie odszyfrowania zawartosci email wyslanej przez wlasciciela klucza\"** - Jest to odpowiedź nieprawidłowa. Klucz publiczny służy do szyfrowania *wiadomości przesyłanej do* posiadacza klucza, a klucz prywatny *własny* do odszyfrowywania wiadomości zaszyfrowanej kluczem publicznym adresata i podpisywania wiadomości. Zatem posiadanie klucza publicznego, nie pozwoli rozszyfrować wiadomości, które samemu się wysłało. Klucz publiczny jest tylko wykorzystywany w celu odszyfrowywania wiadomości wysłanych przez inną osobę(posiadającą klucz prywatny).\n\n**Przykład realnego zastosowania:**\nZałóżmy, że użytkownik \"Jan Kowalski\" (identyfikowany przez adres e-mail jan.kowalski@example.com) publikuje swój klucz publiczny PGP na swojej stronie internetowej.\n\n*   **Poufność:** Osoba \"Anna Nowak\", chcąc wysłać poufną wiadomość do Jana, szyfruje ją używając jego klucza publicznego PGP. Tylko Jan, posiadając swój klucz prywatny, będzie mógł odszyfrować tę wiadomość i przeczytać jej treść.\n*   **Autentyczność:** Gdy Jan odpisuje na list Anny, podpisuje wiadomość swoim kluczem prywatnym. Anna otrzymując ten list, może, korzystając z publicznego klucza Jana, zweryfikować jego podpis. Ma wtedy pewność, że list pochodzi od Jana i nikt po drodze go nie modyfikował."
    },
    {
        "questionId": 192,
        "title": "Czy w systemie Ms Windows mozna skorzystac z szyfrowania PGP?",
        "answers": [
            {
                "text": "niestety system ten nie wspiera szyfrowania PGP",
                "isCorrect": false
            },
            {
                "text": "tak, ale tylko przy wykorzystaniu komercyjnych, platnych programow",
                "isCorrect": false
            },
            {
                "text": "tylko przy wykorzystaniu programu Ms Outlook",
                "isCorrect": false
            },
            {
                "text": "tak, jezeli wykorzysta sie odpowiednie oprogramowanie",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "PGP (Pretty Good Privacy) to program służący do szyfrowania i podpisywania cyfrowego danych, w tym wiadomości e-mail, plików i innych danych, zapewniając poufność i autentyczność. Jest to niezależne rozwiązanie, które nie jest zintegrowane z konkretnym systemem operacyjnym. Działa na różnych platformach, w tym systemie Windows, pod warunkiem instalacji odpowiedniego oprogramowania, które implementuje funkcje PGP.\n\n*   **\"niestety system ten nie wspiera szyfrowania PGP\"** - Ta odpowiedź jest niepoprawna. System Windows nie ma wbudowanej natywnej obsługi PGP, ale nie oznacza to, że nie można go używać. Dostępne są różne programy implementujące PGP w systemie Windows.\n\n*   **\"tak, ale tylko przy wykorzystaniu komercyjnych, platnych programow\"** - Ta odpowiedź jest niepoprawna.  Chociaż istnieją komercyjne implementacje PGP dla systemu Windows, to nie jest to jedyne rozwiązanie.  Istnieją również bezpłatne i otwarte implementacje PGP, które można używać, na przykład GnuPG.  Oznacza to, że można stosować PGP w systemie Windows bez ponoszenia kosztów zakupu licencji komercyjnego oprogramowania.\n\n*   **\"tylko przy wykorzystaniu programu Ms Outlook\"** - Ta odpowiedź jest niepoprawna.  PGP nie jest powiązane z konkretną aplikacją, np. MS Outlook.  PGP, jako protokół, można zintegrować z różnymi klientami poczty lub używać go niezależnie do ochrony danych. Istnieją rozszerzenia do MS Outlook umożliwiające obsługę PGP, ale PGP nie jest ograniczone tylko do niego. Przykładowo istnieje rozszerzenie Enigmail do klienta poczty Mozilla Thunderbird.\n\n*   **\"tak, jezeli wykorzysta sie odpowiednie oprogramowanie\"** - Ta odpowiedź jest poprawna.  System Windows nie posiada wbudowanej obsługi PGP, ale użytkownik ma możliwość rozszerzenia jego funkcjonalności poprzez instalację dodatkowego oprogramowania.  Dostępne są różne implementacje PGP dla systemu Windows, zarówno płatne jak i bezpłatne. Aplikacje takie jak GnuPG (GPG4Win) umożliwiają  szyfrowanie i podpisywanie danych PGP w środowisku Windows. Zatem system Windows może być wykorzystany do pełnego korzystania z możliwości protokołu PGP.\n\nKonkretny przykład użycia PGP w systemie Windows to sytuacja, w której pracownik firmy używa Outlooka z rozszerzeniem Enigmail, aby podpisywać i szyfrować poufną korespondencję biznesową przed jej wysłaniem. Klient może nie zdawać sobie sprawy w jakim systemie operacyjnym pracuje jego kontrahent, a mimo to dane są chronione dzięki PGP. Ponadto użytkownik pracujący na systemie Linux może wysłać zaszyfrowaną wiadomość do użytkownika systemu Windows (również szyfrowaną za pomocą PGP) bez obawy, że odbiorca nie będzie w stanie jej odczytać. Kluczowe jest tu użycie tego samego standardu szyfrowania, nie systemu operacyjnego."
    },
    {
        "questionId": 193,
        "title": "Szyfrowanie plikow w systemie Ms Windows:",
        "answers": [
            {
                "text": "jest dostepne dla kazdego pod warunkiem korzystania z partycji typu NTFS",
                "isCorrect": true
            },
            {
                "text": "jest dostepne wylacznie dla administratora systemu",
                "isCorrect": false
            },
            {
                "text": "jest niemozliwe",
                "isCorrect": false
            },
            {
                "text": "jest dostepna dla administratora systemu i operatora kopii bezpieczenstwa",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie plików w systemie Windows opiera się na mechanizmie EFS (Encrypting File System), który jest wbudowany w system operacyjny i pozwala chronić dane przed nieautoryzowanym dostępem poprzez ich zaszyfrowanie. Mechanizm ten jest jednak nierozerwalnie związany z systemem plików NTFS (New Technology File System) stworzonym przez firmę Microsoft. Oznacza to, że szyfrowanie jest możliwe tylko na partycjach sformatowanych w systemie plików NTFS i to bez względu na to, z którego konta loguje się użytkownik. \n\n* **Odpowiedź 1: \"jest dostepne dla kazdego pod warunkiem korzystania z partycji typu NTFS\" jest Prawidłowa.** Każdy użytkownik systemu Windows, który korzysta z partycji sformatowanej w systemie plików NTFS, może zaszyfrować wybrane przez siebie pliki i katalogi. System Windows oferuje graficzny interfejs użytkownika, który pozwala na łatwe i szybkie włączanie i wyłączanie szyfrowania poszczególnych plików i katalogów. Dostęp do zaszyfrowanych danych jest możliwy tylko, gdy użytkownik zaloguje się na konto użytkownika, które dokonało szyfrowania lub na konto odzyskiwania danych, które również ma dostęp do zaszyfrowanych danych.\n\n* **Odpowiedź 2: \"jest dostepne wylacznie dla administratora systemu\" jest Nieprawidłowa.** Szyfrowanie plików za pomocą mechanizmu EFS nie jest ograniczone tylko dla administratora systemu. Każdy użytkownik posiadający konto w systemie Windows może włączyć szyfrowanie, jeśli pracuje na partycji sformatowanej w systemie NTFS. Oczywiście administrator posiada dodatkowe uprawnienia, w szczególności uprawnienia do zarządzania wszystkimi kontami użytkowników w systemie, w tym uprawnienia do odzyskiwania zaszyfrowanych danych, ale to nie wyklucza zwykłych użytkowników z możliwości szyfrowania danych.\n\n* **Odpowiedź 3: \"jest niemozliwe\" jest Nieprawidłowa.** Szyfrowanie plików jest jedną z podstawowych cech systemu Windows pracujących z systemem plików NTFS. \n\n* **Odpowiedź 4: \"jest dostepna dla administratora systemu i operatora kopii bezpieczenstwa\" jest Nieprawidłowa.** Szyfrowanie plików jest możliwe dla każdego użytkownika systemu Windows na partycji NTFS, chociaż oczywiście administrator oraz operatorzy kopii bezpieczeństwa posiadają dodatkowe uprawnienia w postaci możliwości odzyskania zaszyfrowanych danych. Standardowy użytkownik nie posiada takich uprawnień a tylko te, które zostaną mu przydzielone. \n\n**Przykład praktyczny:** Użytkownik o imieniu \"Jan Kowalski\" pracujący na swoim komputerze z systemem Windows, może utworzyć w katalogu \"Moje Dokumenty\" plik z notatkami służbowymi o nazwie \"hasla.txt\" i chronić go przed dostępem innych osób poprzez włączenie szyfrowania tego pliku. W tym celu wystarczy w Eksploratorze Windows we właściwościach danego pliku w opcjach zaawansowanych wybrać możliwość \"Szyfruj zawartość\". Od tego momentu tylko Jan Kowalski, po zalogowaniu się na swoje konto, będzie mógł wyświetlić zawartość pliku. Nawet administrator systemu, logując się na swoje konto, nie będzie mógł uzyskać dostępu do pliku, chyba, że dokona odzyskania klucza za pomocą specjalnego narzędzia. Plik pozostanie chroniony dopóki Jan Kowalski nie zrezygnuje z szyfrowania pliku, lub nie utraci kluczy prywatnych."
    },
    {
        "questionId": 194,
        "title": "Wykorzystujac stanowosc zapory sieciowej mozemy okreslic:",
        "answers": [
            {
                "text": "odrzucic pakiety probujace podszywac sie pod rzekomo istniejace polaczenia",
                "isCorrect": true
            },
            {
                "text": "czy pakiet probuje obejsc nasz system bezpieczenstwa",
                "isCorrect": false
            },
            {
                "text": "czy polaczenie jest juz ustanowione",
                "isCorrect": true
            },
            {
                "text": "czy pakiet zawiera flage ACK",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Stanowość zapory sieciowej odnosi się do jej zdolności do śledzenia stanu połączeń sieciowych. Oznacza to, że zapora nie tylko analizuje pojedyncze pakiety danych, ale także pamięta informacje o wcześniejszych pakietach przesyłanych w ramach tego samego połączenia. Dzięki temu zapora może podejmować bardziej świadome decyzje odnośnie przepuszczania lub blokowania pakietów.\n\n* **\"odrzucic pakiety probujace podszywac sie pod rzekomo istniejace polaczenia\"** - To zdanie jest **prawidłowe**. Zapora sieciowa ze stanowością (ang. *stateful firewall*) śledzi sesje TCP. Dzięki temu jest w stanie rozpoznać pakiety, które nie należą do żadnej z ustanowionych sesji, lub pakiety, które naruszają sekwencję przesyłania pakietów TCP. Przykładem może być atak *session hijacking*, w którym napastnik stara się „wstrzelić” pakiet w istniejącą, poprawną sesję TCP. Zapora ze stanowością jest w stanie wykryć taki pakiet, bo nie będzie on miał prawidłowego numeru sekwencyjnego.\n\n* **\"czy pakiet probuje obejsc nasz system bezpieczenstwa\"** - To zdanie jest **nieprawidłowe**. Zapora sieciowa ze stanowością nie jest w stanie określić czy pakiet próbuje obejść system bezpieczeństwa. Zapora jest w stanie jedynie sprawdzić czy pakiet spełnia wymogi zdefiniowane w listach dostępu, jak i te, które wynikają z aktualnego stanu sesji. Nie jest w stanie przewidzieć czy nadawca ma złośliwe zamiary. To czy dany pakiet próbuje obejść system bezpieczeństwa, można wywnioskować po przeanalizowaniu logów.\n\n*  **\"czy polaczenie jest juz ustanowione\"** - To zdanie jest **prawidłowe**. Zapora sieciowa ze stanowością śledzi stan sesji. Dzięki temu dla każdego pakietu zapora wie czy pakiet jest częścią nowej sesji, czy już istniejącej. Zapora sieciowa może dzięki temu zezwalać na ruch tylko powracający w ramach ustanowionej sesji, co znacznie podnosi bezpieczeństwo. Np. dla ustanowienia połączenia TCP potrzebny jest etap trzech etapów (_ang. three way handshake_). Zapora nie przepuści ruchu danych w stronę serwera dopóki połączenie TCP nie zostanie poprawnie nawiązane, tj. nie zostaną wymienione wszystkie pakiety SYN, SYN-ACK oraz ACK. Pakiety, które nie są częścią ustanowionej sesji, lub pochodzą z nie zaufanego hosta(na przykład z adresu IP z czarnej listy) nie powinny zostać przepuszczone w stronę wewnętrznej sieci LAN.\n\n*  **\"czy pakiet zawiera flage ACK\"** - To zdanie jest **nieprawidłowe**. Zapora sieciowa ze stanowością nie analizuje zawartości pakietów tylko sprawdza stan połączenia, nie analizuje flag. Flaga ACK w nagłówku TCP oznacza, że pakiet ten potwierdza odbiór poprzedniego pakietu. Zapora bezstanowa mogła by w sposób prymitywny blokować pakiety z flagą ACK, ale taki mechanizm nie byłby w stanie odróżnić poprawnych i niepoprawnych pakietów. Zapora ze stanowością, analizuje wartość flagi ACK, ale jest to dla niej tylko informacja pomocnicza, a nie decydująca. \n\nDla przykładu, rozważmy prosty scenariusz: Klient (A) chce połączyć się z serwerem (B) za pomocą protokołu TCP.\n1.  **Stateless Firewall:** Zapora bezstanowa analizowałaby pakiety SYN (żądanie połączenia), SYN-ACK (potwierdzenie serwera) i ACK (potwierdzenie klienta) osobno, nie śledząc ich wzajemnych relacji. Mogłaby mieć ustawioną regułę przepuszczania pakietów z portu 80 (HTTP) do serwera B. Pozwalałoby to każdemu na połączenie z serwerem B, a zapora nie wiedziałaby czy ten pakiet ma prawo przejść czy nie.\n2. **Stateful Firewall:** Zapora ze stanowością rozpoznaje te trzy pakiety w sekwencji TCP. Zapisuje fakt wysłania SYN, oraz oczekiwania na SYN-ACK i ACK. Dzięki temu może decydować, które pakiety są częścią aktywnej (prawidłowej) sesji. Jeśli napastnik (C) wstrzeliłby fałszywy pakiet ACK, który nie pasuje do zapamiętanej sesji, to zapora by go odrzuciła, z uwagi na niepoprawny numer sekwencyjny i niepoprawne flagi, pomimo prawidłowego adresu docelowego i portu."
    },
    {
        "questionId": 195,
        "title": "LMhash to:",
        "answers": [
            {
                "text": "haslo administratora systemu zapisane w sposob jawny",
                "isCorrect": false
            },
            {
                "text": "hasla uzytkownikow w postaci skrotow (hashy) wykorzystywane przez Lan Managera",
                "isCorrect": true
            },
            {
                "text": "Lan Manager hash sluzacy do identyfikacji systemu w sieci lokalnej",
                "isCorrect": false
            },
            {
                "text": "hash numeru seryjnego systemu Ms Windows",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "LMhash to skrót (hash) hasła użytkownika, stosowany w starszych wersjach systemu Windows (przed Windows 2000, NT) przez protokół Lan Manager. Haszowanie to proces, który przekształca dane wejściowe, w tym przypadku hasło użytkownika, w ciąg o stałej długości, który jest trudny (idealnie niemożliwy) do odwrócenia, czyli nie można z hasza uzyskać hasła. Jest to podstawowa technika zabezpieczania haseł, ponieważ nie przechowuje się ich w postaci jawnej, co uniemożliwia ich bezpośrednie pozyskanie w przypadku nieuprawnionego dostępu do bazy haseł.\nHaszowanie tworzy „odcisk” danych, gwarantując że nawet niewielka zmiana danych wejściowych (hasła) wygeneruje całkiem inny skrót(hash). Z uwagi na nieodwracalność funkcji hash, weryfikacja haseł przez system polega na ponownym wygenerowaniu hasha dla hasła podanego przy logowaniu i porównaniu go z hashem przechowywanym w bazie. \n\n*   **„haslo administratora systemu zapisane w sposob jawny”** - To jest niepoprawna odpowiedź. Systemy operacyjne, w tym Windows, nie przechowują haseł w postaci jawnej, gdyż stanowiłoby to poważne zagrożenie bezpieczeństwa. Hasła są przetwarzane z użyciem funkcji haszujących, tworząc skróty hasła, które są trudne do odwrócenia. Ta odpowiedź pomija fundamentalny aspekt bezpieczeństwa haseł.\n\n*   **„hasla uzytkownikow w postaci skrotow (hashy) wykorzystywane przez Lan Managera”** - To jest prawidłowa odpowiedź. LMhash jest starszą, mniej bezpieczną metodą haszowania haseł, która była wykorzystywana przez protokół Lan Manager w systemach Windows przed Windows 2000. Algorytm ten tworzył hash z hasła użytkownika, ale nie był tak skomplikowany i bezpieczny jak nowsze metody np. NTLM. Algorytm używany w LMhash był na tyle słaby, że łatwo było go złamać.\n\n*   **„Lan Manager hash sluzacy do identyfikacji systemu w sieci lokalnej”** - To jest niepoprawna odpowiedź. LMhash służy do haszowania haseł użytkowników, a nie do identyfikacji systemu w sieci lokalnej. Identyfikacja systemu w sieci lokalnej odbywa się za pomocą innych mechanizmów, takich jak unikalne adresy MAC kart sieciowych czy nazwy komputerów w domenie. Haszowanie haseł użytkowników stanowi odrębny mechanizm zabezpieczania przed nieautoryzowanym dostępem do systemu.\n\n*   **„hash numeru seryjnego systemu Ms Windows”** - To jest niepoprawna odpowiedź. LMhash nie jest skrótem numeru seryjnego systemu. Numer seryjny systemu Windows to kod identyfikacyjny produktu i służy głównie do jego identyfikacji i legalnego użytkowania a nie do zabezpieczenia haseł użytkowników. Numer seryjny w Windows może być zakodowany, jednak nie używa do tego algorytmu LMhash.\n\nZrozumienie czym jest LMhash jest istotne z kilku powodów. Po pierwsze, ukazuje ewolucję algorytmów haszujących i ich ciągłe ulepszanie w celu zwiększenia bezpieczeństwa. Po drugie, przypomina o niebezpieczeństwach związanych z stosowaniem słabych algorytmów haszujących, które mimo upływu lat są nadal potencjalnie używane przez starsze systemy, a co więcej, często w nowych systemach są trzymane mechanizmy zgodności wstecz. Po trzecie, pozwala to podjąć właściwe kroki w celu ochrony systemu operacyjnego poprzez wyłączenie przechowywania LMhash i wymuszenia używania silniejszych algorytmów haszujących. Przykładowo administrator systemów w środowisku Windows powinien skonfigurować system tak, by nie przechowywał LMhash (ustawienie polityki bezpieczeństwa systemów Windows lub wyłączenie obsługi protokołu SMBv1)."
    },
    {
        "questionId": 196,
        "title": "Dziedziczenie uprawnien w systemie plikow NTFS:",
        "answers": [
            {
                "text": "uprawnienia sa pobierane bezposrednio z uprawnien obiektu wyzszego",
                "isCorrect": true
            },
            {
                "text": "moze przeniesc rowniez na system plikow FAT64",
                "isCorrect": false
            },
            {
                "text": "jest identycznie z systemem plikow ext3",
                "isCorrect": false
            },
            {
                "text": "nie istnieje w tym systemie plikow",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Dziedziczenie uprawnień w systemie plików NTFS oznacza, że obiekty (pliki i foldery) wewnątrz folderu nadrzędnego domyślnie przejmują uprawnienia z tego folderu nadrzędnego.  Oznacza to, że jeśli folder ma określone prawa dostępu dla użytkownika, grupy lub innych, to wszystkie pliki i foldery w tym folderze, jeśli nic nie zmienimy, będą miały te same uprawnienia. Jest to bardzo ważne w zarządzaniu systemem plików.\n\n**Odpowiedź: \"uprawnienia sa pobierane bezposrednio z uprawnien obiektu wyzszego\" jest poprawna.** Dzieje się tak domyślnie, tzn., jeśli przy tworzeniu nowego obiektu nie określimy inaczej. Oznacza to, że plik lub folder utworzony w folderze z określonymi prawami dostępu automatycznie otrzyma te same prawa, chyba że jawnie je zmienimy. To ułatwia zarządzanie uprawnieniami, ponieważ administrator nie musi ustawiać uprawnień dla każdego pliku osobno, może to robić dla całego katalogu.\n\n**Odpowiedź: \"moze przeniesc rowniez na system plikow FAT64\" jest niepoprawna.**  Dziedziczenie uprawnień jest cechą systemu plików NTFS i nie występuje w systemie plików FAT32/FAT64, co więcej FAT32/FAT64 w ogóle nie obsługuje zaawansowanej kontroli dostępu opartej o listy ACL, a jedynie uprawnienia readonly, archive i hidden. Mechanizm dziedziczenia uprawnień, o którym mowa w pytaniu jest ściśle powiązany z NTFS a nie z FAT32/FAT64.\n\n**Odpowiedź: \"jest identycznie z systemem plikow ext3\" jest niepoprawna.**  Chociaż system plików ext3 posiada mechanizmy kontroli dostępu bazujące również na koncepcji list ACL, to jednak mechanizm dziedziczenia uprawnień jest zaimplementowany inaczej niż w NTFS, mimo pewnych podobieństw. W systemie plików ext3 (jak i innych systemach plików z rodziny Linux) dziedziczenie uprawnień w listach ACL jest nieco inne niż w NTFS. Uprawnienia są sumowane a nie kopiowane, dodatkowo istnieje mechanizm pozwalający na nadpisywanie domyślnych ustawień przez oddzielne konfiguracje uprawnień domyślnych.\n\n**Odpowiedź: \"nie istnieje w tym systemie plikow\" jest niepoprawna.** NTFS jest zaprojektowany tak, aby obsługiwał dziedziczenie uprawnień jako podstawowy mechanizm kontroli dostępu. Domyślnie, każdy plik lub folder dziedziczy uprawnienia od swojego folderu nadrzędnego. Użytkownik ma jednak możliwość wyłączenia tego mechanizmu dla konkretnego folderu, jednak nie zmienia to faktu istnienia tego mechanizmu w systemie plików NTFS.\n\nPrzykład z życia wzięty: wyobraźmy sobie folder _DOKUMENTY_ z prawem odczytu i zapisu dla użytkownika _Jan_. Jeżeli wewnątrz folderu _DOKUMENTY_ stworzymy folder _RAPORTY_ oraz plik _raport1.txt_ to będą one dziedziczyły prawa folderu nadrzędnego czyli folderu _DOKUMENTY_ oznaczając tym samym, że _Jan_ będzie miał również prawo do czytania i zapisywania tych obiektów. Jeżeli zmienimy uprawnienia folderu _RAPORTY_ to utworzone w nim obiekty będą miały nowe uprawnienia, a plik _raport1.txt_ będzie miał nadane uprawnienia z folderu nadrzędnego. \n\nDzięki mechanizmowi dziedziczenia uprawnień łatwiej jest zarządzać uprawnieniami, gdyż  zmiana uprawnień folderu nadrzędnego spowoduje automatyczną zmianę uprawnień na wszystkich obiektach w tym folderze oraz podfolderach. Jednocześnie w przypadku gdy chcemy aby dla konkretnego obiektu wewnątrz struktury katalogów były inne prawa to możemy je na tym obiekcie nadpisać wyłączając dziedziczenie uprawnień."
    },
    {
        "questionId": 197,
        "title": "Wada single-sign-on jest:",
        "answers": [
            {
                "text": "relacja zaufania miedzy parami hostow w domenie zaufania z wylaczeniem hosta zapewniajacego uwierzytelnianie",
                "isCorrect": false
            },
            {
                "text": "mozliwosc logowania sie tylko na konta systemowe",
                "isCorrect": false
            },
            {
                "text": "zaleznosc od poprawnego dzialania uwierzytelniajacej maszyny",
                "isCorrect": true
            },
            {
                "text": "brak relacji zaufania miedzy hostem uwierzytelniajacym a hostem uslugowym w domenie zaufania",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Single Sign-On (SSO) to mechanizm, który umożliwia użytkownikowi logowanie się do wielu aplikacji i usług za pomocą jednego zestawu poświadczeń (np. login i hasło). Działa to w ten sposób, że po jednokrotnym zalogowaniu się, użytkownik uzyskuje dostęp do wielu powiązanych systemów bez konieczności ponownego logowania. SSO tworzy relacje zaufania w obrębie danej domeny, w której systemy \"ufają\" serwerowi uwierzytelniania, że zweryfikował on tożsamość użytkownika. \n\n**Odpowiedź pierwsza: \"relacja zaufania miedzy parami hostow w domenie zaufania z wylaczeniem hosta zapewniajacego uwierzytelnianie\"** jest niepoprawna. SSO polega na tym, że to *host uwierzytelniający*, a nie poszczególne hosty miedzy soba, jest zaufanym punktem w domenie.  Poszczególne hosty, które oferują usługi w ramach domeny zaufania \"ufają\"  temu hostowi, że użytkownik został prawidłowo uwierzytelniony.\n\n**Odpowiedź druga: \"mozliwosc logowania sie tylko na konta systemowe\"** jest niepoprawna. SSO może integrować się z różnymi typami kont, w tym kontami systemowymi, ale również kontami aplikacyjnymi czy kontami usług. SSO dotyczy procesu uwierzytelniania a nie rodzaju konta. Nie ma wiec ograniczenia na to na jakie konto loguje się użytkownik.\n\n**Odpowiedź trzecia: \"zaleznosc od poprawnego dzialania uwierzytelniajacej maszyny\"** jest poprawna. Centralizacja procesu uwierzytelniania w SSO oznacza, że jeśli serwer uwierzytelniający ulegnie awarii, stanie się niedostępny, lub zostanie zaatakowany, to użytkownicy nie będą mieli dostępu do żadnej z usług, która opiera się o dany mechanizm SSO. Jest to newralgiczne słabe ogniwo systemu, ponieważ od tego serwera zależy cała reszta. Przykładowo, w firmie korzystającej z SSO, jeśli serwer uwierzytelniający przestanie działać, pracownicy nie będą mogli zalogować się do żadnego z systemów firmowych ani do poczty czy też do systemu CRM.\n\n**Odpowiedź czwarta: \"brak relacji zaufania miedzy hostem uwierzytelniajacym a hostem uslugowym w domenie zaufania\"** jest niepoprawna. Podstawowym założeniem SSO jest relacja zaufania miedzy systemem oferującym usługę a hostem dokonującym uwierzytelniania. Jest to kluczowe dla poprawności działania całego mechanizmu.  Hosty usługowe ufają, że host uwierzytelniający prawidłowo zweryfikował tożsamość użytkownika.\n\nPodsumowując, choć SSO ułatwia życie użytkownikom, ma poważną wadę: uzależnia dostępność wielu usług od pojedynczego punktu, co czyni go potencjalnym celem ataku i punktem awarii."
    },
    {
        "questionId": 198,
        "title": "Aby serwer uslug w domenie kerberos mogl dzialac wykorzystujac uwierzytelniania Single-Sign-On, musi:",
        "answers": [
            {
                "text": "uzywac odpowiednio zmodyfikowanych demonow uslug, ktore potrafia rozmawiac z serwerem Kerberos",
                "isCorrect": true
            },
            {
                "text": "uzywa zmodyfikowanego stosu IP, ktory wspolpracuje z serwerem KDC",
                "isCorrect": false
            },
            {
                "text": "zapewnia sprzetowe szyfrowanie i generowanie liczb losowych",
                "isCorrect": false
            },
            {
                "text": "uzywa specjalnego jadra systemu operacyjnego, wspierajacego wspolprace z serwerem KDC",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Kerberos to protokół uwierzytelniania sieciowego oparty na zaufanej stronie trzeciej, znanej jako Centrum Dystrybucji Kluczy (KDC, ang. Key Distribution Center).  Umożliwia on Single Sign-On (SSO), czyli jednokrotne uwierzytelnienie użytkownika pozwalające na dostęp do różnych usług w sieci bez ponownego podawania hasła.  Aby system działał prawidłowo serwery, z których usług korzystają użytkownicy,  muszą aktywnie uczestniczyć w procesie uwierzytelniania.  Standardowy stos protokołów IP nie posiada wbudowanej znajomości Kerberosa i nie jest wstanie go obsłużyć, dlatego  usługi w domenie Kerberos, aby korzystać z mechanizmu SSO,  muszą posiadać specjalnie zmodyfikowane demony.\n\n**Odpowiedź a) \"używać odpowiednio zmodyfikowanych demonów usług, które potrafią rozmawiać z serwerem Kerberos\" jest poprawna.** Jest to kluczowe dla poprawnego działania SSO w Kerberosie. Demony usług (_ang. daemon_), czyli aplikacje działające w tle i oferujące określoną funkcjonalność (np. serwer www), muszą być świadome protokołu Kerberos, czyli muszą być odpowiednio zmodyfikowane, aby móc uwierzytelniać użytkownika, korzystając z danych udostępnianych przez KDC. Oznacza to, że demony te muszą umieć:\n    *   Komunikować się z KDC: Pobierać bilety (_ang. ticket_) pozwalające uwierzytelnić użytkownika. Bilety to zaszyfrowane dane potwierdzające tożsamość użytkownika i zawierające klucz sesyjny.\n    *   Weryfikować bilety: Dekodować bilety w celu sprawdzenia, czy użytkownik został poprawnie uwierzytelniony i tym samym czy ma uprawnienia do danej usługi.\n    *   Wykorzystywać klucze sesyjne: Szyfrować i odszyfrowywać komunikację z użytkownikiem.\n    *   Przykładowo, klasyczny serwer FTP musi zostać zastąpiony kerberizowaną wersją, która potrafi nawiązywać kontakt z serwerem KDC.\n\n**Odpowiedź b) \"używa zmodyfikowanego stosu IP, który współpracuje z serwerem KDC\" jest niepoprawna.**  Stos protokołów IP (_ang. TCP/IP stack_) to zestaw protokołów odpowiedzialnych za przesyłanie danych w sieci. Standardowy stos IP nie ma żadnej wbudowanej wiedzy o Kerberos. Uwierzytelnienie Kerberosem jest procesem warstwy aplikacyjnej. Chociaż Kerberos korzysta z transportowych usług TCP i UDP, to nie wymaga modyfikacji samego stosu IP, a odpowiedniego kodu w aplikacjach. Stos IP w tym przypadku zajmuje się transportem pakietów danych.\n\n**Odpowiedź c) \"zapewnia sprzętowe szyfrowanie i generowanie liczb losowych\" jest niepoprawna.** Kerberos co prawda wykorzystuje kryptografię do ochrony przesyłanych danych (symetryczną i asymetryczną),  jednak nie wymaga on do poprawnego działania sprzętowego szyfrowania ani generatorów liczb losowych. Te elementy mają znaczenie dla bezpieczeństwa, ale nie są konieczne do włączenia mechanizmu SSO za pomocą Kerberosa.  Implementacja KDC i kerberizowanych aplikacji wykorzystuje oprogramowanie do szyfrowania, a nie specjalistyczne rozwiązania sprzętowe.\n\n**Odpowiedź d) \"używa specjalnego jądra systemu operacyjnego, wspierającego współpracę z serwerem KDC\" jest niepoprawna.** Jądro systemu operacyjnego (_ang. kernel_) jest podstawowym oprogramowaniem kontrolującym dostęp do sprzętu i zasobów systemu operacyjnego. Systemy operacyjne takie jak Linux, czy Windows, nie mają wbudowanej obsługi protokołu Kerberos w jądrze. Oznacza to, że jądro nie bierze bezpośredniego udziału w uwierzytelnianiu Kerberosem. Potrzebna jest do tego odpowiednia zmodyfikowana aplikacja działająca w przestrzeni użytkownika i biblioteki, które umożliwiają kontakt z KDC."
    },
    {
        "questionId": 199,
        "title": "Nazwa domenowa komputera a nazwa domeny kerberos:",
        "answers": [
            {
                "text": "musi byc rozna",
                "isCorrect": false
            },
            {
                "text": "musi byc identyczna",
                "isCorrect": false
            },
            {
                "text": "zaleca sie, aby byla identyczna",
                "isCorrect": true
            },
            {
                "text": "zaleca sie, aby byla rozna",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Nazwa domeny Kerberos, zwana również realm, to domena administracyjna, w której działają mechanizmy uwierzytelniania Kerberos. Kerberos jest protokołem uwierzytelniania sieciowego, który umożliwia hostom wzajemne uwierzytelnianie. Używa do tego celu tajnych kluczy i bazy danych zawierającej informacje o użytkownikach i hostach, za co odpowiedzialny jest serwer KDC (Key Distribution Center). Klient prosi serwer KDC o tzw. bilet, który służy do uwierzytelniania przed docelowym serwerem. Nazwa domeny Kerberos pozwala uniknąć konfliktów i nieporozumień, gdy więcej niż jedna domena używa tego protokołu.\n\nNazwa domenowa komputera, inaczej nazwa hosta, identyfikuje dany komputer w sieci DNS (Domain Name System). Jest używana do mapowania nazw przyjaznych dla człowieka na adresy IP. Nazwa domenowa komputera powinna być spójna i zrozumiała dla ludzi.\n\n*   **\"musi byc rozna\"** - To jest nieprawidłowa odpowiedź. Technicznie nazwa domeny komputera i nazwa domeny Kerberos nie muszą być różne i systemy nadal będą działać. Jednak taka praktyka może prowadzić do nieporozumień i problemów konfiguracyjnych. Np. system operacyjny może podczas konfiguracji poprawnie ustawić domyślne wartości, które będą jednak inne dla domeny Kerberos i domeny DNS.\n\n*   **\"musi byc identyczna\"** - To jest nieprawidłowa odpowiedź. Technicznie nazwa domeny komputera i nazwa domeny Kerberos nie muszą być identyczne, chociaż ich różnica może utrudniać administrację i zrozumienie struktury sieci, ale sama funkcjonalność protokołu Kerberos nie ulegnie zepsuciu.\n\n*   **\"zaleca sie, aby byla identyczna\"** - To jest prawidłowa odpowiedź. Zaleca się, aby nazwa domeny komputera i nazwa domeny Kerberos były identyczne z kilku względów. Ułatwia to identyfikację i administrację systemami, które korzystają z Kerberosa. Pozwala uniknąć pomyłek konfiguracyjnych, ponieważ konfiguracja domyślna systemów zakłada identyczność tych nazw. Na przykład, gdy użytkownik loguje się do domeny Kerberos, a jego komputer należy do tej samej domeny DNS, proces uwierzytelniania jest bardziej płynny. Użytkownik nie musi konfigurować połączeń, logowania na poszczególne serwery, ponieważ serwer Kerberos wie, że użytkownik ma prawo korzystać z tego zasobu z uwagi na to, że jest z tej samej domeny.\n\n*   **\"zaleca sie, aby byla rozna\"** - To jest nieprawidłowa odpowiedź. Zaleca się identyczność tych nazw a nie ich różnicę. Różnica tych nazw nie wpływa na funkcjonowanie protokołu Kerberos jednak utrudnia administrację.\n\nW praktyce, w domenie, gdzie używa się Kerberosa, często spotyka się identyczne nazwy domeny DNS i domeny Kerberos. Na przykład, jeśli Twoja firma nazywa się \"example.com\", to zarówno nazwa domeny DNS, jak i Kerberos, powinny być ustawione na \"example.com\" lub w przypadku małych organizacji może to być \"EXAMPLE.COM\" (domena Kerberos domyślnie jest pisana wielkimi literami). Jeżeli, ktoś chciałby dołączyć komputer do domeny, to musi on posługiwać się domeną identyczną jak domena Kerberos, aby połączenie przebiegło bezproblemowo."
    },
    {
        "questionId": 200,
        "title": "Mechanizm TCP Wrapper:",
        "answers": [
            {
                "text": "pozwala ograniczac dostep do uslug uruchamianych przez xinetd",
                "isCorrect": true
            },
            {
                "text": "pozwala blokowac spam przychodzacy do serwera SMTP",
                "isCorrect": false
            },
            {
                "text": "pozwala szyfrowac ruch TCP z uzyciem protokolow TLS/SSL",
                "isCorrect": false
            },
            {
                "text": "powstal, aby wprowadzic silne uwierzytelnianie dla tzw. small services",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm TCP Wrapper, implementowany przez program `tcpd`, to narzędzie kontroli dostępu, które działa na poziomie systemu operacyjnego. Jego głównym zadaniem jest ograniczenie możliwości nawiązywania połączeń z usługami sieciowymi. Działa on w oparciu o dwa pliki konfiguracyjne: `/etc/hosts.allow` i `/etc/hosts.deny`. W tych plikach administrator systemu określa, które hosty lub sieci mają dostęp do danych usług, a które mają być blokowane. Kluczowe jest to, że `tcpd` **nie zapewnia szyfrowania ani uwierzytelniania** przesyłanych danych, a jedynie kontrolę dostępu do usług.\n\n**Odpowiedź 1: \"pozwala ograniczac dostep do uslug uruchamianych przez xinetd\"** jest **poprawna**. `xinetd` (eXtended Internet Daemon) to super-serwer, który zarządza usługami sieciowymi w systemach Linux. `xinetd` uruchamia usługi dopiero, gdy nastąpi żądanie połączenia z daną usługą przez zewnętrznego klienta, a `tcpd` często jest wykorzystywany w konfiguracji z `xinetd` jako program kontroli dostępu. W pliku konfiguracyjnym `xinetd` (np. `/etc/xinetd.d/tftp`) podaje się nazwę programu, który ma być uruchomiony po nawiązaniu połączenia do danej usługi, często tym programem jest program `tcpd`, a dopiero program `tcpd` wywołuje właściwą usługę sieciową np. `in.tftpd`. Dzięki temu rozwiązaniu `tcpd` przejmuje kontrolę nad ruchem sieciowym i decyduje, czy połączenie z daną usługą jest dozwolone, czy nie. Przykładowo, jeśli skonfigurujemy `tcpd` tak aby usługa `tftp` była dostępna tylko dla hostów z sieci 192.168.1.0/24, to próba nawiązania połączenia z tym portem przez hosty spoza tej sieci zostanie zablokowana.\n\n**Odpowiedź 2: \"pozwala blokowac spam przychodzacy do serwera SMTP\"** jest **niepoprawna**. `tcpd` działa na poziomie warstwy transportowej (TCP/UDP) modelu OSI i kontroluje dostęp do usług na podstawie adresów IP i portów, jednak nie analizuje on zawartości przesyłanych danych, w tym treści e-maili, przez co nie ma możliwości rozpoznawania treści spamu. Dlatego, aby blokować spam potrzebne są bardziej zaawansowane mechanizmy, które analizują zawartość wiadomości email, a nie tylko adres źródłowy. Blokowanie spamu z użyciem tylko tcpd jest mało skuteczne. Blokować można co najwyżej cały ruch na porcie 25 (SMTP) dla wybranych adresów, co nie jest do końca tym samym, co filtrowanie spamu.\n\n**Odpowiedź 3: \"pozwala szyfrowac ruch TCP z uzyciem protokolow TLS/SSL\"** jest **niepoprawna**. `tcpd` nie oferuje żadnych funkcji szyfrowania danych przesyłanych w połączeniu TCP/UDP. Szyfrowanie to zadanie dla innych protokołów, np. TLS/SSL, które działają na wyższych poziomach modelu OSI. `tcpd` jedynie kontroluje czy połączenie może w ogóle zostać nawiązane a po nawiązaniu połączenia cały ruch do danej usługi jest przesyłany bez jakiejkolwiek ochrony kryptograficznej. Protokół TLS/SSL musi być obsługiwany przez aplikację, która używa protokołu TCP/UDP. Przykładowo do przesyłania danych z szyfrowaniem należy użyć protokołu HTTPS, a nie HTTP. \n\n**Odpowiedź 4: \"powstal, aby wprowadzic silne uwierzytelnianie dla tzw. small services\"** jest **niepoprawna**. Choć `tcpd` pozwala na zdefiniowanie _kto_ może uzyskać dostęp do usługi, to **nie wzmacnia on procedury uwierzytelniania**. `tcpd` nie potrafi w żaden sposób zweryfikować hasła czy klucza publicznego przesyłanego przez sieć. Uwierzytelnianie to zadanie dla samej usługi sieciowej. Termin \"small services\" odnosi się do prostych usług, często starszych takich jak rlogin czy tftp, które same z siebie mają bardzo ograniczone możliwości uwierzytelniania lub w ogóle ich nie posiadają i to właśnie takie usługi `tcpd` ma za zadanie chronić. Uwierzytelnianie, jak również szyfrowanie danych jest zadaniem protokołów wyższych warstw modelu ISO/OSI."
    },
    {
        "questionId": 201,
        "title": "Tunel Net-to-Net to",
        "answers": [
            {
                "text": "koncepcja polaczenia dwoch lub wiecej sieci, w ktorej istnieja zestawione tunele miedzy bramami dla kazdej z sieci w sieci Internet",
                "isCorrect": true
            },
            {
                "text": "bezposrednie polaczenie typu proxy dwoch sieci przez Internet",
                "isCorrect": false
            },
            {
                "text": "tunel zestawiany miedzy systemami autonomicznymi w celu wymiany informacji o trasach routingu",
                "isCorrect": false
            },
            {
                "text": "bezposrednie polaczenie dwoch lub wiecej sieci przez Internet",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Tunel Net-to-Net to koncepcja sieci wirtualnej (VPN), w której połączenia są zestawiane pomiędzy bramami sieciowymi (ang. gateway) dla każdej z łączonych sieci lokalnych. Sieć VPN Net-to-Net tworzy logiczny tunel poprzez publiczną sieć Internet lub inną sieć, w której komunikacja nie jest uważana za zaufaną. Bramy, będąc końcami tunelu, odpowiedzialne są za szyfrowanie i deszyfrowanie ruchu sieciowego. Ruch wewnątrz każdej z podłączonych do VPN sieci lokalnych nie musi być szyfrowany.\n\n*   **Poprawna odpowiedź:** \"koncepcja polaczenia dwoch lub wiecej sieci, w ktorej istnieja zestawione tunele miedzy bramami dla kazdej z sieci w sieci Internet\". Jest to prawidłowa definicja tunelu Net-to-Net. W tym typie konfiguracji VPN, tunel nie łączy bezpośrednio hostów, lecz tworzy wirtualną sieć pomiędzy fizycznymi sieciami. Bramy VPN pełnią rolę pośredników, przekierowując i zabezpieczając ruch między lokalnymi sieciami, które pozostają niezabezpieczone w swoich wewnętrznych granicach. Przykładowo, dwie firmy mogą użyć tunelu Net-to-Net VPN, aby bezpiecznie połączyć swoje lokalne sieci w dwóch różnych miastach.\n\n*   **Niepoprawna odpowiedź:** \"bezposrednie polaczenie typu proxy dwoch sieci przez Internet\". Odpowiedź ta jest niepoprawna, ponieważ tunel Net-to-Net nie jest połączeniem typu proxy. Połączenie proxy działa jako pośrednik dla pojedynczego hosta, kierując jego żądania, a tunel VPN kieruje cały ruch sieciowy pomiędzy bramami. Tunel Net-to-Net tworzy bezpieczne przejście dla ruchu pomiędzy dwoma sieciami, a nie pośredniczy w ruchu jak serwer proxy.\n\n*   **Niepoprawna odpowiedź:** \"tunel zestawiany miedzy systemami autonomicznymi w celu wymiany informacji o trasach routingu\". Odpowiedź ta odnosi się do zupełnie innego mechanizmu, mianowicie protokołu BGP, który umożliwia wymianę informacji o trasach routingu między autonomicznymi systemami, a tunel Net-to-Net tworzy szyfrowane połączenie między sieciami. Tunele Net-to-Net nie skupiają się na dynamicznej wymianie tras, a na bezpiecznej transmisji ruchu.\n\n*   **Niepoprawna odpowiedź:** \"bezposrednie polaczenie dwoch lub wiecej sieci przez Internet\". Odpowiedź ta jest niepoprawna, gdyż podkreśla bezpośredniość połączenia, co nie jest właściwe, gdyż połączenie w tunelu Net-to-Net nie jest bezpośrednie. W rzeczywistości ruch w tunelu VPN jest szyfrowany i transportowany poprzez publiczną sieć Internet. Tunelowanie VPN pozwala na wykorzystanie publicznej sieci Internet jako medium do transportu danych, ale nie udostępnia bezpośredniego połączenia."
    },
    {
        "questionId": 202,
        "title": "Klucz FEK to",
        "answers": [
            {
                "text": "klucz asymetryczny",
                "isCorrect": false
            },
            {
                "text": "klucz prywatny uzytkownika",
                "isCorrect": false
            },
            {
                "text": "klucz publiczny uzytkownika",
                "isCorrect": false
            },
            {
                "text": "klucz symetryczny",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Klucz FEK (File Encryption Key) to klucz symetryczny, używany do szyfrowania i deszyfrowania danych w systemach szyfrowania plików. Klucze symetryczne, w przeciwieństwie do asymetrycznych, charakteryzują się tym, że ten sam klucz służy zarówno do szyfrowania jak i deszyfrowania danych.\n\n**Odpowiedź \"klucz asymetryczny\" jest niepoprawna,** ponieważ klucze asymetryczne to para kluczy: publiczny i prywatny. Klucz publiczny służy do szyfrowania danych lub weryfikacji podpisów cyfrowych, a klucz prywatny do deszyfrowania lub składania podpisów cyfrowych. Algorytmy asymetryczne są stosowane np. przy ustalaniu bezpiecznego połączenia, wymianie kluczy szyfrujących lub składaniu podpisów cyfrowych. Nie wykorzystuje się ich do szyfrowania plików bezpośrednio.\n\n**Odpowiedź \"klucz prywatny użytkownika\" jest niepoprawna,** ponieważ klucz prywatny to część pary kluczy asymetrycznych i służy do deszyfrowania danych, które zostały zaszyfrowane kluczem publicznym lub do tworzenia podpisów cyfrowych. Nie stosuje się go do bezpośredniego szyfrowania plików. Klucz prywatny musi być pilnie strzeżony.\n\n**Odpowiedź \"klucz publiczny użytkownika\" jest niepoprawna,** ponieważ klucz publiczny to część pary kluczy asymetrycznych i służy do szyfrowania danych lub weryfikacji podpisów cyfrowych. Nie stosuje się go do bezpośredniego szyfrowania plików. Jest on z założenia dostępny publicznie.\n\n**Odpowiedź \"klucz symetryczny\" jest poprawna.** Klucz FEK to klucz symetryczny, co oznacza, że ten sam klucz jest używany zarówno do szyfrowania, jak i deszyfrowania danych. FEK jest generowany losowo i ma na celu szyfrowanie dużych ilości danych (np. zawartości plików czy partycji). Klucze symetryczne są o wiele szybsze od kluczy asymetrycznych, stąd ich przydatność do szyfrowania dużej ilości danych. W systemach szyfrowania, takich jak BitLocker, FEK szyfruje faktyczne dane na dysku, a następnie sam klucz FEK jest szyfrowany z wykorzystaniem mechanizmu asymetrycznego, a klucz prywatny służący do odszyfrowania FEK może być chroniony hasłem użytkownika lub przechowywany w module sprzętowym TPM. Dzięki temu mamy gwarancję poufności przechowywanych danych a także możemy być pewni, że w przypadku utraty hasła możemy odzyskać dane poprzez wykorzystanie innego klucza, który też wchodzi w skład mechanizmu ochrony klucza FEK."
    },
    {
        "questionId": 203,
        "title": "Polaczenie pasywne ftp to:",
        "answers": [
            {
                "text": "jeden z czterech rodzajow polaczen jakie moze nawiazac klient tj. polaczenie danych, polaczenie sterujace, polaczenie aktywne, polaczenie pasywne",
                "isCorrect": false
            },
            {
                "text": "specjalny rodzaj szybkich polaczen przeznaczony do wysylania duzych porcji danych do klientow",
                "isCorrect": false
            },
            {
                "text": "polaczenie, w ktorym klient informuje serwer, aby to on okreslil port a klient polaczy sie z tym portem i pobierze dane",
                "isCorrect": true
            },
            {
                "text": "specjalny rodzaj polaczen dzieki ktorym mozliwe jest polaczenie w sytuacji gdy klient i serwer znajduja sie za firewallem realizujacym SNAT",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół FTP (File Transfer Protocol) wykorzystuje dwa kanały komunikacyjne: kanał sterowania (control channel) oraz kanał danych (data channel). Kanał sterowania jest ustanawiany przez klienta i służy do wydawania poleceń do serwera (np. logowanie, zmiana katalogu, pobranie pliku). Kanał danych jest wykorzystywany do przesyłania zawartości pliku. Wyróżniamy dwa tryby ustanawiania kanału danych: tryb aktywny i tryb pasywny.\n\nW trybie aktywnym klient łączy się z serwerem na porcie 21 (kanał sterowania) i podczas negocjacji połączenia, po otrzymaniu polecenia typu PORT, informuje serwer na jakim porcie nasłuchuje w celu otrzymania kanału danych. W takim przypadku, to serwer inicjuje połączenie z klientem na porcie danych, który jest wskazany przez klienta w poprzednim poleceniu PORT. Z punktu widzenia klienta, serwer aktywnie łączy się z nim, stąd nazwa \"aktywny tryb FTP\".\n\nTryb pasywny FTP został stworzony z myślą o obsłudze klientów znajdujących się za zaporami sieciowymi wykonującymi translację adresów NAT (Network Address Translation), w szczególności SNAT (Source NAT). W trybie pasywnym, klient łączy się z serwerem na porcie 21 (kanał sterowania), a następnie w momencie przesyłania danych wysyła polecenie PASV (ang. passive). Serwer po otrzymaniu polecenia PASV podaje klientowi port, na którym nasłuchuje. Klient łączy się z serwerem na wskazanym porcie i pobiera dane. W tym trybie to klient inicjuje połączenie z serwerem na porcie danych. To serwer pasywnie czeka na połączenie, stąd nazwa \"pasywny tryb FTP\".\n\n**Odpowiedź 1:** \"jeden z czterech rodzajow polaczen jakie moze nawiazac klient tj. polaczenie danych, polaczenie sterujace, polaczenie aktywne, polaczenie pasywne\" jest **niepoprawna**.  Prawidłowo, FTP używa kanału sterowania i danych, ale \"aktywne\" i \"pasywne\" to tryby, w jakich klient inicjuje kanał *danych*, a nie niezależne rodzaje połączeń.  Ustanowienie kanału sterowania nie zależy od używanego trybu transferu danych, a  może nastąpić w trybie aktywnym jak i pasywnym.\n\n**Odpowiedź 2:** \"specjalny rodzaj szybkich polaczen przeznaczony do wysylania duzych porcji danych do klientow\" jest **niepoprawna**. Tryb pasywny nie wpływa na szybkość transferu danych.  Szybkość transmisji zależna jest od wielu czynników (np. prędkości łącza). Tryb pasywny ma na celu usunięcie problemów z połączeniami występującymi, gdy klient FTP znajduje się za zaporą sieciową z NAT.\n\n**Odpowiedź 3:** \"polaczenie, w ktorym klient informuje serwer, aby to on okreslil port a klient polaczy sie z tym portem i pobierze dane\" jest **poprawna**. Jest to definicja pasywnego trybu FTP.  Klient wysyła komendę PASV, a serwer odpowiada, podając adres IP i numer portu, na który klient ma się połączyć. Takie podejście rozwiązuje problem z zaporami sieciowymi. Z punktu widzenia serwera, klient łączy się z nim, zamiast by serwer próbował się łączyć do klienta.\n\n**Odpowiedź 4:** \"specjalny rodzaj polaczen dzieki ktorym mozliwe jest polaczenie w sytuacji gdy klient i serwer znajduja sie za firewallem realizujacym SNAT\" jest **niepoprawna**.  Choć tryb pasywny *pomaga* w połączeniach za NAT (a w szczególności za SNAT), to tryb pasywny nie jest *wyłącznie* do tego wykorzystywany. Tryb pasywny może być wykorzystywany, gdy obie strony połączenia znajdują się w jednej sieci, nie ma potrzeby wykorzystywania SNAT. Tryb pasywny został wprowadzony, aby umożliwić tworzenie połączeń FTP przez klientów znajdujących się za zaporami sieciowymi. To tryb aktywny powoduje problemy, gdy klient znajduje się za zaporą NAT."
    },
    {
        "questionId": 204,
        "title": "Polaczenie aktywne ftp to:",
        "answers": [
            {
                "text": "jeden z czterech rodzajow polaczen jakie moze nawiazac klient tj. polaczenie danych, polaczenie sterujace, polaczenie aktywne, polaczenie pasywne",
                "isCorrect": false
            },
            {
                "text": "sytuacja, w ktorej serwer ftp tworzy polaczenie do klienta na losowy wybrany port przez klienta, aby przeslac zadany plik",
                "isCorrect": true
            },
            {
                "text": "sytuacja w ktorej specjalnie skonfigurowany serwer ftp potrafi przyjmowac polaczenia gdy sam znajduje sie za firewallem realizujacym usluge SNAT",
                "isCorrect": false
            },
            {
                "text": "sytuacja w ktorej przychodzace polaczenie od serwera ftp do klienta ftp jest przekierowywane na firewallu do klienta znajdujacego sie w sieci lokalnej",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Aktywne połączenie FTP odnosi się do sposobu, w jaki serwer FTP inicjuje połączenie danych z klientem. Protokół FTP wykorzystuje dwa oddzielne połączenia TCP: jedno do przesyłania poleceń, tzw. połączenie sterujące, oraz drugie do przesyłania danych, tzw. połączenie danych. W trybie aktywnym to klient informuje serwer o porcie na którym nasłuchuje połączenia danych, a serwer z kolei inicjuje połączenie z tym portem w celu przesłania danych.\n\n**Odpowiedź 1:** \"jeden z czterech rodzajow polaczen jakie moze nawiazac klient tj. polaczenie danych, polaczenie sterujace, polaczenie aktywne, polaczenie pasywne\" - **Niepoprawna**. Odpowiedź miesza pojęcia. Połączenie danych i sterujące to dwa kanały używane przez protokół FTP. Aktywne i pasywne odnoszą się do *trybu* wykorzystania połączenia danych. Klient nie nawiązuje połączenia aktywnego i pasywnego jednocześnie.\n\n**Odpowiedź 2:** \"sytuacja, w ktorej serwer ftp tworzy polaczenie do klienta na losowy wybrany port przez klienta, aby przeslac zadany plik\" - **Poprawna**. Dokładnie opisuje, na czym polega tryb aktywny FTP. Klient (przeglądarka lub specjalny program FTP) przesyła polecenie PORT zawierające informację o adresie IP klienta i porcie na którym będzie nasłuchiwać połączenia danych. Następnie, serwer inicjuje połączenie danych do klienta, używając tych informacji.\n\n**Odpowiedź 3:** \"sytuacja w ktorej specjalnie skonfigurowany serwer ftp potrafi przyjmowac polaczenia gdy sam znajduje sie za firewallem realizujacym usluge SNAT\" - **Niepoprawna**. Opisuje sytuacje w której serwer FTP wykorzystuje translacje adresów sieciowych SNAT (ang. Source NAT), aby móc nawiązywać połączenia gdy sam znajduje się w sieci prywatnej i wykorzystuje adres publiczny do łączenia się ze światem. To nie definiuje aktywnego połączenia FTP.\n\n**Odpowiedź 4:** \"sytuacja w ktorej przychodzace polaczenie od serwera ftp do klienta ftp jest przekierowywane na firewallu do klienta znajdujacego sie w sieci lokalnej\" - **Niepoprawna**. To opisuje typowe zadanie firewalla w trybie pasywnym FTP, kiedy serwer nasłuchuje na porcie i czeka na inicjacje połączenia przez klienta. Opis przekierowania portu do sieci lokalnej nie jest charakterystyczną cechą aktywnego połączenia FTP.\n\n**Przykład:**\nZałóżmy, że klient FTP o adresie IP 192.168.1.10 i porcie 2111 wysyła do serwera FTP polecenie LIST. Klient jest skonfigurowany do używania aktywnego trybu. Klient wysyła polecenie PORT z informacją, że będzie nasłuchiwał połączenia danych na losowo wybranym porcie, np 2222. Serwer FTP odbiera komendę LIST oraz PORT. Następnie, po przetworzeniu komendy LIST serwer FTP inicjuje połączenie TCP z adresem IP klienta 192.168.1.10 na porcie 2222."
    },
    {
        "questionId": 205,
        "title": "Skrot IKE oznacza:",
        "answers": [
            {
                "text": "rodzaj algorytmow wymiany kluczy w FreeS/Wan",
                "isCorrect": true
            },
            {
                "text": "bardzo wazny element pakietu FreeS/Wan pozwalajacy tworzyc bezpieczne polaczenie sterujace tunelami VPN",
                "isCorrect": true
            },
            {
                "text": "Information Key Exchange",
                "isCorrect": false
            },
            {
                "text": "jeden z algorytmow szyfrowania w pakiecie FreeS/Wan",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "IKE (Internet Key Exchange) to protokół wymiany kluczy, który jest kluczowym elementem w ramach IPsec (Internet Protocol Security). IPsec, z kolei, to zbiór protokołów zapewniających bezpieczeństwo komunikacji sieciowej na poziomie warstwy IP. Głównym zadaniem IKE jest umożliwienie bezpiecznego uzgodnienia parametrów połączenia, w tym kluczy kryptograficznych, które są następnie wykorzystywane przez protokoły IPsec (głównie ESP) do szyfrowania i uwierzytelniania pakietów. IKE jest protokołem warstwy aplikacyjnej i w swojej istocie to protokół negocjacji, uzgadniania algorytmów i kluczy i nie posiada on bezpośrednio implementacji żadnego algorytmu szyfrowania ani żadnej metody haszowania, te algorytmy wybierane są z puli dostępnych implementacji w bibliotekach kryptograficznych (jak np. OpenSSL). IKE występuje najczęściej w dwóch wersjach - IKEv1 i IKEv2.\n\n  * **\"rodzaj algorytmow wymiany kluczy w FreeS/Wan\"** - **PRAWIDŁOWA**. IKE *jest* rodzajem algorytmu(protokołem) wymiany kluczy, *implementowanym* w ramach pakietu FreeS/Wan. FreeS/Wan jest implementacją protokołu IPsec. FreeS/Wan w celu utworzenia bezpiecznego kanału komunikacyjnego musi wykorzystać protokół wymiany kluczy, którym jest IKE, aby stworzyć wspólny tajny klucz, który będzie używany do szyfrowania pakietów. Podsumowując IKE to protokół, natomiast FreeS/Wan to implementacja protokołu IPsec wykorzystującego protokół IKE.\n\n  * **\"bardzo wazny element pakietu FreeS/Wan pozwalajacy tworzyc bezpieczne polaczenie sterujace tunelami VPN\"** - **PRAWIDŁOWA**. IKE pełni bardzo ważną rolę w pakiecie FreeS/Wan, umożliwiając tworzenie bezpiecznych połączeń VPN. Bez IKE negocjacja kluczy szyfrujących i parametrów połączenia w ramach IPsec nie byłaby możliwa. Zatem IKE jest kluczowym elementem w procesie tworzenia bezpiecznych tuneli VPN, wykorzystujących FreeS/Wan, a protokół IKE jest tym mechanizmem, który pozwala zabezpieczyć ruch między końcami tunelu. IKE ma za zadanie stworzenie wspólnego tajnego klucza używanego przez protokoły IPsec.\n\n  *  **\"Information Key Exchange\"** - **NIEPRAWIDŁOWA**. IKE to *Internet Key Exchange*, a nie \"Information Key Exchange\". Jest to błędne rozwinięcie skrótu. Mimo, że IKE w istocie wymienia _informacje_, to nie na poziomie pojęć w warstwie abstrakcji, tylko na poziomie konkretnych bitów parametrów połączenia i tajnych kluczy sesyjnych.\n\n  * **\"jeden z algorytmow szyfrowania w pakiecie FreeS/Wan\"** - **NIEPRAWIDŁOWA**.  IKE *nie jest* algorytmem szyfrowania samym w sobie. IKE to protokół, w ramach którego uzgadniane są algorytmy szyfrowania oraz same klucze. Algorytmy szyfrowania, takie jak AES, 3DES, Blowfish są odrębnymi mechanizmami kryptograficznymi. To IPsec (np. w protokole ESP), a nie IKE, bezpośrednio szyfruje dane w tunelach VPN wykorzystujących FreeS/Wan. IKE to mechanizm do bezpiecznej wymiany tajnych parametrów, które mogą zostać użyte przez protokół ESP.\n\n**Podsumowanie:**\nIKE jest protokołem niezbędnym w IPsec do bezpiecznej wymiany i uzgadniania kluczy, które później wykorzystywane są przez inne protokoły IPsec w celu ochrony danych w sieci VPN. Nie jest algorytmem szyfrowania, ale raczej mechanizmem pozwalającym na wybór konkretnych algorytmów w trakcie negocjacji. FreeS/Wan implementuje protokół IPsec, który wykorzystuje protokół IKE."
    },
    {
        "questionId": 206,
        "title": "Pakiet FreeS/Wan sklada sie z:",
        "answers": [
            {
                "text": "z trzech komponentow: lata na jadro KLIPS, demon PLUTO, zestaw skryptow",
                "isCorrect": true
            },
            {
                "text": "z dwoch protokolow: AH i ESP",
                "isCorrect": false
            },
            {
                "text": "z kilkunastu roznych algorytmow szyfrowania m.in. DES i 3DES oraz protokolu wymiany kluczy: ISAKMP",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Pakiet FreeS/WAN to konkretna implementacja protokołu IPsec i nie jest nim samym, ani algorytmami kryptograficznymi, czy protokołem wymiany kluczy. Jest to system składający się z kilku wzajemnie zależnych od siebie elementów współpracujących, w celu zestawienia tunelu VPN. W skład tego pakietu wchodzą:\n\n*   **Łata na jądro KLIPS (ang. Kernel IPsec)** - jest to modyfikacja jądra systemu Linux, która umożliwia obsługę mechanizmów IPsec. KLIPS to starsza implementacja IPsec w jądrze Linux, zanim powstał nowszy framework XFRM, i jest ona stosowana we FreeS/WAN. Łata ta dodaje do jądra obsługę pakietów IPsec i umożliwia ochronę (szyfrowanie, uwierzytelnianie) przesyłanych danych na poziomie warstwy sieciowej. W nowszych implementacjach IPsec i nowszych wersjach jądra system Linux ta funkcjonalność zawarta jest w module XFRM(ang. IPsec Transform framework)\n*   **Demon PLUTO** -  odpowiedzialny za zarządzanie połączeniami w IPsec i ich konfiguracją w ramach pakietu FreeS/WAN. Wykorzystuje on protokół ISAKMP(ang. Internet Security Association and Key Management Protocol) do negocjowania kluczy. Demon ten utrzymuje tablicę asocjacji bezpieczeństwa(ang. SA - Security Association) oraz tablicę polityk bezpieczeństwa (ang. SPD - Security Policy Database) a także odpowiada za proces uwierzytelniania.\n*   **Zestaw skryptów** - dodatkowe programy, które są wykorzystywane do administrowania systemem, konfiguracji, uruchamiania i zatrzymywania usług, oraz wykonywania testów połączeń VPN. Do tych skryptów należą również skrypty, które konfigurują interfejsy sieciowe tun/tap, przy pomocy których działa FreeS/WAN. \n\n**Odpowiedź pierwsza jest poprawna:** FreeS/WAN to konkretna implementacja protokołu IPsec a nie abstrakcyjny zbiór algorytmów, a wręcz zawiera swoją implementację, składającą się z trzech powyżej wymienionych elementów. \n\n**Odpowiedź druga jest niepoprawna:** AH i ESP to protokoły wchodzące w skład specyfikacji IPsec. AH (ang. _Authentication Header_) umożliwia autentykację oraz ochronę integralności pakietu IP, a ESP (ang. _Encapsulating Security Payload_) umożliwia szyfrowanie oraz opcjonalną autentykację pakietu IP. Nie są one jednak elementami składowymi pakietu FreeS/WAN. Zatem odpowiedź jest niepoprawna ponieważ myli ogólny framework IPsec z implementacją tego protokołu o nazwie FreeS/WAN. \n\n**Odpowiedź trzecia jest niepoprawna:** Algorytmy szyfrowania np. DES, 3DES, oraz protokoły wymiany kluczy takie jak ISAKMP są wykorzystywane w konfiguracji mechanizmu IPsec (a więc i w FreeS/WAN), ale sam pakiet FreeS/WAN nie jest \"zbiorem algorytmów\". FreeS/WAN jest bardziej zbiorem funkcji i programów, niż zbiorem algorytmów. Te programy wykorzystują mechanizmy kryptograficzne, ale same w sobie nie są algorytmami. Odpowiedź jest niepoprawna z tego samego powodu co odpowiedź 2. Myli ogólny framework IPsec z jego implementacją o nazwie FreeS/WAN. \n\n**Podsumowując:** prawidłowa odpowiedź podkreśla, że FreeS/WAN to konkretne rozwiązanie (implementacja), a nie tylko zbiór algorytmów, czy protokołów. Ta wiedza ma kluczowe znaczenie przy konfigurowaniu i wdrażaniu systemów VPN."
    },
    {
        "questionId": 207,
        "title": "Kryptografia oportunistyczna to:",
        "answers": [
            {
                "text": "nowy rodzaj szyfrowania, bardzo wydajny i nie do zlamania w dzisiejszych czasach z uzyciem obecnych maszyn obliczeniowych",
                "isCorrect": false
            },
            {
                "text": "automatyczny sposob negocjowania parametrow polaczenia zaimplementowany w pakiecie FreeS/Wan",
                "isCorrect": true
            },
            {
                "text": "eksperymentalny projekt nowego rodzaju szyfrowania rozwijany na potrzeby amerykanskiej Agencji Bezpieczenstwa Narodowego",
                "isCorrect": false
            },
            {
                "text": "prosty rodzaj szyfrowania, nazwa \"oportunistyczna\" zaczerpnieta od francuskiego slowa: opportunisme oznaczajacego \"sprzyjajacy, dogodny\"",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Kryptografia oportunistyczna odnosi się do automatycznego sposobu negocjowania parametrów połączenia, w tym parametrów bezpieczeństwa, takich jak szyfrowanie, najczęściej w ramach protokołów bezpieczeństwa, takich jak IPsec. Nie jest to nowy algorytm szyfrowania, ale podejście do ustanawiania połączeń, które stara się wykorzystać dostępne możliwości szyfrowania, gdy tylko jest to możliwe, bez konieczności wcześniejszej, ręcznej konfiguracji każdej strony komunikacji. \n\n**Odpowiedź 1: „nowy rodzaj szyfrowania, bardzo wydajny i nie do zlamania w dzisiejszych czasach z uzyciem obecnych maszyn obliczeniowych”** - Jest **niepoprawna**. Kryptografia oportunistyczna nie jest nowym algorytmem szyfrowania ani rozwiązaniem nie do złamania. Opiera się ona na znanych algorytmach, takich jak AES, 3DES, czy Blowfish (szyfrowanie symetryczne) oraz RSA czy Diffie-Hellman (wymiana kluczy). Jej siła polega na automatyzacji *użycia* tych algorytmów, a nie na samej mocy obliczeniowej czy nowości algorytmu.\n\n**Odpowiedź 2: „automatyczny sposob negocjowania parametrow polaczenia zaimplementowany w pakiecie FreeS/Wan”** - Jest **poprawna**. FreeS/Wan to otwartoźródłowa implementacja protokołu IPsec dla systemów Linux, która wykorzystuje podejście kryptografii oportunistycznej. Oznacza to, że gdy dwa systemy wspierające IPsec nawiązują połączenie, automatycznie negocjują oni parametry bezpieczeństwa. Na przykład, jeśli obie strony obsługują szyfrowanie AES, to zostanie ono wybrane. Jeśli jedna strona szyfrowania nie wspiera, to połączenie zostanie nawiązane z użyciem mechanizmów o niższym stopniu bezpieczeństwa, lub bez użycia ich w ogóle. Tego typu automatyczna negocjacja umożliwia transparentne użycie IPsec bez wymogu konfiguracji każdej pary komunikujących się systemów, minimalizując trudności administracyjne.\n\n**Odpowiedź 3: „eksperymentalny projekt nowego rodzaju szyfrowania rozwijany na potrzeby amerykanskiej Agencji Bezpieczenstwa Narodowego”** - Jest **niepoprawna**. Kryptografia oportunistyczna nie jest projektem eksperymentalnym, lecz znanym i powszechnie stosowanym podejściem do bezpieczeństwa. Co więcej, nie jest rozwijana „na potrzeby” żadnej agencji – jej idea to ogólnie dostępna i stosowana w protokołach dających się implementować na różnym oprogramowaniu.\n\n**Odpowiedź 4: „prosty rodzaj szyfrowania, nazwa \"oportunistyczna\" zaczerpnieta od francuskiego slowa: opportunisme oznaczajacego \"sprzyjajacy, dogodny\"”** - Jest **niepoprawna**.  Nazwa \"oportunistyczna\" nawiązuje do sposobu działania, a nie algorytmu. System \"wykorzystuje okazję\" do zaszyfrowania połączenia, jeśli tylko obie strony na to pozwalają, starając się zaoferować jak największe bezpieczeństwo, bez obciążania użytkownika wiedzą z zakresu konfiguracji systemów bezpieczeństwa."
    },
    {
        "questionId": 208,
        "title": "Narzedzie FreeS/Wan to:",
        "answers": [
            {
                "text": "lata na jadro implementujaca funkcjonalnosc ISec plus zestaw skryptow do zarzadzania tym narzedziem",
                "isCorrect": true
            },
            {
                "text": "program dzialajacy w przestrzeni uzytkownika ktory posiada jeden plik konfiguracyjny zlokalizowany domyslnie: /etc/spiec",
                "isCorrect": false
            },
            {
                "text": "narzedzie w formie laty na jadro systemu Linux wraz z zestawem skryptow zarzadzajacych oraz demon pozwalajacy wymieniac klucze",
                "isCorrect": true
            },
            {
                "text": "narzedzie bardzo podobne do narzedzia Vtun sluzace do zestawiania polaczen VPN",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "FreeS/WAN, to projekt, którego celem jest dostarczenie otwartego i bezpłatnego rozwiązania, pozwalającego na implementację IPsec w systemach Linux. IPsec, czyli Internet Protocol Security, jest zbiorem protokołów używanych do zapewnienia bezpieczeństwa komunikacji w sieciach IP. Protokół ten zapewnia poufność, integralność i autentyczność przesyłanych danych. FreeS/WAN nie jest pojedynczą aplikacją, lecz zbiorem narzędzi i modyfikacji jądra systemu.\n\nPierwsza poprawna odpowiedź: „lata na jadro implementujaca funkcjonalnosc ISec plus zestaw skryptow do zarzadzania tym narzedziem” – Jest **poprawna**, ponieważ FreeS/WAN wymaga modyfikacji jądra systemu operacyjnego Linux (_kernel patch_) aby protokół IPsec mógł działać na poziomie sieciowym. Oprócz tego pakiet ten dostarcza zestaw skryptów, służących do konfiguracji i zarządzania połączeniami IPsec. Te skrypty pracują w przestrzeni użytkownika, ułatwiając korzystanie z protokołu IPsec, ale sam protokół IPsec jest realizowany w jądrze systemu.\n\nDruga odpowiedź: „program dzialajacy w przestrzeni uzytkownika ktory posiada jeden plik konfiguracyjny zlokalizowany domyslnie: /etc/spiec” – Jest **niepoprawna**, ponieważ FreeS/WAN nie jest zwykłą aplikacją działającą w przestrzeni użytkownika. Chociaż do konfiguracji używa się plików tekstowych (główny plik konfiguracyjny to najczęściej /etc/ipsec.conf), to rdzeń tego narzędzia, odpowiedzialny za faktyczne szyfrowanie i uwierzytelnianie pakietów, wymaga modyfikacji jądra systemu. Nie ma też jednego pliku konfiguracyjnego o nazwie /etc/spiec, zamiast tego do konfiguracji używa się wielu plików umiejscowionych w katalogu /etc/ipsec.d/ lub /etc/openswan/, czy w systemach Fedora, /etc/pluto/.\n\nTrzecia poprawna odpowiedź: „narzedzie w formie laty na jadro systemu Linux wraz z zestawem skryptow zarzadzajacych oraz demon pozwalajacy wymieniac klucze” – Jest **poprawna**, ponieważ FreeS/WAN działa poprzez modyfikację jądra systemu operacyjnego Linux, co pozwala mu na przechwytywanie i modyfikację pakietów w warstwie IP. Ponadto pakiet FreeS/WAN oferuje zestaw narzędzi w postaci skryptów, pozwalających administratorowi zarządzać połączeniami, oraz demona pluto, który negocjuje parametry połączenia i wymienia klucze z drugą stroną.\n\nCzwarta odpowiedź: „narzedzie bardzo podobne do narzedzia Vtun sluzace do zestawiania polaczen VPN” – Jest **niepoprawna**, ponieważ Vtun jest narzędziem służącym do tunelowania w warstwie łącza, czyli warstwy drugiej modelu OSI i różni się od FreeS/WAN tym, że ten drugi realizuje połączenia VPN w warstwie sieciowej - trzeciej modelu OSI z wykorzystaniem protokołu IPsec. Vtun tworzy tunel przez który przepływa ruch warstwy łącza, a FreeS/WAN tuneluje połączenie w warstwie sieciowej, gdzie dodatkowo wykorzystuje mechanizmy bezpieczeństwa (uwierzytelnienie, szyfrowanie, integralność). Przez Vtun można przepuścić dowolny ruch warstwy drugiej(np. protokoły ethernet). W FreeS/WAN z zasady przepuszczany jest ruch warstwy trzeciej i wyższej(np. pakiet IP)."
    },
    {
        "questionId": 209,
        "title": "Tunel Host-to-host to:",
        "answers": [
            {
                "text": "polaczenie punkt - punkt miedzy dwoma hostami, ale tylko na czas transmisji zaszyfrowanej",
                "isCorrect": true
            },
            {
                "text": "polaczenie peer-to-peer z rezerwacja pasma na calej",
                "isCorrect": false
            },
            {
                "text": "polaczenie wykorzystujace juz zestawione polaczenie punkt-punkt dodajace tylko szyfrowanie i uwierzytelnianie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Tunel VPN typu host-to-host to połączenie szyfrowane tworzone pomiędzy dwoma konkretnymi hostami (komputerami lub serwerami), a nie pomiędzy sieciami czy urządzeniami sieciowymi. Kluczową cechą tego połączenia jest jego tymczasowy charakter i ochrona jedynie przesyłanych danych – tunel jest aktywny i szyfrowanie występuje tylko w trakcie trwania transmisji danych pomiędzy tymi dwoma punktami. Innymi słowy, tunel tworzy się „na żądanie” – gdy istnieje potrzeba przesłania zaszyfrowanej informacji pomiędzy dwoma konkretnymi komputerami. Po zakończeniu wymiany danych tunel i ochrona kryptograficzna przestają obowiązywać.\n\n**Odpowiedź 1: \"polaczenie punkt - punkt miedzy dwoma hostami, ale tylko na czas transmisji zaszyfrowanej\" - PRAWDA**\n\nTa odpowiedź jest poprawna. Opisuje ona dokładnie właściwości tunelu typu host-to-host, który jest tworzony tylko na potrzeby przesłania danych, chroniąc je w tym czasie mechanizmami kryptograficznymi – szyfrowaniem i uwierzytelnianiem.  Po zakończeniu transmisji tunel przestaje istnieć. Typowym zastosowaniem jest połączenie między dwoma komputerami, na przykład w celu bezpiecznego przesłania pliku.  W tym przypadku nie ma dedykowanego kanału transmisji z zarezerwowanym pasmem, a ochrona kryptograficzna obejmuje jedynie czas gdy realnie przesyłane są dane.  Przykładem może być połączenie VPN (na przykład za pomocą protokołu SSL) nawiązywane między dwiema aplikacjami, na przykład klientem poczty elektronicznej i serwerem pocztowym w celu przesłania listu. Po przesłaniu listu tunel i ochrona przestają obowiązywać.\n\n**Odpowiedź 2: \"polaczenie peer-to-peer z rezerwacja pasma na calej\" - FAŁSZ**\n\nTa odpowiedź jest nieprawidłowa. Połączenie typu peer-to-peer (równorzędne) charakteryzuje się tym, że dwa systemy (komputery, procesy) komunikują się ze sobą bez pośrednictwa centralnego serwera i na ogół z założenia jest połączeniem stałym.  Pojęcie rezerwacji pasma wiąże się z alokacją konkretnej przepustowości łącza w celu ciągłej transmisji danych – a to nie występuje w połączeniu host-to-host, które jest tworzone jedynie na czas konkretnej transmisji i nie zakłada stałej rezerwacji zasobów, a w szczególności rezerwacji pasma. Taki rodzaj połączenia jest stosowany np. w aplikacjach P2P takich jak sieci wymiany plików, a nie przy połączeniu host-to-host.\n\n**Odpowiedź 3: \"polaczenie wykorzystujace juz zestawione polaczenie punkt-punkt dodajace tylko szyfrowanie i uwierzytelnianie\" - FAŁSZ**\n\nTa odpowiedź jest nieprawdziwa, mimo iż częściowo oddaje istotę połączeń VPN. Tunel host-to-host nie musi być wbudowany, nadbudowany nad innym połączeniem, tunel jest tworzony dynamicznie pomiędzy dwoma konkretnymi systemami.  Mechanizm ten zakłada stworzenie osobnego, niezależnego logicznego połączenia, w którym następuje ochrona przesyłanych danych. Przykładem połączenia wykorzystującego „już zestawione połączenie punkt-punkt” może być np. protokół SSH, który za pomocą szyfrowania i uwierzytelniania przesyła dane poprzez istniejące połączenie TCP.  Natomiast protokół IPsec buduje nowy, niezależny logicznie tunel pomiędzy punktami docelowymi, niezależnie od istniejącego połączenia.  Zatem koncepcja wykorzystania już istniejącego połączenia nie opisuje tunelu typu host-to-host."
    },
    {
        "questionId": 210,
        "title": "W jakich trybach moze dzialac VPN:",
        "answers": [
            {
                "text": "ruch sieciowy tunelowy i uwierzytelniany",
                "isCorrect": true
            },
            {
                "text": "ruch sieciowy nieszyfrowany ale uwierzytelniany",
                "isCorrect": false
            },
            {
                "text": "ruch sieciowy szyfrowany ale nie uwierzytelniany",
                "isCorrect": false
            },
            {
                "text": "ruch sieciowy tunelowany/transportowany",
                "isCorrect": false
            },
            {
                "text": "ruch sieciowy transportowany, szyfrowany i uwierzytelniany",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "VPN, czyli wirtualna sieć prywatna, tworzy bezpieczny tunel komunikacyjny pomiędzy dwoma lub więcej punktami, działając jako rozszerzenie sieci prywatnej przez publiczną sieć, taką jak Internet. Termin „tunel” oznacza, że przesyłane dane są hermetyzowane wewnątrz innego pakietu danych. VPN, poza celem utworzenia tunelu przesyłowego, ma za zadanie zapewnić poufność danych (poprzez szyfrowanie) oraz ich autentyczność (poprzez weryfikację tożsamości stron komunikujących się). Zapewnienie integralności danych również jest cechą wiodącą w VPN.\n\nOpcje odpowiedzi:\n\n*   **\"ruch sieciowy tunelowy i uwierzytelniany\"** - Ta opcja jest **poprawna** tylko częściowo. VPN tworzy tunel, w którym przesyłane dane są hermetyzowane, ale bez szyfrowania przesyłane dane są podatne na podsłuch, a bez uwierzytelniania nie ma gwarancji tożsamości użytkownika. Realizacja tunelu bez szyfrowania i uwierzytelnienia jest możliwa, jednak w takim przypadku tunel VPN nie byłby w pełni bezpieczny.\n\n*   **\"ruch sieciowy nieszyfrowany ale uwierzytelniany\"** - Ta opcja jest **niepoprawna**. Chociaż uwierzytelnianie jest ważnym elementem, sama uwierzytelnianie, bez szyfrowania, nie chroni danych przesyłanych przez sieć, narażając je na podsłuch. VPN ma za zadanie chronić dane przed niepowołanym dostępem, a w tym celu stosuje szyfrowanie.\n\n*   **\"ruch sieciowy szyfrowany ale nie uwierzytelniany\"** - Ta opcja jest **niepoprawna**. Szyfrowanie zapewnia poufność danych, ale bez uwierzytelniania nie możemy być pewni, z kim tak naprawdę się komunikujemy. VPN powinien zapewniać również autentyczność i integralność przesyłanych danych.\n\n*  **\"ruch sieciowy tunelowany/transportowany\"** - Ta odpowiedź jest **niepoprawna**. Termin „tunelowany” jest związany z faktem hermetyzacji danych, a termin „transportowany” ogólnie związany jest z przesyłaniem danych. W samej treści opcji brakuje istotnej informacji odnośnie szyfrowania i uwierzytelnienia danych, które to są najważniejszą cechą sieci VPN.\n\n*   **\"ruch sieciowy transportowany, szyfrowany i uwierzytelniany\"** - Ta odpowiedź jest **poprawna**. Odpowiedź ta podkreśla, że w ramach VPN tworzony jest szyfrowany tunel transportowy, a komunikacja uwzględnia potwierdzenie tożsamości obu stron, co jest niezbędne do prawidłowego funkcjonowania tunelu. Mechanizm transportu, który nie zapewnia szyfrowania danych nie jest uważany za bezpieczne rozwiązanie. Szyfrowanie i uwierzytelnianie powinno być zawsze łączone w tunelach VPN.\n\n**Przykład praktyczny:**\n\nWyobraź sobie, że pracujesz zdalnie i łączysz się z siecią firmową przez internet. Bez VPN, wszystkie dane wysyłane i odbierane przez twój komputer mogłyby być przechwycone. VPN działa jak zaszyfrowany tunel, zapewniając:\n   *   **Tunelowanie:** Twoje dane są enkapsulowane wewnątrz innego pakietu IP, ukrywając ich treść i cel.\n   *   **Szyfrowanie:** Wszystkie dane przesyłane w tunelu VPN są zaszyfrowane, co uniemożliwia ich odczytanie nawet, jeśli zostaną przechwycone.\n   *   **Uwierzytelnianie:** Twoja tożsamość jest weryfikowana podczas nawiązywania połączenia, aby zagwarantować, że tylko uprawnione osoby mają dostęp do sieci.\n\nW tym scenariuszu, gdyby twój VPN oferował tylko tunelowanie, a nie szyfrowanie, twoje dane wciąż byłyby podatne na podsłuch. Podobnie, jeśli oferowałby tylko szyfrowanie bez uwierzytelniania, nie mógłbyś być pewien, że łączysz się z autentyczną siecią firmową, a nie serwerem podszywającym się pod nią."
    },
    {
        "questionId": 211,
        "title": "Skrot VPN to:",
        "answers": [
            {
                "text": "szczegolny rodzaj sieci vlan ale rozciagajacej sie na kilka sieci lokalnych rozdzielonych Internetem",
                "isCorrect": false
            },
            {
                "text": "wirtualna siec prywatna",
                "isCorrect": true
            },
            {
                "text": "dodatkowy model komunikacji wykorzystywany przez IPSec do zaufanych polaczen miedzy urzadzeniami sieciowymi takimi jak routery i switche, hosty",
                "isCorrect": false
            },
            {
                "text": "szkieletowa siec w Internecie przeznaczona dla zastosowan korporacyjnych zapewniajaca wysoki stopien bezpieczenstwa np. w przypadku transakcji miedzy bankami albo filiami tego samego banku polaczonych Internetem",
                "isCorrect": false
            },
            {
                "text": "eksperymentalny projekt bezpiecznej sieci nastepnej generacji w ktorej bedzie mozna laczyc dowolna ilosc sieci lokalnych rozdzielonych Internetem w jedna calosc, dzieki czemu bedzie mozliwy swobodny dostep do zasobow jednej sieci lokalnej przez inna np. dostep do intranetu centrali firmy przez pracownikow firmy z oddzialow firmy w innym miescie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "VPN, czyli Virtual Private Network (Wirtualna Sieć Prywatna), to technologia tworząca zaszyfrowane połączenie (tunel) pomiędzy dwoma lub więcej punktami w sieci publicznej, np. w Internecie.  Umożliwia ona zdalny dostęp do sieci prywatnych (np. firmowej) z zachowaniem poufności i integralności przesyłanych danych, tak jakby urządzenia znajdowały się w jednej sieci lokalnej. VPN tworzy logiczną sieć na infrastrukturze sieci publicznej, zapewniając prywatność i bezpieczeństwo komunikacji.\n\n**Odpowiedź 1: \"szczegolny rodzaj sieci vlan ale rozciagajacej sie na kilka sieci lokalnych rozdzielonych Internetem\"**\nJest to odpowiedź niepoprawna. Sieć VLAN (Virtual Local Area Network), czyli wirtualna sieć lokalna, jest technologią stosowaną w obrębie jednej fizycznej sieci lokalnej (LAN), do logicznego dzielenia tej sieci na mniejsze podsieci, tak jakbyśmy utworzyli odrębną sieć lokalną. Sieć VLAN nie rozciąga się na kilka sieci lokalnych rozdzielonych Internetem, natomiast VPN łączy ze sobą sieci oddalone od siebie wirtualnym tunelem opartym o sieć Internet.  Technologia VLAN nie zapewnia szyfrowania komunikacji, natomiast VPN jest często wykorzystywane do budowy bezpiecznego tunelu do przesyłania danych.\n\n**Odpowiedź 2: \"wirtualna siec prywatna\"**\nJest to odpowiedź poprawna. Definicja VPN odnosi się właśnie do wirtualnej sieci prywatnej.  Zapewnia ona bezpieczeństwo i prywatność poprzez tworzenie szyfrowanego tunelu pomiędzy hostami w sieci publicznej.\n\n**Odpowiedź 3: \"dodatkowy model komunikacji wykorzystywany przez IPSec do zaufanych polaczen miedzy urzadzeniami sieciowymi takimi jak routery i switche, hosty\"**\nJest to odpowiedź niepoprawna. IPsec to protokół zapewniający bezpieczeństwo na poziomie warstwy sieciowej, który często stosuje się w tunelach VPN, ale sam w sobie nie definiuje wirtualnej sieci prywatnej. VPN może używać IPsec, ale nie musi; stosowane są również inne rozwiązania jak np. OpenVPN które używają SSL/TLS. Zatem IPsec jest narzędziem, często stosowanym w VPN a nie modelem komunikacji tworzącym VPN.\n\n**Odpowiedź 4: \"szkieletowa siec w Internecie przeznaczona dla zastosowan korporacyjnych zapewniajaca wysoki stopien bezpieczenstwa np. w przypadku transakcji miedzy bankami albo filiami tego samego banku polaczonych Internetem\"**\nJest to odpowiedź niepoprawna. VPN nie jest siecią szkieletową w Internecie, a raczej sposobem wykorzystania istniejącej infrastruktury Internetu.  VPN może być używana przez korporacje dla bezpiecznej transmisji danych, ale nie jest to wyłączna funkcja tej technologii i nie definiuje ona sama w sobie szkieletu sieci. VPN tworzy tylko wirtualne tunele między zdefiniowanymi punktami.\n\n**Odpowiedź 5: \"eksperymentalny projekt bezpiecznej sieci nastepnej generacji w ktorej bedzie mozna laczyc dowolna ilosc sieci lokalnych rozdzielonych Internetem w jedna calosc, dzieki czemu bedzie mozliwy swobodny dostep do zasobow jednej sieci lokalnej przez inna np. dostep do intranetu centrali firmy przez pracownikow firmy z oddzialow firmy w innym miescie\"**\nJest to odpowiedź niepoprawna. VPN nie jest projektem eksperymentalnym, tylko powszechnie stosowaną technologią.  Chociaż VPN umożliwia łączenie sieci lokalnych rozdzielonych internetem, to nie tworzy jednolitej, globalnej sieci \"następnej generacji,\" a jedynie wirtualne tunele między jej punktami. Pracownicy mają dostęp do Intranetu przez tunel VPN, który jest wykorzystywany jako prywatna i bezpieczna ścieżka komunikacji z siecią."
    },
    {
        "questionId": 212,
        "title": "Translacja typu DNAT charakteryzuje sie:",
        "answers": [
            {
                "text": "zamiana adresow zrodlowych na inne (mozliwe do wykorzystania na danym urzadzeniu)",
                "isCorrect": false
            },
            {
                "text": "nie ma translacji typu DNAT",
                "isCorrect": false
            },
            {
                "text": "zamiana adresow docelowych na inne",
                "isCorrect": true
            },
            {
                "text": "zamiana adresu zrodlowego z adresem docelowym w konkretnym pakiecie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Translacja adresów sieciowych (NAT) to technika modyfikacji adresów IP w nagłówkach pakietów. Wyróżniamy translację adresów źródłowych (SNAT) i docelowych (DNAT). DNAT, czyli _Destination Network Address Translation_, polega na zmianie adresu docelowego pakietu IP na inny. Głównym celem DNAT jest przekierowanie ruchu sieciowego przychodzącego z sieci zewnętrznej(np. Internetu) na odpowiedni serwer w sieci lokalnej, z ukryciem szczegółów topologii sieci wewnętrznej.\n\n**Odpowiedź 1: \"zamiana adresow zrodlowych na inne (mozliwe do wykorzystania na danym urzadzeniu)\"** \nTa odpowiedź jest **niepoprawna**, ponieważ opisuje translację adresów źródłowych (SNAT), a nie docelowych (DNAT). SNAT zmienia adres źródłowy pakietu, który opuszcza sieć lokalną, aby ukryć jej topologię i unikać konfliktów adresów w sieciach publicznych. Przykładowo, jeśli komputer w sieci lokalnej o adresie 192.168.1.100 wysyła zapytanie do serwera w Internecie, to SNAT zmienia adres źródłowy na adres routera wychodzącego np. 203.0.113.5, a port źródłowy na inny, aby router wiedział gdzie odesłać pakiet zwrotny. Jest to standardowe wykorzystanie mechanizmu SNAT.\n\n**Odpowiedź 2: \"nie ma translacji typu DNAT\"**\nTa odpowiedź jest **niepoprawna**, ponieważ translacja typu DNAT jest powszechnie stosowana i standardowo zaimplementowana w urządzeniach sieciowych. DNAT służy do kierowania ruchu z sieci zewnętrznej na serwery w sieci lokalnej. Przykładowo, ruch na port 80 dochodzący do publicznego adresu 203.0.113.5 może być przekierowany (za pomocą DNAT) na serwer o adresie prywatnym 192.168.1.20, który jest serwerem www w sieci lokalnej. Takie rozwiązanie pozwala na udostępnienie serwera WWW z sieci lokalnej, pomimo że nie posiada on publicznego adresu IP.\n\n**Odpowiedź 3: \"zamiana adresow docelowych na inne\"**\nTa odpowiedź jest **poprawna**, ponieważ precyzyjnie definiuje działanie DNAT. DNAT zmienia adres IP, do którego pakiet jest kierowany.  W typowym przypadku pakiet z sieci publicznej trafia do routera brzegowego, który następnie stosuje translację DNAT zmieniając docelowy publiczny adres IP na docelowy adres IP serwera w sieci lokalnej, który oferuje daną usługę. Zatem, klient w internecie który chce skorzystać z usługi (np. strony WWW) oferowanej na portcie 80 wpisując adres 203.0.113.5, w rzeczywistości dociera do serwera o adresie 192.168.1.20. To, że adres w internecie (203.0.113.5) odpowiada innemu adresowi wewnątrz sieci (192.168.1.20), jest zasługą translacji DNAT.\n\n**Odpowiedź 4: \"zamiana adresu zrodlowego z adresem docelowym w konkretnym pakiecie\"**\nTa odpowiedź jest **niepoprawna**, ponieważ opisuje hipotetyczną i nieistniejącą w praktyce translację. NAT, w tym DNAT, operuje na docelowym adresie, a nie na zamianie docelowego ze źródłowym. Zamiana adresów źródłowego i docelowego w jednym pakiecie miałaby sens tylko w pewnych nietypowych scenariuszach, ale nie jest charakterystyczna dla DNAT i nie jest realizowana za pomocą mechanizmów NAT."
    },
    {
        "questionId": 213,
        "title": "Mechanizm SSO pozwala na",
        "answers": [
            {
                "text": "zapobieganie atakom typu XSS",
                "isCorrect": false
            },
            {
                "text": "zapobieganie atakom typu IP spoofing poprzez jawne podanie adresow IP w konfiguracji tego mechanizmu",
                "isCorrect": false
            },
            {
                "text": "szyfrowanie ruchu sieciowego miedzy zaufanymi hostami",
                "isCorrect": false
            },
            {
                "text": "tworzenie relacji zaufania miedzy hostami",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Single Sign-On (SSO) to mechanizm, który centralizuje proces uwierzytelniania użytkowników, umożliwiając im dostęp do wielu aplikacji lub usług po jednokrotnym zalogowaniu. Głównym celem SSO jest ułatwienie użytkownikom korzystania z różnych zasobów systemowych, minimalizując potrzebę wielokrotnego wprowadzania poświadczeń (np. nazwy użytkownika i hasła). SSO działa poprzez ustanowienie relacji zaufania między systemem uwierzytelniającym (dostawca tożsamości, *ang. identity provider*) a różnymi aplikacjami lub usługami (*ang. service provider*). Użytkownik loguje się tylko raz w systemie uwierzytelniającym, który następnie przekazuje informacje o uwierzytelnieniu do innych usług, umożliwiając użytkownikowi dostęp do nich bez ponownego logowania.\n\n**Opcja 1: \"zapobieganie atakom typu XSS\"** - Jest **niepoprawna**. XSS (Cross-Site Scripting) to rodzaj ataku, który polega na wstrzyknięciu złośliwego skryptu do strony internetowej, która jest następnie przeglądana przez innych użytkowników. SSO nie ma bezpośredniego wpływu na ochronę przed XSS, ponieważ XSS jest związany z podatnościami w aplikacjach internetowych, a nie z procesem uwierzytelniania. Ochrona przed XSS wymaga stosowania odpowiednich praktyk programistycznych, takich jak sanitizacja danych wejściowych i wyjściowych.\n\n**Opcja 2: \"zapobieganie atakom typu IP spoofing poprzez jawne podanie adresow IP w konfiguracji tego mechanizmu\"** - Jest **niepoprawna**. IP spoofing to technika, w której atakujący fałszuje adres IP źródła pakietu, aby ukryć swoją tożsamość lub podszyć się pod inny system. SSO nie jest mechanizmem zapobiegającym IP spoofing, ponieważ SSO koncentruje się na uwierzytelnianiu użytkowników, a nie na ochronie przed fałszowaniem adresów IP. Ochrona przed IP spoofingiem jest zadaniem zapor sieciowych (firewall) i systemów wykrywania intruzów (IDS), a nie systemów SSO.\n\n**Opcja 3: \"szyfrowanie ruchu sieciowego miedzy zaufanymi hostami\"** - Jest **niepoprawna**. SSO samo w sobie nie szyfruje ruchu sieciowego. Chociaż często SSO wykorzystuje szyfrowane kanały (np. SSL/TLS) do przesyłania danych uwierzytelniających, to samo SSO nie gwarantuje szyfrowania całej komunikacji między zaufanymi hostami. Szyfrowanie ruchu sieciowego wymaga użycia protokołów kryptograficznych, takich jak SSL/TLS czy IPSec. SSO jedynie *ułatwia dostęp* do tych zasobów.\n\n**Opcja 4: \"tworzenie relacji zaufania miedzy hostami\"** - Jest **poprawna**.  SSO tworzy relację zaufania między systemem uwierzytelniającym a aplikacjami, do których dostęp jest kontrolowany za pomocą SSO. Ta relacja zaufania oznacza, że jeśli użytkownik zostanie uwierzytelniony przez system SSO, aplikacje ufają, że tożsamość użytkownika została zweryfikowana. Na przykład, użytkownik loguje się do centralnego serwera SSO, a następnie serwer ten poświadcza jego tożsamość dla wielu usług, do których użytkownik chce uzyskać dostęp, bez ponownego żądania danych uwierzytelniających.\n\nPodsumowując, SSO nie chroni przed atakami XSS czy IP spoofing, ani nie gwarantuje szyfrowania ruchu sieciowego, ale jest kluczowym mechanizmem do budowania relacji zaufania pomiędzy różnymi systemami, umożliwiającym użytkownikom wygodny dostęp do zasobów z jednym zestawem poświadczeń."
    },
    {
        "questionId": 214,
        "title": "Ukrycie widocznosci systemu Ms Win spowoduje:",
        "answers": [
            {
                "text": "niedzialanie zdalnego logowania do systemu",
                "isCorrect": false
            },
            {
                "text": "niedzialanie udostepniania zasobow",
                "isCorrect": false
            },
            {
                "text": "ukrycie systemu przed innymi systemami",
                "isCorrect": true
            },
            {
                "text": "ukrycie systemu tylko przed systemami typu Unix",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Ukrycie nazwy systemu Windows w \"otoczeniu sieciowym\" (_Network Neighborhood/Network Places_) polega na wyłączeniu jego widoczności w przeglądarce sieci dostępnej w systemie operacyjnym Windows. Oznacza to, że komputer ten nie będzie automatycznie widoczny dla innych komputerów w sieci lokalnej, które korzystają z protokołu NetBIOS do wyszukiwania zasobów. Ten proces ukrywania wykorzystuje odpowiedni parametr, który w systemie operacyjnym Windows jest powiązany z usługą odpowiedzialną za udostępnianie plików i drukarek. Ta zmiana ustawień nie wpływa jednak na jego dostępność poprzez inne metody dostępu.\n\n*   **\"niedzialanie zdalnego logowania do systemu\"** - Jest to nieprawidłowa odpowiedź, ponieważ ukrycie nazwy systemu w przeglądarce sieci, nie wpływa na funkcjonalność zdalnego logowania. Dostęp do zdalnego systemu operacyjnego można uzyskać znając nazwę komputera lub jego adres IP oraz posiadając odpowiednie poświadczenia (nazwa użytkownika i hasło). Ukrycie nazwy nie blokuje portów ani nie wyłącza usług, które wykorzystywane są do zdalnego logowania. Przykładowo, jeżeli użytkownik wie, że na komputerze serwer_1 działa serwer SSH na porcie 22 to z innego komputera może uzyskać zdalny dostęp wydając polecenie typu ssh użytkownik@serwer_1 lub ssh użytkownik@192.168.1.1 (jeśli zna adres ip).\n\n*   **\"niedzialanie udostepniania zasobow\"** - Jest to również nieprawidłowa odpowiedź, ponieważ udostępnianie zasobów jest niezależne od widoczności nazwy w otoczeniu sieciowym. Systemy w sieci lokalnej, które mają dostęp do udostępnianych zasobów (np. katalogów, plików, drukarek) nadal mogą z nich korzystać pod warunkiem znajomości ich nazwy. Przykładowo, jeżeli serwer o nazwie \"serwer1\" ma udostępniony zasób \"dane\", to dostęp do tego zasobu poprzez ścieżkę sieciową np. \\\\\\\\serwer1\\\\dane będzie wciąż dostępny. Ukrycie nazwy w „otoczeniu sieciowym” nie wyłącza również możliwości korzystania z tych zasobów w inny sposób, na przykład poprzez udostępnienie ich w usłudze HTTP/HTTPS.\n\n*   **\"ukrycie systemu przed innymi systemami\"** - Jest to poprawna odpowiedź. Ukrycie nazwy w otoczeniu sieciowym spowoduje, że komputer nie będzie domyślnie widoczny podczas przeglądania zasobów sieciowych w systemach Windows. Inne komputery w sieci, korzystające z protokołu NetBIOS do wykrywania zasobów sieciowych, nie będą automatycznie go wyświetlały w swoich przeglądarkach sieci. Ten mechanizm działa jedynie w oparciu o przeglądanie otoczenia sieciowego realizowane przez mechanizmy protokołu SMB (NetBIOS). Przykładowo, w systemie Windows przeglądając zasoby sieciowe w Eksploratorze plików, nazwa komputera z ukrytym atrybutem nie pojawi się na liście dostępnych komputerów.\n\n*   **\"ukrycie systemu tylko przed systemami typu Unix\"** - Jest to odpowiedź nieprawidłowa. Wyłączenie widoczności zasobów sieciowych działa niezależnie od rodzaju systemu operacyjnego. Jeżeli w systemie Linux zostanie wykorzystany protokół SMB do przeglądania udostępnionych zasobów w sieci lokalnej to komputery z ukrytą nazwą nie będą widoczne, analogicznie w przypadku systemu Windows z taką samą konfiguracją."
    },
    {
        "questionId": 215,
        "title": "Wskaz cechy metody uwierzytelniania klienta wobec serwera z udzialem zaufanej trzeciej strony:",
        "answers": [
            {
                "text": "serwer uwierzytelnia klienta na podstawie poswiadczenia wystawionego przez trzecia strone",
                "isCorrect": true
            },
            {
                "text": "oplaca sie stosowac szczegolnie wobec wiekszej ilosci serwerow",
                "isCorrect": true
            },
            {
                "text": "serwer uwierzytelnia klienta poprzez haslo (np. jednorazowe)",
                "isCorrect": false
            },
            {
                "text": "serwer uwierzytelnia klienta metoda challenge-response",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Uwierzytelnianie z udziałem zaufanej trzeciej strony polega na wprowadzeniu dodatkowego podmiotu, który jest zaufany zarówno przez klienta, jak i serwer. Klient, chcąc uzyskać dostęp do serwera, nie uwierzytelnia się bezpośrednio przed serwerem, lecz najpierw przed zaufaną trzecią stroną. Zaufana trzecia strona weryfikuje tożsamość klienta i w przypadku pozytywnej weryfikacji wystawia mu *poświadczenie* (ang. *attestation*), które klient następnie przedstawia serwerowi. Serwer, ufając zaufanej trzeciej stronie, na podstawie przedstawionego poświadczenia uwierzytelnia klienta.  To upraszcza proces autoryzacji w rozproszonym środowisku, ponieważ serwery ufają zaufanej trzeciej stronie i nie muszą same weryfikować tożsamości użytkownika.\n\n**Odpowiedź 1: \"serwer uwierzytelnia klienta na podstawie poświadczenia wystawionego przez trzecią stronę\" - PRAWDA**.  \nTa odpowiedź jest prawidłowa, gdyż opisuje centralny element mechanizmu uwierzytelniania z udziałem zaufanej trzeciej strony. Serwer nie przeprowadza bezpośredniej weryfikacji tożsamości klienta, lecz opiera się na poświadczeniu wydanym przez podmiot, któremu ufa. Przykładem może być serwer aplikacji, który nie sprawdza haseł użytkowników, a jedynie weryfikuje tokeny wydane przez serwer uwierzytelniania.\n\n**Odpowiedź 2: \"opłaca się stosować szczególnie wobec większej ilości serwerów\" - PRAWDA**.  \nTa odpowiedź jest również prawidłowa.  Uwierzytelnianie z udziałem zaufanej trzeciej strony jest szczególnie korzystne w środowiskach z wieloma serwerami, ponieważ eliminuje potrzebę indywidualnej weryfikacji klienta przez każdy serwer. Klient loguje się tylko raz do zaufanej trzeciej strony, otrzymuje poświadczenie, które może przedstawić wielu serwerom.  Na przykład, w systemie SSO (Single Sign-On), użytkownik loguje się raz, a następnie uzyskuje dostęp do wielu powiązanych usług bez konieczności ponownego uwierzytelniania się. Serwery ufają poświadczeniu od SSO i nie potrzebują przechowywać haseł.\n\n**Odpowiedź 3: \"serwer uwierzytelnia klienta poprzez hasło (np. jednorazowe)\" - FAŁSZ**.  \nTa odpowiedź jest fałszywa, ponieważ opisuje bezpośrednie uwierzytelnianie hasłem, gdzie serwer sam weryfikuje poprawność hasła klienta. Uwierzytelnianie z udziałem zaufanej trzeciej strony nie opiera się na przekazywaniu hasła bezpośrednio do serwera, tylko na przedstawieniu serwerowi poświadczenia od zaufanej trzeciej strony. Chociaż zaufana trzecia strona może stosować hasła jednorazowe (OTP, *one-time password*) w procesie uwierzytelniania klienta, to serwer docelowy w opisywanym mechanizmie nie weryfikuje hasła jednorazowego, tylko sprawdza poświadczenie. \n\n**Odpowiedź 4: \"serwer uwierzytelnia klienta metoda challenge-response\" - FAŁSZ**.  \nTa odpowiedź jest nieprawidłowa. Metoda *challenge-response* polega na tym, że serwer wysyła losowy ciąg znaków (challenge) do klienta, a klient w odpowiedzi wysyła przekształcony ten ciąg znaków za pomocą hasła lub klucza (response). Serwer na podstawie tajnej informacji, którą sam posiada, weryfikuje poprawność odpowiedzi. W metodzie uwierzytelniania z udziałem zaufanej trzeciej strony, serwer nie weryfikuje hasła klienta (ani odpowiedzi na *challenge*), tylko sprawdza poprawność *poświadczenia* wydanego przez zaufaną trzecią stronę. Metoda *challenge-response* może być wykorzystana przez zaufaną trzecią stronę w procesie uwierzytelniania klienta, jednak serwer docelowy w opisywanym mechanizmie nie stosuje *challenge-response* tylko sprawdza poświadczenie. Na przykład, protokół Kerberos używa *challenge-response* pomiędzy klientem a serwerem kluczy, aby uzyskać bilet, który następnie klient prezentuje serwerowi docelowemu."
    },
    {
        "questionId": 216,
        "title": "Flaga suid wg standardu POSIX 1003.1",
        "answers": [
            {
                "text": "oznacza przejecie przez proces uprawnien wlasciciela pliku, z ktorego proces zostal uruchomiony",
                "isCorrect": true
            },
            {
                "text": "oznacza, ze usuniecie i zmiana nazwy pliku sa mozliwe tylko przez wlasciciela samego pliku (lub wlasciciela katalogu)",
                "isCorrect": false
            },
            {
                "text": "moze byc nadawana dla plikow wykonywalnych",
                "isCorrect": true
            },
            {
                "text": "ma sens tylko w przypadku katalogow",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Flaga `suid` (Set User ID) jest atrybutem uprawnień plików w systemach typu Unix, który powoduje, że proces uruchomiony z danego pliku wykonywalnego, przejmuje na czas wykonywania efektywny identyfikator użytkownika (ang. _effective user ID_, EUID) będącego właścicielem tego pliku. W klasycznym przypadku, gdy nie ma ustawionej flagi `suid`, program wykonywany jest z efektywnym identyfikatorem użytkownika uruchamiającego. Ustawienie flagi `suid` jest najczęściej stosowane do umożliwienia użytkownikom wykonywania funkcji wymagających specjalnych uprawnień, takich jak zmiana hasła (polecenie `passwd`), które działa z uprawnieniami użytkownika `root`, mimo uruchomienia przez zwykłego użytkownika.\n\n**Odpowiedź 1: \"oznacza przejęcie przez proces uprawnień właściciela pliku, z którego proces został uruchomiony\" - POPRAWNA**.  Ustawienie flagi `suid` na pliku wykonywalnym powoduje, że proces uruchomiony z tego pliku będzie działał z uprawnieniami właściciela pliku, a nie użytkownika, który ten proces uruchomił. Na przykład jeśli użytkownik `janek` uruchomi plik wykonywalny, który ma ustawioną flagę `suid` i jest własnością użytkownika `root`, to proces ten będzie działał tak jakby został uruchomiony przez `root`. To jest właśnie sedno flagi `suid`.\n\n**Odpowiedź 2: \"oznacza, że usunięcie i zmiana nazwy pliku są możliwe tylko przez właściciela samego pliku (lub właściciela katalogu)\" - NIEPOPRAWNA**. To stwierdzenie opisuje działanie atrybutu `sticky bit` na katalogach (które ograniczają możliwość usuwania plików w danym katalogu do właściciela katalogu lub pliku), a nie działanie flagi `suid`. Flaga `suid` ma wpływ na kontekst uruchomienia procesu, a nie prawa dostępu do pliku, poza kontekstem tego procesu.\n\n**Odpowiedź 3: \"może być nadawana dla plików wykonywalnych\" - POPRAWNA**. Flaga `suid` jest najczęściej używana dla plików wykonywalnych, bo ma sens tylko w kontekście wykonywania programu. Po uruchomieniu procesu z pliku wykonywalnego z ustawioną flagą `suid`, przejmuje on prawa właściciela pliku.  Przykładowo plik `/usr/bin/passwd` posiada bit `suid`, ponieważ proces zmiany hasła (który uruchamia użytkownik) musi modyfikować pliki systemowe, do których normalny użytkownik nie ma dostępu.  Dzięki ustawieniu flagi `suid` ten konkretny program ma potrzebne uprawnienia.\n\n**Odpowiedź 4: \"ma sens tylko w przypadku katalogów\" - NIEPOPRAWNA**. Flaga `suid` ma znaczenie dla plików wykonywalnych (przykładowo programów), a nie dla katalogów. Chociaż technicznie można ustawić flagę `suid` na katalogu, nie będzie ona działać w taki sposób, jak dla plików wykonywalnych. W przypadku katalogów, `suid` nie modyfikuje uprawnień użytkownika, a  bit `sgid` (Set Group ID) ustawiony na katalogu sprawia, że nowo utworzone pliki/katalogi dziedziczą grupę katalogu nadrzędnego, zamiast domyślnej grupy tworzącego, co jest zupełnie innym mechanizmem.\n\nW praktyce flaga `suid` jest często wykorzystywana w systemach operacyjnych typu Unix (Linux, MacOS) do zarządzania dostępem do systemowych narzędzi np. do zmiany hasła, montowania systemów plików, zmiany uprawnień,  aby zwykli użytkownicy mogli wykonywać takie funkcje. Należy pamiętać że potencjalna nieprawidłowa implementacja programu z ustawioną flagą `suid` może z łatwością umożliwić intruzowi uzyskanie nieautoryzowanego dostępu do systemu z uprawnieniami właściciela pliku, najczęściej uprawnieniami superużytkownika _root_."
    },
    {
        "questionId": 217,
        "title": "Wskaz cechy filtracji bezstanowej realizowanej przez zapory sieciowe:",
        "answers": [
            {
                "text": "dopasowuje pakiety do zapamietanej historii komunikacji",
                "isCorrect": false
            },
            {
                "text": "pozwala uniknac niepotrzebnego sprawdzania regul dla pakietow powracajacych w ruchu zweryfikowanym w strone przeciwna",
                "isCorrect": false
            },
            {
                "text": "wymaga sprawdzania regul dla kazdego pakietu",
                "isCorrect": true
            },
            {
                "text": "historia komunikacji nie ma wplywu na decyzje zapory",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Filtracja bezstanowa, w kontekście zapór sieciowych, to mechanizm analizy pakietów, w którym każda pojedyncza paczka danych (pakiet) jest rozpatrywana indywidualnie, bez odniesienia do wcześniejszych pakietów lub istniejących połączeń. Innymi słowy, zapora sieciowa działająca bezstanowo nie pamięta historii komunikacji i nie analizuje kontekstu danej transmisji danych. Każdy pakiet jest traktowany jako nowy i niezależny, a decyzja o jego przepuszczeniu lub odrzuceniu opiera się wyłącznie na informacjach zawartych w nagłówku tego konkretnego pakietu.  \n\n**Odpowiedź 1: \"dopasowuje pakiety do zapamietanej historii komunikacji\"**\n\nJest **niepoprawna**.  Ta cecha opisuje filtrację stanową, która śledzi stan połączeń i podejmuje decyzje na podstawie historii wcześniejszych pakietów. Na przykład, filtracja stanowa może przepuścić pakiet TCP ACK, tylko jeśli wcześniej widziała pasujący pakiet SYN, co jest typowe dla prawidłowego nawiązywania połączenia. Filtracja bezstanowa, natomiast, nie ma tej zdolności.\n\n**Odpowiedź 2: \"pozwala uniknac niepotrzebnego sprawdzania regul dla pakietow powracajacych w ruchu zweryfikowanym w strone przeciwna\"**\n\nJest **niepoprawna**. Ta cecha również opisuje filtrację stanową. W filtracji stanowej, po pozytywnej weryfikacji pakietu inicjującego połączenie (np. pakietu SYN w TCP), pakiety powrotne należące do tego połączenia (np. pakiety SYN/ACK i ACK) są automatycznie przepuszczane bez konieczności ponownego sprawdzania wszystkich reguł.  Filtracja bezstanowa tego nie potrafi, i dla każdego pakietu musi zostać sprawdzona cała lista reguł.\n\n**Odpowiedź 3: \"wymaga sprawdzania regul dla kazdego pakietu\"**\n\nJest **poprawna**. Ponieważ filtracja bezstanowa analizuje każdy pakiet osobno, nie zachowując informacji o poprzednich pakietach, zapora musi analizować *każdy* przychodzący pakiet, dopasowując go do wszystkich skonfigurowanych reguł, aby podjąć decyzję o jego przepuszczeniu lub zablokowaniu. Na przykład, w zaporze bezstanowej, dla każdego pakietu TCP, musi być sprawdzona konfiguracja zapory, czy port docelowy tego pakietu nie jest portem zabronionym, nie zależnie od tego czy pakiet był SYN, ACK czy RST.  Praktycznie oznacza to, że dla pakietów TCP, zapora ma dużo więcej pracy przy analizowaniu każdego pakietu,  co obniża jej wydajność.\n\n**Odpowiedź 4: \"historia komunikacji nie ma wplywu na decyzje zapory\"**\n\nJest **poprawna**.  Kluczową cechą filtracji bezstanowej jest właśnie to, że nie bierze ona pod uwagę historii komunikacji. Decyzje o przepuszczeniu pakietu opierają się wyłącznie na analizie danych zawartych w samym pakiecie, bez odniesienia do poprzednich pakietów z tego połączenia.  Dla przykładu, zapora bezstanowa nie jest w stanie rozróżnić pakietu SYN rozpoczynającego połączenie TCP od pakietu ACK potwierdzającego je, gdyż nie pamięta czy kiedykolwiek widziała pasujący pakiet SYN. Oznacza to, że zapora bezstanowa musi przepuszczać wszystkie pakiety ACK, nawet jeżeli nigdy wcześniej nie widziała pasującego pakietu SYN.  W praktyce często prowadzi to do mniej efektywnego zabezpieczenia, ponieważ takie pakiety mogą być elementem ataku.\n\nPodsumowując, filtracja bezstanowa jest prostsza w implementacji, ale mniej skuteczna niż filtracja stanowa, ponieważ nie uwzględnia kontekstu komunikacji. Oznacza to, że *każdy* pakiet musi zostać przeanalizowany, i nie można z góry założyć czy pakiet jest częścią prawidłowej komunikacji czy też jest częścią próby ataku."
    },
    {
        "questionId": 218,
        "title": "Koncepcja \"zamknietych grup uzytkownikow\" dotyczy odseparowania danych przetwarzanych przez odrebne grupy uzytkownikow tego samego srodowiska sieciowego. Ktore z ponizszych mechanizmow sa realizacja tej koncepcji:",
        "answers": [
            {
                "text": "uwiezienie (jail)",
                "isCorrect": false
            },
            {
                "text": "protokol rezerwacji zasobow (RSVP)",
                "isCorrect": false
            },
            {
                "text": "transmisja grupowa (multicast) w sieci Ethernet",
                "isCorrect": false
            },
            {
                "text": "sieci wirtualne VLAN",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Koncepcja \"zamkniętych grup użytkowników\" w kontekście bezpieczeństwa systemów komputerowych odnosi się do logicznego odseparowania ruchu sieciowego generowanego przez różne grupy użytkowników, nawet jeśli fizycznie korzystają oni z tej samej infrastruktury sieciowej. Kluczowym celem jest tutaj kontrola dostępu do danych i zasobów w zależności od przynależności użytkownika do określonej grupy.\n\n**Sieci wirtualne VLAN** (ang. _Virtual LAN_) są rozwiązaniem, które bezpośrednio realizuje tę koncepcję. VLAN-y pozwalają na logiczne podzielenie fizycznej sieci lokalnej (LAN) na mniejsze, odizolowane segmenty, z których każdy zachowuje się jak oddzielna sieć lokalna. W praktyce, urządzenia w jednym VLAN-ie mogą nie widzieć ruchu generowanego w innym VLAN-ie, chyba że specjalnie zezwala na to konfiguracja. To odseparowanie odbywa się na poziomie drugiej warstwy modelu OSI (warstwa łącza danych) a konkretnie z użyciem tagowanych ramek Ethernet. Każda ramka Ethernet w standardzie 802.1Q (który dodaje możliwość stosowania VLAN-ów) jest oznaczona identyfikatorem VLAN (ang. VLAN ID) który to identyfikator decyduje do którego wirtualnego segmentu sieci ma być dostarczona dana ramka.  Na przykład, firma może utworzyć oddzielne VLAN-y dla działu sprzedaży, działu IT i działu księgowości. Dzięki temu pracownicy działu sprzedaży nie będą mieli dostępu do danych z działu księgowości, nawet jeśli wszyscy korzystają z tej samej fizycznej sieci. Przełączniki sieciowe zarządzalne pełnią kluczową rolę w implementacji VLAN-ów. W nich konfigurowane są porty, które należą do odpowiednich VLAN-ów. VLAN-y stanowią fundamentalne narzędzie do budowania bezpiecznych i logicznie odseparowanych od siebie środowisk w sieciach LAN.\n\n**Uwięzienie (jail)**, choć jest formą izolacji, nie działa na poziomie sieciowym. Jest to mechanizm izolowania procesów w systemie operacyjnym. Umożliwia ograniczenie aplikacji do określonego katalogu i niedopuszczenie do odwoływania się do innych zasobów systemu plików. Na przykład serwer HTTP uruchomiony w \"jail\" nie ma dostępu do plików poza swoim katalogiem \"więzienia\". Jail jest rodzajem \"piaskownicy\" w systemie operacyjnym, ale nie segmentuje sieci. Aplikacja uruchomiona w takim środowisku nadal może się komunikować z innymi aplikacjami z poza \"piaskownicy\". \n\n**Protokół rezerwacji zasobów (RSVP)** (ang. _Resource Reservation Protocol_) jest protokołem sygnalizacyjnym, który ma za zadanie rezerwować pasmo w sieci dla określonego strumienia danych. RSVP nie kontroluje dostępu do danych, a jedynie zapewnia jakość usługi (QoS). Na przykład, można zarezerwować pasmo dla strumienia audio w celu zapewnienia jego ciągłości. Nie tworzy on żadnych logicznych grup użytkowników, a jedynie rezerwuje pasmo na żądanie aplikacji.\n\n**Transmisja grupowa (multicast) w sieci Ethernet** służy do jednoczesnego przesyłania danych do grupy odbiorców. Wykorzystuje mechanizm adresów grupowych warstwy łącza danych. Urządzenie wysyłające pakiet kieruje go na adres grupowy a tylko karty sieciowe urządzeń podłączone do sieci, które są zapisane do takiej grupy odbiorców będą odbierać tą transmisje. Multicast ułatwia rozsyłanie danych do wielu odbiorców, jednak nie rozdziela użytkowników pod względem bezpieczeństwa. Wszyscy członkowie tej samej grupy multicast mają dostęp do danych przesyłanych w ramach tej grupy. Na przykład, transmisja strumieniowa wideo może być realizowana za pomocą multicastu, jednak wszyscy odbiorcy będą mieli dostęp do strumienia, który w danej grupie jest dostępny. Multicast nie służy do podziału użytkowników pod względem bezpieczeństwa."
    },
    {
        "questionId": 219,
        "title": "Wskaz cechy protokolu Hot Standby Routing Protocol:",
        "answers": [
            {
                "text": "oferuje transparentne zasilanie z kilku redundantnych torow energetycznych",
                "isCorrect": false
            },
            {
                "text": "jest wykorzystywany w LAN Emulation",
                "isCorrect": false
            },
            {
                "text": "chroni przed atakami DoS poprzez czasowe wylaczenie routingu po wykryciu proby ataku",
                "isCorrect": false
            },
            {
                "text": "oferuje transparentna redundancje urzadzen sieciowych",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Hot Standby Routing Protocol (HSRP) to protokół firmy Cisco, który zapewnia redundancję routerów w sieci. Jest to protokół warstwy 3 modelu OSI i pozwala na utworzenie wirtualnego routera o wspólnym adresie IP. W sieci, w której działają dwa routery, tylko jeden z nich jest w danej chwili aktywny i obsługuje ruch sieciowy, zaś drugi czeka w trybie \"standby\" (_ang. hot standby_). Jeśli z jakiegoś powodu (np. awarii) aktywny router przestaje działać, to jego rolę przejmuje w trybie natychmiastowym router pozostający dotychczas w trybie \"standby\".  Z punktu widzenia końcowych komputerów podłączonych do sieci awaria routera jest niezauważalna, gdyż wirtualny adres IP, za który odpowiedzialny jest protokół HSRP, pozostaje cały czas dostępny. Umożliwia to osiągnięcie wysokiej dostępności usług sieciowych z minimalnym ryzykiem wystąpienia przestoju.\n\n*   **\"oferuje transparentne zasilanie z kilku redundantnych torow energetycznych\"** - Ta odpowiedź jest **niepoprawna**. HSRP nie ma nic wspólnego z zasilaniem. Redundantne tory energetyczne są rozwiązaniem stosowanym w centrach danych i serwerowniach w celu zapewnienia ciągłości zasilania w przypadku awarii jednej z linii zasilających. Jest to fizyczna ochrona przed awarią zasilania, a nie ochrona na poziomie sieci.\n\n*   **\"jest wykorzystywany w LAN Emulation\"** - Ta odpowiedź jest **niepoprawna**. LAN Emulation (LANE) jest techniką pozwalającą na tworzenie wirtualnych sieci LAN w oparciu o infrastrukturę ATM (Asynchronous Transfer Mode). HSRP nie jest wykorzystywany w LAN Emulation, gdyż realizuje on inną funkcjonalność.\n\n*   **\"chroni przed atakami DoS poprzez czasowe wylaczenie routingu po wykryciu proby ataku\"** - Ta odpowiedź jest **niepoprawna**. HSRP nie ma wbudowanych mechanizmów obrony przed atakami typu Denial of Service (DoS). HSRP jest zaprojektowany w celu zapewnienia ciągłości routingu w przypadku awarii routera, ale nie chroni przed atakami, które mają na celu przeciążenie lub unieruchomienie zasobów sieciowych. Choć w przypadku awarii routera na skutek ataku DoS protokół HSRP przejmie ruch, to sam w sobie nie jest mechanizmem przeciwdziałającym DoS.\n\n*   **\"oferuje transparentna redundancje urzadzen sieciowych\"** - Ta odpowiedź jest **poprawna**. HSRP jest protokołem, który w sposób przejrzysty dla końcowych urządzeń (np. komputerów) zapewnia redundancję routerów. W przypadku awarii aktywnego routera, zapasowy router natychmiast przejmuje jego funkcję i zapewnia ciągłość działania sieci. Wszelkie zmiany na poziomie sieci pozostają ukryte dla klientów, którzy nie widzą i nie odczuwają żadnych zmian.  Na przykład, jeśli firma posiada dwa routery połączone z internetem, które pracują w mechanizmie HSRP to awaria jednego routera nie spowoduje przerwy w dostępie do internetu ponieważ drugi router automatycznie przejmie jego funkcję."
    },
    {
        "questionId": 220,
        "title": "Wskaz kiedy system kontroli dostepu MAC moze zezwolic podmiotowi P na dopisanie danych do zasobu Z:",
        "answers": [
            {
                "text": "gdy zbior kategorii przynaleznosci danych Z zawiera sie w zbiorze kategorii P",
                "isCorrect": true
            },
            {
                "text": "gdy poziom zaufania P jest nizszy niz Z",
                "isCorrect": true
            },
            {
                "text": "gdy poziom zaufania P jest wyzszy niz Z",
                "isCorrect": false
            },
            {
                "text": "gdy poziom zaufania P jest wyzszy niz Z",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to system kontroli dostępu, w którym dostęp do zasobów nie jest ustalany przez właściciela zasobu, tylko przez sztywne reguły ustalone przez administratora bezpieczeństwa. W MAC kluczowe znaczenie mają poziomy zaufania(ang. _sensitivity levels_) i kategorie przynależności danych. Poziomy zaufania są hierarchiczne i reprezentują np. poziomy poufności danych(jawne, poufne, tajne, ściśle tajne). Kategorie przynależności nie są hierarchiczne, reprezentują rodzaj informacji (osobowe, finansowe, militarne, krypto). W systemie MAC każdemu podmiotowi (ang. _subject_) i każdemu zasobowi(ang. _object_) przypisana jest etykieta bezpieczeństwa(ang. _security label_), która składa się z poziomu zaufania i kategorii przynależności danych.\nW MAC istnieje zasada \"no write down\", która mówi, że podmiot może zapisywać informacje tylko do zasobów o poziomie zaufania równym lub wyższym niż poziom zaufania podmiotu.\nZatem:\n\n*   **\"gdy zbior kategorii przynaleznosci danych Z zawiera sie w zbiorze kategorii P\"** - **Poprawna.**  MAC operuje na etykietach bezpieczeństwa, które składają się z poziomu zaufania i kategorii. W tym przypadku, jeśli kategorie zasobu Z są podzbiorem kategorii podmiotu P, oznacza to, że podmiot jest uprawniony do dostępu do tych kategorii, gdyż \"zawiera\" w sobie wszystkie wymagane kategorie danego zasobu. Dodanie informacji do zasobu Z o takich kategoriach nie obniża poziomu bezpieczeństwa, gdyż podmiot P obejmuje wszystkie kategorie, do których ma prawo zapisu. Praktycznie, jest to sytuacja, gdy np. użytkownik posiadający dostęp do informacji o kategorii Finansowe i Osobiste chce dopisać coś do zasobu o kategorii Finansowe. To jest dozwolone w MAC.\n\n*   **\"gdy poziom zaufania P jest nizszy niz Z\"** - **Poprawna.**  W systemach MAC obowiązuje zasada \"no write down\", zatem poziom zaufania podmiotu P (który próbuje zapisać dane do zasobu Z) musi być mniejszy lub równy poziomowi zaufania zasobu Z. W omawianym przypadku poziom zaufania P jest niższy niż Z co oznacza że P nie ma prawa zapisać danych w Z z uwagi na obniżenie poziomu bezpieczeństwa systemu. W praktyce oznacza to, że zasób o etykiecie \"ściśle tajne\" nie może zostać zmieniony/dopisany przez podmiot o etykiecie \"poufne\".\n\n*   **\"gdy poziom zaufania P jest wyzszy niz Z\"** - **Niepoprawna.** Zasadą MAC jest “no write down”, która mówi, że podmiot nie może zapisywać danych o niższej etykiecie niż ma sam. Zapisanie danych przez podmiot P o wyższym poziomie zaufania do zasobu Z o niższym poziomie zaufania, skutkowałoby obniżeniem bezpieczeństwa systemu (wyciek informacji). W praktyce oznacza to, że zasób o etykiecie \"poufne\" nie może zostać zmieniony/dopisany przez podmiot o etykiecie \"ściśle tajne\".\n\n*   **\"gdy poziom zaufania P jest wyzszy niz Z\"** - **Niepoprawna.** Jest to powtórzenie poprzedniej odpowiedzi i jak wyżej, system MAC nie pozwoli podmiotowi P zapisać danych o niższej etykiecie niż ma sam."
    },
    {
        "questionId": 221,
        "title": "Wskaz kiedy system kontroli dostepu MAC nie zezwoli podmiotowi P na dopisanie danych do zasobu Z:",
        "answers": [
            {
                "text": "gdy zbiory kategorii przynaleznosci danych P i Z sa rozlaczne",
                "isCorrect": true
            },
            {
                "text": "gdy zbior kategorii przynaleznosci danych Z zawiera sie w zbiorze kategorii P",
                "isCorrect": false
            },
            {
                "text": "gdy poziom zaufania Z jest nizszy niz P",
                "isCorrect": true
            },
            {
                "text": "gdy poziom zaufania Z jest wyzszy niz P",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to mechanizm kontroli dostępu, w którym system operacyjny narzuca reguły dostępu, a nie właściciel zasobu. W MAC dostęp do zasobu zależy od dwóch parametrów etykiety bezpieczeństwa: poziomu zaufania (np. jawne, poufne, tajne) i kategorii przynależności danych (np. finansowe, osobowe, militarne). Reguły MAC określają, kiedy podmiot (np. użytkownik, proces) może odczytywać lub zapisywać dane zasobu. W szczególności w odniesieniu do zapisu danych w systemie MAC:\n\n**Odpowiedź 1: \"gdy zbiory kategorii przynależności danych P i Z są rozłączne\" - JEST POPRAWNA.**  W MAC każda informacja ma poziom zaufania i kategorie przynależności. Etykieta ochrony danych (ang. *sensitivity label*) łączy te dwie informacje, tworząc np. parę (tajne, {militarne, kryptograficzne}). W przypadku, gdy zbiory kategorii danych podmiotu `P` oraz zasobu `Z` nie mają wspólnych kategorii (są rozłączne),  system MAC nie zezwoli na zapis. Na przykład, podmiot z etykietą (poufne, {osobowe}) nie będzie mógł zmodyfikować zasobu o etykiecie (tajne, {militarne}), ponieważ zbiory kategorii {osobowe} i {militarne} są rozłączne, chociaż poziom zaufania podmiotu jest mniejszy od poziomu zaufania zasobu.\n\n**Odpowiedź 2: \"gdy zbior kategorii przynależności danych Z zawiera się w zbiorze kategorii P\" - JEST NIEPOPRAWNA.** W MAC zapis jest zabroniony, gdy zbiory kategorii nie są rozłączne, natomiast fakt, że zbiór kategorii zasobu Z zawiera się w zbiorze kategorii podmiotu P, nie oznacza, że zapis będzie zabroniony. Na przykład, podmiot z etykietą (tajne, {militarne, kryptograficzne}) może zapisywać dane do zasobu o etykiecie (poufne, {militarne}), gdyż w systemie MAC zapis jest zabroniony, gdy podmiot zapisuje dane o niższej etykiecie, czyli zapis (poufne, {militarne}) do (tajne, {militarne, kryptograficzne}) byłby zabroniony, ale nie na odwrót.\n\n**Odpowiedź 3: \"gdy poziom zaufania Z jest niższy niż P\" - JEST POPRAWNA.**  W systemie MAC obowiązuje zasada „nie zapisuj w dół\" (ang. *no write-down*).  Oznacza to, że podmiot nie może zapisywać danych do zasobu, który ma niższy poziom zaufania niż podmiot. Przykładowo, proces z poziomem zaufania 'tajne' nie może modyfikować zasobu z poziomem zaufania 'poufne'. Ma to zapobiec sytuacjom wycieku informacji z wyższych poziomów zaufania na niższe. Na przykład podmiot z etykietą (tajne, {militarne}) nie może zmodyfikować zasobu o etykiecie (poufne, {militarne}).\n\n**Odpowiedź 4: \"gdy poziom zaufania Z jest wyższy niż P\" - JEST NIEPOPRAWNA.** MAC zezwala na zapis do zasobu o wyższym poziomie zaufania. Podmiot nie może zapisywać danych do zasobu o niższej etykiecie niż ma sam podmiot. Zatem podmiot o poziomie zaufania ‘poufne’ może modyfikować zasób o poziomie ‘tajne’. Ta sytuacja nie spowoduje złamania zasady ‘no write down’. Na przykład podmiot z etykietą (poufne, {militarne}) może zmodyfikować zasób o etykiecie (tajne, {militarne})."
    },
    {
        "questionId": 222,
        "title": "Mechanizm SSO (single-sign-on):",
        "answers": [
            {
                "text": "sluzy ochronie danych uwierzytelniajacych uzytkownika",
                "isCorrect": true
            },
            {
                "text": "pozwala jednolicie chronic podpisem cyfrowym poufnosc calej komunikacji",
                "isCorrect": false
            },
            {
                "text": "sluzy ochronie niezaprzeczalnosci danych skladowanych w repozytorium",
                "isCorrect": false
            },
            {
                "text": "pozwala jednolicie chronic podpisem cyfrowym integralnosc calej komunikacji",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Single Sign-On (SSO) to mechanizm, który ma na celu ochronę danych uwierzytelniających użytkownika, takich jak hasła. SSO nie zapewnia bezpośrednio ochrony danych w trakcie transmisji, integralności danych, czy ich niezaprzeczalności. Główną ideą SSO jest umożliwienie użytkownikowi jednokrotnego uwierzytelnienia się w systemie, a następnie uzyskania dostępu do wielu różnych aplikacji lub usług bez konieczności ponownego wprowadzania danych uwierzytelniających. SSO koncentruje się na tym, aby proces logowania był wygodny, ale jednocześnie bezpieczny. \n\n**Odpowiedź \"służy ochronie danych uwierzytelniających użytkownika\" jest prawidłowa.** SSO minimalizuje liczbę miejsc, w których hasła muszą być przechowywane, przesyłane i weryfikowane. Przykładowo, w środowisku korporacyjnym użytkownik loguje się raz do systemu operacyjnego a następnie automatycznie uzyskuje dostęp do firmowej poczty, systemów CRM czy baz danych, bez podawania po raz kolejny hasła dostępu. SSO eliminuje potrzebę zarządzania wieloma hasłami przez każdego użytkownika, przez co minimalizuje się ryzyko złamania czy kradzieży hasła poprzez ich uproszczenie lub zapisywanie w miejscach łatwo dostępnych, na przykład na karteczkach. \n\n**Odpowiedź \"pozwala jednolicie chronić podpisem cyfrowym poufność całej komunikacji\" jest nieprawidłowa.**  Podpis cyfrowy (ang. _digital signature_) służy do weryfikacji autentyczności i integralności dokumentu lub wiadomości, ale nie do szyfrowania samej treści.  Podpis cyfrowy wykorzystuje kryptografię asymetryczną – klucz prywatny (znany tylko nadawcy) służy do podpisania danych, a klucz publiczny (znany każdemu) służy do weryfikacji podpisu. SSO natomiast dotyczy procesu uwierzytelniania a nie ochrony treści komunikacji. Do ochrony poufności przesyłanych danych wykorzystywane są mechanizmy szyfrowania, które mogą ale nie muszą być włączone do działania systemu SSO.  \n\n**Odpowiedź \"służy ochronie niezaprzeczalności danych składowanych w repozytorium\" jest nieprawidłowa.** Niezaprzeczalność (ang. _non-repudiation_) to pewność, że żadna ze stron komunikacji nie będzie mogła wyprzeć się wykonania danej operacji, np. wysłania wiadomości. Chociaż system SSO może być elementem systemu uwzględniającego aspekty niezaprzeczalności to jednak sam system SSO nie jest przeznaczony do tego aby bezpośrednio chronić niezaprzeczalność. Przykładowo wiadomość o zawarciu kontraktu w systemie komputerowym podpisana podpisem cyfrowym jest niezaprzeczalna i ma moc prawną a SSO pozwala po prostu na dostęp do takiego dokumentu z wykorzystaniem procedury jednokrotnego uwierzytelniania. \n\n**Odpowiedź \"pozwala jednolicie chronić podpisem cyfrowym integralność całej komunikacji\" jest nieprawidłowa.** Podobnie jak w odpowiedzi dotyczącej ochrony poufności danych podpis cyfrowy służy do ochrony integralności ale nie jest to podstawowa funkcja systemu SSO. Podpis cyfrowy, jak sama nazwa wskazuje, chroni integralność podpisywanych danych, a nie całej komunikacji. System SSO skupia się na uwierzytelnieniu użytkowników i umożliwieniu im dostępu do wielu zasobów z wykorzystaniem pojedynczego procesu logowania, a nie na ochronie integralności wszystkich danych przesyłanych w sieci."
    },
    {
        "questionId": 223,
        "title": "Statyczne reguly filtracji (filtracja bezstanowa) nie radza sobie z precyzyjna filtracja ruchu:",
        "answers": [
            {
                "text": "HTTP, gdy serwer pracuje w trybie bezstanowym",
                "isCorrect": false
            },
            {
                "text": "HTTP, gdy serwer pracuje w trybie stanowym",
                "isCorrect": false
            },
            {
                "text": "FTP, gdy serwer pracuje w trybie aktywnym",
                "isCorrect": true
            },
            {
                "text": "FTP, gdy serwer pracuje w trybie pasywnym",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Statyczne reguły filtracji, znane również jako filtracja bezstanowa, analizują każdy pakiet danych niezależnie, bez uwzględniania kontekstu wcześniejszych pakietów w danym połączeniu. Oznacza to, że decyzja o przepuszczeniu lub odrzuceniu pakietu jest podejmowana wyłącznie na podstawie informacji zawartych w jego nagłówku (np. adres IP źródła i przeznaczenia, numer portu protokołu TCP/UDP). Ten sposób filtracji sprawdza się dobrze w przypadku protokołów, w których numery portów są z góry określone i nie zmieniają się w trakcie trwania sesji, ale stwarza problemy z protokołami dynamicznymi, które negocjują porty w trakcie komunikacji.\n\n* **\"HTTP, gdy serwer pracuje w trybie bezstanowym\"** - Odpowiedź niepoprawna. HTTP jest protokołem bezstanowym (_stateless_). Oznacza to, że każda wymiana danych, każde żądanie i odpowiedź, są traktowane jako osobne, niezależne zdarzenia. Komunikacja HTTP odbywa się najczęściej na porcie 80. Statyczna reguła filtrująca, blokująca lub przepuszczająca ruch na port 80 w protokole TCP, będzie skutecznie filtrować ruch HTTP, niezależnie od tego, czy serwer HTTP jest bezstanowy.\n\n* **\"HTTP, gdy serwer pracuje w trybie stanowym\"** - Odpowiedź niepoprawna. Mimo, że serwer HTTP w trybie stanowym, może zapamiętywać niektóre informacje (np. sesję użytkownika, ciasteczka, poprzednie żądania), to połączenie odbywa się cały czas na tym samym porcie (80) co czyni połączenie dalej kontrolowalne przez zaporę filtrującą tylko statycznie. Stanowy serwer HTTP nie negocjuje żadnych dodatkowych portów i nadal jest przewidywalny dla zapory sieciowej opartej o statyczne reguły. \n\n* **\"FTP, gdy serwer pracuje w trybie aktywnym\"** - Odpowiedź poprawna. Protokół FTP (_File Transfer Protocol_) w trybie aktywnym działa tak, że klient nawiązuje połączenie sterujące z serwerem na porcie 21 (ustalony port), jednak do transferu danych wykorzystywane jest nowe połączenie na porcie wybranym przez klienta. Adres IP serwera oraz port na którym ma działać połączenie dla danych przesyłane są przez klienta do serwera za pomocą połączenia kontrolnego (port 21) jako komunikat PORT. Statyczna reguła filtrująca może przepuszczać pakiety na port 21, lecz zablokuje próbę ustanowienia połączenia na port wyznaczony przez klienta (port z zakresu 1024-65535). Potrzebny byłby dodatkowy mechanizm, dynamicznie modyfikujący reguły filtracji, tak aby dostosować je do zmieniających się w czasie sesji parametrów połączenia. Takiego mechanizmu niestety nie posiadają statyczne reguły. To uniemożliwia pełną kontrolę nad sesją FTP w trybie aktywnym. Wyjątkiem jest sytuacja, gdy numer portu przesyłany w komendzie PORT odpowiada numerowi portu w konfiguracji firewalla, takie rozwiązanie jest niebezpieczne, gdyż umożliwia podanie dowolnego portu w komendzie PORT oraz w przypadku zmiany portu na serwerze firewall przestanie działać. \n\n* **\"FTP, gdy serwer pracuje w trybie pasywnym\"** - Odpowiedź niepoprawna. W trybie pasywnym serwer FTP udostępnia port, na którym klient ma nawiązać połączenie, i komunikuje go klientowi poprzez port 21, wykorzystując komendę PASV. Klient inicjuje połączenie na zadeklarowanym przez serwer porcie danych. Takie zachowanie umożliwia zdefiniowanie statycznej reguły na zaporze przepuszczającej pakiet na określony z góry zakres portów. Mimo, że mechanizm negocjacji portu istnieje jest on bardziej przewidywalny, gdyż serwer mówi klientowi jaki port powinien wybrać dla danych i statyczna reguła może obsłużyć ten scenariusz.\n\n**Podsumowując:** Statyczne reguły filtracji, stosowane w zaporach bezstanowych, nie są w stanie poradzić sobie z dynamicznymi negocjacjami portów. Klasycznym przykładem tego problemu jest protokół FTP w trybie aktywnym, który wykorzystuje dwa kanały: jeden do przesyłania komend (port 21) a drugi do przesyłania danych, które mogą być realizowane na dynamicznie wybieranych portach. Protokół HTTP z uwagi na swoja bezstanowość oraz przewidywalność w przydzielaniu portu dla połączenia nie jest podatny na to samo zagrożenie."
    },
    {
        "questionId": 224,
        "title": "Standard IEEE 802.1x:",
        "answers": [
            {
                "text": "realizuje autoryzacje i kontrole dostepu do lokalnej infrastruktury sieciowej",
                "isCorrect": true
            },
            {
                "text": "wspolpracuje z protokolami takimi jak RADIUS lub TACACS+",
                "isCorrect": true
            },
            {
                "text": "dotyczy zabezpieczenia poufnosci",
                "isCorrect": false
            },
            {
                "text": "dotyczy uprawnien dostepu do zasobow plikowych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "IEEE 802.1x to standard definiujący mechanizm kontroli dostępu do sieci, działający na poziomie portu (port-based network access control). Standard ten ma na celu zapewnienie, że tylko autoryzowane urządzenia i użytkownicy mogą uzyskać dostęp do sieci. Działa on poprzez wymaganie uwierzytelnienia przed przyznaniem dostępu do sieci. Uwierzytelnianie to zazwyczaj odbywa się za pośrednictwem zewnętrznego serwera.\n\n**Odpowiedź 1: \"realizuje autoryzacje i kontrole dostepu do lokalnej infrastruktury sieciowej\"**\nJest to poprawna odpowiedź, ponieważ IEEE 802.1x jest standardem, który w istocie służy do kontrolowania dostępu do sieci. Realizuje autoryzację (weryfikację, czy dany użytkownik ma prawo korzystać z sieci) oraz kontrolę dostępu (ogranicza dostęp do zasobów sieciowych tylko dla autoryzowanych użytkowników i urządzeń). Na przykład w sieci firmowej, 802.1x może być używany aby uniemożliwić podłączenie nieznanego laptopa lub telefonu do sieci. Dopiero po pomyślnym uwierzytelnieniu użytkownik uzyska dostęp do sieci. \n\n**Odpowiedź 2: \"wspolpracuje z protokolami takimi jak RADIUS lub TACACS+\"**\nTa odpowiedź jest również poprawna. IEEE 802.1x samodzielnie nie realizuje procesu uwierzytelniania. Standard ten korzysta z zewnętrznego serwera uwierzytelniania, a najczęściej wykorzystywanymi protokołami są RADIUS (Remote Authentication Dial-In User Service) oraz TACACS+ (Terminal Access Controller Access-Control System Plus). Protokół RADIUS służy do uwierzytelniania i autoryzacji, a TACACS+ zapewnia te same funkcje wraz z opcją audytu. W praktyce, gdy użytkownik próbuje uzyskać dostęp do sieci poprzez urządzenie wspierające 802.1x (np. przełącznik sieciowy), ten standard przesyła dane uwierzytelniające do serwera RADIUS lub TACACS+, który decyduje o udzieleniu lub odmowie dostępu do sieci.\n\n**Odpowiedź 3: \"dotyczy zabezpieczenia poufnosci\"**\nTa odpowiedź jest błędna. IEEE 802.1x koncentruje się na kontroli dostępu do sieci, a nie na zapewnieniu poufności danych. Chociaż sama procedura uwierzytelniania może korzystać z szyfrowania (np. hasła przesyłane do serwera), sam standard 802.1x nie szyfruje ruchu sieciowego po autoryzacji. Po uzyskaniu dostępu do sieci komunikacja między klientem a serwerem odbywa się zazwyczaj bez szyfrowania, chyba że zastosowany jest dodatkowy protokół np. IPSec, który zapewnia poufność przesyłanych danych.\n\n**Odpowiedź 4: \"dotyczy uprawnien dostepu do zasobow plikowych\"**\nTa odpowiedź jest niepoprawna, ponieważ standard IEEE 802.1x nie jest związany z uprawnieniami dostępu do zasobów plikowych, czyli plikami i katalogami. Standard ten dotyczy kontroli dostępu do samej sieci, a nie do zasobów systemu plików na serwerach czy stacjach roboczych. Kontrola dostępu do zasobów plikowych realizowana jest przez mechanizmy systemu operacyjnego na poziomie lokalnym danego komputera np. poprzez ustawienie uprawnień w ACL(_ang. Access Control List_)."
    },
    {
        "questionId": 225,
        "title": "Algorytm 3DES w trybie EDE wykorzystuje klucze o dlugosci:",
        "answers": [
            {
                "text": "256b",
                "isCorrect": false
            },
            {
                "text": "116b",
                "isCorrect": false
            },
            {
                "text": "64b",
                "isCorrect": true
            },
            {
                "text": "192b",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Algorytm 3DES (Triple DES) jest symetrycznym algorytmem szyfrowania blokowego, który powstał jako wzmocnienie algorytmu DES. DES operuje na 64-bitowych blokach danych używając klucza o długości 56 bitów (64 bity z czego 8 bitów kontroli parzystości). W 3DES, blok danych jest poddawany trzem kolejnym operacjom DES. Istnieją trzy podstawowe tryby pracy 3DES: EEE, EDE2 i EDE3. W trybie EEE (Encrypt-Encrypt-Encrypt), blok danych jest szyfrowany trzykrotnie za pomocą trzech różnych kluczy. W trybie EDE (Encrypt-Decrypt-Encrypt), blok danych jest szyfrowany kluczem K1, następnie deszyfrowany kluczem K2, a następnie znowu szyfrowany kluczem K3. W wariancie EDE2, klucze K1 i K3 są identyczne a w wariancie EDE3 wszystkie 3 klucze są różne. \nZ punktu widzenia długości klucza, 3DES EDE wykorzystuje trzy 56-bitowe klucze w przypadku EDE3 lub dwa 56-bitowe klucze w przypadku EDE2, jednak jego efektywna długość klucza jest równa 112-bitom (w przypadku EDE2) lub 168 bitom w przypadku EDE3. W praktyce najczęściej spotykanym trybem jest EDE2, z tego powodu często mówi się, że 3DES ma klucz 112-bitowy, jednak w przypadku 3DES EDE, każdy klucz użyty do szyfrowania pojedynczej operacji DES, ma długość 56 bitów, ale sama operacja szyfrowania jest trzykrotna, z tego powodu 3DES jest bardziej bezpiecznym algorytmem niż DES. \n\n*   **256b:** To jest niepoprawna odpowiedź. Algorytm 3DES nie używa kluczy o długości 256 bitów w trybie EDE.  Algorytm AES (Advanced Encryption Standard) może używać kluczy tej długości. Zastosowanie w praktyce algorytmu 3DES EDE z kluczem o długości 256 bitów spowodowałoby utratę kompatybilności z istniejącymi rozwiązaniami.\n\n*   **116b:** To jest niepoprawna odpowiedź.  Żaden z powszechnie używanych trybów 3DES nie używa kluczy o tej długości. Efektywna długość klucza 3DES EDE2 to 112b. Wartość 116b jest wartością całkowicie błędną. \n\n*   **64b:**  To jest *poprawna* odpowiedź. DES jest algorytmem, który operuje na 64-bitowych blokach danych, ale klucz ma efektywnie 56 bitów, gdyż pozostałe 8 bitów to bity parzystości. Każdy pojedynczy klucz w 3DES, w tym w trybie EDE, ma długość 64b z czego 56b to klucz faktyczny.\n\n*   **192b:** To jest niepoprawna odpowiedź. Algorytm 3DES w trybie EDE3 (z trzema różnymi kluczami) ma efektywną długość klucza 168 bitów (3 * 56) jednak żaden pojedynczy klucz nie ma 192 bitów.  Algorytm AES (Advanced Encryption Standard) może używać kluczy tej długości. \n\nPraktyczne zastosowanie 3DES EDE można zaobserwować na przykład w systemach płatniczych np. bankomatach. Użycie długości klucza 64b (długość używana przez DES) byłoby zbyt słabe do ochrony transakcji bankowych i poufnych danych."
    },
    {
        "questionId": 226,
        "title": "Wskaz cechy charakteryzujace kontrole dostepu MAC:",
        "answers": [
            {
                "text": "wlasciciel zasobu nie moze przekazac mozliwosc decydowania o uprawnieniach dostepu do tego zasobu",
                "isCorrect": true
            },
            {
                "text": "właściciel zasobu może przekazać możliwość decydowania o uprawnieniach dostępu do tego zasobu",
                "isCorrect": false
            },
            {
                "text": "wlasciciel zasobu nie moze decydowac o uprawnieniach dostepu do tego zasobu",
                "isCorrect": true
            },
            {
                "text": "wlasciciel zasobu moze decydowac o uprawnieniach dostepu do tego zasobu",
                "isCorrect": false
            },
            {
                "text": "tylko wlasciciel zasobu moze dysponowac prawami dostepu do tego zasobu",
                "isCorrect": true
            },
            {
                "text": "tylko wyrozniony oficer bezpieczenstwa moze dysponowac prawami dostepu do zasobow",
                "isCorrect": true
            },
            {
                "text": "etykiety ochrony danych przypisane do zasobow automatycznie wymuszaja uprawnienia",
                "isCorrect": true
            }
        ],
        "clue": 5,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to model kontroli dostępu, w którym dostęp do zasobów systemu komputerowego jest kontrolowany na podstawie centralnie definiowanej polityki bezpieczeństwa, a nie na podstawie uznania właściciela zasobu jak w przypadku Discretionary Access Control (DAC). MAC charakteryzuje się przede wszystkim ścisłym przestrzeganiem reguł dostępu, które są w nim zdefiniowane. Kluczowym elementem MAC są etykiety ochrony danych(_ang. sensitivity labels_), które są przypisywane zarówno do obiektów(zasobów), jak i podmiotów (użytkowników, procesów). Te etykiety określają poziom poufności informacji i uprawnienia użytkownika. System operacyjny MAC wymusza reguły dostępu w oparciu o te etykiety, ograniczając swobodę użytkowników i właścicieli zasobów.\n\n**\"wlasciciel zasobu nie moze przekazac mozliwosc decydowania o uprawnieniach dostepu do tego zasobu\"** - **Poprawna.** W systemach MAC, właściciel zasobu nie ma prawa przekazać innym użytkownikom kontroli nad tym zasobem. To system, a konkretnie polityka bezpieczeństwa zdefiniowana centralnie, reguluje dostęp na podstawie etykiet, a nie uznanie właściciela zasobu. Przykładowo, właściciel pliku z etykietą \"tajne\" nie może udzielić dostępu do niego osobie bez odpowiedniej etykiety.\n\n**\"właściciel zasobu może przekazać możliwość decydowania o uprawnieniach dostępu do tego zasobu\"** - **Niepoprawna.** To stwierdzenie opisuje model DAC, a nie MAC. W DAC, właściciel zasobu ma prawo swobodnie decydować o prawach dostępu innych użytkowników.\n\n**\"wlasciciel zasobu nie moze decydowac o uprawnieniach dostepu do tego zasobu\"** - **Poprawna.** W MAC właściciel zasobu nie ma bezpośredniego wpływu na to kto i w jaki sposób może korzystać z danego zasobu. O uprawnieniach dostępu decyduje system na podstawie zdefiniowanych zasad bezpieczeństwa oraz na podstawie etykiet poufności zasobu i uprawnień użytkownika. Przykładowo, właściciel dokumentu z klauzulą tajności nie ma uprawnień aby umożliwić dostęp do tego dokumentu osobie, która nie przeszła stosownej procedury weryfikacji uprawnień.\n\n**\"wlasciciel zasobu moze decydowac o uprawnieniach dostepu do tego zasobu\"** - **Niepoprawna.** W MAC, dostęp nie jest oparty o decyzję właściciela zasobu, lecz o politykę bezpieczeństwa zdefiniowaną w systemie.\n\n**\"tylko wlasciciel zasobu moze dysponowac prawami dostepu do tego zasobu\"** - **Poprawna.** W MAC, właściciel zasobu również nie ma prawa samodzielnie decydować o prawach dostępu do zasobu, zależy to wyłącznie od ustawionej polityki bezpieczeństwa i tego czy zasób posiada odpowiednią etykietę poufności, która pasuje do użytkownika, który chce uzyskać do niego dostęp. W tym kontekście termin „dysponować prawami dostępu” znaczy, że właściciel zasobu, jako podmiot, który może mieć dostęp do zasobu, musi być uprawniony przez system, a nie samodzielnie decydować o tym dostępie.\n\n**\"tylko wyrozniony oficer bezpieczenstwa moze dysponowac prawami dostepu do zasobow\"** - **Poprawna.** To stwierdzenie, choć nie jest uniwersalną zasadą, często jest spotykane w systemach MAC w praktyce. Oznacza, że polityka bezpieczeństwa, a tym samym możliwość decydowania o uprawnieniach w systemie MAC, jest zazwyczaj przypisana do wyspecjalizowanego oficera bezpieczeństwa (lub ich grupy) i w ten sposób system MAC ma narzucać stosowanie tych reguł. W systemach MAC to polityka bezpieczeństwa decyduje kto ma prawa dostępu do zasobu. Użytkownik musi spełnić pewne warunki aby uzyskać te prawa. Jednym z tych warunków jest posiadanie etykiety poufności uprawniającej go do dostępu do danego zasobu.\n\n**\"etykiety ochrony danych przypisane do zasobow automatycznie wymuszaja uprawnienia\"** - **Poprawna.** Etykiety ochrony danych (_ang. sensitivity labels_), przypisane do zasobów w systemie MAC, automatycznie wymuszają uprawnienia zgodnie z polityką bezpieczeństwa. System MAC sam podejmuje decyzję o dostępie do zasobów w oparciu o etykiety poufności, nawet właściciel zasobu nie jest w stanie ominąć tego mechanizmu. Przykładowo, jeśli dokument ma etykietę \"ściśle tajne\", to użytkownik z etykietą \"poufne\" nie będzie mógł go odczytać, niezależnie od tego czy jest jego właścicielem czy nie."
    },
    {
        "questionId": 227,
        "title": "Ktory z wymienionych protokolow nie chroni przed podszywaniem sie pod podmiot uwierzytelniajacy:",
        "answers": [
            {
                "text": "SSL v3",
                "isCorrect": false
            },
            {
                "text": "SSL v2",
                "isCorrect": false
            },
            {
                "text": "TLS v1",
                "isCorrect": false
            },
            {
                "text": "PAP",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół PAP (Password Authentication Protocol) jest protokołem uwierzytelniania, który przesyła hasła w postaci jawnej, co czyni go bardzo podatnym na podsłuchiwanie. W tym scenariuszu, osoba podsłuchująca mogłaby przechwycić dane uwierzytelniające (nazwę użytkownika i hasło) i wykorzystać je do podszycia się pod tego użytkownika bez wiedzy oryginalnej strony połączenia. Oznacza to, że atakujący, zdobywając hasło z przechwyconej komunikacji, może skutecznie udawać zaufany podmiot uwierzytelniający i połączyć się z chronionym serwerem.\n\nSSL v2, SSL v3 oraz TLS v1 to protokoły, które wykorzystują mechanizmy kryptograficzne do uwierzytelniania oraz szyfrowania, przez co są odporne na opisane wyżej ataki polegające na przechwyceniu hasła. Protokół SSL v2 posiada znane luki w działaniu, które mogą być użyte do przeprowadzania ataku polegającego na podszyciu się pod serwer uwierzytelniający, mimo wszystko sam protokół posiada mechanizmy obrony przed przechwyceniem hasła.\n\n**SSL v2 (Secure Sockets Layer version 2)**, jest starszą wersją protokołu SSL, która jest podatna na atak _man-in-the-middle_ (człowiek pośrodku) - atakujący może przechwycić połączenie oraz wysłać swój publiczny klucz do klienta oraz serwera. W efekcie klient będzie myślał że rozmawia z serwerem a serwer z klientem. Atakujący jest niewidoczny dla stron połączenia. Protokół ten, mimo że był stosowany w przeszłości, jest obecnie uważany za niebezpieczny i nie powinien być używany. Przez samo szyfrowanie jest on w pewnym stopniu odporny na ataki typu podsłuchiwania. \n\n**SSL v3 (Secure Sockets Layer version 3)**, jest nowszą wersją protokołu SSL, która została zaprojektowana w celu poprawienia bezpieczeństwa i wydajności względem SSL v2. SSL v3 używa mechanizmów kryptograficznych - w szczególności certyfikatów X.509 - do uwierzytelniania stron (serwera) oraz do uzgodnienia klucza szyfrowania komunikacji. W odróżnieniu od SSL v2, protokół ten jest odporny na wyżej wymienione ataki, jest też bardziej elastyczny w wyborze algorytmów kryptograficznych.  Jednak nawet ten protokół nie jest odporny na wszystkie ataki. Nadal możliwe jest przeprowadzenie ataku, który powoduje fałszywe akceptowanie certyfikatu jeśli klient nie zadba o poprawne ustawienia certyfikatów zaufanych CA. Atak ten polega na podsunięciu przez atakującego fałszywego certyfikatu, który zostanie zaakceptowany przez aplikacje po stronie klienta. Mimo tego protokół SSL v3 jest bezpieczniejszy od protokołu PAP.\n\n**TLS v1 (Transport Layer Security version 1)**, jest to następca protokołu SSL, jego zadaniem było poprawienie bezpieczeństwa i wydajności. Protokół TLS v1 jest kompatybilny z protokołem SSL v3, jednakże jest również odporny na ataki znane w protokole SSL v2 oraz wprowadza wiele nowych poprawek. W efekcie jego stosowanie jest bardzo zalecane. Tak jak SSL v3 do ochrony przed podszywaniem się stosuje certyfikaty cyfrowe do weryfikowania stron połączenia. \n\nW przeciwieństwie do protokołu PAP, protokoły SSL v3 i TLS v1, w domyślnej i prawidłowej konfiguracji, wymagają weryfikacji tożsamości serwera, co uniemożliwia atakującemu podszycie się pod niego. Użycie certyfikatów cyfrowych podpisanych przez zaufane centrum certyfikacji(CA) podczas protokołu uzgadniania sesji SSL/TLS umożliwia sprawdzenie tożsamości serwera. Bez poprawnej konfiguracji certyfikatów po stronie klienta może dojść do sytuacji w której fałszywy certyfikat zostanie uznany jako poprawny i wywoła podobne zagrożenia jak te w protokole PAP, czyli podszycie pod serwer. Uwierzytelnienie z wykorzystaniem certyfikatów cyfrowych to zabezpieczenie zarówno przed podsłuchiwaniem jak i przed podszywaniem się pod zaufany podmiot.\n\n**Praktyczny przykład:** W przypadku gdy usługa logowania do serwera odbywa się za pomocą protokołu PAP, potencjalny napastnik może podsłuchiwać transmisję. Wykorzystując program typu Wireshark (lub inny sniffer pakietów), atakujący może przechwycić przesyłane hasło, a następnie zalogować się do serwera podszywając się pod użytkownika. Natomiast w przypadku usług korzystających z SSL/TLS, napastnik potrzebowałby również odpowiedniego klucza prywatnego serwera aby się podszyć. Oznacza to, że ataki z wykorzystaniem SSL/TLS są znacznie trudniejsze i w prawidłowej konfiguracji praktycznie niemożliwe do wykonania.\n\n**Podsumowując**, PAP jest niebezpiecznym protokołem z uwagi na jawne przesyłanie hasła. Protokoły SSL/TLS mimo że używają mechanizmów kryptografii i są bezpieczniejsze od PAP to i w nich można znaleźć pewne niebezpieczne luki. Domyślne ustawienia protokołów SSL/TLS oferują duży stopień bezpieczeństwa, jednak nie gwarantują całkowitej ochrony przed atakami i należy mieć na uwadze ewentualne luki bezpieczeństwa, które potencjalnie mogą zostać użyte przez napastnika."
    },
    {
        "questionId": 228,
        "title": "Ktory z wymienionych protokolow nie chroni przed podszywaniem sie pod podmiot uwierzytelniajacy:",
        "answers": [
            {
                "text": "IPsec/IKE",
                "isCorrect": false
            },
            {
                "text": "IPsec/ISAKMP",
                "isCorrect": false
            },
            {
                "text": "PAP",
                "isCorrect": true
            },
            {
                "text": "SSL",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół uwierzytelniania to zestaw reguł i kroków, które pozwalają na zweryfikowanie tożsamości podmiotu próbującego uzyskać dostęp do systemu, zasobu lub usługi. Podszywanie się pod podmiot uwierzytelniający, często nazywane spoofingiem, to atak, w którym nieuprawniony podmiot próbuje udawać, że jest uprawnionym, aby oszukać system i uzyskać nieautoryzowany dostęp. Celem takiego ataku jest oszukanie systemu, aby ten uwierzył że atakujący jest kimś innym. \nProtokół IPsec jest protokołem warstwy sieciowej, który oferuje szyfrowanie, uwierzytelnianie i integralność danych przesyłanych przez sieć. IPsec może działać w dwóch trybach: transportowym i tunelowym. Tryb transportowy szyfruje jedynie dane użytkowe pakietu, podczas gdy tryb tunelowy szyfruje cały pakiet IP. Protokół IKE (Internet Key Exchange) lub ISAKMP (Internet Security Association and Key Management Protocol) służą do bezpiecznego uzgodnienia kluczy kryptograficznych, niezbędnych do szyfrowania i uwierzytelniania sesji IPsec. W trakcie negocjacji IKE/ISAKMP strony wzajemnie uwierzytelniają swoją tożsamość, zazwyczaj wykorzystując certyfikaty cyfrowe. Stosowanie certyfikatów cyfrowych oraz kryptografii asymetrycznej i symetrycznej pozwala na ochronę przed podszywaniem się pod podmiot uwierzytelniający. Dzięki zastosowaniu kryptografii w protokole IKE/ISAKMP, oraz asocjacji bezpieczeństwa w IPsec, strony upewniają się o tożsamości drugiej strony połączenia i ochraniają komunikację przed podsłuchiwaniem i manipulacją. Przechwycenie pakietu IKE/ISAKMP nie pozwoli podszywającemu na utworzenie nowego połączenia. Podszywający nie będzie posiadał certyfikatów lub kluczy do utworzenia takiego połączenia, a dodatkowo nie jest w stanie podsłuchać komunikacji, aby wykorzystać przechwycone informacje do utworzenia takiego połączenia. \nProtokół PAP (Password Authentication Protocol) to prosty protokół uwierzytelniania, najczęściej wykorzystywany w protokole PPP (Point-to-Point Protocol). Protokół PAP przesyła nazwę użytkownika i hasło, które w żadnej z wersji nie są chronione. Podsłuchujący kanał transmisji może przechwycić te informacje i wykorzystać je do podszycia się pod podmiot uwierzytelniający. Protokół ten nie posiada żadnych mechanizmów ochrony przed podszywaniem się. Dlatego też protokół ten nie jest zalecany do używania w systemach komputerowych z uwagi na niski poziom bezpieczeństwa. Protokół PAP został zastąpiony przez protokół CHAP w którym hasło nie jest przesyłane otwartym tekstem, tylko jest ono hashowane przed przesłaniem. \nProtokół SSL (Secure Sockets Layer), lub jego następca TLS (Transport Layer Security) to protokoły, które zapewniają szyfrowaną komunikację, a dodatkowo pozwalają na uwierzytelnienie serwera względem klienta, opcjonalnie klienta względem serwera. W protokole SSL przesyłane jest hasło do klucza prywatnego, a nie otwarty tekst. Aby podszyć się pod podmiot uwierzytelniający, konieczne jest przejęcie certyfikatu serwera, w tym również klucza prywatnego, co jest zadaniem trudnym i kosztownym, gdyż wymaga przełamania mechanizmów kryptograficznych. W trybie podstawowym, bez autoryzacji klientów, protokół ten zapewnia uwierzytelnienie serwera względem klienta, a więc chroni przed podszywaniem się pod serwer (np. w przypadku ataków man-in-the-middle). \nZatem, tylko protokół PAP przesyła hasło otwartym tekstem i nie posiada mechanizmów chroniących przed podszywaniem się. Pozostałe protokoły wykorzystują silniejsze metody uwierzytelniania oraz szyfrowania, co czyni podszywanie się pod podmiot uwierzytelniający bardzo trudnym."
    },
    {
        "questionId": 229,
        "title": "Wskaz przyklady zamaskowanych kanalow komunikacyjnych:",
        "answers": [
            {
                "text": "system plikow (tworzenie / usuwanie pliku)",
                "isCorrect": true
            },
            {
                "text": "obciazenie procesora",
                "isCorrect": true
            },
            {
                "text": "SSL",
                "isCorrect": false
            },
            {
                "text": "VPN",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Zamaskowane kanały komunikacyjne, zwane również ukrytymi kanałami lub kanałami pobocznymi, to drogi komunikacji, które nie są przeznaczone do przesyłania danych, a które mogą być wykorzystane do przesyłania informacji w sposób niejawny lub do ominięcia mechanizmów bezpieczeństwa. Wykorzystują one normalne, legalne działanie systemu lub protokołów w celu ukrycia nieautoryzowanej komunikacji.\n\n**System plików (tworzenie / usuwanie pliku):** Jest to **poprawny** przykład zamaskowanego kanału komunikacyjnego. Atakujący może wykorzystać regularne operacje systemu plików, takie jak tworzenie i usuwanie plików, do przesyłania bitów informacji. Na przykład, utworzenie pliku może reprezentować bit 1, a jego usunięcie bit 0. Sekwencja takich operacji pozwala na przekazywanie dowolnych danych. Takie działanie jest trudne do wykrycia, ponieważ jest to normalna operacja systemu, która może nie wzbudzać podejrzeń. Typowe narzędzia do monitorowania systemów mogą skupiać się na rejestrowaniu treści plików lub operacji sieciowych, a nie na samej sekwencji zdarzeń tworzenia/usuwania plików. Przykładem może być malware, które po przejęciu kontroli nad systemem tworzy pliki o określonych nazwach, lub dokonuje ich kasowania w ustalonym interwale czasowym. W ten sposób może przesłać do atakującego informacje o systemie na którym jest uruchomione, lub po prostu wysłać skradzione dane.\n\n**Obciążenie procesora:** Jest to **poprawny** przykład zamaskowanego kanału komunikacyjnego. Atakujący może kontrolować obciążenie procesora, aby przekazywać informacje, na przykład wysokie obciążenie może oznaczać bit 1, a niskie obciążenie bit 0. To działanie jest również trudne do wykrycia, gdyż systemy operacyjne często mają zmienne obciążenie procesora, które może być wynikiem wielu czynników. Ukrycie informacji w obciążeniu procesora jest o tyle interesujące, iż nie ma żadnego nagłówka, z którym można byłoby połączyć daną informację. Atakujący, poprzez celowe zwiększanie obciążenia procesora może przesłać np. informacje o stanie zainfekowanego systemu lub skradzione dane. Działanie to jest o tyle podstępne, iż nie musi być realizowane po przez wykonywanie aplikacji a jedynie po przez wykorzystanie legalnych obliczeń lub poprzez cykl uśpienia procesora.\n\n**SSL:** Jest to **niepoprawny** przykład zamaskowanego kanału komunikacyjnego. SSL (Secure Sockets Layer) to protokół kryptograficzny służący do zapewnienia poufności i integralności danych przesyłanych w sieci, ale nie jest kanałem ukrytym. Używa on standardowych portów TCP i protokołów wymiany danych. Celem SSL jest ochrona jawnych kanałów komunikacyjnych, a nie ich ukrycie. Przykładowo, podczas przeglądania stron www, protokół HTTPS wykorzystuje SSL lub jego nowszą wersję TLS(Transport Layer Security) do zaszyfrowania danych wymienianych między przeglądarką a serwerem. To połączenie jest szyfrowane, aby nikt poza komunikującymi się stronami nie mógł odczytać przesyłanych danych. Jednak sam proces komunikacji jest jawny i łatwy do wykrycia. Nie można tej metody komunikacji traktować jako maskowany kanał komunikacyjny. \n\n**VPN:** Jest to **niepoprawny** przykład zamaskowanego kanału komunikacyjnego. VPN (Virtual Private Network) to technologia służąca do tworzenia bezpiecznego tunelu w sieci publicznej, np. w Internecie. VPN  szyfruje cały ruch między użytkownikiem a siecią, z którą się łączy. Ma na celu ochronę danych przed podsłuchem, ale nie ukrywa samego faktu nawiązania komunikacji. Przykładowo, podczas zdalnego dostępu do firmowej sieci VPN, cały ruch sieciowy pomiędzy komputerem użytkownika a firmowym serwerem jest szyfrowany. Nie można wykorzystać protokołu VPN jako maskowanego kanału komunikacyjnego, gdyż protokół ten jest wykorzystywany do ochrony legalnych danych transmitowanych po publicznej sieci."
    },
    {
        "questionId": 230,
        "title": "Wskaz cechy certyfikatow kwalifikowanych (wg obowiazujacego prawodawstwa polskiego):",
        "answers": [
            {
                "text": "wazne sa nie dluzej niz 2 lata",
                "isCorrect": true
            },
            {
                "text": "sluza do szyfrowania dokumentow",
                "isCorrect": false
            },
            {
                "text": "sluza do szyfrowania poczty",
                "isCorrect": false
            },
            {
                "text": "wywoluja skutki prawne rownowazne podpisowi wlasnorecznemu",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Certyfikaty kwalifikowane, zgodnie z polskim prawem, to specjalny rodzaj certyfikatów cyfrowych, które posiadają określone cechy i zastosowania. Nie są one tożsame z ogólnym pojęciem certyfikatów. Kluczowym aspektem certyfikatów kwalifikowanych jest ich status prawny, który nadaje im pewne szczególne właściwości.\n\n**Odpowiedź 1: \"ważne są nie dłużej niż 2 lata\"** - **PRAWDA**. Certyfikaty kwalifikowane mają ograniczony okres ważności, aby zapewnić aktualność danych i ochronę przed potencjalnymi kompromitacjami. Zgodnie z regulacjami, ich ważność nie może przekraczać 2 lat. Jest to element bezpieczeństwa, który zapewnia, że klucze i informacje zawarte w certyfikacie są weryfikowane i odświeżane regularnie, co minimalizuje ryzyko użycia przez nieuprawnione osoby, lub z powodu słabości samego algorytmu szyfrowania.\n\n**Odpowiedź 2: \"służą do szyfrowania dokumentów\"** - **FAŁSZ**. Choć certyfikaty kwalifikowane wykorzystują mechanizmy kryptograficzne, ich głównym celem nie jest szyfrowanie dokumentów. Zamiast tego służą one do podpisywania dokumentów, aby potwierdzić autentyczność i integralność dokumentu. Szyfrowanie to ochrona poufności. Podczas wysyłania dokumentu możemy zaszyfrować jego treść tak, aby mógł ja odczytać tylko odbiorca posiadający klucz, aby zagwarantować, że osoba nieuprawniona, nawet jeśli przechwyci dokument, nie będzie mogła go odczytać. Natomiast podpis elektroniczny, potwierdza, że nadawcą jest osoba posiadająca podpisany klucz publiczny oraz że dokument nie został zmodyfikowany, w tym przypadku odbiorca nie ma możliwości odczytania dokumentu za pomocą podpisu elektronicznego.\n\n**Odpowiedź 3: \"służą do szyfrowania poczty\"** - **FAŁSZ**. Certyfikaty kwalifikowane *nie są przeznaczone* do ogólnego szyfrowania poczty. Choć mogą być używane w systemach pocztowych w celu autoryzacji nadawcy i podpisywania maili, nie są one zazwyczaj używane do szyfrowania całej zawartości wiadomości. Do tego celu są wykorzystywane certyfikaty SSL lub S/MIME. Ich głównym celem, jest poświadczenie autentyczności nadawcy.\n\n**Odpowiedź 4: \"wywołują skutki prawne równoważne podpisowi własnoręcznemu\"** - **PRAWDA**. To jest kluczowa cecha certyfikatów kwalifikowanych w Polsce. Zgodnie z Ustawą o podpisie elektronicznym z dnia 18 września 2001 r., certyfikaty kwalifikowane generują skutki prawne równoważne podpisowi własnoręcznemu. Oznacza to, że dokument podpisany certyfikatem kwalifikowanym ma taką samą moc prawną jak dokument podpisany odręcznie. Przykładowo umowa podpisana w formie elektronicznej z użyciem certyfikatu kwalifikowanego posiada taką sama moc prawną jak ta sama umowa podpisana odręcznie na papierze.\n\n**Podsumowując:** Certyfikaty kwalifikowane to nie tylko narzędzie techniczne. Są one elementem szerszego ekosystemu prawnego i biznesowego. Ich użycie niesie za sobą daleko idące konsekwencje i odpowiedzialność prawną, co odróżnia je od innych, \"zwykłych\" certyfikatów. Wprowadzanie procedur opartych na podpisie elektronicznym z wykorzystaniem certyfikatów kwalifikowanych wymaga skrupulatnego wdrożenia, mającego na celu zapewnienie bezpieczeństwa procesów ich wykorzystywania."
    },
    {
        "questionId": 231,
        "title": "Ktory protokol umozliwia transparentna dla stacji sieciowej obsluge uszkodzenia jej routera domyslnego?",
        "answers": [
            {
                "text": "RIP (Routing Information Protocol)",
                "isCorrect": false
            },
            {
                "text": "TRP (Transparent Router Protocol)",
                "isCorrect": false
            },
            {
                "text": "LSP (Link State Protocol)",
                "isCorrect": false
            },
            {
                "text": "HSRP (Hot Standby Routing Protocol)",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół HSRP (Hot Standby Routing Protocol) to protokół zapewniający wysoką dostępność brzegowych routerów w sieciach lokalnych. Działa on w ten sposób, że grupa routerów dzieli się jeden wirtualny adres IP będący adres domyślnej bramy dla komputerów w danej sieci lokalnej. Jeden z routerów jest aktywny i realizuje całą komunikację, podczas gdy pozostałe pozostają w stanie rezerwowym, oczekując na awarię aktywnego routera. W przypadku awarii aktywnego routera jeden z rezerwowych routerów przejmuje jego zadania oraz adres wirtualny, realizując tym samym ciągłość działania sieci. Protokół HSRP działa na warstwie łącza danych i w praktyce jest niezależny od protokołów warstwy wyższej(np IP). Konfiguracja HSRP jest realizowana niezależnie na każdym routerze. W konfiguracji można zdefiniować priorytet każdego routera, router z najwyższym priorytetem staje się domyślnie aktywny. Priorytet może być również ustawiony z użyciem liczb z przedziału 0-255, im większa wartość tym większy priorytet.\n\nOpcja *a* (RIP - Routing Information Protocol) jest dynamicznym protokołem routingu, który służy do wymiany informacji o trasach między routerami w sieci.  RIP działa na warstwie aplikacji. Routery działające w oparciu o protokół RIP przesyłają informacje o swoich tablicach routingu, a na podstawie tych informacji samodzielnie aktualizują swoje tablice. RIP sam w sobie nie oferuje mechanizmu przejrzystej obsługi awarii routera domyślnego. W przypadku awarii routera domyślnego komputery w sieci muszą ponownie pozyskać informację o nowej bramie co najczęściej powoduje chwilową przerwę w komunikacji.\n\nOpcja *b* (TRP - Transparent Router Protocol) nie jest standardowym protokołem i nie występuje w dokumentach RFC. Najprawdopodobniej jest to nazwa wymyślona na potrzeby tego pytania.\n\nOpcja *c* (LSP - Link State Protocol)  jest ogólną kategorią protokołów routingu, do której zalicza się również popularny protokół OSPF. Protokoły te działają w warstwie sieciowej. Protokoły te, w odróżnieniu od protokołów wektorów dystansu (np. RIP), znają topologię całej sieci i na podstawie tej wiedzy samodzielnie wyliczają ścieżki do poszczególnych celów sieciowych.  Podobnie jak RIP protokoły te  nie zapewniają przejrzystego przejęcia komunikacji w przypadku awarii routera domyślnego.\n\nOpcja *d* (HSRP - Hot Standby Routing Protocol) jest protokołem działającym w warstwie łącza danych, zaprojektowanym w celu zapewnienia wysokiej dostępności brzegowych routerów poprzez utworzenie grupy routerów współdzielących jeden wirtualny adres IP, który jest następnie wykorzystywany jako adres bramy domyślnej przez hosty w sieci lokalnej. W przypadku awarii aktywnego routera następuje automatyczne przełączenie na router rezerwowy. Komputery w sieci lokalnej nie odczuwają w żaden sposób tej zmiany, ponieważ nadal wszystkie pakiety są wysyłane na ten sam adres IP – wirtualny adres bramy. HSRP nie jest protokołem dynamicznego routingu, ale protokołem zapewniającym redundancję brzegową, co czyni go poprawną odpowiedzią.\n\nW praktyce, użycie HSRP zapewnia użytkownikom ciągłość dostępu do sieci, nawet jeśli nastąpi awaria jednego z routerów. Systemy działające w sieci lokalnej wykorzystują adres wirtualnej bramy domyślnej, a routery na które skonfigurowany jest HSRP odpowiedzialne są za propagacje ruchu sieciowego do wybranej sieci publicznej. Komputery w sieci lokalnej nawet nie wiedzą, że wystąpił przełącznik i w komunikacji bierze udział router zapasowy."
    },
    {
        "questionId": 232,
        "title": "Wskaz wlasnosci protokolu HSRP (Hot Standby Router Protocol):",
        "answers": [
            {
                "text": "sluzy do tworzenia tuneli VPN",
                "isCorrect": false
            },
            {
                "text": "zabezpiecza poczte elektroniczna",
                "isCorrect": false
            },
            {
                "text": "pozwala uzyskac redundancje routerow",
                "isCorrect": true
            },
            {
                "text": "wspomaga uwierzytelnianie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół HSRP (Hot Standby Router Protocol) jest protokołem zapewniającym redundancję routerów w sieciach komputerowych. Redundancja, w kontekście systemów komputerowych i sieci, to posiadanie zapasowych komponentów gotowych do przejęcia funkcji uszkodzonych lub niedostępnych elementów podstawowych, dzięki czemu system może nadal działać bez zakłóceń. HSRP działa w taki sposób, że kilka routerów (zwykle dwa) dzieli wspólny wirtualny adres IP. Jeden z tych routerów jest aktywny i przekazuje ruch sieciowy. Pozostałe routery są w stanie rezerwowym. Jeżeli router aktywny ulegnie awarii, jeden z routerów rezerwowych przejmuje rolę routera aktywnego, a ruch sieciowy jest kontynuowany bez przerwy. W takim przypadku następuje zmiana tras w sieci. HSRP działa więc jako zabezpieczenie przed awarią pojedynczego routera. HSRP nie jest protokołem służącym do tworzenia tuneli VPN.\n\n*   **\"służy do tworzenia tuneli VPN\"** - To stwierdzenie jest niepoprawne. Tunele VPN (Virtual Private Network) są tworzone za pomocą protokołów takich jak IPsec, OpenVPN, lub WireGuard. Te protokoły służą do tworzenia bezpiecznych połączeń między odległymi sieciami lub komputerami, szyfrując ruch i tunelując go przez sieć publiczną np. Internet. HSRP natomiast nie szyfruje danych ani nie tworzy tuneli. Jego celem jest tylko zapewnienie ciągłości działania sieci na poziomie routerów.\n*   **\"zabezpiecza pocztę elektroniczną\"** - To stwierdzenie jest niepoprawne. Protokoły zabezpieczające pocztę elektroniczną to m.in. S/MIME, PGP, STARTTLS, lub DKIM. Protokół HSRP nie ma nic wspólnego z zabezpieczeniem przesyłania poczty. Jego zadaniem jest wyłącznie zabezpieczenie dostępu do sieci poprzez zapewnienie redundancji routerów.\n*   **\"pozwala uzyskać redundancję routerów\"** - To stwierdzenie jest poprawne. HSRP jest protokołem, który pozwala na zbudowanie systemu w którym, w przypadku awarii aktywnego routera, jego rolę przejmuje router zapasowy, tym samym zapewniając dostęp do usług dla wszystkich klientów sieci w razie awarii. Dla użytkowników końcowych, ten proces przełączenia powinien być niewidoczny i nie odczuwalny jako przerwa w dostępności usług.\n*   **\"wspomaga uwierzytelnianie\"** - To stwierdzenie jest niepoprawne. Protokół HSRP nie ma na celu uwierzytelniania użytkowników lub urządzeń. Uwierzytelnianie jest realizowane na innych poziomach w protokołach takich jak RADIUS czy Kerberos. HSRP natomiast działa na niższym poziomie sieciowym i koncentruje się na zapewnieniu dostępności usług poprzez redundancję routerów.\n\nPrzykład praktyczny:\nWyobraźmy sobie dużą firmę, w której dostęp do serwerów i usług sieciowych jest realizowany przez pojedynczy router. Jeżeli ten router ulegnie awarii, cała firma może mieć problemy z dostępem do Internetu oraz do wewnętrznych aplikacji. Aby zminimalizować ryzyko awarii, można zastosować protokół HSRP. Konfigurujemy dwa routery tak, że jeden z nich jest aktywny i przekazuje ruch sieciowy a drugi jest routerem zapasowym i nasłuchuje zdarzeń w sieci. Oba routery wykorzystują ten sam wirtualny adres IP jako adres bramy sieciowej. W przypadku awarii aktywnego routera, router zapasowy natychmiast przejmuje jego rolę. Użytkownicy firmy nie odczują żadnej przerwy w dostępie do usług ponieważ adres IP bramy sieciowej nie zmienił się."
    },
    {
        "questionId": 233,
        "title": "Wskaz najbezpieczniejszy standard zabezpieczen komunikacji w sieciach bezprzewodowych Wi-Fi: ",
        "answers": [
            {
                "text": "IEEE 802.11 WEP",
                "isCorrect": false
            },
            {
                "text": "IEEE 802.11i WPA",
                "isCorrect": true
            },
            {
                "text": "WPA-Enterprise",
                "isCorrect": false
            },
            {
                "text": "WPA-PSK",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół IEEE 802.11i, znany również jako WPA (_Wi-Fi Protected Access_), stanowi ulepszenie protokołu WEP (_Wired Equivalent Privacy_) i jest najbezpieczniejszym standardem zabezpieczeń komunikacji w sieciach bezprzewodowych Wi-Fi, spośród przedstawionych w odpowiedziach do pytania. WPA został opracowany jako odpowiedź na poważne luki w zabezpieczeniach WEP. WPA używa algorytmu TKIP (_Temporal Key Integrity Protocol_) do szyfrowania, który zapewnia dynamiczne zmienianie kluczy szyfrujących. W efekcie zmniejsza to skuteczność ataku, w którym atakujący gromadzi pakiety do deszyfrowania. WPA ma wady i zostało zastąpione nowszą wersją o nazwie WPA2. WPA jest jednak uważane za bardziej bezpieczne niż WEP, ale mniej bezpieczne niż WPA2.\n\n**IEEE 802.11 WEP** jest przestarzałym i bardzo niebezpiecznym standardem zabezpieczeń, w którym klucz szyfrujący jest ustawiony ręcznie i nie jest on dynamicznie zmieniany. W konsekwencji, po przechwyceniu klucza przez atakującego, cała komunikacja może zostać odszyfrowana. W praktyce, złamanie klucza WEP zajmuje kilkanaście minut a programy do tego celu można bez problemu pobrać z internetu. Jest to przykład *niebezpiecznego protokołu* z powodu jego niskiego poziomu bezpieczeństwa.\n\n**WPA-Enterprise** to tryb WPA używany głównie w dużych organizacjach. W tym trybie uwierzytelnianie następuje przy pomocy serwera RADIUS, co zapewnia większą elastyczność i scentralizowane zarządzanie dostępem. Mechanizm ten jest bezpieczny i na pewno bardziej bezpieczny niż WEP, jednak nie jest to standard definiujący podstawową zasadę zabezpieczeń w sieciach bezprzewodowych. Określa jedynie sposób implementacji uwierzytelniania w WPA. Nie należy mylić pojęć.\n\n**WPA-PSK** (Pre-Shared Key), czasami zwane WPA-Personal, jest wariantem WPA stosowanym głównie w domowych i małych sieciach. W tym trybie wszystkie urządzenia korzystają z tego samego klucza szyfrującego, co czyni go mniej bezpiecznym niż WPA-Enterprise, ale znacznie bezpieczniejszym niż WEP. Jest to przykład ustawienia autoryzacji w WPA ale nie stanowi on odrębnego standardu. Nie jest również najbezpieczniejszym standardem zabezpieczeń.\n\nPodsumowując, **IEEE 802.11i WPA** jest najbezpieczniejszą odpowiedzią, w porównaniu do pozostałych (WEP i WPA-PSK), z uwagi na fakt iż stanowi mechanizm ulepszonej ochrony, który został opracowany w celu zastąpienia przestarzałego i niebezpiecznego standardu WEP, przy jednoczesnym zachowaniu zgodności wstecz oraz w przypadku trybu WPA-Enterprise mechanizm dodatkowo wzmacnia ochronę przy użyciu zewnętrznego serwera autoryzującego. Nie jest to jednak najbezpieczniejszy standard gdyż w jego miejsce powstał standard WPA2."
    },
    {
        "questionId": 234,
        "title": "Ktore z ponizszych standardow nie oferuja zadnej redundancji:",
        "answers": [
            {
                "text": "RAID 0",
                "isCorrect": true
            },
            {
                "text": "RAID 5",
                "isCorrect": false
            },
            {
                "text": "RAID 3",
                "isCorrect": false
            },
            {
                "text": "RAID 1",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "RAID (Redundant Array of Independent Disks) to technologia łączenia wielu fizycznych dysków twardych w jedną logiczną całość, w celu zwiększenia wydajności lub bezpieczeństwa przechowywanych danych. Różne poziomy RAID charakteryzują się różnym podejściem do zapisu danych.\n\n**RAID 0 (striping)** dzieli dane na bloki i zapisuje je naprzemiennie na wszystkich dyskach w macierzy. Zwiększa to wydajność odczytu i zapisu, ponieważ operacje są wykonywane równolegle. Jednak RAID 0 **nie oferuje żadnej redundancji**. W przypadku awarii jednego dysku, **wszystkie dane w macierzy są tracone**, ponieważ bloki danych są rozproszone na wszystkich dyskach i nie ma sposobu na ich odzyskanie. Na przykład, jeśli mamy macierz RAID 0 złożoną z trzech dysków i jeden z nich ulegnie awarii, wszystkie dane, łącznie z fragmentami rozproszonymi po pozostałych dwóch sprawnych dyskach, zostaną utracone.\n\n**RAID 1 (mirroring)** duplikuje dane na dwóch lub więcej dyskach. Oznacza to, że każdy dysk zawiera identyczną kopię danych. W przypadku awarii jednego dysku, system nadal może pracować na podstawie danych z pozostałych. Dzięki temu RAID 1 **zapewnia redundancję i odporność na awarie**, ale efektywna pojemność macierzy jest równa pojemności najmniejszego dysku. Na przykład, macierz RAID 1 z dwóch dysków o pojemności 1 TB, będzie miała efektywną pojemność 1 TB (ponieważ drugi dysk jest jedynie kopią) i odporność na awarię jednego dysku.\n\n**RAID 3**  wykorzystuje parzystość, aby chronić dane. W tym celu, jeden dysk jest przeznaczony wyłącznie na przechowywanie danych parzystości. Dane są dzielone na bloki i zapisywane na pozostałych dyskach, a na dysku parzystości zapisywana jest suma kontrolna tych danych. W przypadku awarii jednego dysku, dane można odzyskać z pozostałych dysków oraz danych parzystości. RAID 3 **zapewnia redundancję i odporność na awarie** jednego dysku. Przykładowo w macierzy RAID 3 złożonej z 5 dysków, 4 dyski będą wykorzystane na przechowywanie danych, a jeden na dane parzystości. W przypadku awarii jednego z 4 dysków dane zostaną odzyskane dzięki parzystości z 5 dysku.\n\n**RAID 5** to ulepszona wersja RAID 3. Podobnie jak RAID 3, dane są dzielone na bloki i zapisywane na dyskach, a suma kontrolna jest przechowywana na dysku parzystości, ale w RAID 5 dane parzystości są rozproszone na wszystkich dyskach. Zwiększa to wydajność w porównaniu do RAID 3, ponieważ dane parzystości nie są zapisywane zawsze na tym samym dysku. Tak jak w RAID 3 również RAID 5 **zapewnia redundancję i odporność na awarie** jednego dysku. Macierz RAID 5 złożona z 5 dysków będzie miała 4 dyski na dane i jeden na dane parzystości rozproszone na 5 dyskach.\n\nPodsumowując, spośród podanych opcji tylko RAID 0 nie oferuje żadnej redundancji danych."
    },
    {
        "questionId": 235,
        "title": "Ktora klasa RAID zapewnia odpornosc na jednoczesna awarie 2 dyskow w 5-dyskowej macierzy?",
        "answers": [
            {
                "text": "RAID 2",
                "isCorrect": false
            },
            {
                "text": "RAID 1",
                "isCorrect": true
            },
            {
                "text": "RAID 6",
                "isCorrect": true
            },
            {
                "text": "zadna z powyzszych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "RAID (Redundant Array of Independent Disks) to technologia wirtualizacji pamięci masowej, która łączy wiele fizycznych dysków w jedną logiczną jednostkę, zwiększając wydajność i niezawodność. Różne poziomy RAID oferują różne kompromisy między wydajnością, pojemnością i odpornością na awarie.\n\n**RAID 2**, choć teoretycznie istnieje, jest rzadko używany. Rozkłada dane na poziomie bitów pomiędzy dyski i wykorzystuje kod Hamminga do korekcji błędów. RAID 2 teoretycznie może przetrwać awarię dysku, ale w praktyce jest rzadko stosowany i nie jest optymalny w kontekście jednoczesnej awarii dwóch dysków. Zatem odpowiedź *RAID 2* jest *niepoprawna*.\n\n**RAID 1**, zwany również mirroringiem, tworzy dokładną kopię danych na dwóch lub więcej dyskach. W 5-dyskowym RAID 1, dane byłyby zapisywane na każdym dysku jednocześnie. Dzięki temu odczyt może być przyspieszony, a system jest odporny na awarię jednego z dysków, gdyż pozostałe dyski zawierają kompletną kopię danych. Przy awarii dwóch dysków system utraci dane. Zatem odpowiedź *RAID 1* jest *niepoprawna*.\n\n**RAID 6**, w odróżnieniu od RAID 5, wykorzystuje dwa zbiory bitów parzystości. Dane są rozkładane blokowo na dyskach, a na każdym dysku jest dodatkowo generowana informacja o parzystości, pozwalająca na rekonstrukcję danych w razie awarii. RAID 6 jest odporny na awarię dwóch dysków, ponieważ informacja o parzystości jest tworzona z dwóch niezależnych zbiorów danych i na jej podstawie możliwe jest odzyskanie utraconych danych. W 5-dyskowym RAID 6, gdy dwa dyski ulegną awarii, dane można odzyskać na podstawie danych i dwóch zbiorów bitów parzystości z pozostałych 3 sprawnych dysków. Odpowiedź *RAID 6* jest *poprawna*.\n\nOdpowiedź *żadna z powyższych* jest *niepoprawna*, ponieważ RAID 6 zapewnia odporność na awarię dwóch dysków.\n\nW praktyce:\n\n*   W przypadku systemów o wysokiej dostępności, np. baz danych, gdzie krytyczna jest nieprzerwana praca, często używa się RAID 6, bo toleruje jednoczesną awarię dwóch dysków.\n*   RAID 1 jest często używany w serwerach poczty elektronicznej, gdzie kluczowe jest odtworzenie danych przy minimalnym czasie przestoju serwera. Używa się do tego RAID 1 ponieważ dysponuje najszybszym odczytem ze wszystkich poziomów RAID a zapis jest tylko nieznacznie wolniejszy. \n*   RAID 2 jest głównie konstrukcją teoretyczną, bez zastosowania w praktycznych wdrożeniach serwerowych."
    },
    {
        "questionId": 236,
        "title": "Program xinetd to:",
        "answers": [
            {
                "text": "wazny element systemu operacyjnego Linux, odpowiedzialny za uruchamianie innych programow",
                "isCorrect": true
            },
            {
                "text": "krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony",
                "isCorrect": false
            },
            {
                "text": "krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony, jest rodzicem dla wszystkich nowo powstalych procesow",
                "isCorrect": false
            },
            {
                "text": "bardzo wazny komponent systemu Linux, bez ktorego system operacyjny nie bedzie dzialal prawidlowo z uwagi na niemoznosc uruchamiania dodatkowych programow",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`xinetd` (extended Internet daemon) to program w systemach Linux/Unix, który działa jako *super-serwer*. Oznacza to, że `xinetd` nasłuchuje na określonych portach sieciowych. Kiedy przyjdzie żądanie połączenia na dany port, zamiast aby dany serwer usługi działał non-stop, uruchamia on odpowiedni program obsługujący żądanie połączenia. Po zakończeniu obsługi połączenia program jest zatrzymywany i zwalnia zasoby. `xinetd` nie jest podstawowym składnikiem systemu operacyjnego, który musi być uruchomiony, aby system działał poprawnie, tylko aplikacją, która odpowiada za uruchamianie innych programów, które realizują usługi sieciowe.\n\nOpcja \"**wazny element systemu operacyjnego Linux, odpowiedzialny za uruchamianie innych programow**\" jest **poprawna**. `xinetd` jest istotnym elementem, ponieważ zarządza, które programy mają być uruchomione przy żądaniu połączenia sieciowego. Działa na żądanie i uruchamia programy do obsługi danej usługi sieciowej, która jest potrzebna tylko w danym momencie. Przykładowo, jeśli nikt nie będzie korzystał z usługi telnet, to serwer usługi telnet nie musi być uruchomiony przez cały czas działania systemu. Uruchomiony zostanie dopiero przy próbie połączenia z użyciem usługi telnet. Podobna sytuacja jest w przypadku usługi ftp.\n\nOpcja \"**krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony**\" jest **niepoprawna**. System operacyjny Linux może uruchomić się i działać poprawnie bez `xinetd`. `xinetd` nie jest niezbędny do działania Linuxa. Jest on dodatkowym programem, który można wykorzystać jako mechanizm do uruchamiania innych usług sieciowych.\n\nOpcja \"**krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony, jest rodzicem dla wszystkich nowo powstalych procesow**\" jest **niepoprawna**. Jest to koncepcja _init_ oraz _systemd_, które uruchamiane są na samym początku działania systemu, i to one są rodzicami dla większości nowo powstających procesów, a nie `xinetd`. `xinetd` nie jest \"rodzicem\" dla wszystkich procesów tylko, dla tych programów które są konfigurowane w jego pliku konfiguracyjnym, aby dany program obsługiwał dany port sieciowy.\n\nOpcja \"**bardzo wazny komponent systemu Linux, bez ktorego system operacyjny nie bedzie dzialal prawidlowo z uwagi na niemoznosc uruchamiania dodatkowych programow**\" jest **niepoprawna**. System Linux nie wymaga programu `xinetd` do prawidłowego działania. Wiele dodatkowych programów można uruchamiać bez wykorzystania `xinetd`. Zamiast `xinetd`, do uruchamiania usług sieciowych w systemie Linux można użyć np. systemd. `xinetd` to po prostu dodatkowy program, który nie jest niezbędny do prawidłowego działania Linuxa. Podobnie jak nie jest niezbędny protokół DHCP czy DNS."
    },
    {
        "questionId": 237,
        "title": "Relacja zaufania w uwierzytelnianiu w srodowisku sieciowym:",
        "answers": [
            {
                "text": "jest wykorzystywana zarowno przez systemy Unix, jak i MS Windows",
                "isCorrect": true
            },
            {
                "text": "moze byc jednostronna lub dwustronna",
                "isCorrect": true
            },
            {
                "text": "nie jest przechodnia",
                "isCorrect": false
            },
            {
                "text": "jest realizacja koncepcji SSO",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Relacja zaufania w kontekście uwierzytelniania systemów komputerowych opisuje sytuację, w której jeden system (system ufający) akceptuje tożsamość użytkownika zweryfikowaną przez inny system (system zaufany).  Oznacza to, że po pomyślnym uwierzytelnieniu przez system zaufany, użytkownik otrzymuje dostęp do zasobów systemu ufającego bez konieczności ponownego uwierzytelniania. Jest to element mechanizmu _single sign-on (SSO)_. Relacje te pozwalają użytkownikom na łatwiejsze korzystanie z wielu systemów.\n\n**Opcja 1: \"jest wykorzystywana zarowno przez systemy Unix, jak i MS Windows\" - PRAWDA**\n\nRelacje zaufania są stosowane zarówno w systemach Unix/Linux, jak i MS Windows. W systemach Unix/Linux, relacje zaufania mogą być konfigurowane za pomocą plików  `/etc/hosts.equiv`  (zaufanie systemowe) i `~/.rhosts` (zaufanie użytkownika).  W  `hosts.equiv` administrator systemu konfiguruje listę nazw hostów (komputerów), które są zaufane i tym samym mogą uzyskiwać dostęp do kont lokalnych na hoście na którym zdefiniowano ten plik bez podawania hasła. Każdy użytkownik może za to dodać do swojego pliku  `~/.rhosts` listę komputerów i użytkowników na tych komputerach, którym ufa, czyli tym samym umożliwia im uzyskanie dostępu do konta użytkownika bez podawania hasła.  W systemach MS Windows, relacje zaufania są używane w środowisku domenowym Active Directory. Domena w Active Directory, jest to zbiór systemów, użytkowników, komputerów i innych obiektów podległych jednemu mechanizmowi uwierzytelniania.  Relacje zaufania w domenach Windows umożliwiają użytkownikom dostęp do zasobów innej domeny, jeśli domena z której pochodzi użytkownik jest zaufana dla docelowej domeny. Jest to przykład implementacji idei SSO w systemie Windows. Zatem opcja jest prawidłowa. \n\n**Opcja 2: \"moze byc jednostronna lub dwustronna\" - PRAWDA**\n\nRelacja zaufania może być jednostronna, gdzie system A ufa systemowi B, ale system B nie ufa systemowi A. W przypadku relacji dwustronnej system A ufa systemowi B i odwrotnie system B ufa systemowi A. W systemach Windows możliwe jest również utworzenie relacji zaufania transferującego. Relacje te są jednak nietypowe.  W konfiguracji systemów Unix/Linux relacje zaufania w oparciu o /etc/hosts.equiv i ~/.rhosts są zawsze jednostronne. Zatem opcja jest prawidłowa. \n\n**Opcja 3: \"nie jest przechodnia\" - FAŁSZ**\n\nRelacja zaufania nie jest z założenia przechodnia. To znaczy, że jeśli system A ufa systemowi B, a system B ufa systemowi C, to nie oznacza automatycznie, że system A ufa systemowi C. W praktyce oznacza to, że użytkownik uwierzytelniony w systemie A będzie miał dostęp do zasobów systemu B bez dodatkowej weryfikacji, natomiast nie uzyska takiego dostępu w systemie C, pomimo tego, iż system C ufa systemowi B.  Każda relacja zaufania musi być zdefiniowana w sposób jawny.  Transytywność może być dodana do niektórych implementacji (np. w przypadku relacji zaufania między domenami MS Windows).  Zatem opcja jest nieprawidłowa. \n\n**Opcja 4: \"jest realizacja koncepcji SSO\" - FAŁSZ**\n\nRelacja zaufania jest elementem _implementacji_ mechanizmów SSO, a nie całą realizacją SSO. Single Sign-On (SSO) to koncepcja, która pozwala użytkownikowi na uwierzytelnienie się raz i uzyskanie dostępu do wielu powiązanych systemów bez konieczności ponownego podawania danych uwierzytelniających.  W praktyce SSO wykorzystuje wiele mechanizmów do osiągnięcia tego celu. Mechanizm relacji zaufania to tylko jeden z elementów bardziej złożonego systemu SSO. Mechanizm relacji zaufania można uznać za element składowy technologii SSO, ale nie samą ideę SSO. Zatem opcja jest nieprawidłowa.\n\n**Podsumowanie**\n\nWybór prawidłowych odpowiedzi wymaga zrozumienia, że relacja zaufania jest koncepcją, która jest *wykorzystywana* w systemach operacyjnych Unix i Windows, może być jednostronna lub dwustronna, nie jest jednak przechodnia, co oznacza, że relacja między dwoma systemami nie oznacza automatycznie relacji zaufania między innymi systemami, które mają relacje zaufania z tymi dwoma systemami i ostatecznie, że relacja zaufania *wspomaga*  mechanizmy SSO."
    },
    {
        "questionId": 238,
        "title": "Mechanizm ACL umozliwia:",
        "answers": [
            {
                "text": "nadawanie praw (rwx) wielu uzytkownikom i grupom",
                "isCorrect": true
            },
            {
                "text": "odtwarzanie zniszczonych plikow",
                "isCorrect": false
            },
            {
                "text": "nadawanie nowych praw (np. dopisywania) wielu uzytkownikom",
                "isCorrect": false
            },
            {
                "text": "ustanowienie szyfrowania plikow",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Listy Kontroli Dostępu (ACL, _ang. Access Control Lists_) to mechanizmy umożliwiające precyzyjną kontrolę uprawnień dostępu do zasobów systemu komputerowego. Zasobami mogą być pliki, katalogi, obiekty bazodanowe lub inne elementy systemu operacyjnego. W przeciwieństwie do standardowych uprawnień w systemach Unix/Linux, które ograniczają się do określenia dostępu dla właściciela zasobu, grupy, do której ten właściciel należy oraz wszystkich innych użytkowników, ACL pozwalają na definiowanie uprawnień dla konkretnych użytkowników lub grup, nadając tym samym elastyczności w zarządzaniu uprawnieniami dostępu. Uprawnienia te to najczęściej prawo do odczytu (_r_), zapisu (_w_), oraz wykonania (_x_). ACL umożliwiają zdefiniowanie kombinacji tych praw dla konkretnych użytkowników i grup.\n\n*   **\"nadawanie praw (rwx) wielu uzytkownikom i grupom\"** - Jest to **poprawna** odpowiedź. ACL zostały zaprojektowane by umożliwić administratorom przypisywanie praw dostępu (r-odczyt, w-zapis, x-wykonanie) do plików, katalogów i innych zasobów wielu użytkownikom i grupom, bez konieczności tworzenia skomplikowanej struktury grup lub nadawania szerokich uprawnień wszystkim użytkownikom. Przykładowo, w systemie Linux z użyciem komendy `setfacl` można ustawić prawa do odczytu i zapisu (_rw_) dla użytkownika _jan_ i do odczytu (_r_) dla grupy _zespol1_ do pliku _plik.txt_.  \n    `setfacl -m u:jan:rw plik.txt`  \n    `setfacl -m g:zespol1:r plik.txt`\n*   **\"odtwarzanie zniszczonych plikow\"** - Jest to **niepoprawna** odpowiedź. ACL służą do kontroli dostępu, a nie do odzyskiwania utraconych danych. Odtwarzanie plików jest zadaniem systemów backupu lub mechanizmów odzyskiwania danych. ACL nie mają wpływu na sposób przechowywania plików, ani nie dostarczają mechanizmów do cofnięcia zmian w strukturze systemu plików.\n*   **\"nadawanie nowych praw (np. dopisywania) wielu uzytkownikom\"** - Jest to **niepoprawna** odpowiedź. ACL umożliwiają przypisywanie i modyfikowanie wszelkich praw dostępu, nie tylko tych nowych. Można też te prawa odbierać czy też modyfikować istniejące. Modyfikacja nie musi dotyczyć tylko dopisywania.\n*   **\"ustanowienie szyfrowania plikow\"** - Jest to **niepoprawna** odpowiedź. Szyfrowanie plików jest odrębną funkcjonalnością, którą realizują mechanizmy i algorytmy kryptograficzne. ACL nie szyfrują plików, a tylko kontrolują kto i w jaki sposób ma do nich dostęp. Mechanizmy szyfrowania plików operują na niższym poziomie od ACL i ACL nie maja z tymi mechanizmami nic wspólnego.\n\nW praktyce, ACL mogą być użyte w systemie Linux do zabezpieczenia serwera WWW. Domyślnie pliki serwera WWW, aby były publicznie dostępne dla użytkowników Internetu, muszą posiadać prawa do odczytu dla wszystkich. Jednak gdyby pliki te stały się celem ataku za pomocą wstrzyknięcia złośliwego kodu do plików HTML, wówczas atakujący może chcieć modyfikować zawartość tych plików a nie tylko je czytać. Aby tego uniknąć można wykorzystać rozszerzone listy dostępu do plików i określić, iż uprawnienia do odczytu posiadają wszyscy natomiast do zapisu będzie posiadał tylko użytkownik administracyjny i specjalna grupa serwera WWW, w której nie będzie znajdował się żaden użytkownik systemu poza tymi wyznaczonymi."
    },
    {
        "questionId": 239,
        "title": "Jakie restrykcje pozwala narzucic systemowa funkcja chroot() systemu Unix?:",
        "answers": [
            {
                "text": "ograniczenie odczytu do okreslonego poddrzewa systemu plikow",
                "isCorrect": true
            },
            {
                "text": "ograniczenie komunikacji sieciowej do wybranych portow",
                "isCorrect": false
            },
            {
                "text": "niedostepnosc odziedziczonych deskryptorow",
                "isCorrect": false
            },
            {
                "text": "ograniczenie zapisu do okreslonego poddrzewa systemu plikow",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Funkcja systemowa `chroot()` systemu Unix służy do ograniczania widoku systemu plików dla danego procesu. Dokładniej, zmienia ona katalog główny (root directory) procesu na inny, podany jako argument. Proces wykonujący funkcję `chroot()` widzi tylko pliki i katalogi znajdujące się w nowym drzewie plików. Pliki lub katalogi poza tym poddrzewem nie są dla tego procesu dostępne. Zmiana katalogu głównego następuje tylko w obrębie wywołującego procesu i jego procesów potomnych. Inne procesy na systemie operacyjnym nie są na to w żaden sposób narażone. Proces wywołujący funkcję `chroot()` nadal ma dostęp do wcześniej otwartych plików (i-węzłów) przy pomocy deskryptorów plików.\n\n**Odpowiedź 1: \"ograniczenie odczytu do okreslonego poddrzewa systemu plikow\"**\n\nJest to **poprawna** odpowiedź. Funkcja `chroot()` ogranicza odczyt, ponieważ proces nie może uzyskać dostępu do żadnych plików ani katalogów, które nie znajdują się w nowym, ograniczonym katalogu głównym. Aplikacja widzi jedynie zasoby dostępne w tym poddrzewie. Przykładowo, jeśli aplikacja WWW zostanie uwięziona w katalogu `/var/www`, to nie będzie ona w stanie odczytać pliku `/etc/passwd`, gdyż znajduje się on poza jej nowym drzewem plików.\n\n**Odpowiedź 2: \"ograniczenie komunikacji sieciowej do wybranych portow\"**\n\nJest to **niepoprawna** odpowiedź. Funkcja `chroot()` nie ma bezpośredniego wpływu na komunikację sieciową. Proces uwięziony za pomocą `chroot()` nadal może (o ile ma do tego uprawnienia w systemie operacyjnym) komunikować się w sieci. Konieczne są inne mechanizmy w celu ograniczenia komunikacji sieciowej, np. zapory ogniowe (firewall). Proces po wywołaniu `chroot()` nadal będzie miał dostęp do gniazd sieciowych, które uzyskał jeszcze przed uwięzieniem i z nich może korzystać. Mechanizm `chroot()` zapewnia izolację procesu tylko w odniesieniu do systemu plików. Przykładowo serwer SSH uwięziony za pomocą `chroot` nadal może łączyć się na dowolny port z innymi serwerami (jeżeli nie ma na niego nałożonych dodatkowych ograniczeń).\n\n**Odpowiedź 3: \"niedostepnosc odziedziczonych deskryptorow\"**\n\nJest to **niepoprawna** odpowiedź. Funkcja `chroot()` nie uniemożliwia dostępu do odziedziczonych deskryptorów. Oznacza to, że jeśli proces przed wywołaniem `chroot()` otworzy plik (np. plik konfiguracyjny), to po wywołaniu `chroot()` nadal będzie miał do niego dostęp poprzez odziedziczony deskryptor pliku. Nie będzie mógł jednak tego pliku ponownie otworzyć. Dodatkowo deskryptory plików odnoszą się do otwartych plików i-węzłów w systemie, natomiast mechanizm `chroot()` odnosi się do ścieżek plików, dlatego nie wpływa na deskryptory. Przykładowo, aplikacja która przed wywołaniem `chroot` otworzyła plik `/etc/passwd` nadal może odczytać zawartość pliku po uwięzieniu, gdyż ma deskryptor do i-węzła tego pliku.\n\n**Odpowiedź 4: \"ograniczenie zapisu do okreslonego poddrzewa systemu plikow\"**\n\nJest to **poprawna** odpowiedź. Tak jak w przypadku odczytu funkcja `chroot()` ogranicza także zapis do poddrzewa. Proces uwięziony za pomocą `chroot()` nie może zapisywać plików poza nowym drzewem plików. Aplikacja może oczywiście modyfikować pliki do których ma prawa zapisu, ale tylko w drzewie uwięzienia, nie poza nim. Na przykład serwer poczty elektronicznej uwięziony za pomocą `chroot()` w katalogu `/var/spool/mail` nie będzie miał możliwości zapisu w katalogu `/var/log`, chyba, że katalog ten jest podkatalogiem katalogu `/var/spool/mail` co jednak nie powinno mieć miejsca ze względów bezpieczeństwa."
    },
    {
        "questionId": 240,
        "title": "Ktore z ponizszych mechanizmow stosuja programy malware w celu kamuflazu swojej obecnosci:",
        "answers": [
            {
                "text": "opancerzenie (armor)",
                "isCorrect": true
            },
            {
                "text": "zamaskowane wezly (shadow i-node)",
                "isCorrect": false
            },
            {
                "text": "fingerprinting",
                "isCorrect": false
            },
            {
                "text": "polimorfizm",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "**Opancerzenie (armor)** i **polimorfizm** są technikami maskowania wykorzystywanymi przez złośliwe oprogramowanie (malware). Opancerzenie, znane również jako armoring, odnosi się do technik, które utrudniają analizę i inżynierię wsteczną kodu malware. Obejmuje to różne metody, takie jak pakowanie (kompresja i szyfrowanie kodu), zaciemnianie kodu (przekształcanie czytelnego kodu w trudniejszy do zrozumienia) i umieszczanie w kodzie pułapek na debuggery (antydebuggery). Celem opancerzenia jest utrudnienie analitykom bezpieczeństwa zrozumienie, jak malware działa, a w konsekwencji – stworzenie skutecznego antywirusa lub metody usuwania. Przykładowo, malware może używać technik pakowania, kompresując swój kod i ukrywając go w zaszyfrowanej formie, którą dopiero w trakcie wykonywania rozpakowuje i uruchamia.\n\nPolimorfizm to technika polegająca na zmianie wyglądu kodu malware przy każdej infekcji. Oznacza to, że malware potrafi modyfikować swój kod przy zachowaniu identycznej funkcjonalności. Zmiany mogą obejmować kolejność instrukcji, dodawanie bezużytecznych instrukcji lub zmiany w sposobie kodowania danych. Polimorfizm utrudnia detekcję malware opartą na sygnaturach, czyli unikalnych wzorcach kodu. Klasyczne oprogramowanie antywirusowe, które identyfikuje znane malware poprzez jego sygnaturę, w tym przypadku napotyka trudności. Antywirus musi analizować zachowanie malware w środowisku symulowanym, aby poprawnie je zidentyfikować, a nie na podstawie wzorca kodu.\n\n**Zamaskowane węzły (shadow i-node)** to nie jest technika maskowania wykorzystywana przez malware. Jest to mechanizm zarządzania plikami występujący w niektórych systemach plików, szczególnie Unix-owych. Shadow inodes umożliwiają przypisanie do pliku wielu i-węzłów, czyli struktur opisujących atrybuty i lokalizację pliku na dysku. Takie rozwiązanie jest wykorzystywane w kontekście kontroli dostępu do plików i nie jest typowo wykorzystywane przez malware.\n\n**Fingerprinting** nie jest techniką kamuflażu, tylko identyfikacji. Fingerprinting odnosi się do technik identyfikacji systemów lub oprogramowania na podstawie charakterystycznych cech (odcisków palca). Metoda ta jest wykorzystywana do identyfikacji rodzaju systemu operacyjnego, wersji oprogramowania czy przeglądarki internetowej. Fingerprinting jest bardzo często wykorzystywane przez napastników do identyfikacji ofiar, a nie do maskowania malware. Przykładowo, napastnicy na podstawie fingerprintu mogą dowiedzieć się, z jakiej wersji danego oprogramowania lub systemu operacyjnego korzysta atakowany komputer, dzięki czemu mogą łatwiej dopasować atak."
    },
    {
        "questionId": 241,
        "title": "SFTP to:",
        "answers": [
            {
                "text": "klient protokolu FTP bedacy czescia pakietu SSH",
                "isCorrect": false
            },
            {
                "text": "niezalezna implementacja protokolu Secure FTP",
                "isCorrect": false
            },
            {
                "text": "SSL FTP , czyli wersja protokolu FTP wykorzystujaca mechanizm certyfikatow SSL",
                "isCorrect": false
            },
            {
                "text": "podsystem SSH sluzacy do przesylania plikow",
                "isCorrect": true
            },
            {
                "text": "podsystem raportowania o bledach w SSH",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "SFTP, czyli Secure File Transfer Protocol, nie jest samodzielnym protokołem, lecz podsystemem protokołu SSH (Secure Shell) służącym do bezpiecznego przesyłania plików. Oznacza to, że SFTP działa w oparciu o istniejące połączenie SSH. Gdy używasz SFTP, tak naprawdę nawiązujesz szyfrowane połączenie SSH i w jego ramach używasz specjalizowanego podsystemu do zarządzania plikami. SFTP nie działa bezpośrednio z protokołem TCP, ale wykorzystuje go poprzez mechanizm SSH. W praktyce oznacza to, że  do nawiązania bezpiecznego połączenia i transferu danych, SFTP  korzysta z szyfrowania i uwierzytelniania SSH. Mechanizm ten jest bardzo efektywny, gdyż do ochrony danych wykorzystywane są sprawdzone i bezpieczne algorytmy kryptograficzne. \n\n**Odpowiedź 1: \"klient protokolu FTP bedacy czescia pakietu SSH\" - Niepoprawna.**  SFTP *nie* jest klientem protokołu FTP. FTP, czyli File Transfer Protocol, to inny, niezabezpieczony protokół przesyłania plików, który działa bez szyfrowania. SFTP, w przeciwieństwie do FTP, *nie* jest częścią pakietu SSH, lecz jest  podsystemem pakietu SSH. Ten podsystem jest wykorzystywany do przesyłania plików po uprzednim nawiązaniu połączenia SSH.\n\n**Odpowiedź 2: \"niezalezna implementacja protokolu Secure FTP\" - Niepoprawna.** Chociaż SFTP jest protokołem bezpiecznym, nie jest on *niezależną* implementacją Secure FTP. Termin Secure FTP odnosi się raczej do FTPS, czyli FTP działającego na szyfrowanym protokole SSL/TLS. SFTP jest całkowicie oddzielnym protokołem, zdefiniowanym jako część pakietu SSH, który udostępnia bezpieczny kanał dla transferu plików.\n\n**Odpowiedź 3: \"SSL FTP , czyli wersja protokolu FTP wykorzystujaca mechanizm certyfikatow SSL\" - Niepoprawna.**  SSL FTP, znane również jako FTPS (FTP over SSL), to faktycznie wersja protokołu FTP, która korzysta z certyfikatów SSL/TLS, aby zaszyfrować transmisję danych, w przeciwieństwie do SFTP. FTPS jest to rozszerzenie protokołu FTP. FTPS i SFTP są zupełnie różnymi protokołami. \n\n**Odpowiedź 4: \"podsystem SSH sluzacy do przesylania plikow\" - Poprawna.**  SFTP *jest* podsystemem protokołu SSH przeznaczonym do bezpiecznego przesyłania plików. Działa na  już istniejącym, szyfrowanym połączeniu SSH. W tym kontekście SSH jest tunelem, a SFTP aplikacją, która z tego tunelu korzysta do przesyłania plików.  Dlatego też wszystkie operacje na plikach, takie jak przesyłanie, tworzenie, kasowanie i modyfikowanie, są wykonywane w sposób bezpieczny.  SFTP wykorzystuje port TCP do komunikacji i najczęściej jest to port TCP numer 22.  SFTP, tak samo jak  SSH, używa mechanizmów kryptografii publicznej do  weryfikacji tożsamości użytkownika, jak również algorytmów szyfrowania symetrycznego do szyfrowania przesyłanych danych.  W praktyce, gdy korzystasz z programu, np. scp (secure copy) lub klienta graficznego do przesyłania plików przez SFTP,  tak naprawdę nawiązujesz sesję SSH, w ramach której wykonywane są bezpieczne operacje transferu plików.\n\n**Odpowiedź 5: \"podsystem raportowania o bledach w SSH\" - Niepoprawna.** SFTP *nie* jest podsystemem raportowania o błędach w SSH. Chociaż, jeśli wystąpią problemy z sesją SFTP, SSH zgłosi o tym informację.  Jednak jego podstawowym celem jest bezpieczne przesyłanie plików. System raportowania o błędach w SSH może być częścią samego protokołu SSH lub jakiegoś dodatkowego logowania. SFTP jest całkowicie niezależne od systemu raportowania o błędach w SSH."
    },
    {
        "questionId": 242,
        "title": "Ktore zdania poprawnie opisuja nawiazywanie sesji SSL?:",
        "answers": [
            {
                "text": "serwer przesyla komunikat ServerHello ze swoim certyfikatem",
                "isCorrect": true
            },
            {
                "text": "klient uwierzytelnia serwer na podstawie odebranego certyfikatu",
                "isCorrect": true
            },
            {
                "text": "serwer przesyla komunikat ServerHello z opcjonalnym losowym zawolaniem",
                "isCorrect": true
            },
            {
                "text": "klient odsyla podpisane zawolanie do serwera tylko jesli serwer zadal uwierzytelnienia klienta",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Proces nawiązywania sesji SSL/TLS, zwany uzgadnianiem (handshake), jest sekwencją wymiany komunikatów między klientem a serwerem, która ma na celu ustanowienie bezpiecznego, szyfrowanego połączenia. Celem jest nie tylko szyfrowanie danych ale także sprawdzenie tożsamości stron komunikujących się.\n\n**Odpowiedź 1: \"serwer przesyla komunikat ServerHello ze swoim certyfikatem\" - JEST POPRAWNA.**\nPodczas procesu uzgadniania SSL/TLS, serwer istotnie wysyła komunikat `ServerHello`. Ten komunikat zawiera m.in. identyfikator sesji, informację o wybranym protokole szyfrowania i algorytmie kompresji, oraz co kluczowe, *certyfikat* serwera. Certyfikat jest cyfrowym dokumentem, który zawiera klucz publiczny serwera oraz jego nazwę. Certyfikat jest podpisany przez zaufane centrum certyfikacji (CA), co pozwala klientowi na zweryfikowanie autentyczności serwera.  Bez tego kroku, klient nie mógłby potwierdzić, że komunikuje się z zamierzonym serwerem. Przykładowo, gdy łączysz się z bankiem przez HTTPS, przeglądarka otrzymuje certyfikat serwera banku i na jego podstawie sprawdza, czy rzeczywiście łączysz się z serwerem swojego banku.\n\n**Odpowiedź 2: \"klient uwierzytelnia serwer na podstawie odebranego certyfikatu\" - JEST POPRAWNA.**\nPo odebraniu komunikatu `ServerHello` wraz z certyfikatem serwera, klient przystępuje do jego weryfikacji. Klient sprawdza ważność certyfikatu(czy nie jest unieważniony i czy data ważności nie wygasła), sprawdza czy certyfikat jest podpisany przez znany klientowi zaufany urząd certyfikacji. Ten krok jest krytyczny dla zapewnienia bezpieczeństwa, gdyż pozwala klientowi potwierdzić tożsamość serwera, z którym nawiązuje połączenie. Bez tego kroku klient nie miałby pewności z kim tak naprawdę się łączy. W praktyce podczas przeglądania stron www i logowaniu się do banku to właśnie dzięki certyfikatom mamy pewność że strona www należy do banku. \n\n**Odpowiedź 3: \"serwer przesyla komunikat ServerHello z opcjonalnym losowym zawolaniem\" - JEST POPRAWNA.**\nKomunikat `ServerHello` może, ale nie musi zawierać dodatkowe dane losowe generowane przez serwer. Te dane, nazywane *losowym zawołaniem*, są używane podczas kolejnych kroków uzgadniania sesji w celu wygenerowania kluczy sesyjnych. Te losowe dane mają zapewnić, że proces negocjacji parametrów połączenia będzie unikalny dla każdej sesji, nawet jeśli serwer generuje w pewnym okresie czasu kolejne połączenia, do którego ten sam klient próbował by się podłączyć. Opcjonalne żądanie tych danych jest ważne, gdy serwer wymaga uwierzytelnienia klienta -  w tym przypadku serwer musi upewnić się, że klient jest autentyczny i posiada klucz prywatny, powiązany z certyfikatem.\n\n**Odpowiedź 4: \"klient odsyla podpisane zawolanie do serwera tylko jesli serwer zadal uwierzytelnienia klienta\" - JEST POPRAWNA.**\nW sytuacji, gdy serwer wymaga uwierzytelnienia klienta, to po przesłaniu `ServerHello`, serwer przesyła żądanie certyfikatu klienta oraz *losowe zawołanie* wygenerowane przez siebie. W odpowiedzi klient odsyła *podpisane zawołanie*, czyli zaszyfrowane (kluczem prywatnym klienta) otrzymane zawołanie, oraz swój certyfikat X.509. Serwer w ten sposób może zweryfikować autentyczność klienta i upewnić się, że klient posiada klucz prywatny powiązany z użytym certyfikatem. Jest to analogiczne do weryfikacji certyfikatu serwera przez klienta, tyle że w drugą stronę. W praktyce podczas uwierzytelniania w banku na karcie inteligentnej to właśnie w ten sposób bank weryfikuje tożsamość użytkownika."
    },
    {
        "questionId": 243,
        "title": "Ktore z wymienionych protokolow i standardow oferuja szyfrowana transmisje wiadomosci pocztowych?:",
        "answers": [
            {
                "text": "X.400",
                "isCorrect": false
            },
            {
                "text": "S/MIME",
                "isCorrect": true
            },
            {
                "text": "PGP",
                "isCorrect": true
            },
            {
                "text": "SMTP",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Szyfrowana transmisja wiadomości pocztowych to proces, który ma na celu ochronę poufności przesyłanych treści przed nieuprawnionym dostępem. Osiąga się to poprzez użycie algorytmów kryptograficznych do zaszyfrowania danych przed ich przesłaniem i odszyfrowania po dotarciu do odbiorcy. Nie wszystkie protokoły i standardy poczty elektronicznej oferują wbudowane mechanizmy szyfrowania.\n\n**X.400** jest standardem dla systemów obsługi wiadomości elektronicznych (MHS - Message Handling System), opracowanym przez Międzynarodowy Związek Telekomunikacyjny (ITU). X.400 definiuje sposób przesyłania, przechowywania i formatowania wiadomości elektronicznych, jednak sam w sobie *nie oferuje mechanizmów szyfrowania treści wiadomości*. Jest to raczej standard opisujący infrastrukturę i format, a nie sposób ochrony przed podsłuchem.\n\n**S/MIME** (Secure/Multipurpose Internet Mail Extensions) jest standardem rozszerzającym MIME o mechanizmy kryptograficzne. MIME (Multipurpose Internet Mail Extensions) to standard, który rozszerza format wiadomości e-mail, umożliwiając przesyłanie tekstu, obrazów, dźwięków i innych typów danych w jednej wiadomości. S/MIME dodaje do tego warstwę bezpieczeństwa, *umożliwiając szyfrowanie i podpisywanie cyfrowe wiadomości e-mail*. Używa algorytmów kryptografii asymetrycznej do dystrybucji kluczy i symetrycznej do szyfrowania treści, zapewniając poufność i autentyczność przesyłanych wiadomości. Przykładowo, wysyłając zaszyfrowaną wiadomość S/MIME, nadawca szyfruje ją kluczem publicznym odbiorcy, a odszyfrowuje ją tylko odbiorca swoim kluczem prywatnym.\n\n**PGP** (Pretty Good Privacy) to program komputerowy i otwarty standard, który *umożliwia szyfrowanie, podpisywanie i deszyfrowanie danych, w tym wiadomości e-mail*. PGP wykorzystuje algorytmy kryptografii symetrycznej i asymetrycznej, podobnie jak S/MIME, do ochrony poufności i integralności danych. PGP używa tzw. \"web of trust\" dla weryfikacji wiarygodności kluczy, gdzie użytkownicy wzajemnie podpisują swoje klucze publiczne, poświadczając w ten sposób ich autentyczność.\n\n**SMTP** (Simple Mail Transfer Protocol) to protokół używany do przesyłania wiadomości e-mail między serwerami poczty. Sam *SMTP nie oferuje mechanizmów szyfrowania treści wiadomości*. Umożliwia jedynie transport, a nie zabezpieczenie danych przed nieuprawnionym dostępem. Chociaż protokół SMTP może być używany w połączeniu z TLS (Transport Layer Security) do szyfrowania transmisji połączenia z serwerem pocztowym, to ta metoda dotyczy jedynie szyfrowania połączenia między klientem a serwerem, a nie treści wiadomości e-mail. W takim przypadku, treść listu dalej może być niechroniona.\n\nZatem, prawidłowe odpowiedzi to S/MIME oraz PGP, ponieważ są to standardy i oprogramowanie do *szyfrowania i/lub podpisywania* wiadomości email, zapewniając ochronę poufności i autentyczności."
    },
    {
        "questionId": 244,
        "title": "Wskaz mozliwe srodki ochronne przed atakami przepelnienia bufora:",
        "answers": [
            {
                "text": "niewykonywany segment kodu",
                "isCorrect": false
            },
            {
                "text": "niewykonywany segment stosu",
                "isCorrect": true
            },
            {
                "text": "kontrola zakresu danych globalnych programu na etapie wykonania",
                "isCorrect": true
            },
            {
                "text": "kontrola zakresu danych lokalnych funkcji na etapie kompilacji",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Przepełnienie bufora (_buffer overflow_) to błąd programistyczny, który występuje, gdy program próbuje zapisać dane poza zakresem przydzielonej pamięci. Najczęściej spotykane jest to w przypadku przepełnienia bufora na stosie (ang. _stack_). Stos to obszar pamięci, gdzie przechowywane są zmienne lokalne funkcji, adresy powrotu, oraz inne dane powiązane z wywoływaniem funkcji. Przepełnienie bufora na stosie jest szczególnie niebezpieczne, gdyż poprzez nadpisanie adresów powrotu, atakujący może przejąć kontrolę nad przepływem wykonania programu.\n\n**Niewykonywany segment stosu:** Oznacza wprowadzenie mechanizmu, dzięki któremu dany obszar pamięci (w tym wypadku stos) może być używany wyłącznie do przechowywania danych, a nie jako miejsce wykonywania kodu. W tym kontekście, wprowadzenie niewykonywalnego segmentu stosu, chroni przed atakiem, w którym atakujący nadpisuje adres powrotu do funkcji na stosie na adres kodu, który wprowadził sam w obszar pamięci. Uniemożliwiając wykonanie kodu na stosie, czynimy taką technikę ataku bezużyteczną. Poprawna odpowiedź, gdyż jest to mechanizm ochronny implementowany w wielu systemach operacyjnych, zwłaszcza serwerowych, na poziomie sprzętowym. \n\n**Kontrola zakresu danych globalnych programu na etapie wykonania:** Kontrola zakresu danych globalnych na etapie wykonania (ang. _run-time_) polega na monitorowaniu dostępu do globalnych zmiennych programu, aby upewnić się, że program nie zapisuje wartości poza dozwolonym obszarem. Takie mechanizmy, choć przydatne do wykrywania wielu innych błędów programistycznych (np. związanych z uszkodzeniem pamięci, przypadkowego nadpisania danych), nie chronią przed atakami typu przepełnienie bufora na stosie, gdyż to jest odrębna przestrzeń pamięci, która nie jest pod kontrolą mechanizmów, które nadzorują dostęp do danych globalnych. Poprawna odpowiedź, gdyż jest to mechanizm ochronny, który może pomóc w wykryciu nieprawidłowego dostępu do pamięci, jednak nie jest ukierunkowany na ataki przepełnienia bufora w obszarze stosu.\n\n**Kontrola zakresu danych lokalnych funkcji na etapie kompilacji:** Kontrola zakresu zmiennych lokalnych na etapie kompilacji (ang. _compile-time_) polega na analizie kodu źródłowego, aby upewnić się, że dostęp do zmiennych lokalnych nie przekracza dozwolonych rozmiarów bufora. Technika ta wymaga wsparcia kompilatora i analizy przepływu danych. Kompilator jest w stanie wykryć błędy przepełnienia w przypadkach, gdy są one łatwe do znalezienia, na przykład: _char buf[10]; strcpy(buf, \"dlugi tekst\");_ , jest w stanie wykryć ten błąd na etapie kompilacji. W bardziej złożonych przypadkach, gdzie rozmiar bufora zależy od zmiennych, kompilator może zgłosić jedynie potencjalne zagrożenie. Poprawna odpowiedź, gdyż taka kontrola jest jedną z lepszych metod walki z tego typu zagrożeniem. \n\n**Niewykonywany segment kodu**: Segment kodu jest obszarem pamięci gdzie przetrzymywany jest wykonywany kod. Nadpisanie adresu powrotu przez atakującego umożliwia skok do kodu przetrzymywanego w stosie (lub w heapie, w zależności od szczegółów wykonania ataku). Wprowadzenie mechanizmu, który nie pozwala na wykonywanie kodu w obszarze stosu pozwala skutecznie walczyć z atakami typu przepełnienia bufora w obszarze stosu. Niepoprawna odpowiedź, gdyż nie chroni przed atakami typu przepełnienie bufora na stosie (ang. _stack buffer overflow_). Nie chroni również przed atakami w których kod jest umieszczany w obszarze danych.\n\nPodsumowując, kombinacja niewykonywanego segmentu stosu, kontroli zakresu danych globalnych podczas wykonania, i kontroli zakresu danych lokalnych funkcji podczas kompilacji to efektywna strategia obrony przed atakami wykorzystującymi przepełnienie bufora. Praktycznie, nowoczesne kompilatory i systemy operacyjne wykorzystują kilka z tych metod w celu ochrony systemów operacyjnych przed szkodliwym działaniem z zewnątrz."
    },
    {
        "questionId": 245,
        "title": "Wskaz szyfry symetryczne:",
        "answers": [
            {
                "text": "Blowfish",
                "isCorrect": true
            },
            {
                "text": "DES",
                "isCorrect": true
            },
            {
                "text": "ElGamal",
                "isCorrect": false
            },
            {
                "text": "zadne z powyzszych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Szyfrowanie symetryczne to rodzaj szyfrowania, w którym do szyfrowania i deszyfrowania danych używany jest ten sam klucz. Algorytmy symetryczne są zazwyczaj szybsze i mniej obciążające obliczeniowo niż algorytmy asymetryczne, co czyni je odpowiednimi do szyfrowania dużych ilości danych. Klucz symetryczny musi być jednak przekazany w sposób bezpieczny stronom komunikacji, co stanowi pewne wyzwanie.\n\n*   **Blowfish:** Blowfish jest algorytmem szyfrowania symetrycznego, zaprojektowanym przez Bruce'a Schneiera. Jest to algorytm blokowy, który może być używany do szyfrowania danych w pakietach o długości 64 bitów, wykorzystując klucze o długości od 32 do 448 bitów. Blowfish, z uwagi na to, że jest algorytmem symetrycznym, nadaje się do szyfrowania dużych ilości danych, np. przesyłanych przez internet. Jest to algorytm wydajny i odporny na wiele znanych ataków, dlatego też jest bardzo często wykorzystywany we współczesnych systemach informatycznych. **Zatem, odpowiedź ta jest poprawna.**\n\n*   **DES:** DES (Data Encryption Standard) to historyczny algorytm szyfrowania symetrycznego, opracowany na początku lat 70. XX wieku przez IBM. Algorytm ten operuje na 64-bitowych blokach danych z użyciem 56-bitowego klucza. Ze względu na zbyt krótką długość klucza DES jest obecnie uważany za niebezpieczny i nie jest zalecane jego używanie we współczesnych systemach. Został zastąpiony algorytmem AES. Niemniej, jest on przykładem algorytmu symetrycznego, ponieważ używa tego samego klucza do szyfrowania i deszyfrowania danych. **Zatem, odpowiedź ta jest poprawna.**\n\n*   **ElGamal:** ElGamal jest algorytmem szyfrowania asymetrycznego, opartym na trudności obliczeniowej problemu logarytmu dyskretnego. Algorytmy asymetryczne wykorzystują parę kluczy – klucz publiczny, który jest ogólnodostępny i służy do szyfrowania, oraz klucz prywatny, który jest trzymany w sekrecie i służy do deszyfrowania. ElGamal, z uwagi na wykorzystanie klucza publicznego do szyfrowania a prywatnego do odszyfrowania, nie jest algorytmem symetrycznym. **Zatem, odpowiedź ta jest niepoprawna.**\n\n*   **żadne z powyższych:** Ponieważ Blowfish i DES są algorytmami symetrycznymi, stwierdzenie, że \"żadne z powyższych\" nie jest algorytmem symetrycznym, jest nieprawdziwe. **Zatem, odpowiedź ta jest niepoprawna.**\n\nW praktyce, algorytmy symetryczne, takie jak Blowfish i DES, wykorzystuje się do szyfrowania dużych plików lub strumieni danych, gdzie szybkość operacji szyfrowania ma znaczenie. Z kolei ElGamal lub RSA, ze względu na asymetryczność kluczy, używa się na przykład do szyfrowania kluczy sesyjnych, wykorzystywanych potem przez algorytmy symetryczne. Przykładowo, gdy przesyłamy zaszyfrowane dane przy pomocy protokołu SSL (np. przy połączeniu z zabezpieczoną stroną www), w pierwszym etapie przesyłany jest klucz symetryczny, zaszyfrowany kluczem publicznym serwera. Później, cała wymiana danych odbywa się już przy użyciu algorytmu symetrycznego z ustalonym kluczem sesji."
    },
    {
        "questionId": 246,
        "title": "Protokol IPv6:",
        "answers": [
            {
                "text": "oferuje mechanizm AH w celu zapewnienia autentycznosci",
                "isCorrect": true
            },
            {
                "text": "oferuje mechanizm ESP w celu zapewnienia poufnosci",
                "isCorrect": true
            },
            {
                "text": "nie oferuje AH, jako ze jego zadania powiela ESP",
                "isCorrect": false
            },
            {
                "text": "nie oferuje zadnych mechanizmow bezpieczenstwa (wymaga dodatkowej implementacji IPsec)",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół IPv6, w przeciwieństwie do IPv4, posiada wbudowane mechanizmy bezpieczeństwa w postaci protokołów IPsec, a dokładniej **AH** (Authentication Header) i **ESP** (Encapsulating Security Payload). IPsec, czyli _Internet Protocol Security_, jest zbiorem protokołów zapewniających bezpieczeństwo komunikacji w warstwie sieciowej modelu OSI. Te mechanizmy są integralną częścią IPv6, co oznacza, że każde wdrożenie IPv6 **powinno** korzystać z nich.\n\n*   **Odpowiedź: \"oferuje mechanizm AH w celu zapewnienia autentyczności\" jest prawidłowa.** Protokół **AH (Authentication Header)** ma za zadanie zapewnić **autentyczność** i **integralność** pakietu IP. Autentyczność w tym kontekście oznacza pewność, że pakiet został wysłany przez tego nadawcę, za którego się podaje, a integralność, że treść pakietu nie została zmodyfikowana w trakcie transmisji. AH realizuje te cele poprzez dodanie do pakietu skrótu kryptograficznego obliczonego na podstawie jego zawartości oraz klucza, znanego jedynie nadawcy i odbiorcy. Przykładem zastosowania może być ochrona komunikacji serwera DNS. Adres serwera DNS jest daną jawną i nie trzeba jej szyfrować, jednak ochrona przed podszyciem oraz zmianą jest bardzo ważna. Stąd protokół AH jest wystarczającym mechanizmem do zabezpieczenia autentyczności odpowiedzi z serwera DNS.\n\n*   **Odpowiedź: \"oferuje mechanizm ESP w celu zapewnienia poufności\" jest prawidłowa.** Protokół **ESP (Encapsulating Security Payload)** ma za zadanie zapewnić **poufność** i **integralność** pakietu. Poufność jest osiągana poprzez zaszyfrowanie danych pakietu. ESP, podobnie jak AH, może również generować skróty kryptograficzne, zapewniając integralność danych. ESP jest wykorzystywany gdy dane przesyłane między dwoma punktami muszą być chronione przed nieautoryzowanym odczytem, przykładem może być utworzenie kanału VPN, w którym komunikacja jest chroniona przed niepowołanym odczytem.\n\n*   **Odpowiedź: \"nie oferuje AH, jako ze jego zadania powiela ESP\" jest nieprawidłowa.** Zarówno AH jak i ESP są protokołami stanowiącymi integralną część IPsec, a co za tym idzie są elementem standardu IPv6. AH i ESP mają różne przeznaczenia, choć ich funkcje częściowo się nakładają. AH jest protokołem odpowiedzialnym za autentyczność, natomiast ESP zapewnia poufność.\n    *   Chociaż ESP może też zapewniać integralność, to w pewnych sytuacjach (np. w sieciach o niskim poziomie zagrożeń) wystarczająca jest sama ochrona autentyczności oferowana przez AH.\n\n*   **Odpowiedź: \"nie oferuje zadnych mechanizmow bezpieczenstwa (wymaga dodatkowej implementacji IPsec)\" jest nieprawidłowa.** Jak wspomniano na początku, IPsec nie jest opcjonalnym dodatkiem, lecz integralnym elementem IPv6. AH i ESP to protokoły, które tworzą IPsec i są dostępne dla każdej stacji implementującej stos protokołów IPv6.\n    *   Oczywiście, można wyłączyć te mechanizmy, ale nie znikają one z implementacji protokołu, tak jak miało to miejsce z protokołem IPv4.\n\n**Podsumowanie**: W praktyce oznacza to, że każdy pakiet IPv6 może być zabezpieczony, lub nie, w zależności od potrzeb oraz możliwości konfiguracyjnych systemów. Protokół IPsec integruje się z IPv6 dając do dyspozycji protokoły AH i ESP z których administrator sieci może korzystać."
    },
    {
        "questionId": 247,
        "title": "Ktora zasada realizacji zabezpieczen wymaga konsekwentnego zastosowania odpowiedniego mechanizmu ochrony wobec wszystkich wykorzystywanych protokolow aplikacyjnych:",
        "answers": [
            {
                "text": "spojnosci poziomej",
                "isCorrect": true
            },
            {
                "text": "spojnosci pionowej",
                "isCorrect": false
            },
            {
                "text": "naturalnego styku",
                "isCorrect": false
            },
            {
                "text": "obligatoryjnej kontroli dostepu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Zasada spójności poziomej w bezpieczeństwie systemów komputerowych odnosi się do konieczności zastosowania mechanizmów ochrony w sposób konsekwentny i jednolity na tym samym poziomie systemu. Oznacza to, że jeśli zabezpieczamy komunikację w warstwie aplikacji, musimy objąć ochroną wszystkie używane w tej warstwie protokoły, a nie tylko wybrane. Innymi słowy, wszystkie komponenty na tym samym poziomie abstrakcji powinny być zabezpieczone z podobną intensywnością.\n\n**spójności poziomej** - Jest to **poprawna** odpowiedź. Zasada spójności poziomej wymaga, aby wszystkie protokoły aplikacyjne (np. HTTP, SMTP, FTP) były zabezpieczone na równym poziomie. Zaniedbanie choćby jednego z nich tworzy furtkę dla potencjalnego ataku. Na przykład, jeśli chronimy hasła przesyłane przez HTTP za pomocą szyfrowania, ale zapomnimy o analogicznej ochronie haseł w protokole FTP, napastnik będzie mógł wykorzystać łatwiejszy do ataku, niezabezpieczony protokół FTP.\n**spójności pionowej** - Jest to **niepoprawna** odpowiedź. Spójność pionowa odnosi się do konsekwentnego stosowania zabezpieczeń na różnych poziomach systemu. Mówi ona o tym, że jeżeli zabezpieczamy dostęp do danych na poziomie aplikacji, to równie starannie powinniśmy zabezpieczyć dostęp do tych danych na poziomie systemu operacyjnego. Jest to ważna zasada, ale nie ta, o którą pyta pytanie.\n**naturalnego styku** - Jest to **niepoprawna** odpowiedź. Zasada naturalnego styku mówi o tym, że systemy bezpieczeństwa nie powinny utrudniać pracy użytkownikom. Mechanizmy zabezpieczeń powinny być przejrzyste i intuicyjne w obsłudze, aby użytkownicy nie próbowali ich omijać, co osłabiłoby poziom bezpieczeństwa całego systemu. Ta zasada dotyczy użyteczności, a nie poziomego zabezpieczenia protokołów.\n**obligatoryjnej kontroli dostepu** - Jest to **niepoprawna** odpowiedź. Obligatoryjna kontrola dostępu (MAC) jest to model kontroli dostępu, w którym uprawnienia nie są przyznawane na podstawie uznania właściciela zasobu, lecz na podstawie z góry określonych reguł, narzuconych przez administratora systemu. Jest to podejście do kontroli dostępu, a nie do poziomej spójności zabezpieczeń.\n\nPodsumowując, zasada spójności poziomej to kluczowy element projektowania bezpiecznych systemów. Bez jej przestrzegania system, nawet z silnymi mechanizmami ochrony w niektórych miejscach, będzie łatwy do zaatakowania przez komponenty o pominiętej lub słabej ochronie. Konsekwentne zabezpieczenie wszystkich protokołów aplikacyjnych to podstawa bezpiecznego działania każdego systemu."
    },
    {
        "questionId": 248,
        "title": "Moduly PAM (Pluggable Authentication Modules) umozliwiaja:",
        "answers": [
            {
                "text": "oddzielenie konfiguracji procesu uwierzytelniania od kodu aplikacji",
                "isCorrect": true
            },
            {
                "text": "integracje uwierzytelniania uzytkownikow sieci pomiedzy systemami Windows i Linux",
                "isCorrect": true
            },
            {
                "text": "dostep serwera uslugi www (np. z systemu operacyjnego MS Windows w srodowisku domenowym) do zewnetrznych zrodel danych uwierzytelniajacych, np. bazy danych",
                "isCorrect": false
            },
            {
                "text": "implementuje filtry Bayesa do ochrony poczty przed niepozadanymi przesylkami",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm PAM (Pluggable Authentication Modules) to architektura w systemach Linux/Unix, która umożliwia elastyczne zarządzanie uwierzytelnianiem, autoryzacją i obsługą sesji. Jego głównym celem jest oddzielenie specyficznej logiki procesu uwierzytelniania od kodu samych aplikacji. Oznacza to, że aplikacja która wymaga np. uwierzytelniania użytkownika, nie musi sama obsługiwać tego procesu. Zamiast tego wywołuje funkcję biblioteki PAM przekazując jej dane użytkownika, nazwę usługi i żądanie wykonania. Resztą (np. w jaki sposób ma być zweryfikowane hasło) zajmuje się biblioteka PAM. Modułowa architektura PAM umożliwia łatwe dostosowanie metod autoryzacji i uwierzytelnienia bez konieczności modyfikacji kodu samej aplikacji. PAM korzysta z modułów (tzw. wtyczek), które implementują konkretną metodę uwierzytelniania np. na podstawie danych w lokalnym pliku /etc/passwd, bazie danych LDAP, Kerberos czy z wykorzystaniem tokenów jednorazowych. Mechanizm ten wykorzystuje zestaw plików konfiguracyjnych, które pozwalają na załączenie/wyłączenie danego modułu dla wybranej usługi. Ustawienia te pozwalają na dostosowywanie sposobu uwierzytelnienia w zależności od typu usługi (np. dostęp z lokalnego terminala lub zdalny dostęp przez ssh). Konfigurację modułów PAM dla każdej usługi (np. login, sshd, sudo) możemy znaleźć w katalogu _/etc/pam.d/_.\n \n**Odpowiedź 1: \"oddzielenie konfiguracji procesu uwierzytelniania od kodu aplikacji\"** - Jest to **poprawna odpowiedź**. PAM jest właśnie architekturą, która dąży do oddzielenia kodu autoryzacji i uwierzytelniania od logiki danej aplikacji. Aplikacja wywołuje bibliotekę PAM i nie interesuje się, w jaki sposób dane do logowania użytkownika zostaną sprawdzone. To podejście modularne ma wiele zalet, chociażby w przyszłości zmianę procedury uwierzytelniania można wprowadzić w jednym miejscu nie zmieniając każdej aplikacji, która wykorzystuje system uwierzytelniania. Na przykład chcemy użyć bazy danych LDAP zamiast tradycyjnej metody hasłowej wystarczy jedynie edytować plik konfiguracyjny i załadować moduł _pam_ldap_, nie zmieniając samego kodu aplikacji np. _sshd_.\n \n**Odpowiedź 2: \"integracje uwierzytelniania uzytkownikow sieci pomiedzy systemami Windows i Linux\"** - Jest to **poprawna odpowiedź**. Mechanizmy PAM nie zapewniają tego wprost, jednak poprzez różne wtyczki można uzyskać podobny efekt. Na przykład, chcąc zintegrować Linux z infrastrukturą Active Directory systemu Windows można wykorzystać moduł _pam_winbind_ (wymagający dodatkowej konfiguracji w systemie Linux oraz serwerze Windows) i dzięki temu użytkownicy systemu Windows mogą logować się również w systemie Linux z wykorzystaniem tych samych haseł. Jest to przykład integracji w oparciu o bazę uwierzytelniającą zdefiniowaną w domenie Windows. Innym przykładem może być baza katalogowa LDAP, która może być wykorzystana jako miejsce składowania i weryfikowania użytkowników zarówno dla systemu Linux jak i Windows. Wystarczy tylko w systemie Linux użyć wtyczki _pam_ldap_ i w systemie Windows użyć _active directory_ w celu zintegrowania obu systemów. PAM nie narzuca żadnych rozwiązań, co daje nam bardzo dużą swobodę implementacji i tworzenia dowolnego rozwiązania. \n \n**Odpowiedź 3: \"dostep serwera uslugi www (np. z systemu operacyjnego MS Windows w srodowisku domenowym) do zewnetrznych zrodel danych uwierzytelniajacych, np. bazy danych\"** - Jest to **niepoprawna odpowiedź**. PAM jest mechanizmem dostępnym w systemie Linux/Unix. Może on jednak służyć, poprzez odpowiednie wtyczki, do uwierzytelnienia serwera www(np. Apache) ale działającego na serwerze Linux, do bazy danych np. MySQL. Natomiast system Windows nie wykorzystuje mechanizmów PAM, posiada swoje własne mechanizmy autoryzacji i uwierzytelniania i nie ma żadnego wpływu na działanie systemu PAM w systemach Linux/Unix.  W systemie Windows usługa WWW, czyli IIS ma swój własny system wtyczek uwierzytelniających, np. z wykorzystaniem bazy LDAP, SQL Server i innych ale nie PAM.\n\n**Odpowiedź 4: \"implementuje filtry Bayesa do ochrony poczty przed niepozadanymi przesylkami\"** - Jest to **niepoprawna odpowiedź**. Mechanizm PAM nie posiada takich możliwości, jego zadaniem jest tylko i wyłącznie obsługa procedury uwierzytelniania użytkownika. Filtry Bayesa w systemie Linux zaimplementowane są w aplikacjach obsługujących serwery pocztowe. System PAM nie ma żadnego wpływu na działanie usług pocztowych, jeśli chodzi o filtrowanie SPAMu."
    },
    {
        "questionId": 249,
        "title": "Okresl prawidlowa kolejnosc pelnej sekwencji odwolan klienta do serwerow w przypadku dostepu do uslugi SMTP w srodowisku Kerberos:",
        "answers": [
            {
                "text": "serwer TGS  - serwer AS  - serwer TGS - serwer SMTP",
                "isCorrect": false
            },
            {
                "text": "serwer AS  - serwer TGS - serwer SMTP - serwer AS",
                "isCorrect": false
            },
            {
                "text": "serwer AS - serwer TGS - serwer SMTP",
                "isCorrect": true
            },
            {
                "text": "serwer TGS - serwer AS - serwer SMTP",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół Kerberos to protokół uwierzytelniania oparty na kluczach symetrycznych, szeroko stosowany w środowiskach korporacyjnych i przedsiębiorstwach. Jego celem jest umożliwienie bezpiecznego dostępu do usług w sieci poprzez uwierzytelnienie użytkownika i udzielenie mu tymczasowych uprawnień, tzw. biletów (_tickets_). W protokole Kerberos wyróżniamy trzy główne komponenty: serwer uwierzytelniania (AS), serwer biletów (TGS) oraz serwer usługi (w tym przypadku SMTP).\n\n**Poprawna sekwencja interakcji klienta z serwerami w środowisku Kerberos podczas dostępu do usługi SMTP jest następująca: serwer AS - serwer TGS - serwer SMTP.**\n\n*   **Serwer AS (Authentication Server)**: Pierwszym krokiem jest kontakt klienta z serwerem AS. Serwer AS jest odpowiedzialny za początkowe uwierzytelnienie klienta. Klient wysyła żądanie uwierzytelnienia do AS, podając swoje identyfikatory (np. nazwę użytkownika). Serwer AS, po sprawdzeniu identyfikatorów, generuje bilet TGT (_Ticket Granting Ticket_) i szyfruje go kluczem użytkownika. Ten bilet jest używany do późniejszych żądań o dostęp do innych usług, bez potrzeby ponownego podawania hasła użytkownika. Dodatkowo serwer AS zwraca klucz sesyjny, który jest wspólny dla klienta i serwera TGS.\n*   **Serwer TGS (Ticket Granting Server)**: Kolejnym krokiem jest kontakt klienta z serwerem TGS, używając otrzymanego biletu TGT od AS. Klient wysyła żądanie o dostęp do konkretnej usługi (w tym przypadku SMTP) wraz z biletem TGT. Serwer TGS sprawdza poprawność biletu TGT oraz autoryzuje użytkownika do dostępu do usługi SMTP. Serwer TGS generuje bilet dostępu do usługi SMTP i szyfruje go kluczem serwera SMTP. Dodatkowo serwer TGS przesyła do klienta klucz sesyjny, który jest wspólny dla klienta i serwera SMTP.\n*   **Serwer SMTP**: Ostatnim etapem jest kontakt klienta z serwerem SMTP. Klient przesyła bilet dostępu do usługi SMTP otrzymany od serwera TGS. Serwer SMTP, po zweryfikowaniu biletu, udziela klientowi dostępu do usługi. Komunikacja między klientem a serwerem SMTP jest szyfrowana kluczem sesyjnym uzgodnionym z TGS.\n\n**Analiza niepoprawnych odpowiedzi:**\n\n*   **\"serwer TGS - serwer AS - serwer TGS - serwer SMTP\"**: Ta sekwencja jest niepoprawna, ponieważ nie ma sensu, aby klient kontaktował się z serwerem TGS przed uzyskaniem biletu TGT od serwera AS. Serwer TGS potrzebuje biletu TGT, który jest wydawany dopiero przez AS po uwierzytelnieniu użytkownika. Powtórne żądanie z serwera TGS przed uzyskaniem dostępu do serwera SMTP jest nadmiarowe i niepotrzebne. W praktyce, klient nie może zdobyć biletu do SMTP przed zdobyciem biletu TGT od AS.\n*   **\"serwer AS - serwer TGS - serwer SMTP - serwer AS\"**: Ta sekwencja jest niepoprawna, ponieważ klient po uzyskaniu biletu do serwera SMTP nie ma potrzeby kontaktować się ponownie z serwerem AS. Serwer AS jest potrzebny jedynie przy pierwszym uwierzytelnieniu i uzyskaniu biletu TGT. Ta sekwencja jest nieefektywna i wskazuje na nie zrozumienie cyklu życia biletów. W praktyce klient, posiadając bilet do usługi SMTP, nie ma potrzeby kontaktować się ponownie z serwerem AS, co podnosi efektywność protokołu.\n*   **\"serwer TGS - serwer AS - serwer SMTP\"**: Ta sekwencja jest niepoprawna, ponieważ nie ma sensu, aby klient kontaktował się z serwerem TGS przed uzyskaniem biletu TGT od serwera AS. Takie żądanie serwera TGS do serwera AS jest niepotrzebne, ponieważ bilet TGT zawiera informacje o kliencie, które TGS może zweryfikować bez udziału serwera AS. W praktyce takie zachowanie nie jest częścią protokołu Kerberos.\n\n**Praktyczny przykład:**\nWyobraźmy sobie sieć firmową, gdzie pracownicy logują się do komputerów przy użyciu Kerberos. Gdy pracownik chce wysłać e-maila, jego aplikacja pocztowa kontaktuje się najpierw z serwerem AS aby zdobyć bilet TGT. Następnie, korzystając z TGT kontaktuje się z serwerem TGS, aby zdobyć bilet dla serwera SMTP. Na końcu, używając biletu SMTP, może bezpiecznie wysłać e-mail. Ta sekwencja chroni hasła użytkowników i przesyła tylko tymczasowe bilety, co minimalizuje ryzyko nadużyć."
    },
    {
        "questionId": 250,
        "title": "Ktore protokoly umozliwiaja propagacje portow w tunelu kryptograficznym?:",
        "answers": [
            {
                "text": "ESP",
                "isCorrect": false
            },
            {
                "text": "SSH",
                "isCorrect": true
            },
            {
                "text": "SSL",
                "isCorrect": true
            },
            {
                "text": "AH",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSL (Secure Sockets Layer) oraz SSH (Secure Shell) umożliwiają tworzenie tuneli kryptograficznych, które mogą być wykorzystane do propagacji portów. Propagacja portów, znana również jako przekierowanie portów lub tunelowanie portów, to technika, która umożliwia przekierowanie ruchu z określonego portu na lokalnym komputerze do innego portu na zdalnym serwerze, a często również do innego serwera za danym hostem. W przypadku tunelowania kryptograficznego cały ruch jest dodatkowo szyfrowany, co chroni przed przechwyceniem i analizą transmitowanych danych.\n\n**ESP (Encapsulating Security Payload)**, będący protokołem z rodziny IPsec, służy do zapewnienia poufności oraz autentyczności komunikacji IP. ESP nie oferuje jednak mechanizmu propagacji portów. Protokół ten jest wykorzystywany do szyfrowania i ochrony danych na poziomie warstwy sieciowej, jednak sam w sobie nie realizuje przekierowania portów. ESP jest często wykorzystywany jako element składowy tuneli VPN IPsec, a więc protokół ten może być użyty w parze z mechanizmem tunelowania.\n\n**SSH (Secure Shell)** to protokół warstwy aplikacji, który pozwala na bezpieczne (szyfrowane) połączenie z komputerem zdalnym, w tym zdalne wykonywanie poleceń w terminalu. SSH oferuje również funkcję przekierowywania portów, która umożliwia kierowanie ruchu z określonego portu w lokalnym systemie przez zaszyfrowany tunel do określonego portu na systemie zdalnym. Klient SSH nasłuchuje na lokalnym porcie i wszystkie próby połączenia do tego portu kieruje przez tunel kryptograficzny na serwer SSH który odbiera taki ruch, serwer SSH dalej może przekierować ten ruch na zdefiniowany port docelowy, zdefiniowany podczas tworzenia tunelu. Na przykład użytkownik, który połączy się przez SSH do bramy, może przekierować ruch z portu 8080 na swoim komputerze do portu 80 serwera HTTP w sieci wewnętrznej. Z punktu widzenia użytkownika program (przeglądarka) łączy się do portu 8080 lokalnego komputera, ale faktycznie poprzez tunel SSH przeglądarka widzi zasoby serwera HTTP działającego w sieci za bramą.\n\n**SSL (Secure Sockets Layer)**, obecnie częściej znany jako TLS (Transport Layer Security), to protokół, który służy do szyfrowania komunikacji na poziomie warstwy transportowej. W przypadku SSL w wersji 3.0. i protokołu TLS w wersji 1.0, tunelowanie portów najczęściej polega na opakowaniu całej komunikacji protokołu warstwy aplikacji w szyfrowaną warstwę. Przeglądarka HTTP wykorzystuje protokół HTTPS, który oznacza połączenie do serwera www poprzez tunel SSL. Istnieją również inne protokoły wykorzystujące SSL np. POP3S(port 995). Mechanizm tunelowania z SSL oferuje podobną koncepcje jak mechanizm port forwarding w protokole SSH. Istnieją również aplikacje tunelujące dowolny ruch z użyciem protokołu SSL/TLS np. program Stunnel. Takie aplikacje lokalnie odbierają ruch, a następnie przesyłają go zaszyfrowanym tunelem SSL do hosta docelowego, który odbiera ten zaszyfrowany ruch i rozpakowuje go, tak aby można było wykorzystać dane z tego tunelu.\n\n**AH (Authentication Header)**, podobnie jak ESP, jest protokołem z rodziny IPsec, wykorzystywanym do zapewnienia autentyczności i integralności pakietów IP. AH również nie oferuje mechanizmu propagacji portów. Jest to protokół warstwy sieciowej i sam w sobie nie realizuje przekierowania portów. Mechanizmy AH i ESP często działają w parze tworząc tunel VPN ale same w sobie nie tworzą tunelu z możliwością propagacji portów. Protokół AH skupia się jedynie na ochronie nagłówków i pakietów przed nieautoryzowaną modyfikacją ale nie oferuje szyfrowania przesyłanych danych."
    },
    {
        "questionId": 251,
        "title": "Standard SASL (Simple Authentication and Security Layer) umozliwi:a",
        "answers": [
            {
                "text": "rozszerzenie mechanizmu uwierzytelniania protokolu SMTP o mechanizm hasel jednorazowych",
                "isCorrect": true
            },
            {
                "text": "rozszerzenie mechanizmu uwierzytelniania protokolu IMAP o wspolprace z systemem Kerberos",
                "isCorrect": true
            },
            {
                "text": "rozszerzenie mechanizmu kontroli dostepu do katalogu domowego o listy ACL",
                "isCorrect": false
            },
            {
                "text": "redukcje mechanizmu kontroli dostepu do plikow w Windows do postaci rwx",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "SASL (Simple Authentication and Security Layer) jest frameworkiem, który umożliwia rozszerzenie mechanizmów uwierzytelniania w różnych protokołach sieciowych, takich jak SMTP (Simple Mail Transfer Protocol) i IMAP (Internet Message Access Protocol). SASL nie jest protokołem samym w sobie, ale raczej standardowym sposobem dodawania obsługi różnych mechanizmów uwierzytelniania.  Definiuje on interfejs pomiędzy aplikacją (np. serwerem poczty) a bibliotekami uwierzytelniającymi. Pozwala to na elastyczną zmianę metody uwierzytelniania bez modyfikacji samej aplikacji.\n\n**Odpowiedź 1: \"rozszerzenie mechanizmu uwierzytelniania protokolu SMTP o mechanizm hasel jednorazowych\" jest poprawna.**  SASL umożliwia dodanie obsługi haseł jednorazowych (OTP - One-Time Passwords) do SMTP. Klasyczne uwierzytelnianie SMTP jest słabe, hasło jest przesyłane w postaci jawnej(base64). Dzięki SASL serwer SMTP może oferować nowoczesne, bardziej bezpieczne metody, np. hasła jednorazowe, które są ważne tylko raz, eliminując ryzyko ponownego użycia hasła przechwyconego przez intruza. Przykładowo, administrator serwera pocztowego, chcąc zwiększyć bezpieczeństwo,  może włączyć  wtyczkę SASL do obsługi haseł jednorazowych, wymagając od użytkowników dodatkowego kodu przy logowaniu.\n\n**Odpowiedź 2: \"rozszerzenie mechanizmu uwierzytelniania protokolu IMAP o wspolprace z systemem Kerberos\" jest poprawna.** SASL umożliwia również integrację IMAP z Kerberosem. IMAP standardowo używa prostej metody uwierzytelniania, polegającej na przesyłaniu hasła w postaci jawnej(base64).  Kerberos jest mechanizmem uwierzytelniania opartym o bilety, oferujący znacznie wyższy poziom bezpieczeństwa, szczególnie w dużych infrastrukturach korporacyjnych.  Używając SASL, serwer IMAP może delegować uwierzytelnianie do serwera Kerberos, a użytkownicy mogą logować się do poczty za pomocą tych samych biletów Kerberos, których używają do dostępu do innych zasobów sieciowych (np. plików).  To eliminuje konieczność zapamiętywania wielu haseł i centralizuje zarządzanie tożsamością użytkowników.\n\n**Odpowiedź 3: \"rozszerzenie mechanizmu kontroli dostepu do katalogu domowego o listy ACL\" jest niepoprawna.** SASL skupia się na uwierzytelnianiu (potwierdzeniu tożsamości użytkownika), a nie na autoryzacji (określeniu, do czego użytkownik ma dostęp). Listy ACL (Access Control Lists) służą do kontrolowania dostępu do zasobów (np. plików i katalogów), czyli do autoryzacji. SASL  nie ma bezpośredniego wpływu na mechanizmy ACL. Te dwa mechanizmy działają w innych kontekstach bezpieczeństwa. System operacyjny wykorzystuje ACL do kontroli dostępu do plików, a aplikacja wykorzystuje SASL do weryfikacji tożsamości użytkownika, który żąda dostępu.\n\n**Odpowiedź 4: \"redukcje mechanizmu kontroli dostepu do plikow w Windows do postaci rwx\" jest niepoprawna.** SASL w ogóle nie wpływa na mechanizmy kontroli dostępu do plików systemu operacyjnego, na przykład w systemie Windows, gdzie  uprawnienia do plików oparte są na rozbudowanym mechanizmie ACL, które umożliwiają określenie wielu szczegółowych uprawnień i kontroli dostępu nie tylko dla pojedynczego użytkownika, ale również dla całych grup oraz list użytkowników. SASL  nie wprowadza zmian w systemie kontroli dostępu plików. Redukcja kontroli dostępu do plików do postaci rwx(odczyt, zapis, wykonywanie) jest charakterystyczna dla systemu Linux/Unix i starszych systemów Windows(FAT16/32) i nie ma to związku z SASL."
    },
    {
        "questionId": 252,
        "title": "Ktore zdania poprawnie opisuja proces uwierzytelniania w usludze pocztowej?:",
        "answers": [
            {
                "text": "standard ESMTP umozliwia uwierzytelnianie metoda zawolanie-odzew",
                "isCorrect": true
            },
            {
                "text": "standard SMTP umozliwia uwierzytelnianie metoda zawolanie-odzew",
                "isCorrect": false
            },
            {
                "text": "w standardzie SMTP serwery uwierzytelniane sa na podstawie adresow",
                "isCorrect": true
            },
            {
                "text": "standard ESMTP oferuje mechanizmy uwierzytelniania SASL i TLS",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół SMTP (Simple Mail Transfer Protocol) to podstawowy protokół używany do przesyłania wiadomości e-mail między serwerami. Oryginalny SMTP nie zawierał żadnych wbudowanych mechanizmów uwierzytelniania. Oznacza to, że serwery SMTP w podstawowym schemacie nie weryfikują, czy nadawca wiadomości jest rzeczywiście uprawniony do jej wysłania. Protokół ESMTP (Extended Simple Mail Transfer Protocol) jest rozszerzeniem protokołu SMTP, które dodaje nowe funkcje, takie jak właśnie metody uwierzytelniania oraz szyfrowanie.\n\n*   **\"standard ESMTP umozliwia uwierzytelnianie metoda zawolanie-odzew\"** - **PRAWDA**. ESMTP, poprzez rozszerzenia takie jak AUTH, umożliwia uwierzytelnianie za pomocą mechanizmu zawolanie-odzew (ang. _challenge-response_). Polega to na tym, że serwer wysyła losowy ciąg znaków (wyzwanie) do klienta, a klient musi użyć hasła i funkcji skrótu, aby odesłać prawidłową odpowiedź. Taki mechanizm pozwala uniknąć przesłania hasła w postaci jawnej. Praktyczny przykład: klient poczty żądający wysłania maila, zostaje poproszony o hasło przez serwer, jednak hasło nie jest przesyłane jawnie, tylko w postaci odpowiedzi na wyzwanie serwera.\n\n*   **\"standard SMTP umozliwia uwierzytelnianie metoda zawolanie-odzew\"** - **FAŁSZ**. Protokół SMTP sam w sobie nie oferuje mechanizmu uwierzytelniania typu zawolanie-odzew. Uwierzytelnianie, jeśli jest, opiera się zazwyczaj o sprawdzenie adresu IP hosta nadawcy, co nie chroni przed sfałszowaniem adresu lub podszyciem się pod autoryzowany host. SMTP przesyła wiadomości e-mail bez weryfikacji tożsamości nadawcy – polega na tym, że serwer na podstawie swojej polityki zaufania do serwerów przesyłających do niego listy, albo na podstawie adresu IP podejmuje decyzję o przyjęciu lub odrzuceniu listu. \n\n*   **\"w standardzie SMTP serwery uwierzytelniane sa na podstawie adresow\"** - **PRAWDA**. Chociaż SMTP nie ma wbudowanych zaawansowanych mechanizmów uwierzytelniania, serwery SMTP często opierają się na zaufaniu do adresów IP (lub zakresów adresów IP) serwerów, które łączą się z nimi. Nie jest to jednak silne uwierzytelnianie. Serwer może zdefiniować, że połączenia z określonych adresów IP są autoryzowane. Nie stanowi to jednak pewnej metody. Podszycie się pod zaufany adres nie stanowi dużego problemu w świecie komputerów, ze względu na łatwość manipulacji nagłówkami pakietów. Serwer może sprawdzić, czy dany adres należy do zakresu adresów które mają prawo do niego wysyłać wiadomości email.\n\n*   **\"standard ESMTP oferuje mechanizmy uwierzytelniania SASL i TLS\"** - **PRAWDA**. ESMTP rozszerza protokół SMTP, dodając opcję  weryfikacji tożsamości użytkowników (uwierzytelniania) i  szyfrowania połączenia z użyciem protokołu TLS. SASL (Simple Authentication and Security Layer) to ramka dla mechanizmów uwierzytelniania, a TLS (Transport Layer Security) jest protokołem kryptograficznym zapewniającym poufność komunikacji. Przykładowo, klient poczty e-mail używa rozszerzenia ESMTP z SASL do uwierzytelnienia się na serwerze poczty, który następnie  przesyła wiadomości email z użyciem bezpiecznego i zaszyfrowanego połączenia opartego o protokół TLS."
    },
    {
        "questionId": 253,
        "title": "Ochrone SYSKEY wprowadzono w systemie MS Windows w celu:",
        "answers": [
            {
                "text": "szyfrowania plikow uzytkownikow w systemie NTFS",
                "isCorrect": false
            },
            {
                "text": "wzmocnionego szyfrowania postaci hash hasel uzytkownikow",
                "isCorrect": true
            },
            {
                "text": "odszyfrowania plikow przez systemowa usluge odzyskiwania plikow",
                "isCorrect": false
            },
            {
                "text": "szyfrowania plikow systemowych w systemie NTFS",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Ochrona SYSKEY w systemie MS Windows dotyczy wzmocnienia bezpieczeństwa przechowywanych skrótów haseł użytkowników. W systemach Windows, hasła nie są przechowywane w postaci jawnej, lecz w postaci skrótów, tzw. hash. Hash jest wynikiem jednokierunkowej funkcji kryptograficznej działającej na haśle, co uniemożliwia odtworzenie hasła z jego skrótu. Problem polega na tym, że nawet skrót hasła, gdy zostanie pozyskany przez intruza, np. z wykradzionego pliku SAM, może być poddany atakowi brute force lub słownikowemu. Atak ten polega na wygenerowaniu skrótów wielu potencjalnych haseł, a następnie porównaniu tak wygenerowanych skrótów z posiadanym skrótem hasła ofiary.  Ochrona SYSKEY jest mechanizmem, który szyfruje skróty haseł w rejestrze, sprawiając że skrót jest bezużyteczny bez znajomości odpowiedniego klucza. Ochrona SYSKEY jest zatem dodatkowym zabezpieczeniem dla przechowywanych haseł, mającym na celu utrudnienie ich złamania, nawet w przypadku wykradzenia baz danych skrótów haseł użytkowników.\n\n*   **\"szyfrowania plików użytkowników w systemie NTFS\"** - Ta odpowiedź jest niepoprawna. SYSKEY nie służy do szyfrowania plików,  lecz do ochrony haseł. Szyfrowanie plików to funkcja EFS (Encrypting File System) w systemie NTFS, a nie SYSKEY. Wyobraźmy sobie, że mamy dysk z danymi zaszyfrowanymi EFS, bez znajomości hasła użytkownika dysk ten jest bezużyteczny.\n*   **\"wzmocnionego szyfrowania postaci hash haseł użytkowników\"** - Ta odpowiedź jest poprawna. SYSKEY to mechanizm, który ma na celu szyfrowanie postaci skrótów haseł, utrudniając tym samym ich złamanie. Bez SYSKEY atakujący posiadający nawet skrót hasła z pliku SAM (Security Account Manager) mógłby łatwiej odgadnąć hasło, teraz z SYSKEY musi jeszcze pozyskać klucz SYSKEY lub metodą brute force atakować skrót z wykorzystaniem klucza SYSKEY. Utrudnienie jest zatem znaczne.\n*   **\"odszyfrowania plików przez systemową usługę odzyskiwania plików\"** - Ta odpowiedź jest niepoprawna. Chociaż SYSKEY ma swoją rolę w procesie logowania, to nie ma nic wspólnego z funkcją odzyskiwania plików w systemie Windows. Funkcja odzyskiwania plików to funkcja usługi systemowej i jest to coś innego niż funkcja SYSKEY. \n*   **\"szyfrowania plików systemowych w systemie NTFS\"** - Ta odpowiedź jest niepoprawna. SYSKEY nie służy do szyfrowania plików systemowych, lecz do szyfrowania postaci hash haseł. Chociaż dane są przechowywane w rejestrze systemu to nadal nie jest to szyfrowanie plików."
    },
    {
        "questionId": 254,
        "title": "Skrot KDC w systemie Kerberos oznacza:",
        "answers": [
            {
                "text": "Key Distribution Center",
                "isCorrect": true
            },
            {
                "text": "Kerberos Domain Controller",
                "isCorrect": false
            },
            {
                "text": "Kerberos Directory Center",
                "isCorrect": false
            },
            {
                "text": "Kerberos Designated Certificate",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "KDC, czyli Key Distribution Center, to kluczowy element protokołu Kerberos. Kerberos jest protokołem uwierzytelniania, który pozwala na bezpieczne uwierzytelnianie użytkowników i usług w sieci komputerowej. KDC pełni rolę zaufanej trzeciej strony, która wydaje bilety (ang. *tickets*) dostępu. Te bilety są dowodem uwierzytelnienia i pozwalają użytkownikom oraz usługom na wzajemną komunikację bez potrzeby każdorazowego podawania hasła.\n\nKDC w systemie Kerberos składa się z dwóch logicznych części, działających na tym samym komputerze, lub na dwóch powiązanych serwerach: serwera uwierzytelniania (ang. *Authentication Server* - AS) i serwera przyznawania biletów (ang. *Ticket Granting Server* - TGS). Użytkownik najpierw kontaktuje się z AS, aby zdobyć *bilet przyznający bilet*(ang. *Ticket Granting Ticket* - TGT), który jest biletem otwierającym furtkę do dalszego uwierzytelniania. Następnie, z tym TGT kontaktuje się z TGS, by uzyskać bilet dla konkretnej usługi. W praktyce, użytkownik (lub usługa) nie kontaktuje się bezpośrednio z AS i TGS, lecz interakcję z tymi usługami przejmuje lokalny system operacyjny lub aplikacja.\n\n*   **\"Key Distribution Center\"** Jest to poprawna odpowiedź, ponieważ KDC dosłownie tłumaczy się na Centrum Dystrybucji Kluczy. W kontekście Kerberosa, KDC właśnie to robi, dystrybuuje klucze potrzebne do szyfrowania komunikacji i uwierzytelniania. Realizuje to poprzez wydawanie biletów.\n*   **\"Kerberos Domain Controller\"** Jest to błędna odpowiedź. Chociaż KDC często występuje w środowiskach domenowych, zwłaszcza w Microsoft Active Directory, gdzie serwer domeny pełni rolę KDC, termin ten nie oddaje istoty samej funkcji KDC. Kontroler domeny jest pojęciem szerszym, które określa serwer odpowiedzialny za zarządzanie domeną, w tym uwierzytelnianie, ale niekoniecznie musi bazować na protokole Kerberos. KDC jest wyspecjalizowaną usługą w ramach protokołu Kerberos i może funkcjonować niezależnie od domeny.\n*   **\"Kerberos Directory Center\"** Jest to błędna odpowiedź.  Mimo że KDC może korzystać z bazy danych do przechowywania informacji o użytkownikach (np. LDAP), to jego główną funkcją jest dystrybucja kluczy, a nie przechowywanie informacji katalogowych. Bazy danych z informacjami o użytkownikach są wykorzystywane do poprawnej pracy KDC, ale samo KDC nie jest centrum katalogowym.\n*   **\"Kerberos Designated Certificate\"** Jest to błędna odpowiedź.  Chociaż certyfikaty są wykorzystywane w niektórych rozszerzeniach Kerberosa, to KDC nie jest certyfikatem ani nim nie zarządza. Certyfikaty mogą być używane jako alternatywa dla kluczy, ale nie są centralną częścią KDC. KDC nie wydaje certyfikatów użytkownikom, jego funkcja ogranicza się do wydawania biletów. Certyfikaty często wykorzystywane są jako uzupełnienie bezpieczeństwa dla protokołu Kerberos, w ramach rozszerzeń takich jak PKINIT (_ang. Public Key Cryptography for Initial Authentication in Kerberos_), ale nie jest to wymagany element protokołu Kerberos.\n\nZrozumienie poprawnej nazwy KDC, jak również zrozumienie jego funkcji jest kluczowe do zrozumienia działania protokołu Kerberos.  W rzeczywistych systemach, kiedy dochodzi do awarii lub niedostępności KDC to użytkownicy nie są w stanie zalogować się do swoich systemów operacyjnych jak i do większości serwerów, z którymi powiązana jest usługa Kerberos.  Utrzymanie ciągłości działania KDC jest jednym z najważniejszych zadań administratora systemu w środowisku, w którym działa Kerberos."
    },
    {
        "questionId": 255,
        "title": "Funkcja skrotu dajaca wynik 512-bitowy:",
        "answers": [
            {
                "text": "ma teoretyczna odpornosc na kolizje = 2^256",
                "isCorrect": true
            },
            {
                "text": "wymaga klucza 512b",
                "isCorrect": false
            },
            {
                "text": "wymaga klucza 256b",
                "isCorrect": false
            },
            {
                "text": "ma teoretyczna odpornosc na atak urodzinowy = 2^256",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Funkcja skrótu (ang. _hash function_) to algorytm, który przekształca dane wejściowe o dowolnej długości w wyjście o ustalonej, z góry określonej długości, zwane skrótem (ang. _hash_). Funkcje skrótu są podstawowym narzędziem w kryptografii, które wykorzystywane są do wielu zadań. Przykładowo, funkcje skrótu są wykorzystywane w protokołach uwierzytelniania, w podpisie elektronicznym, a także w integralności danych. Ważną cechą funkcji skrótu jest odporność na kolizje. Odporność na kolizje oznacza, że znalezienie dwóch różnych danych wejściowych, które dają taki sam skrót, jest z obliczeniowego punktu widzenia niemożliwe. Praktycznie niemożliwe, gdyż nie można formalnie udowodnić, że dane dwie różne dane wejściowe dają w 100% gwarantowany unikalny skrót. \n\nFunkcje skrótu **nie używają kluczy** w taki sposób jak szyfry. Klucz, używany w kryptografii symetrycznej lub asymetrycznej, jest parametrem, który wpływa na proces szyfrowania i deszyfrowania. Funkcja skrótu nie posiada odwracalnej funkcji deszyfrowania i nie może być wykorzystana do odszyfrowania wiadomości, a jedynie do obliczenia skrótu z tej wiadomości. Funkcja skrótu wykorzystywana jest do zabezpieczania wiadomości poprzez wykonanie podpisu elektronicznego, w którym wyliczony skrót wiadomości jest dodatkowo zaszyfrowany kluczem prywatnym nadawcy.\n\nZadanie to odnosi się do funkcji skrótu, której wynikiem jest skrót o długości 512 bitów. Przykładowo, funkcją skrótu o takiej długości jest algorytm SHA-512.  Funkcje skrótu mają odporność na kolizje. Termin *kolizja* oznacza znalezienie dwóch różnych danych wejściowych, które dają w wyniku identyczny skrót. Odporność na kolizje oznacza, że znalezienie takich danych jest obliczeniowo bardzo trudne, a często wręcz niemożliwe przy obecnych możliwościach obliczeniowych. Im dłuższy skrót, tym większa odporność na kolizje.\n\n**Odpowiedź pierwsza \"ma teoretyczna odpornosc na kolizje = 2^256\" jest poprawna.** Jest to związane z  tzw. paradoksem urodzin, który mówi, że prawdopodobieństwo kolizji nie wzrasta liniowo z długością skrótu, a znacznie szybciej. Paradoks urodzin w prosty sposób można zobrazować na przykładzie urodzin. Jeżeli w sali mamy 23 osoby, to prawdopodobieństwo, że dwie z nich mają urodziny w tym samym dniu roku wynosi ok 50%. Pomimo że wszystkich dni w roku jest 365, to już zaledwie 23 osoby dają wysokie prawdopodobieństwo powtórzenia dnia urodzenia. W systemach kryptograficznych im dłuższy skrót tym mniejsze prawdopodobieństwo wystąpienia powtórzenia, jednak wzrost nie jest liniowy a jak udowodnił matematyk Gabriel Lamé jest kwadratowy. Zatem jeżeli skrót posiada 512 bitów, to prawdopodobieństwo kolizji wynosi ok. 2<sup>256</sup>.  To nie oznacza, że znalezienie kolizji jest niemożliwe, tylko obliczeniowo bardzo trudne. Zazwyczaj przyjmuje się, że jeżeli znalezienie kolizji jest obliczeniowo trudniejsze niż 2<sup>128</sup> operacji, to jest wystarczające. \n\n**Odpowiedź druga \"wymaga klucza 512b\" jest niepoprawna.** Funkcje skrótu nie operują na kluczach w takim znaczeniu jak algorytmy szyfrowania. Klucz szyfrowania jest niezbędny do szyfrowania i deszyfrowania. Natomiast funkcje skrótu tworzą skrót z podanych danych. Algorytmy haszujące nie posiadają kluczy w sensie klucza symetrycznego czy asymetrycznego. Parametrami dla funkcji skrótu są dane i algorytm który służy do wyliczenia skrótu. Czasami może być użyty tzw. _salt_, który w istocie jest jawną daną, której zadaniem jest utrudnienie ataków na hasła użytkowników.\n\n**Odpowiedź trzecia \"wymaga klucza 256b\" jest niepoprawna** z tego samego powodu co odpowiedź druga. Funkcje skrótu nie używają kluczy.\n\n**Odpowiedź czwarta \"ma teoretyczna odpornosc na atak urodzinowy = 2^256\" jest poprawna.** Atak urodzinowy wykorzystuje paradoks urodzin. Polega on na tym, że  znalezienie dwóch różnych danych wejściowych, które dają taki sam skrót (kolizję), jest  znacznie prostsze niż znalezienie konkretnego skrótu dla dowolnych danych wejściowych. Zatem jeżeli skrót ma 512 bitów, to prawdopodobieństwo kolizji wynosi ok. 2<sup>256</sup>. Z tego powodu odporność na atak urodzinowy jest mniejsza o połowę długości bitowej skrótu."
    },
    {
        "questionId": 256,
        "title": "Jakie komponenty tworza kazda zapore sieciowa?:",
        "answers": [
            {
                "text": "dekoder ramek PDU",
                "isCorrect": false
            },
            {
                "text": "filtr pakietow",
                "isCorrect": true
            },
            {
                "text": "sniffer pakietow",
                "isCorrect": false
            },
            {
                "text": "skaner portow",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Podstawowym elementem każdej zapory sieciowej jest filtr pakietów. Filtr pakietów to mechanizm, który analizuje nagłówki każdego pakietu sieciowego i na podstawie zdefiniowanych reguł podejmuje decyzję czy pakiet powinien być przepuszczony dalej czy też zablokowany. Filtr pakietów działa na warstwie sieciowej (warstwa 3) modelu OSI lub w niektórych implementacjach, również w warstwie łącza danych (warstwa 2) analizując parametry takie jak adres IP źródła i adres IP docelowy, numery portów TCP/UDP, typ protokołu, a w przypadku rozszerzonych implementacji także stan połączenia TCP czy flagi sterujące. Przykładowo, reguła filtru pakietów może blokować wszystkie pakiety docierające na dany port, na przykład 22 (ssh), z zewnątrz sieci chronionej, a przepuszczać pakiety wychodzące na dowolny port z sieci chronionej.\n\n*   **dekoder ramek PDU:** Dekoder ramek PDU to element, który interpretuje zawartość pakietów danych (PDU, Protocol Data Unit) na niższym poziomie protokołu, na przykład nagłówek ethernetowy lub też warstwy łącza danych. Takie dekodowanie nie jest podstawowym zadaniem zapory sieciowej. Zapora sieciowa, czyli firewall, nie zagląda do wnętrza pakietu poza jego nagłówkami, a te mogą różnić się w zależności od protokołu. Zapora nie potrzebuje znać szczegółów ramek warstwy łącza danych. Analizuje jedynie adresy i numery portów oraz inne opcje protokołów warstwy sieciowej i transportowej. Dekoder ramek PDU jest wykorzystywany przez analizatory pakietów (np. wireshark).\n\n*   **filtr pakietow:** Jest to prawidłowa odpowiedź. Filtr pakietów jest podstawowym komponentem każdej zapory sieciowej, ponieważ realizuje podstawową funkcję takiej zapory, tj. blokowanie lub przepuszczanie pakietów zgodnie z zadanymi regułami. Bez filtru pakietów nie byłoby możliwe selektywne sterowanie ruchem sieciowym. Na przykład zapora sieciowa typu _firewall_ może na podstawie filtru pakietów przepuszczać pakiety na port 80 (www) z sieci zewnętrznej do stacji sieci chronionej ale jednocześnie blokować pakiety docierające do stacji w chronionej sieci na port 23 (telnet).\n\n*   **sniffer pakietow:** Sniffer pakietów, to narzędzie, które ma za zadanie przechwytywać pakiety i zapisywać ich zawartość, na przykład w pliku. Sniffer może być używany do analizy działania sieci komputerowej, do debugowania aplikacji lub do nieautoryzowanego podsłuchiwania transmisji. Sniffer nie jest częścią zapory, ani też nie stanowi elementu ochronnego, jest narzędziem do obserwacji ruchu sieciowego. Sniffery w połączeniu z zaporami sieciowymi mogą służyć do identyfikacji np. ataku hakerskiego, gdy zapora sieciowa zarejestruje podejrzaną aktywność.\n\n*   **skaner portow:** Skaner portów to narzędzie, którego zadaniem jest wysyłanie zapytań do wskazanego komputera w celu określenia jakie porty są otwarte i dostępne dla połączeń. Takie działanie jest zazwyczaj wykorzystywane w celu uzyskania informacji o dostępnych usługach oferowanych przez zdalny host. Choć skanowanie portów jest często wykorzystywane jako element ataku, sam skaner portów nie jest częścią składową zapory sieciowej. Skaner jest narzędziem, które może być użyte, aby ustalić, czy zapora sieciowa poprawnie blokuje pakiety na określonych portach. Skaner portów, w połączeniu z zaporą sieciową może pomóc administratorowi systemu w określeniu czy usługa która powinna być niedostępna od zewnątrz faktycznie jest niedostępna, a nie jedynie udaje."
    },
    {
        "questionId": 257,
        "title": "Wskaz operacje stosowane w metodzie ARP cache detekcji snifferow:",
        "answers": [
            {
                "text": "wyslanie zapytania ICMP echo request z falszywym adresem zrodlowym IP na adres podejrzewanej stacji",
                "isCorrect": true
            },
            {
                "text": "wyslanie ogloszenia ARP o falszywym adresie IP",
                "isCorrect": true
            },
            {
                "text": "wyslanie zapytania ICMP echo request z falszywym adresem docelowym IP i oczekiwaniu na odpowiedz",
                "isCorrect": false
            },
            {
                "text": "odpytanie podejrzewanej stacji o wszystkie adresy MAC sieci lokalnej",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Technika ARP cache poisoning, wykorzystywana do detekcji snifferów, polega na manipulacji wpisami w lokalnych tablicach ARP (Address Resolution Protocol) innych urządzeń w sieci, w celu ujawnienia obecności podsłuchującego. ARP to protokół warstwy łącza danych, który służy do mapowania adresów IP na fizyczne adresy MAC urządzeń sieciowych. Każde urządzenie sieciowe utrzymuje lokalną tablicę ARP, która przechowuje te mapowania, co pozwala na szybką komunikację bez konieczności ciągłego odpytywania o adres MAC przy każdym połączeniu.\n\n**Odpowiedź 1: \"wyslanie zapytania ICMP echo request z falszywym adresem zrodlowym IP na adres podejrzewanej stacji\" jest poprawna.** Wysyłanie zapytania ICMP echo request (ping) z fałszywym adresem IP źródła, skierowanego do potencjalnego sniffera jest używane, aby sprowokować ten sniffer do wysłania odpowiedzi ARP. Sniffer, który działa w trybie podsłuchu (promiscuous mode) nie powinien odpowiadać na pingi które nie są kierowane do jego własnego adresu IP, jednak jeśli takie pakiety są wysyłane z fałszywym adresem źródłowym, sniffer chcąc sprawdzić adres MAC (potrzebny do wysłania odpowiedzi) może odesłać zapytanie ARP z własnym adresem IP. Taki pakiet zostaje wysłany na adres rozgłoszeniowy (broadcast) i jest on widoczny dla wszystkich urządzeń w sieci, w tym dla urządzenia podejrzewanego o bycie snifferem. W praktyce administrator musi nasłuchiwać i wyłapywać podejrzane pakiety ARP, zwłaszcza te które mają fałszywy adres źródłowy.\n\n**Odpowiedź 2: \"wyslanie ogloszenia ARP o falszywym adresie IP\" jest poprawna.** Rozgłaszanie (broadcast) fałszywych ogłoszeń ARP z niepoprawnym mapowaniem adresów IP na adresy MAC, to podstawowa technika ARP cache poisoning. Celem jest tu zmuszenie potencjalnego sniffera do aktualizacji swojego cache ARP, a co za tym idzie do wysłania odpowiedzi ARP z jego własnym adresem. Sniffer działający pasywnie, nie będąc celem komunikacji sieciowej, nie powinien wysyłać żadnych ramek. Natomiast jeśli otrzyma fałszywe mapowanie ARP to zaktualizuje swój cache, a co za tym idzie, od czasu do czasu w swoim środowisku sieciowym w celu podtrzymania poprawności mapowań będzie wysyłać zapytania lub ogłoszenia ARP. Administrator posiadając narzędzie do podsłuchu sieci, może wyłapać taki pakiet z adres IP, który jest nie znany (fałszywy).\n\n**Odpowiedź 3: \"wyslanie zapytania ICMP echo request z falszywym adresem docelowym IP i oczekiwaniu na odpowiedz\" jest niepoprawna.** Wysyłanie ICMP echo request z fałszywym adresem docelowym nie spowoduje, że sniffer wyśle odpowiedź ARP. Sniffer w normalnym trybie pasywnego nasłuchiwania nie powinien odpowiadać na żaden ruch sieciowy, w szczególności na żądania ping, które nie są adresowane bezpośrednio do niego. Nawet jeśli adres IP źródła jest prawidłowy, sniffer ( w normalnym trybie ) powinien pakiety po prostu zignorować.\n\n**Odpowiedź 4: \"odpytanie podejrzewanej stacji o wszystkie adresy MAC sieci lokalnej\" jest niepoprawna.** Nie istnieje mechanizm w protokole ARP, który umożliwiałby odpytanie podejrzanej stacji o całą zawartość jej tablicy ARP. Takie zapytanie musiałoby opierać się o indywidualny kod protokołu, a ten nie istnieje w powszechnie dostępnym protokole ARP. Z drugiej strony takie odpytywanie nie jest potrzebne, ponieważ i tak zależy nam na tym, by sprowokować sniffera do wysłania ramki z własnym adresem.\n\nPodsumowując, poprawne metody detekcji snifferów poprzez ARP cache poisoning to wykorzystanie pakietów ICMP echo z fałszywym adresem źródłowym oraz ogłoszeń ARP z fałszywym mapowaniem adresów IP na MAC. Te działania prowokują sniffera, działającego w trybie pasywnego nasłuchu, do wysłania odpowiedzi ARP, co ujawnia jego obecność w sieci."
    },
    {
        "questionId": 258,
        "title": "Jaka usluga jest szczegolnie narazona na atak TCP spoofing?:",
        "answers": [
            {
                "text": "FTP, poniewaz domyslnie serwery dzialaja w trybie pasywnym",
                "isCorrect": false
            },
            {
                "text": "FTP, poniewaz domyslnie serwery dzialaja w trybie aktywnym",
                "isCorrect": false
            },
            {
                "text": "RCP, poniewaz uzywa adresu klienta do uwierzytelnienia",
                "isCorrect": true
            },
            {
                "text": "RCP, poniewaz nie uzywa adresu klienta do uwierzytelnienia",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Atak TCP spoofing polega na sfałszowaniu adresu IP źródłowego w pakiecie TCP. Atakujący, wysyłając spreparowane pakiety, podszywa się pod legalnego nadawcę. To podszywanie się jest wykorzystywane do przeprowadzenia ataku na system, który błędnie weryfikuje nadawcę na podstawie adresu IP. Usługi i programy, które nie zawierają odpowiednich mechanizmów kryptograficznych weryfikujących tożsamość drugiej strony połączenia są szczególnie podatne na atak TCP spoofing. \n\n**FTP (File Transfer Protocol)** to protokół używany do przesyłania plików między komputerami. W **trybie aktywnym FTP** to klient otwiera połączenie sterujące do serwera (port 21), a serwer otwiera oddzielne połączenie danych z portu 20 do portu ustalonego przez klienta. Klient podaje w porcie sterującym informację o porcie do którego serwer powinien się podłączyć w celu ustanowienia połączenia danych. W **trybie pasywnym FTP**, to klient inicjuje połączenia sterujące(port 21) oraz danych na ustalony port przez serwer. Z punktu widzenia ataku TCP spoofing mechanizm aktywnego połączenia powoduje, że serwer ma nawiązywać połączenie z klientem, a na to podatność na ataki jest znacznie niższa. \n\n**RCP (Remote Copy Protocol)** to protokół służący do zdalnego kopiowania plików między komputerami, bazuje on na usłudze rlogin. Aplikacja rcp do uwierzytelniania klienta wykorzystuje adres IP źródłowego komputera, w którym znajduje się klient.  W przypadku nie wystąpienia poprawnych wpisów w plikach konfiguracyjnych (/etc/hosts.equiv lub ~/.rhosts) używane jest dodatkowe uwierzytelnienie, które wymaga podania hasła. Mimo tego ataki TCP spoofing w powiązaniu z metodą opisaną poniżej (DNS spoofing) są potencjalnie niebezpieczne. Atakujący poprzez modyfikację serwera DNS potrafi przekierować nazwę zaufanej maszyny na swój własny adres i tym samym oszukać usługi wykorzystujące zaufanie przez nazwę. W systemach Unix/Linux usługi r* nie wykorzystują haseł do uwierzytelniania, ale weryfikują nadawcę (zgodnie z logiką mechanizmu zaufania, opisaną w poprzednich modułach). Adres IP źródłowy jest wykorzystywany do sprawdzenia, czy to połączenie jest legalne, dlatego jeśli attackerowi uda się sfałszować adres IP źródłowy, to może oszukać usługę rcp.\n\n**Odpowiedź 1:** *„FTP, ponieważ domyślnie serwery działają w trybie pasywnym”* - Jest to nieprawidłowa odpowiedź, ponieważ w trybie pasywnym FTP, to klient łączy się z serwerem na wcześniej ustalony port. Klient a nie serwer wybiera port źródłowy w danych, dlatego też jest mniejsza podatność na atak z wykorzystaniem mechanizmu spoofing.\n\n**Odpowiedź 2:** *„FTP, ponieważ domyślnie serwery działają w trybie aktywnym”* - Jest to nieprawidłowa odpowiedź, ponieważ w trybie aktywnym FTP, to serwer ma obowiązek podłączenia się do klienta na port przez niego ustalony, przez co podatność na atak jest znacznie mniejsza. Chociaż atak TCP spoofing może skutkować nadużyciem klienta FTP, to nie stanowi on w tym przypadku elementu ataku na serwer. W związku z czym atak nie jest tak łatwy do przeprowadzenia jak w przypadku opcji nr. 3.\n\n**Odpowiedź 3:** *„RCP, ponieważ używa adresu klienta do uwierzytelnienia”* - Jest to **poprawna odpowiedź**. Usługa rcp (jak i inne z rodziny r*) wykorzystuje adres IP klienta w procesie uwierzytelniania w mechanizmie zaufania (bez hasła). W przypadku udanego ataku TCP spoofing i sfałszowaniu adresu IP atakujący ma większą szanse na obejście procesu uwierzytelnienia. \n\n**Odpowiedź 4:** *„RCP, ponieważ nie używa adresu klienta do uwierzytelnienia”* - Jest to nieprawidłowa odpowiedź, gdyż usługi r* polegają na weryfikacji źródłowego adresu IP podczas uwierzytelniania."
    },
    {
        "questionId": 259,
        "title": "Przykladem realizacji mechanizmu uwierzytelniania z udzialem zaufanej trzeciej strony jest:",
        "answers": [
            {
                "text": "protokol Kerberos",
                "isCorrect": true
            },
            {
                "text": "urzad CA",
                "isCorrect": true
            },
            {
                "text": "system PKI",
                "isCorrect": true
            },
            {
                "text": "protokol Diffiego-Hellmana",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Mechanizm uwierzytelniania z udziałem zaufanej trzeciej strony opiera się na założeniu, że istnieje podmiot, któremu ufają wszystkie strony biorące udział w procesie uwierzytelniania. Ten zaufany podmiot bierze na siebie odpowiedzialność weryfikacji tożsamości i wystawia poświadczenie uwierzytelnionej stronie. W informatyce podmiot ten najczęściej jest programem lub systemem do obsługi którego zostało delegowane zadanie weryfikowania danych identyfikacyjnych użytkowników. W praktyce, mechanizm ten ma za zadanie zmniejszyć liczbę zapytań o dane uwierzytelniające, ponieważ dany użytkownik po uwierzytelnieniu w zaufanym podmiocie uzyskuje dostęp do wielu usług bez potrzeby ponownego podawania danych uwierzytelniających.\n\n**Protokół Kerberos** jest przykładem mechanizmu wykorzystującego zaufaną trzecią stronę, czyli Centrum Dystrybucji Kluczy (KDC, _ang. Key Distribution Center_). W protokole Kerberos użytkownik uwierzytelnia się w KDC, które po pomyślnej weryfikacji wydaje mu bilet, który jest wykorzystywany do uzyskania dostępu do innych usług. Użytkownik nie musi się uwierzytelniać ponownie przed każdym zasobem, gdyż KDC wystawia bilet będący poświadczeniem jego tożsamości i to właśnie bilet przedstawiany jest serwerowi jako poświadczenie autentyczności użytkownika. Zatem, KDC jest zaufaną trzecią stroną, która gwarantuje autentyczność użytkownika i umożliwia dostęp do innych zasobów. W ten sposób można wykorzystać raz podane hasło do wielu usług sieciowych.\n  \n**Urząd certyfikacji (CA, _ang. Certification Authority_)** również działa jako zaufana trzecia strona. CA wydaje certyfikaty cyfrowe, które potwierdzają tożsamość podmiotu. Certyfikat zawiera klucz publiczny podmiotu oraz podpis CA, który potwierdza, że certyfikat został wydany przez dany urząd certyfikacji. Inne podmioty ufając danemu CA mogą zaufać również podmiotowi, któremu ten urząd certyfikacji wystawił certyfikat. Przykładem może być przeglądarka internetowa. Przeglądarka internetowa posiada listę zaufanych CA wbudowanych w program. Gdy przeglądarka nawiązuje szyfrowane połączenie HTTPS z serwerem, serwer przedstawia swój certyfikat. Przeglądarka weryfikuje autentyczność tego certyfikatu poprzez sprawdzenie, czy jego podpis został utworzony przez zaufane CA. Jeżeli certyfikat jest podpisany przez CA, któremu ufa przeglądarka, to może zweryfikować poprawność podpisu serwera i zaufać serwerowi.\n\n**System PKI (Infrastruktura Klucza Publicznego, _ang. Public Key Infrastructure_)** stanowi cały zbiór elementów które współpracują aby umożliwić bezpieczną komunikację. System PKI obejmuje CA oraz inne urzędy, które pomagają w tworzeniu hierarchii zaufania. Standardem jest aby hierarchia była rozproszona po całym świecie i każdy użytkownik miał możliwość pozyskania klucza publicznego urzędu certyfikacji, aby móc zweryfikować czy dany certyfikat był wydany przez wiarygodną instytucję. System PKI obejmuje również listę unieważnionych certyfikatów oraz wiele różnych procedur. W systemie PKI Urząd Certyfikacji odgrywa rolę zaufanej trzeciej strony, która dba o wiarygodność wydawanych certyfikatów.\n\n**Protokół Diffiego-Hellmana** jest protokołem wymiany kluczy. Pozwala dwóm stronom, nawet w obecności podsłuchującego, uzgodnić tajny klucz. Ten klucz może być użyty do szyfrowania dalszej komunikacji między stronami. Diffie-Hellman nie zapewnia jednak żadnego mechanizmu uwierzytelniania stron. Oznacza to, że nawet jeśli dwie strony z sukcesem wynegocjują klucz, to nie ma pewności, czy rzeczywiście rozmawiają z podmiotem, z którym zamierzali nawiązać komunikację. Dlatego Diffie-Hellman nie jest przykładem uwierzytelniania z udziałem zaufanej trzeciej strony, ponieważ nie ma w nim elementu zaufanej strony.\n\nW praktyce, wszystkie z wymienionych przykładów (Kerberos, CA, PKI) są wykorzystywane w systemach komputerowych w celu zapewnienia bezpieczeństwa wymiany informacji, zapewniają, że strony biorące udział w komunikacji są tymi za kogo się podają. Przykładowo bez PKI przeglądanie stron internetowych w protokole HTTPS nie byłoby bezpieczne, a serwery i przeglądarki byłyby podatne na ataki typu _man-in-the-middle_."
    },
    {
        "questionId": 260,
        "title": "Mechanizm OTP (one-time passwords):",
        "answers": [
            {
                "text": "uniemozliwia atak poprzez odtwarzanie (replaying)",
                "isCorrect": true
            },
            {
                "text": "weryfikuje nietrywialnosc hasla podczas jego zmiany",
                "isCorrect": false
            },
            {
                "text": "jest niewrazliwy na podsluch",
                "isCorrect": false
            },
            {
                "text": "uniemozliwia zdobycie hasla metoda przeszukiwania wyczerpujacego",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Hasła jednorazowe (OTP, ang. One-Time Passwords) to hasła, które są ważne tylko dla pojedynczej sesji logowania lub transakcji. Kluczowym elementem OTP jest ich jednorazowość - po użyciu stają się bezwartościowe dla potencjalnego atakującego. Oznacza to, że nawet jeśli atakujący przechwyci OTP, nie będzie mógł go ponownie użyć do uzyskania dostępu.\n\n* **„uniemożliwia atak poprzez odtwarzanie (replaying)”** - **Poprawna odpowiedź.** Atak przez odtwarzanie (ang. replay attack) polega na ponownym wykorzystaniu przechwyconej transmisji, np. hasła. Ponieważ OTP jest ważne tylko raz, próba ponownego jego użycia, czyli odtworzenia przechwyconej transmisji, zakończy się niepowodzeniem. Mechanizm OTP skutecznie przeciwdziała temu rodzajowi ataku. Przykładowo, jeśli bank wysyła OTP SMSem i klient użyje go raz do zalogowania, to nawet jeśli ktoś przechwyci ten SMS, nie będzie mógł go wykorzystać do nieautoryzowanego dostępu.\n\n* **„weryfikuje nietrywialnosc hasla podczas jego zmiany”** - **Niepoprawna odpowiedź.** OTP nie ma nic wspólnego z weryfikacją nietrywialności hasła przy jego zmianie. Weryfikacja hasła pod kątem jego złożoności (nietrywialności) ma na celu utrudnienie odgadnięcia statycznego hasła poprzez metodę \"brute-force\" lub ataku słownikowego i jest to zupełnie odrębny mechanizm. OTP jest dodatkowym, niezależnym mechanizmem zabezpieczającym przed innymi atakami i nie ingeruje w statyczne hasło.\n\n* **„jest niewrazliwy na podsluch”** - **Niepoprawna odpowiedź.**  OTP nie chroni przed przechwyceniem (podsłuchem). Transmisja OTP podczas logowania wciąż może zostać podsłuchana, na przykład, poprzez przechwycenie komunikacji sieciowej lub przechwycenie SMS. Jednorazowość hasła czyni je bezużytecznym dla atakującego, nawet po jego przechwyceniu. Ale sam akt transmisji jest podatny na podsłuch. Przykładowo, jeśli hasło wysyłane jest SMS-em, a atakujący podsłucha transmisje SMSów, będzie w stanie pozyskać hasło, ale nie będzie mógł go ponownie wykorzystać.\n\n* **„uniemozliwia zdobycie hasla metoda przeszukiwania wyczerpujacego”** - **Niepoprawna odpowiedź.** Atak metodą przeszukiwania wyczerpującego (ang. brute-force attack) polega na próbie odgadnięcia hasła poprzez sprawdzanie wszystkich możliwych kombinacji. OTP, mimo że jest trudne do odgadnięcia, samo w sobie nie zapobiega metodzie przeszukiwania wyczerpującego.  Atakujący, znając metodę generowania OTP, mógłby teoretycznie próbować generować i sprawdzać różne wersje OTP, jednak ilość hasła jednorazowych, które można wygenerować do danego konta jest z reguły ograniczona. OTP są bardziej skierowane na ochronę przed atakami typu \"replay attack\", a nie przed atakami \"brute-force\". Zabezpieczenie przed atakami \"brute-force\" obejmuje głównie mechanizmy ochrony hasła statycznego przed odgadnięciem (np. silne hasło, uwzględniające duże, małe litery, znaki specjalne i cyfry)."
    },
    {
        "questionId": 261,
        "title": "Ktore z wymienionych technik moga byc wykorzystane do uwierzytelniania z haslami jednorazowymi:",
        "answers": [
            {
                "text": "jednokrotne uwierzytelniane (single sign-on)",
                "isCorrect": false
            },
            {
                "text": "certyfikacja klucza sesji",
                "isCorrect": false
            },
            {
                "text": "metoda zawolanie-odzew (challenge-response)",
                "isCorrect": true
            },
            {
                "text": "synchronizacja czasu",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Hasła jednorazowe (OTP, _ang. One-Time Passwords_) to mechanizm uwierzytelniania, w którym hasło jest ważne tylko raz i zazwyczaj tylko przez krótki czas. Celem użycia haseł jednorazowych jest ochrona przed przechwyceniem hasła w trakcie transmisji lub jego ponownym wykorzystaniem przez atakującego. Istnieją różne metody generowania haseł jednorazowych.\n\n**Metoda zawołanie-odzew (challenge-response):** W tej metodzie serwer wysyła do klienta (użytkownika) losowe dane, tzw. zawołanie (_ang. challenge_). Klient łączy te dane z tajnym kluczem (który może być hasłem, PIN-em, lub innym parametrem znanym tylko klientowi i serwerowi), przetwarza je za pomocą określonej funkcji (często z użyciem funkcji skrótu) i wysyła serwerowi wynik, zwany odzewem (_ang. response_). Serwer, dysponując tym samym kluczem i funkcją, wykonuje te same obliczenia i porównuje otrzymany odzew z obliczonym. Zgodność odzewów potwierdza tożsamość klienta, wykorzystując jednorazowość zawołania. Przykładem jest token sprzętowy, który generuje odzew na zawołanie serwera. Jest to typowy przykład metody OTP.\n\n**Synchronizacja czasu:** Metoda ta opiera się na generowaniu haseł w oparciu o algorytm wykorzystujący aktualny czas. Zarówno serwer jak i klient mają zsynchronizowany czas oraz znają wspólny klucz. Generowanie hasła jest oparte na tajnym kluczu i aktualnej wartości czasu, na przykład liczby sekund od początku epoki unixowej(1 stycznia 1970). Klient i serwer obliczają hasło na podstawie tej samej danej wejściowej i serwer, aby dokonać weryfikacji hasła, generuje hasło dla okresu wcześniejszego jak i obecnego, a także ma niewielki zapas w przyszłość(np. na wypadek opóźnienia pakietu). W praktyce metoda ta jest wykorzystywana w aplikacjach na telefony komórkowe służących jako tokeny generujące hasła jednorazowe, jak Google Authenticator czy Authy. Hasło jednorazowe ma określoną ważność (np. 30 lub 60 sekund) i jest niezależne od hasła użytego wcześniej. Jest to przykład metody OTP.\n\n**Jednokrotne uwierzytelnianie (single sign-on):** SSO to system, który umożliwia użytkownikowi dostęp do wielu usług lub aplikacji przy użyciu jednego zestawu danych uwierzytelniających (np. jednego hasła). SSO **nie jest** metodą generowania hasła jednorazowego, lecz sposobem na redukcję ilości potrzebnych haseł, co może uprościć logowanie dla użytkownika do różnych systemów. Przykładem jest logowanie do usług Google, gdzie logowanie do gmaila umożliwia dostęp do dysku czy kalendarza bez ponownego uwierzytelniania. SSO nie chroni przed atakami typu \"man-in-the-middle\" i **nie jest** formą hasła jednorazowego.\n\n**Certyfikacja klucza sesji:** Certyfikacja klucza sesji to proces, w którym klucz kryptograficzny używany do szyfrowania sesji (na przykład sesji SSL) jest poświadczany za pomocą certyfikatu cyfrowego wystawionego przez zaufane centrum certyfikacji. Metoda ta **nie generuje** hasła jednorazowego. Certyfikat w tym przypadku potwierdza tożsamość serwera do którego się łączymy oraz umożliwia uzgodnienie wspólnego tajnego klucza. Przykładem jest nawiązywanie połączenia https z serwerami WWW. Mechanizm ten, podobnie jak SSO, **nie jest** metodą generowania haseł jednorazowych, lecz sposobem na weryfikację tożsamości serwera oraz uzgodnienia klucza."
    },
    {
        "questionId": 262,
        "title": "Ktore z ponizszych regul sa prawdziwe w przypadku mechanizmu Mandatory Access Control (MAC). Podmiot nie moze ...:",
        "answers": [
            {
                "text": "zapisac danych o etykiecie nizszej niz jego aktualna",
                "isCorrect": true
            },
            {
                "text": "uruchomic procesu o etykiecie wyzszej niz jego aktualna",
                "isCorrect": true
            },
            {
                "text": "zapisac danych o etykiecie wyzszej niz jego aktualna",
                "isCorrect": false
            },
            {
                "text": "czytaj danych o etykiecie nizszej niz jego aktualna",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to model kontroli dostępu, w którym dostęp do zasobów jest regulowany przez z góry określone polityki bezpieczeństwa, a nie uznaniową decyzją właściciela zasobu, jak to ma miejsce w modelu DAC (Discretionary Access Control). W MAC każdemu obiektowi (zasobowi) i podmiotowi (użytkownikowi, procesowi) przypisywana jest etykieta wrażliwości (_ang. sensitivity label_). Etykieta wrażliwości składa się z poziomu zaufania (np. \"poufne\", \"tajne\", \"ściśle tajne\") i kategorii przynależności danych (np. \"finansowe\", \"osobowe\", \"militarne\"). Dodatkowo, dla każdego podmiotu, określa się tzw. poziom uprawnień, czyli zbiór etykiet określający do jakich danych ma dostęp, np. użytkownik może mieć uprawnienia do danych \"poufne\" oraz \"finansowe\". System MAC wymusza ścisłe reguły dotyczące interakcji podmiotów z obiektami. Dwie podstawowe zasady to: \"no read up\" i \"no write down\".\n\n**Odpowiedź 1: \"zapisac danych o etykiecie nizszej niz jego aktualna\"**\n\nTa odpowiedź jest **poprawna**. W systemie MAC obowiązuje reguła \"no write down\", co oznacza, że podmiot (np. proces) nie może zapisać danych o etykiecie niższej niż jego własna etykieta wrażliwości. Dzieje się tak dlatego, że zaufane dane nie mogą być zapisywane do nie zaufanych zasobów, np. proces pracujący z danymi \"tajne\" nie może zapisać ich do zasobu \"poufne\". Jest to podstawowy mechanizm ochrony integralności danych. W praktyce, oznacza to, że proces z etykietą \"ściśle tajne\" nie może modyfikować (zapisywać) plików o etykiecie \"poufne\", aby nie doszło do obniżenia poziomu ochrony tych plików.\n\n**Odpowiedź 2: \"uruchomic procesu o etykiecie wyzszej niz jego aktualna\"**\n\nTa odpowiedź jest **poprawna**. Podmiot w systemie MAC nie może uruchomić procesu o wyższym poziomie uprawnień niż jego aktualny. Podobnie jak w przykładzie wyżej, jest to ochrona przed podniesieniem poziomu bezpieczeństwa przez niewłaściwy proces. Użytkownik o etykiecie \"poufne\" nie może uruchomić procesu który ma prawa \"tajne\" lub \"ściśle tajne\".\n\n**Odpowiedź 3: \"zapisac danych o etykiecie wyzszej niz jego aktualna\"**\n\nTa odpowiedź jest **niepoprawna**. Podmiot w systemie MAC może zapisać dane o etykiecie wyższej niż jego własna, np proces o uprawnieniach \"poufne\" może zapisywać do plików o etykiecie \"tajne\" (oczywiście nie czytać), jednak nigdy nie w drugą stronę, tj. z uprawnieniami \"tajne\" do pliku o etykiecie \"poufne\". Takie działanie jest dozwolone, gdyż nie powoduje to naruszenia polityki bezpieczeństwa. Wyższy poziom zaufania może być przypisany do zasobów o niższym poziomie zaufania, lecz nie w druga stronę. Jest to ochrona poufności danych. \n\n**Odpowiedź 4: \"czytaj danych o etykiecie nizszej niz jego aktualna\"**\n\nTa odpowiedź jest **niepoprawna**. Podmiot w systemie MAC może czytać dane o etykiecie niższej niż jego własna. Jest to dozwolone, gdyż nie stanowi zagrożenia dla bezpieczeństwa systemu. Proces o uprawnieniach \"tajne\" ma prawo czytać zasoby o etykiecie \"poufne\", ale nie w drugą stronę. W systemie MAC obowiązuje zasada \"no read up\"."
    },
    {
        "questionId": 263,
        "title": "Jakie funkcje moga pelnic systemy HIPS?:",
        "answers": [
            {
                "text": "sondowanie uslug (port enumeration)",
                "isCorrect": false
            },
            {
                "text": "zamek-i-klucz",
                "isCorrect": false
            },
            {
                "text": "monitor antywirusowy",
                "isCorrect": true
            },
            {
                "text": "ochrona przed atakami DoS",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "System HIPS (Host-based Intrusion Prevention System) to system ochrony przed włamaniami działający na pojedynczym komputerze (hoście). Zabezpieczenie realizowane jest poprzez kontrolowanie procesów zachodzących na systemie operacyjnym, co obejmuje nadzorowanie aktywności uruchomionych programów, plików i połączeń sieciowych. HIPS nie jest zaporą sieciową, która działa na granicy sieci, a ochrona realizowana przez zaporę sieciową (ang. _firewall_) jest zawsze ograniczona do ochrony sieci przed niechcianym ruchem, a nie do ochrony konkretnego komputera w sieci. HIPS chroni komputer przed działaniem niepożądanego oprogramowania, dzięki sprawdzaniu plików przed ich uruchomieniem. Systemy HIPS mogą realizować różne funkcje bezpieczeństwa, do najpopularniejszych należy ochrona przed złośliwym oprogramowaniem oraz ochrona przed atakami typu DoS. \n\n**sondowanie uslug (port enumeration)** -  jest to technika polegająca na aktywnym skanowaniu portów, czyli sprawdzaniu jakie usługi są udostępniane przez serwer/komputer. Jest to technika, którą używają osoby przygotowujące się do ataku, a nie funkcja systemu HIPS. System HIPS, w zależności od swojej konfiguracji, może wykrywać i rejestrować zdarzenia związane ze skanowaniem portów przez intruza.\n\n**zamek-i-klucz** - nie jest to funkcja systemu HIPS a jedynie metafora lub określenie sposobu uwierzytelniania, gdzie zamek reprezentuje serwer, a klucz to hasło lub inne dane uwierzytelniające. W systemie HIPS, proces uwierzytelniania może być wykonywany poprzez wtyczki do PAM(ang. _Pluggable Authentication Modules_), jednak \"zamek-i-klucz\" to jedynie przenośnia opisująca ten proces. \n\n**monitor antywirusowy** - jest to jedna z podstawowych funkcji systemu HIPS. Monitor antywirusowy sprawdza procesy i pliki przed ich uruchomieniem, a w przypadku podejrzenia niepożądanej aktywności podejmuje odpowiednie działania na przykład zablokowanie dostępu lub usunięcie pliku złośliwego. Monitor antywirusowy jest integralną częścią większości komercyjnych systemów HIPS.\n\n**ochrona przed atakami DoS** - HIPS może wykrywać próby ataków DoS (ang. _Denial of Service_), polegających na próbie przeciążenia systemu operacyjnego złośliwym ruchem lub błędnie skonstruowanymi pakietami. W przypadku systemów HIPS ochrona przed DoS odbywa się poprzez detekcję nietypowego ruchu sieciowego lub nietypowego obciążenia procesora. Wykrycie ataku może spowodować zablokowanie komunikacji z podejrzanego źródła. Zatem ochrona przed atakami DoS jest jedną z istotnych cech każdego systemu HIPS. \n\nPodsumowując, system HIPS może zapewniać ochronę przed złośliwym oprogramowaniem oraz atakami DoS. Inne mechanizmy bezpieczeństwa takie jak np. _port enumeration_ czyli skanowanie portów oraz metafora \"zamek-i-klucz\" nie są funkcjami HIPS."
    },
    {
        "questionId": 264,
        "title": "Do zrealizowania zamaskowanego kanalu komunikacyjnego moze potencjalnie posluzyc:",
        "answers": [
            {
                "text": "port szeregowy",
                "isCorrect": false
            },
            {
                "text": "kolejka drukowania",
                "isCorrect": true
            },
            {
                "text": "system plikow",
                "isCorrect": true
            },
            {
                "text": "obciazenie systemu",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Kanał zamaskowany (covert channel) to metoda komunikacji, która nie została zaprojektowana w celu przesyłania informacji, a mimo to pozwala na ukrytą transmisję danych. Wykorzystuje on standardowe, legalne funkcje systemu do niejawnej wymiany informacji, co utrudnia jego wykrycie. Istotą kanału zamaskowanego jest to, że komunikacja odbywa się w sposób nieoczywisty dla obserwatora, wykorzystując np. parametry systemu lub jego działanie niepowiązane z komunikacją.\n\n*   **port szeregowy:** Port szeregowy jest standardowym interfejsem komunikacyjnym. Mimo że dane mogą być przesyłane portem szeregowym w sposób jawny, nie stanowi on kanału zamaskowanego. Jest to zaprojektowane i powszechnie stosowane medium do przesyłania danych. Port szeregowy jest zatem niepoprawną odpowiedzią.\n\n*   **kolejka drukowania:** Kolejka drukowania (print queue) jest przykładem kanału zamaskowanego. Można w niej umieszczać i usuwać zadania drukowania w określonej sekwencji, co stanowi sposób przesyłania bitów informacji. Na przykład umieszczenie zadania może reprezentować bit 1, a jego brak bit 0, lub też czas oczekiwania na wykonanie druku może nieść informację. Informacja jest zatem ukryta w działaniu systemowej kolejki drukowania, co sprawia, że odpowiedź ta jest poprawna. Atakujący może ukryć w ten sposób informację przed niepowołanym okiem.\n\n*   **system plików:** System plików może być użyty jako kanał zamaskowany. Tworzenie, modyfikowanie i usuwanie plików w określonych lokalizacjach i o konkretnych parametrach może być sposobem przekazywania informacji. Na przykład obecność pliku w pewnym miejscu w systemie plików może oznaczać bit 1, a jego brak bit 0. Podobnie można wykorzystać rozmiar lub datę modyfikacji pliku. Ta metoda niejawnej komunikacji sprawia, że system plików jest poprawną odpowiedzią. Działania takie mogą być bardzo trudne do wykrycia.\n\n*   **obciążenie systemu:** Obciążenie systemu, rozumiane jako stopień wykorzystania jego zasobów (procesor, pamięć), może posłużyć jako kanał zamaskowany. Atakujący może manipulować obciążeniem systemu, aby przekazać informacje w postaci bitów, gdzie na przykład zwiększone obciążenie oznacza bit 1, a mniejsze bit 0. Obserwatorowi trudno jest stwierdzić, czy obciążenie systemu jest wynikiem naturalnej pracy czy celowej manipulacji. Dlatego obciążenie systemu jest również poprawną odpowiedzią.\n\nPodsumowując, kanały zamaskowane wykorzystują pozornie standardowe i nieszkodliwe elementy systemu do ukrytej komunikacji. Odpowiedź wskazująca port szeregowy jest niepoprawna z uwagi na to, że jest on legalnym i powszechnym kanałem komunikacji. Kolejka drukowania, system plików i obciążenie systemu są przykładami elementów, które mogą być wykorzystane jako zamaskowane kanały komunikacji i dlatego zostały one poprawnie wskazane."
    },
    {
        "questionId": 265,
        "title": "Wskaz warunek wystarczajacy do weryfikacji podpisu cyfrowego wiadomosci S/MIME:",
        "answers": [
            {
                "text": "uprzednie przeslanie do nadawcy klucza publicznego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "uprzednie przeslanie do odbiorcy klucza publicznego nadawcy",
                "isCorrect": true
            },
            {
                "text": "dostep do centrum CA w celu pobrania certyfikatu wskazanego w podpisie (i innych certyfikatow na sciezce certyfikacji)",
                "isCorrect": false
            },
            {
                "text": "wymiana kluczy miedzy nadawca a odbiorca metoda Diffiego-Hellmana",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Podpis cyfrowy S/MIME wykorzystuje kryptografię asymetryczną, a konkretnie algorytm klucza publicznego do weryfikacji autentyczności i integralności wiadomości. Autentyczność potwierdza, że wiadomość została wysłana przez nadawcę, za którego się podaje, a integralność gwarantuje, że wiadomość nie została zmieniona w trakcie transmisji. W procesie tym nadawca podpisuje wiadomość używając swojego klucza prywatnego, a odbiorca weryfikuje podpis za pomocą klucza publicznego nadawcy. Klucz prywatny jest tajny i znany tylko nadawcy, a klucz publiczny jest udostępniany publicznie, dzięki czemu odbiorca może przeprowadzić weryfikację podpisu.\n\n**Opcja 1: \"uprzednie przeslanie do nadawcy klucza publicznego odbiorcy\"**\n\nTa odpowiedź jest **nieprawidłowa**. Przesłanie klucza publicznego odbiorcy do nadawcy jest związane z *szyfrowaniem* wiadomości, a nie z podpisywaniem. W szyfrowaniu nadawca używa klucza publicznego odbiorcy, aby zaszyfrować wiadomość tak, żeby tylko odbiorca za pomocą swojego klucza prywatnego mógł ją odszyfrować. Podpisanie natomiast wykorzystuje klucz prywatny nadawcy i klucz publiczny odbiorcy jest do tego nieprzydatny.\n\n**Opcja 2: \"uprzednie przeslanie do odbiorcy klucza publicznego nadawcy\"**\n\nTa odpowiedź jest **prawidłowa**. Aby odbiorca mógł zweryfikować podpis cyfrowy, musi posiadać klucz publiczny nadawcy. Podpis tworzony jest przy użyciu klucza prywatnego nadawcy, który jest znany tylko nadawcy. Następnie odbiorca może odszyfrować podpis za pomocą klucza publicznego, który jest związany z kluczem prywatnym, którym podpisana została wiadomość. Jeżeli podpis się zgadza, to wiadomość jest podpisana kluczem prywatnym powiązanym z kluczem publicznym, a więc pochodzi od prawidłowego nadawcy i nie została w trakcie transmisji zmieniona.\n\n**Opcja 3: \"dostep do centrum CA w celu pobrania certyfikatu wskazanego w podpisie (i innych certyfikatow na sciezce certyfikacji)\"**\n\nTa odpowiedź jest **nieprawidłowa**, chociaż ma pewne powiązanie z prawidłową. Owszem, aby mieć zaufanie do klucza publicznego nadawcy, odbiorca musi zweryfikować, czy klucz publiczny nadawcy jest poprawny i czy pochodzi on od nadawcy. Weryfikacja taka odbywa się przy pomocy *certyfikatu cyfrowego*, który poświadcza, że dany klucz publiczny należy do danej osoby. Weryfikację certyfikatów przeprowadza zaufana trzecia strona - centrum certyfikacji (CA, _ang. Certification Authority_). W praktyce jest tak, że certyfikat wystawiony dla nadawcy jest podpisany przez CA. W celu całkowitej weryfikacji certyfikatu, musimy mieć zaufanie do tego CA, a więc i certyfikat CA, co z kolei wymaga certyfikatu poświadczającego autentyczność CA, i tak dalej. W ten sposób tworzy się tzw. *łańcuch zaufania*, którego zakończeniem jest korzeń, a wiec urząd certyfikacji któremu bezwzględnie ufamy. Certyfikat takiego korzenia często jest wbudowany w popularnych przeglądarkach internetowych oraz programach pocztowych.  Jednak bezpośrednie pobranie certyfikatu jest potrzebne, ale nie wystarczające, gdyż w ten sposób weryfikujemy zaufanie do nadawcy, ale aby zweryfikować poprawność podpisu cyfrowego wiadomości S/MIME potrzebujemy sam klucz publiczny z certyfikatu nadawcy, a nie cały certyfikat.\n\n**Opcja 4: \"wymiana kluczy miedzy nadawca a odbiorca metoda Diffiego-Hellmana\"**\n\nTa odpowiedź jest **nieprawidłowa**. Metoda Diffiego-Hellmana jest algorytmem wymiany kluczy, który pozwala dwóm stronom w niechronionym kanale komunikacyjnym uzgodnić tajny klucz, który następnie może być wykorzystany do szyfrowania symetrycznego. Metoda ta nie służy do podpisywania wiadomości. Szyfrowanie symetryczne wykorzystywane jest do szyfrowania treści wiadomości, a do podpisu wykorzystuje się kryptografię asymetryczną. Podpis jest obliczany na podstawie zawartości wiadomości i podpisywany kluczem prywatnym."
    },
    {
        "questionId": 266,
        "title": "Jakie wlasciwosci mozna ustawic w Zasadach hasel w systemie Windows?:",
        "answers": [
            {
                "text": "zlozonosc hasel",
                "isCorrect": true
            },
            {
                "text": "maksymalna dlugosc nazwy uzytkownika",
                "isCorrect": false
            },
            {
                "text": "minimalna dlugosc nazwy uzytkownika",
                "isCorrect": false
            },
            {
                "text": "wlaczenie szyfrowania AES hasel uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "minimalna dlugosc hasla uzytkownika",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Zasady haseł (ang. _password policies_) w systemie Windows to zestaw reguł, które administrator może skonfigurować w celu wymuszenia stosowania przez użytkowników silnych i trudnych do odgadnięcia haseł. Dostęp do tych ustawień uzyskuje się poprzez lokalne zasady zabezpieczeń (ang. _Local Security Policy_). Zasady haseł pomagają w ochronie systemu przed atakami, w których hasła są łamane na wiele sposobów. Dostępne ustawienia pozwalają na definiowanie właściwości hasła. \n\n*   **zlozonosc hasel** - Ta opcja jest **poprawna**. W zasadach haseł można wymusić tzw. _złożoność hasła_. Złożoność oznacza, że hasło musi spełniać określone kryteria, takie jak minimalna długość, użycie znaków specjalnych, cyfr, wielkich i małych liter. Na przykład hasło musi zawierać co najmniej 8 znaków, w tym co najmniej jedną cyfrę, jedną dużą literę oraz jeden znak specjalny. Wymuszanie złożoności haseł zmniejsza prawdopodobieństwo jego złamania metodami słownikowymi lub tzw. \"brute-force\". W praktyce, bez włączonej tej opcji system MS Windows pozwala na ustawienie hasła np. na wartość \"haslo\", co czyni system łatwym do ataku.\n\n*   **maksymalna dlugosc nazwy uzytkownika** - Ta opcja jest **niepoprawna**. Zasady haseł w systemie Windows nie pozwalają na ustawienie maksymalnej długości nazwy użytkownika. Długość nazwy użytkownika jest ustalana w momencie tworzenia konta i nie jest powiązana z zasadami haseł. Jest to parametr konta a nie parametru bezpieczeństwa hasła. W praktyce długość nazwy użytkownika jest ograniczona ze względu na parametry systemu a nie parametry bezpieczeństwa hasła.\n\n*   **minimalna dlugosc nazwy uzytkownika** - Ta opcja jest **niepoprawna**. Podobnie jak w przypadku maksymalnej długości nazwy użytkownika, również minimalna długość nazwy użytkownika nie jest parametrem ustawianym w zasadach haseł. Jest to parametr konta a nie parametru bezpieczeństwa hasła. W praktyce długość nazwy użytkownika jest ograniczona ze względu na parametry systemu a nie parametry bezpieczeństwa hasła.\n\n*  **wlaczenie szyfrowania AES hasel uzytkownikow** - Ta opcja jest **niepoprawna**. Zasady haseł nie kontrolują algorytmu szyfrowania haseł w bazie danych systemu. Zasadami hasła ustalamy reguły odnośnie formy hasła jaką ma wybrać użytkownik. System Windows domyślnie wykorzystuje funkcję skrótu (hash) do przechowywania hasła (nie można z hasha odtworzyć hasła) , natomiast nie kontrolujemy algorytmu jakim to hasło jest przechowywane. W starszych wersjach systemu Windows hash jest tworzony za pomocą algorytmu MD4/MD5, w nowszych systemach hash jest tworzony za pomocą algorytmu sha1/sha256. Opcja ta sugeruje wykorzystanie szyfrowania AES, co nie jest prawdą. W systemie MS Windows hasła są przechowywane jako hash-e a nie jako zaszyfrowany tekst.\n\n*   **minimalna dlugosc hasla uzytkownika** - Ta opcja jest **poprawna**. W ustawieniach zasad haseł można określić minimalną liczbę znaków, które hasło musi zawierać. Krótkie hasła są bardzo podatne na złamanie. Ustawienie minimalnej długości hasła zmusza użytkownika do tworzenia haseł trudniejszych do odgadnięcia. Domyślnie system Windows nie wymaga ustawienia minimalnej długości hasła. W praktyce ustawienie minimalnej długości na 8 znaków jest bardzo dobrym rozwiązaniem. Oczywiście można stosować dłuższe hasła."
    },
    {
        "questionId": 267,
        "title": "Systemowa zapora sieciowa w systemie Windows:",
        "answers": [
            {
                "text": "pozwala zestawiac tunel IPsec domyslnie szyfrujac dane algorytmem 3DES",
                "isCorrect": true
            },
            {
                "text": "moze monitorowac parametry asocjacji IPsec",
                "isCorrect": true
            },
            {
                "text": "pozwala zestawiac tunel IPsec domyslnie szyfrujac dane algorytmem AES",
                "isCorrect": false
            },
            {
                "text": "moze monitorowac parametry asocjacji ISAKMP",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Systemowa zapora sieciowa w systemie Windows, choć podstawowa, oferuje pewne możliwości związane z protokołem IPsec (Internet Protocol Security), który zapewnia ochronę komunikacji na poziomie sieciowym. IPsec jest zbiorem protokołów stosowanych do ochrony ruchu IP poprzez uwierzytelnianie i szyfrowanie każdego pakietu.\n\n**Odpowiedź 1: \"pozwala zestawiac tunel IPsec domyslnie szyfrujac dane algorytmem 3DES\" jest poprawna**. Systemowa zapora sieciowa w systemie Windows integruje się z IPsec, umożliwiając tworzenie tuneli VPN. Domyslnym algorytmem szyfrującym używanym w połączeniach IPsec jest 3DES (Triple DES). Jest to algorytm symetryczny, który używa klucza o długości 168 bitów. Chociaż 3DES nie jest już uważany za najnowocześniejszy algorytm, jest często stosowany w starszych implementacjach IPsec. Implementacja IPsec w Windows wspiera wiele algorytmów szyfrujących, jednak domyślnie wykorzystywany jest 3DES.\n\n**Odpowiedź 2: \"moze monitorowac parametry asocjacji IPsec\" jest poprawna**. Systemowa zapora Windows oferuje pewne możliwości monitorowania stanu asocjacji bezpieczeństwa (ang. _Security Association_ – SA) IPsec. Asocjacja bezpieczeństwa jest zbiorem parametrów (takich jak klucze szyfrowania, algorytmy, adresy IP) które zostały wynegocjowane i są używane w ramach bezpiecznego kanału komunikacji IPsec. Mechanizmy monitorowania umożliwiają administratorowi sprawdzenie poprawności działania tunelu VPN, a także zweryfikowanie zestawionych połączeń.\n\n**Odpowiedź 3: \"pozwala zestawiac tunel IPsec domyslnie szyfrujac dane algorytmem AES\" jest niepoprawna**. Chociaż nowsze wersje IPsec obsługują algorytm AES (Advanced Encryption Standard), systemowa zapora w systemie Windows jako algorytm domyślny stosuje 3DES. AES jest uważany za mocniejszy i szybszy algorytm szyfrowania symetrycznego, i w wielu aplikacjach kryptograficznych zastępuje już algorytm 3DES, jednak w systemie Windows domyślne ustawienie to nadal 3DES.\n\n**Odpowiedź 4: \"moze monitorowac parametry asocjacji ISAKMP\" jest niepoprawna**. ISAKMP (_Internet Security Association and Key Management Protocol_), znany też jako IKE (_Internet Key Exchange_), to protokół służący do uzgadniania parametrów połączenia IPsec, w tym kluczy szyfrowania. Systemowa zapora sieciowa w systemie Windows nie monitoruje parametrów samego procesu uzgadniania protokołu IKE, a raczej parametry istniejącej asocjacji bezpieczeństwa, które powstały po procesie negocjacji. Oznacza to, że narzędzia monitorujące zapory windows nie pozwalają administratorowi, aby monitorować proces wymiany informacji IKE, ale tylko informację o utworzonym połączeniu IPsec."
    },
    {
        "questionId": 268,
        "title": "Lokalna zapora sieciowa systemu Windows na stanowisku X zablokowala mozliwosc zdalnego odpytywania o dostepnosc X przy pomocy narzedzia ping, pozostawiajac jednak mozliwosc zdalnego dostepu do serwera www w tym systemie. Mogla to osiagnac poprzez:",
        "answers": [
            {
                "text": "wylaczenie obslugi przychodzacych komunikatow ICMP echo",
                "isCorrect": true
            },
            {
                "text": "odrzucanie calego ruchu ICMP",
                "isCorrect": false
            },
            {
                "text": "zablokowanie komunikacji z siecia dla programu ping",
                "isCorrect": false
            },
            {
                "text": "wylaczenie ruchu IP na wszystkich interfejsach, ale pozostawienie dostepu do wskazanych portow TCP",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Zapora sieciowa, działająca na stanowisku X, może blokować dostęp do systemu za pomocą narzędzia `ping`, które korzysta z protokołu ICMP (Internet Control Message Protocol), a jednocześnie pozostawić otwarty dostęp do serwera www, który korzysta z protokołu TCP (Transmission Control Protocol), przez filtrowanie ruchu oparte na protokołach. Oznacza to, że reguły zapory pozwalają na ruch sieciowy wykorzystujący protokół TCP (używany przez serwery WWW) ale blokują ruch ICMP (wykorzystywany przez polecenie `ping`).\n\n*   **Poprawna odpowiedź: wyłączenie obsługi przychodzących komunikatów ICMP echo.**\n\n    Protokół ICMP jest używany przez narzędzie `ping` do testowania dostępności hostów. Komunikaty ICMP echo (żądanie echa) i echo reply (odpowiedź echa) są wykorzystywane przez polecenie `ping`. Zapora sieciowa może być skonfigurowana tak, aby blokować przychodzące pakiety ICMP typu echo-request, jednocześnie zezwalając na inne rodzaje ruchu, takie jak TCP używany przez serwery www. W praktyce wiele administratorów sieci wyłącza obsługę ping dla publicznych interfejsów swoich serwerów z uwagi na potencjalne ataki z wykorzystaniem protokołu ICMP. Pozostawiając działanie serwera www bez zmian. Jest to konkretny przykład zastosowania firewalla do selektywnego blokowania ruchu.\n\n*   **Niepoprawna odpowiedź: odrzucanie całego ruchu ICMP.**\n\n    Odrzucanie całego ruchu ICMP byłoby zbyt drastyczne i niepotrzebne, gdy celem jest tylko zablokowanie możliwości korzystania z polecenia `ping`. Takie zachowanie zapory uniemożliwiłoby nie tylko testowanie dostępności przy użyciu polecenia `ping`, ale również zablokowałoby inne, przydatne mechanizmy wykorzystujące protokół ICMP np. diagnostykę sieci, np. _path MTU discovery_. Ponieważ nie ma konieczności blokowania całego ruchu ICMP odpowiedź jest nie poprawna.\n\n*   **Niepoprawna odpowiedź: zablokowanie komunikacji z siecią dla programu ping.**\n\n    Zapory sieciowe zazwyczaj operują na poziomie protokołów (np. TCP, UDP, ICMP) a nie aplikacji. Choć można budować reguły zapory z wykorzystaniem nazw konkretnych aplikacji, to w istocie za takim mechanizmem ukrywa się filtrowanie połączeń na konkretnych portach. To rozwiązanie, które byłoby bardziej specyficzne niż jest to wymagane w opisanym scenariuszu.  Zapory nie działają w ten sposób - nie blokują połączenia konkretnej aplikacji. Aplikacja ping korzysta z protokołu ICMP więc wystarczy zablokować ICMP w zaporze aby zablokować działanie aplikacji ping. Dlatego też odpowiedź ta jest niepoprawna.\n\n*   **Niepoprawna odpowiedź: wyłączenie ruchu IP na wszystkich interfejsach, ale pozostawienie dostepu do wskazanych portow TCP.**\n\n    Wyłączenie ruchu IP na wszystkich interfejsach jest wysoce drastycznym rozwiązaniem. Taka konfiguracja zapory sieciowej wykluczyłaby możliwość komunikacji z komputerem nie tylko przy użyciu polecenia `ping`, ale również uniemożliwiłaby działanie serwera www, który używa protokołu TCP. Pozostawienie dostępu do wskazanych portów TCP byłoby niemożliwe, gdyż brak ruchu IP uniemożliwiłby komunikację protokołem TCP.  Zatem zablokowałoby wszystkie usługi sieciowe, a nie wybrane. Odpowiedź jest więc niepoprawna, gdyż celowo pozostawiono dostęp do serwera www."
    },
    {
        "questionId": 269,
        "title": "Uzytkownik U systemu Unix nalezacy do grupy G1 nie ma wpisu na liscie ACL do zasobu O w systemie plikow. Jednak grupie G1 na liscie ACL tego zasobu nadano prawa r i w, natomiast wszystkim pozostalym (others) - prawa r oraz x. Ktore efektywne uprawnienia do O posiada U? (U nie jest wlascicielem O i nie nalezy do grupy zasobu O):",
        "answers": [
            {
                "text": "r",
                "isCorrect": true
            },
            {
                "text": "w",
                "isCorrect": true
            },
            {
                "text": "x",
                "isCorrect": false
            },
            {
                "text": "zadne",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "W systemach uniksowych, a w tym w Linuxie, kontrola dostępu do zasobów (plików, katalogów, etc.) opiera się na modelu uprawnień, który uwzględnia trzy kategorie podmiotów: właściciela zasobu, grupę, do której należy właściciel i pozostali użytkownicy. Dodatkowo, w systemie ACL (_Access Control Lists_) dozwolone jest precyzyjniejsze określenie uprawnień, poprzez wskazanie konkretnych użytkowników, grup, oraz dodatkowych masek pozwalających doprecyzować prawa dostępu. Standardowe uprawnienia w systemie Unix to: _r_ (odczyt), _w_ (zapis) oraz _x_ (wykonywanie/przeszukiwanie). System operacyjny analizuje uprawnienia w kolejności: najpierw sprawdzane są uprawnienia właściciela, później ACL, następnie uprawnienia grupy, do której należy użytkownik, a na końcu \"others\".\n\nW tym pytaniu, użytkownik U, który należy do grupy G1 nie ma wpisu w ACL dla zasobu O. ACL przypisuje grupie G1 prawa _r_ i _w_, natomiast uprawnienia \"others\" to _r_ i _x_. Użytkownik U nie jest właścicielem O i nie należy do grupy zasobu O.\n\nZatem, ponieważ U nie ma własnego wpisu w ACL, nie jest właścicielem O, i nie należy do grupy zasobu O to uprawnienia do O są obliczane w oparciu o uprawnienia grupowych (G1) oraz \"others\". Prawem nadrzędnym są uprawnienia grupowych, zatem użytkownik otrzymuje prawa r i w wynikające z ustawień grupy. Dodatkowo system operacyjny dopuszcza się do puli uprawnień z grupy \"others\" czyli r i x. W efekcie pula uprawnień to: r, w oraz x. \n\n*   **r:** Jest to poprawne uprawnienie. Użytkownik ma prawo odczytu wynikające z uprawnień grupy G1, a także z uprawnień dla \"others\".\n*   **w:** Jest to poprawne uprawnienie. Użytkownik ma prawo zapisu wynikające z uprawnień grupy G1.\n*   **x:** Jest to niepoprawne uprawnienie. Użytkownik nie ma wyraźnie przypisanego prawa wykonywania z ACL grupy G1. Prawo to wynika z uprawnień dla \"others\". System jednak sprawdza uprawnienia grupy G1 i je przypisuje. Pomijane są uprawnienia dla \"others\" w zakresie uprawnień jakie ma przypisane G1. W efekcie użytkownik nie ma prawa wykonywania.\n*   **żadne:** To nie jest poprawne uprawnienie. Użytkownik U ma prawa dostępu.\n\n**Przykład:**\nZałóżmy, że zasób O to plik o nazwie \"dane.txt\", a U to użytkownik \"janek\". \"Janek\" jest członkiem grupy \"programisci\" i  pliku dane.txt w ACL: \n\n*  grupa programisci ma prawa r i w\n* pozostali użytkownicy maja uprawnienia r i x.\nW pliku ACL nie istnieje wpis dla użytkownika \"janek\".\nW tej sytuacji użytkownik \"janek\" będzie miał efektywne uprawnienia do odczytu i zapisu pliku oraz prawa \"others\" czyli możliwość przeglądania pliku.  Natomiast z prawa wykonania/przeszukiwania nie może skorzystać, gdyż w części uprawnień, do których należy użytkownik, czyli z puli praw G1 uprawnienie to nie występuje."
    },
    {
        "questionId": 270,
        "title": "Zasoby systemu operacyjnego MS Windows udostepnione poprzez SMB:",
        "answers": [
            {
                "text": "moga miec ograniczony dostep do odczytu i/lub zapisu tylko dla wskazanych uzytkownikow",
                "isCorrect": true
            },
            {
                "text": "nazywa sie udzialami",
                "isCorrect": true
            },
            {
                "text": "nazywa sie portami",
                "isCorrect": false
            },
            {
                "text": "przy dostepie zdalnym zawsze wymagane jest logowanie (podawanie hasla)",
                "isCorrect": false
            },
            {
                "text": "tylko uzytkownicy, ktorzy posiadaja lokalne konto w systemie operacyjnym moga uzyskac zdalny dostep do zasobu",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Udostępnianie zasobów w systemie MS Windows za pomocą protokołu SMB (Server Message Block) opiera się na koncepcji tzw. udziałów. Udział (ang. share) to zasób, taki jak katalog, plik lub drukarka, który został udostępniony w sieci i jest dostępny dla innych komputerów i użytkowników. Do zabezpieczania dostępu do tych zasobów stosuje się listy kontroli dostępu (ACL).\n\n**Poprawna odpowiedź 1:** \"mogą mieć ograniczony dostęp do odczytu i/lub zapisu tylko dla wskazanych użytkowników\" - Jest to **poprawna** odpowiedź. Listy kontroli dostępu (ACL), związane z udziałami SMB, pozwalają precyzyjnie określić, które konta użytkowników i/lub grup mają dostęp do odczytu, zapisu, modyfikacji czy usuwania zasobów udostępnianych przez SMB. Na przykład, można ustawić, że użytkownik \"Kowalski\" ma pełny dostęp do udziału \"Dział_Finansowy\", a użytkownik \"Nowak\" tylko prawo do odczytu zawartości tego udziału. W praktyce administratorzy systemów wykorzystują ACL do kontrolowania dostępu do danych i usług w sieci, chroniąc je przed niepowołanym dostępem.\n\n**Poprawna odpowiedź 2:** \"nazywają się udziałami\" - Jest to **poprawna** odpowiedź. W terminologii systemu MS Windows, zasoby udostępnione przez protokół SMB nazywają się udziałami sieciowymi (ang. shares). To jest podstawowe określenie dla tak udostępnionych zasobów. Przykładowo udostępniony katalog to \"udział\", udostępniona drukarka to również \"udział\".\n\n**Niepoprawna odpowiedź 3:** \"nazywają się portami\" - Jest to **niepoprawna** odpowiedź. Porty to numery używane do identyfikacji usług sieciowych działających na komputerze. Numery portów (np. 139 i 445 używane przez SMB) są używane do określania, z jaką usługą komunikuje się komputer, nie identyfikują zasobów udostępnianych przez SMB, do których to dostępu służą udziały. Przykładowo serwer WWW nasłuchuje na porcie 80/443, serwer FTP na 21, serwer bazy danych na 1433. \n\n**Niepoprawna odpowiedź 4:** \"przy dostępie zdalnym zawsze wymagane jest logowanie (podawanie hasła)\" - Jest to **niepoprawna** odpowiedź. Dostęp do zasobów udostępnionych przez SMB nie zawsze wymaga interaktywnego logowania (w postaci np. okienka z pytaniem o hasło). Może on być zrealizowany przy użyciu zapamiętanych poświadczeń. Przykładowo gdy użytkownik loguje się do systemu Windows wykorzystując konto domeny może uzyskać dostęp do udziałów sieciowych domeny bez konieczności podawania hasła. Takie połączenie jest realizowane poprzez mechanizm _pass-through authentication_. Również aplikacje sieciowe np. usługi systemowe mogą mieć zdefiniowane w swoich konfiguracjach uprawnienia do dostępu do zasobów SMB. W takim przypadku hasła są przechowywane w bezpieczny sposób, a sam proces uwierzytelnienia następuje automatycznie bez ingerencji użytkownika.\n\n**Niepoprawna odpowiedź 5:** \"tylko użytkownicy, którzy posiadają lokalne konto w systemie operacyjnym mogą uzyskać zdalny dostęp do zasobu\" - Jest to **niepoprawna** odpowiedź. Dostęp do zasobów udostępnionych poprzez SMB nie jest ograniczony tylko dla użytkowników posiadających konta lokalne na komputerze który udostępnia udział, w przypadku gdy zasoby udostępniane są w domenie, dostęp do udziału mogą uzyskać użytkownicy domenowi (posiadający konta domenowe). Przykładowo w firmie użytkownicy logują się do serwera domenowego który zarządza dostępem do zasobów w obrębie domeny. W takim przypadku logując się do domeny, użytkownik domeny może uzyskać dostęp do zasobów udostępnionych przez serwery tej domeny. Istotna jest znajomość użytkownika i jego grupy w ACL, nie to czy posiada konto lokalne czy domenowe."
    },
    {
        "questionId": 271,
        "title": "ssh -L 9999:cerber:23 polluks  Wybierz prawdziwe stwierdzenia dotyczace powyzszego polecenia:",
        "answers": [
            {
                "text": "ruch miedzy miedzy lokalnym komputerem a polluksem bedzie szyfrowany",
                "isCorrect": true
            },
            {
                "text": "dane kierowane na port 9999 systemu cerber zostana przeslane w zaszyfrowanej formie na port 23 systemu polluks",
                "isCorrect": false
            },
            {
                "text": "dane kierowane na port 9999 systemu cerber zostana przeslane w niezabezpieczonej formie na port 23 systemu polluks",
                "isCorrect": false
            },
            {
                "text": "w wyniku polecenia zestawiony zostanie zabezpieczony tunel miedzy systemem cerberem a polluksem",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Polecenie `ssh -L 9999:cerber:23 polluks` tworzy tunel SSH. Tunel SSH to szyfrowane połączenie między dwoma komputerami, w tym przypadku między twoim komputerem a `polluks`, przy czym twoje polecenie uruchamiasz na komputerze lokalnym. Opcja `-L 9999:cerber:23` ustawia tzw. lokalne przekierowanie portów (ang. _local port forwarding_). Numer `9999` to lokalny port na komputerze, z którego wywołujesz polecenie ssh. Adres `cerber` i port `23` to docelowy adres i port usługi po stronie serwera (czyli po stronie  `polluks`). Kluczowe jest zrozumienie, że `cerber` jest widziany z perspektywy serwera `polluks`, a nie z twojego komputera. To oznacza, że adres `cerber` w domyśle oznacza adres komputera lub innej usługi dostępnej z `polluks`. Polecenie spowoduje nawiązanie połączenia ssh do komputera `polluks`. Po ustanowieniu połączenia cały ruch wysłany na port `9999` twojego komputera zostanie zaszyfrowany, a następnie przesłany poprzez ustanowiony tunel do komputera `polluks`, który z kolei przekieruje ten ruch na port 23 komputera o adresie `cerber`.\n\n**Odpowiedź 1: \"ruch miedzy miedzy lokalnym komputerem a polluksem bedzie szyfrowany\" - PRAWDA.**\nTa odpowiedź jest poprawna, ponieważ cała komunikacja pomiędzy twoim lokalnym komputerem, a komputerem o nazwie `polluks`, wykorzystująca protokół SSH jest szyfrowana. Dotyczy to również danych przesyłanych poprzez tunel. Mechanizm SSH domyślnie szyfruje całą komunikację aby uniemożliwić przechwycenie danych przez nieuprawnione osoby.  W praktyce,  oznacza to, że nikt podsłuchujący sieć nie będzie w stanie odczytać  przesyłanych przez ciebie informacji, np hasła.\n\n**Odpowiedź 2: \"dane kierowane na port 9999 systemu cerber zostana przeslane w zaszyfrowanej formie na port 23 systemu polluks\" - FAŁSZ.**\nTa odpowiedź jest błędna.  Dane kierowane na port `9999` twojego lokalnego komputera zostaną przekierowane do portu `23` serwera o nazwie `cerber`, który musi być widziany ze strony serwera `polluks`. Przekierowanie do `cerber` nie dzieje się na twoim komputerze, tylko dopiero na serwerze `polluks`.  Dodatkowo przesyłane dane są szyfrowane w trakcie ich transportu miedzy twoim komputerem a serwerem `polluks`.  W praktyce oznacza to, że dane wysłane na port `9999` nie są przekazywane do serwera `cerber`  bezpośrednio, tylko są szyfrowane i przesyłane do portu 22 serwera `polluks`, a ten przekierowuje je na port 23 serwera `cerber`.  Jeśli  `cerber` nie jest dostępny z `polluks`  lub na komputerze `polluks` usługa z którą chcesz się połączyć nie jest dostępna , to połączenie nie zostanie ustanowione a twoje  próby połączenia na port `9999` lokalnego komputera nic nie dadzą.\n\n**Odpowiedź 3: \"dane kierowane na port 9999 systemu cerber zostana przeslane w niezabezpieczonej formie na port 23 systemu polluks\" - FAŁSZ.**\nTa odpowiedź jest błędna. Tak jak zostało powiedziane wcześniej, cały ruch który przesyłamy poprzez protokół SSH jest szyfrowany.  Ta odpowiedź odzwierciedla błędne rozumowanie zasady działania tunelu i pomija fakt szyfrowania tunelu. W praktyce oznacza to, że nikt podsłuchujący sieci nie zobaczy twoich danych w nie zaszyfrowanej postaci.\n\n**Odpowiedź 4: \"w wyniku polecenia zestawiony zostanie zabezpieczony tunel miedzy systemem cerberem a polluksem\" - PRAWDA.**\nTa odpowiedź jest poprawna. Poprzez tunel należy rozumieć zaszyfrowany kanał komunikacyjny, po przez który możliwe jest bezpieczne przesyłanie danych. Tunele w protokole SSH są tworzone między komputerem na którym uruchamiamy aplikacje klienta SSH (twój komputer) a serwerem SSH czyli komputerem o nazwie `polluks`. Z tego też powodu komunikacja pomiędzy twoim komputerem a komputerem `polluks` jest bezpieczna. Zazwyczaj tunel wykorzystywany jest tylko i wyłącznie w obrębie przesyłania danych pomiędzy twoim komputerem a komputerem `polluks`. W przykładzie mamy dodatkowo przekierowanie lokalnego portu do portu komputera o nazwie `cerber` z którego możemy korzystać po ustanowieniu tunelu SSH. A więc za pomocą polecenia `ssh -L` tworzymy bezpieczny tunel pomiędzy twoim komputerem a `polluks`."
    },
    {
        "questionId": 272,
        "title": "Kto moze nadawac/modyfikowac uprawnienia POSIX ACL danego obiektu w systemie plikow:",
        "answers": [
            {
                "text": "wlasciciel obiektu, ale pod warunkiem, ze posiada prawo 'w'",
                "isCorrect": false
            },
            {
                "text": "wlasciciel obiektu, niezaleznie od posiadania prawa 'w'",
                "isCorrect": true
            },
            {
                "text": "dowolny uzytkownik posiadajacy prawo modyfikacji pliku",
                "isCorrect": false
            },
            {
                "text": "administrator (root)",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizmy kontroli dostępu POSIX ACL (Access Control Lists) rozszerzają standardowe uprawnienia systemu plików w systemach Linux/Unix (właściciel, grupa, inni) umożliwiając przypisywanie bardziej szczegółowych uprawnień poszczególnym użytkownikom i grupom. W kontekście modyfikacji tych uprawnień, kluczowe jest zrozumienie roli właściciela obiektu oraz użytkownika administratora (root).\n\n**Właściciel obiektu**, czyli użytkownik który stworzył dany obiekt (plik lub katalog), ma domyślnie prawo modyfikowania jego uprawnień ACL **niezależnie** od posiadania prawa zapisu 'w'. To znaczy, że właściciel ma prawo nadawać, modyfikować, oraz odbierać uprawnienia ACL nawet jeśli sam nie posiada prawa do zapisu tego obiektu (np. nie posiada prawa 'w' dla pliku).\n**Administrator (root)**, czyli superużytkownik systemu, ma *zawsze* prawo modyfikować uprawnienia dowolnego obiektu, w tym również ACL. Uprawnienia administratora nie zależą od żadnych innych uprawnień, ani od tego czy ma lub nie ma ustawione prawa dostępu do obiektu.\n\n**Pierwsza odpowiedź jest niepoprawna**, ponieważ łączy ze sobą posiadanie prawa 'w' z możliwością modyfikacji ACL. Chociaż prawo 'w' umożliwia modyfikację zawartości pliku, to nie daje możliwości modyfikacji jego uprawnień (ACL). Przykład: Użytkownik posiada prawo 'w' do pliku - oznacza to, że może modyfikować zawartość pliku, nie może natomiast modyfikować ACL tego pliku. \n\n**Druga odpowiedź jest poprawna**, ponieważ właściciel pliku, nawet jeśli nie ma prawa zapisu (w), ma zawsze prawo modyfikować uprawnienia ACL do tego obiektu. Ta cecha jest bardzo ważna w systemach z zaawansowaną polityką bezpieczeństwa. Przykład: Użytkownik jest właścicielem pliku jednak nie ma do niego prawa 'w', ma natomiast prawo dodawania innych użytkowników na listę ACL.\n\n**Trzecia odpowiedź jest niepoprawna**, ponieważ nie każdy użytkownik, który ma prawo do modyfikacji pliku, ma prawo do modyfikowania uprawnień ACL. Uprawnienie 'w' jest do modyfikacji zawartości pliku. Przykład: użytkownik posiada prawo do zapisu do danego pliku, jednak nie jest właścicielem pliku, nie może modyfikować uprawnień ACL tego pliku.\n\n**Czwarta odpowiedź jest poprawna**, ponieważ administrator, posiada wszystkie uprawnienia w systemie operacyjnym, między innymi również uprawnienia do modyfikowania ACL. Administrator działa w systemie na prawach superużytkownika i jest zawsze zwolniony z wszelkich ograniczeń w systemie plików.\nPrzykład: Administrator zawsze może modyfikować ACL każdego pliku w systemie niezależnie od tego czy ma uprawnienia odczytu czy zapisu danego pliku."
    },
    {
        "questionId": 273,
        "title": "Mechanizm SUID/SGID:",
        "answers": [
            {
                "text": "SUID zawsze powoduje wykonanie aplikacji z uprawnieniami grupy wlasciciela aplikacji",
                "isCorrect": false
            },
            {
                "text": "SUID zawsze powoduje wykonanie aplikacji z uprawnieniami administratorskimi",
                "isCorrect": false
            },
            {
                "text": "SGID zawsze powoduje wykonanie aplikacji z uprawnieniami administratorskimi",
                "isCorrect": false
            },
            {
                "text": "SGID zawsze powoduje wykonanie aplikacji z uprawnieniami grupy wlasciciela aplikacji",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizmy SUID (Set User ID) i SGID (Set Group ID) to specjalne bity uprawnień w systemach uniksowych, które modyfikują sposób, w jaki wykonywane są programy. Bit SUID, ustawiony na pliku wykonywalnym, powoduje, że proces uruchomiony z tego pliku, będzie działał z uprawnieniami _właściciela_ tego pliku, a nie z uprawnieniami użytkownika, który go uruchomił.  Bit SGID działa analogicznie, z tym, że proces dziedziczy _grupę_ właściciela pliku. Jest to istotne rozróżnienie, ponieważ wpływa na prawa dostępu do zasobów systemu i bezpieczeństwo.\n\n**Odpowiedź 1: \"SUID zawsze powoduje wykonanie aplikacji z uprawnieniami grupy wlasciciela aplikacji\"**\n\nTa odpowiedź jest **niepoprawna**. SUID powoduje wykonanie programu z uprawnieniami *właściciela* pliku wykonywalnego, a nie jego *grupy*. Przykładowo, jeśli plik `/usr/bin/mójprogram` ma ustawiony bit SUID i jest własnością użytkownika root, to każdy, kto go uruchomi, będzie miał *efektywnie* uprawnienia użytkownika root podczas wykonywania tego programu.\n\n**Odpowiedź 2: \"SUID zawsze powoduje wykonanie aplikacji z uprawnieniami administratorskimi\"**\n\nTa odpowiedź jest **niepoprawna**. SUID powoduje, że proces wykonuje się z uprawnieniami *właściciela* pliku wykonywalnego. Jeśli właścicielem jest użytkownik `root`, to faktycznie daje uprawnienia administracyjne. Jednak jeśli właścicielem jest inny użytkownik, proces ten będzie działał z uprawnieniami tego *innego* użytkownika.  Na przykład, gdy plik ma SUID, a właścicielem jest użytkownik \"john\", to proces będzie wykonywany z uprawnieniami użytkownika \"john\", a nie administratora. Zatem SUID nie zawsze oznacza uprawnienia administratorskie.\n\n**Odpowiedź 3: \"SGID zawsze powoduje wykonanie aplikacji z uprawnieniami administratorskimi\"**\n\nTa odpowiedź jest **niepoprawna**. Bit SGID, w przeciwieństwie do SUID, powoduje, że proces wykonuje się z uprawnieniami *grupy* właściciela pliku, a nie z uprawnieniami samego *właściciela* ani z uprawnieniami administratorskimi. Analogicznie do SUID, jeśli dany program ma ustawiony SGID i jest własnością grupy `admin`, to proces będzie wykonywany z uprawnieniami tej grupy, a niekoniecznie z uprawnieniami administratorskimi `root`.\n\n**Odpowiedź 4: \"SGID zawsze powoduje wykonanie aplikacji z uprawnieniami grupy wlasciciela aplikacji\"**\n\nTa odpowiedź jest **poprawna**. SGID (Set Group ID) ustawiony na pliku wykonywalnym powoduje, że proces, który ten plik uruchomi, będzie miał efektywne uprawnienia grupy, będącej *właścicielem* tego pliku. Przykładowo, jeśli właścicielem pliku jest grupa \"users\", a bit SGID jest ustawiony, to każdy, kto uruchomi ten plik będzie działać z uprawnieniami grupy \"users\". To rozróżnienie ma kluczowe znaczenie w systemach UNIX/Linux, gdyż umożliwia elastyczne nadawanie uprawnień różnym użytkownikom."
    },
    {
        "questionId": 274,
        "title": "Wpisy ACE (na liscie ACL) zabraniajace dostepu:",
        "answers": [
            {
                "text": "wystepuja tylko w przypadku zwirtualizowanych aplikacji w MS Windows",
                "isCorrect": false
            },
            {
                "text": "nie sa dziedziczone wglab katalogu",
                "isCorrect": false
            },
            {
                "text": "wystepuja tylko w POSIX ACL",
                "isCorrect": false
            },
            {
                "text": "maja priorytet nad wpisami ACE przyznajacymi dostep",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Listy kontroli dostępu (ACL) są mechanizmem używanym do regulowania dostępu do zasobów, takich jak pliki lub katalogi. Każdy wpis w takiej liście nazywa się wpisem kontroli dostępu (ACE, ang. Access Control Entry). Wpis ACE może przyznawać lub odmawiać dostępu do danego zasobu. W przypadku, gdy występuje konflikt pomiędzy wpisami przyznającymi dostęp i wpisami odmawiającymi dostęp, to wpis odmawiający dostęp zawsze ma priorytet. Jest to kluczowa zasada bezpieczeństwa – eksplicitne odmowy dostępu mają pierwszeństwo, zabezpieczając przed przypadkowym umożliwieniem dostępu.\n\n**Odpowiedź a) \"wystepuja tylko w przypadku zwirtualizowanych aplikacji w MS Windows\" jest niepoprawna.** Wpisy ACE zabraniające dostępu są podstawowym elementem działania ACL i nie są one specyficzne dla zwirtualizowanych aplikacji w MS Windows. Używa się ich powszechnie w różnych systemach operacyjnych.\n\n**Odpowiedź b) \"nie sa dziedziczone wglab katalogu\" jest niepoprawna.** Wpisy ACE zabraniające dostępu, tak samo jak i przyznające dostęp, zazwyczaj są dziedziczone przez podkatalogi i pliki w danym katalogu. Należy zwrócić uwagę, iż w niektórych przypadkach możliwe jest wyłączenie tej funkcjonalności.\n\n**Odpowiedź c) \"wystepuja tylko w POSIX ACL\" jest niepoprawna.** Wpisy ACE zabraniające dostępu są dostępne zarówno w listach ACL zdefiniowanych w standardzie POSIX, jak i listach ACL stosowanych w systemie MS Windows.\n\n**Odpowiedź d) \"maja priorytet nad wpisami ACE przyznajacymi dostep\" jest poprawna.** W systemach, które używają list ACL, w przypadku wystąpienia konfliktu między wpisami odmawiającymi i przyznającymi dostęp, wygrywa wpis odmawiający dostęp. W systemach Linux mechanizm ACL jest powszechny i domyślny, w systemach Windows mechanizm ACL jest podstawą działania systemu NTFS.\n    \n**Przykład:** Załóżmy, że mamy katalog `/dane` z następującą listą ACL:\n    * Użytkownik `jan` ma *przyznany* dostęp do odczytu (`r`).\n    * Grupa `finanse` ma *przyznany* dostęp do zapisu (`w`).\n    * Użytkownik `jan` ma *odmówiony* dostęp do zapisu (`!w`).\n\nW tym przykładzie, mimo, że użytkownik `jan` ma przyznane prawa do odczytu, wpis odmawiający dostęp do zapisu ma pierwszeństwo. W efekcie użytkownik `jan` może tylko czytać, a zapisywanie jest zabronione. Użytkownicy w grupie `finanse` mogą zarówno czytać jak i zapisywać. Jeżeli dodamy wpis odmawiający dostęp do zapisu dla grupy `finanse`, wpis ten będzie miał pierwszeństwo przed wpisem, który przyznaje grupie `finanse` dostęp do zapisu.\n\nZrozumienie tej zasady jest bardzo ważne w kontekście bezpieczeństwa. Pozwala ona na konstruowanie systemów o wysokim stopniu bezpieczeństwa, eliminując przypadki nieautoryzowanego dostępu do zasobów. Np. gdy zależy nam aby jakiś plik lub katalog nie był dostępny dla konkretnego użytkownika, to należy zabronić mu dostępu do zasobu, nawet jeśli został mu przyznany dostęp do danej grupy, a ta grupa ma uprawnienia do tego pliku/katalogu. Ta zasada obowiązuje także przy dziedziczeniu uprawnień. Jeśli zabronimy dostępu do danego katalogu, to to zabronienie będzie dziedziczone przez wszystkie podkatalogi, i inne zasoby w tym katalogu."
    },
    {
        "questionId": 275,
        "title": "Jakie metody uwierzytelniania oferuje protokol HTTP:",
        "answers": [
            {
                "text": "obustronne uwierzytelnianie metoda Diffiego-Hellmana",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie serwera poprzez certyfikat X.509",
                "isCorrect": false
            },
            {
                "text": "uwierzytelnianie klienta poprzez userame token (username+password)",
                "isCorrect": true
            },
            {
                "text": "uwierzytelnianie klienta metoda digest (z uzyciem funkcji skrotu)",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół HTTP (Hypertext Transfer Protocol) definiuje kilka metod uwierzytelniania, które pozwalają serwerowi na weryfikację tożsamości użytkownika przed udostępnieniem żądanych zasobów.\n\n*   **\"obustronne uwierzytelnianie metoda Diffiego-Hellmana\"** - To stwierdzenie jest **niepoprawne**. Metoda Diffiego-Hellmana to protokół wymiany kluczy, wykorzystywany do uzgodnienia tajnego klucza, który później może zostać wykorzystany do szyfrowania komunikacji. Nie jest ona stosowana bezpośrednio do obustronnego uwierzytelniania w protokole HTTP. Protokół HTTP sam w sobie nie definiuje protokołu wymiany kluczy, a w konsekwencji nie umożliwia przeprowadzenia obustronnego uwierzytelniania. Diffie-Hellman może być wykorzystany na przykład w protokole SSL/TLS, który jest wyższą warstwą w stosie protokołów.\n\n*   **\"uwierzytelnianie serwera poprzez certyfikat X.509\"** - To stwierdzenie jest **niepoprawne**. Certyfikaty X.509 są używane w protokole SSL/TLS, a nie bezpośrednio w protokole HTTP. Protokół HTTP sam w sobie nie obsługuje uwierzytelniania serwera za pomocą certyfikatów X.509. Protokół HTTPS jest protokołem HTTP działającym w szyfrowanym kanale protokołu SSL/TLS i dopiero w tym przypadku możemy zweryfikować autentyczność serwera przy użyciu certyfikatu X.509.\n\n*   **\"uwierzytelnianie klienta poprzez userame token (username+password)\"** - To stwierdzenie jest **poprawne**.  HTTP Basic Authentication używa tokena w postaci `username:password`, zakodowanego algorytmem Base64. Klient wysyła ten token w nagłówku `Authorization` każdego żądania do serwera. Na przykład, klient może wysłać nagłówek `Authorization: Basic dXNlcm5hbWU6cGFzc3dvcmQ=`, gdzie `dXNlcm5hbWU6cGFzc3dvcmQ=` to zakodowana Base64 postać ciągu \"username:password\". Jest to najprostsza metoda uwierzytelniania w HTTP, jednak nie oferuje wystarczającego poziomu bezpieczeństwa, ponieważ hasło, choć zakodowane Base64,  może być łatwo odczytane. W praktyce mechanizm ten powinien być używany wyłącznie, gdy wykorzystywana jest ochrona przesyłanych danych protokołem SSL/TLS.\n\n*   **\"uwierzytelnianie klienta metoda digest (z uzyciem funkcji skrotu)\"** - To stwierdzenie jest **poprawne**. Digest Authentication to ulepszona wersja Basic Authentication, która nie przesyła hasła użytkownika bezpośrednio przez sieć. W zamian, używa ona funkcji skrótu (hash) do zakodowania hasła i przesyła ten hash. Serwer również przechowuje hasło w postaci hash, zatem dla przeprowadzenia uwierzytelniania, serwer i klient używają tych samych algorytmów skrótu. Przykładowo, po otrzymaniu nagłówka  `WWW-Authenticate: Digest realm=\"testrealm\",nonce=\"456789\"`, klient wylicza skrót z połączenia nazwy użytkownika, realm, hasła i otrzymanego nonce (losowo generowany ciąg znaków), po czym wysyła skrót w nagłówku `Authorization: Digest username=\"testuser\", realm=\"testrealm\", nonce=\"456789\", uri=\"/index.html\", response=\"d6f8a32c4656874...\".` W ten sposób hasło nie jest przesyłane jawnie, co podnosi poziom bezpieczeństwa w stosunku do Basic Authentication. Digest Authentication jest silniejsze niż Basic Authentication, gdyż nie przesyła hasła w tekście jawnym. Jest ono stosowane w wielu aplikacjach internetowych wymagających uwierzytelniania."
    },
    {
        "questionId": 276,
        "title": "Trusted Platform Module (TPM) moze byc wykorzystywany do:",
        "answers": [
            {
                "text": "przechowywania kluczy kryptograficznych uzywanych przez aplikacje w systemie operacyjnym",
                "isCorrect": true
            },
            {
                "text": "uwierzytelniania podmiotu przy wystawianiu certyfikatu przez urzad CA w systemie PKI",
                "isCorrect": false
            },
            {
                "text": "podejmowania decyzji o autoryzacji w systemie kontroli dostepu MAC",
                "isCorrect": false
            },
            {
                "text": "wykonywania operacji kryptograficznych zlecanych przez aplikacje w systemie operacyjnym",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Trusted Platform Module (TPM) to dedykowany mikrokontroler, często implementowany jako oddzielny układ scalony na płycie głównej komputera, który został zaprojektowany w celu zapewnienia funkcji bezpieczeństwa związanych z kryptografią.  TPM jest zasadniczo sprzętowym modułem bezpieczeństwa, co oznacza, że operacje kryptograficzne wykonywane w jego ramach, oraz przechowywanie wrażliwych danych takich jak klucze odbywa się w bezpiecznym środowisku, odpornym na manipulacje. \n\n**Odpowiedź 1 (przechowywania kluczy kryptograficznych używanych przez aplikacje w systemie operacyjnym) jest poprawna.** TPM jest zaprojektowany do bezpiecznego przechowywania kluczy kryptograficznych. Klucze te mogą być używane przez system operacyjny lub aplikacje w nim działające do szyfrowania, deszyfrowania lub uwierzytelniania danych. W przeciwieństwie do przechowywania kluczy w pamięci RAM lub na dysku twardym, gdzie są one bardziej podatne na ataki, TPM zapewnia specjalne, odporne na manipulacje środowisko do ich przechowywania. Przykładowo system operacyjny Windows używa TPM do przechowywania kluczy stosowanych przy szyfrowaniu dysków BitLocker.\n \n**Odpowiedź 2 (uwierzytelniania podmiotu przy wystawianiu certyfikatu przez urząd CA w systemie PKI) jest niepoprawna.** TPM nie jest bezpośrednio zaangażowany w proces wystawiania certyfikatów przez urząd certyfikacji (CA). Urząd CA w infrastrukturze klucza publicznego (PKI) wykorzystuje swoje własne klucze do podpisywania certyfikatów. Użytkownik tworzący prośbę o certyfikat (CSR - _Certificate Signing Request_) generuje klucz prywatny i z niego generowany jest klucz publiczny, który to jest wysyłany do urzędu certyfikacji. Po autoryzacji urzad certyfikacji podpisuje klucz publiczny. TPM może *przechowywać* klucz prywatny używany przez użytkownika do generowania CSR, ale sam proces uwierzytelniania przed CA i wystawianie certyfikatu odbywa się za pośrednictwem oprogramowania, które wykorzystuje TPM, natomiast *nie jest* wykonywany przez TPM. TPM może wzmacniać bezpieczeństwo certyfikatu chroniąc klucz prywatny przed dostępem przez nieautoryzowane oprogramowanie, ale nie wystawia certyfikatów.\n \n**Odpowiedź 3 (podejmowania decyzji o autoryzacji w systemie kontroli dostępu MAC) jest niepoprawna.**  TPM nie jest mechanizmem kontroli dostępu w rozumieniu modelu MAC (_Mandatory Access Control_). System MAC to polityka kontroli dostępu w której polityka jest z góry narzucona przez administratora i niemożliwa do obejścia przez właściciela zasobów. Mechanizm MAC nie jest zależny od sprzętu w którym jest zainstalowany, natomiast TPM jest specjalnym sprzętowym modułem bezpieczeństwa. Mechanizm MAC można za to implementować w systemach z TPM lub bez niego. System MAC określa, które procesy mogą uzyskać dostęp do określonych zasobów i nie bazuje na informacjach z modułu TPM. Przykładowo w systemach z certyfikacją zaufania MAC często wykorzystywane są etykiety wrażliwości (_ang. sensitivity labels_). Sam TPM nie ma kompetencji do odczytywania etykiet wrażliwości, ani podejmowania decyzji w oparciu o polityki systemu MAC. \n \n**Odpowiedź 4 (wykonywania operacji kryptograficznych zlecanych przez aplikacje w systemie operacyjnym) jest poprawna.** TPM posiada możliwość wykonywania operacji kryptograficznych w sposób bezpieczny dla systemu operacyjnego i aplikacji, które wywołują te operacje poprzez specjalne API, np. algorytmy szyfrowania, deszyfrowania, podpisu cyfrowego czy generowanie liczb losowych. Na przykład aplikacje do szyfrowania danych mogą wykorzystać TPM do wygenerowania bezpiecznego klucza szyfrującego bez ujawniania go na zewnątrz TPM. Inny przykład to funkcja _secure boot_ wbudowana w system operacyjny, gdzie TPM weryfikuje czy podczas uruchamiania systemu nie nastąpiła ingerencja nieautoryzowanego oprogramowania."
    },
    {
        "questionId": 277,
        "title": "Czy zaszyfrowany plik w systemie MS Windows mozemy wspoldzielic z innym uzytkownikiem?:",
        "answers": [
            {
                "text": "tylko pod warunkiem przekazania temu uzytkownikowi swojego klucza prywatnego",
                "isCorrect": false
            },
            {
                "text": "tylko pod warunkiem przekazania temu uzytkownikowi swojego klucza publicznego",
                "isCorrect": false
            },
            {
                "text": "nie jest to mozliwe",
                "isCorrect": false
            },
            {
                "text": "pod warunkiem posiadania certyfikatu EFS tego uzytkownika",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "W systemie Windows, szyfrowanie plików za pomocą EFS (Encrypting File System) opiera się na koncepcji kryptografii klucza publicznego i certyfikatów użytkownika. Gdy szyfrujemy plik, system używa klucza publicznego powiązanego z naszym certyfikatem EFS. To nie oznacza jednak, że tylko my możemy ten plik odszyfrować. Domyślnie tylko my możemy go odszyfrować, jednak istnieje możliwość udostępnienia takiego pliku innym użytkownikom. Klucz prywatny, powiązany z certyfikatem, jest używany do odszyfrowania pliku, który był wcześniej zaszyfrowany za pomocą klucza publicznego powiązanego z naszym certyfikatem. Plik jest bezpieczny, gdyż tylko my możemy odszyfrować zaszyfrowany plik, ponieważ tylko my posiadamy klucz prywatny. \n\nOpcja \"tylko pod warunkiem przekazania temu uzytkownikowi swojego klucza prywatnego\" jest **niepoprawna**, ponieważ udostępnienie klucza prywatnego drugiej osobie jest bardzo ryzykowne, gdyż tą samą drogą druga osoba może przekazać nasz klucz prywatny dalej. Zatem utracimy całkowitą kontrolę nad naszymi zaszyfrowanymi plikami. Ponadto, system Windows nie udostępnia łatwo możliwości eksportu klucza prywatnego i jego użycia z innego konta użytkownika, więc nawet technicznie nie jest to proste zadanie. Dodatkowo, klucz prywatny jest wrażliwą daną i nigdy nie powinien być nikomu udostępniany.\n\nOpcja \"tylko pod warunkiem przekazania temu uzytkownikowi swojego klucza publicznego\" jest również **niepoprawna**. Klucz publiczny jest z definicji publiczny i możemy go komu chcemy przekazywać. Jednak klucz publiczny nie służy do odszyfrowania zaszyfrowanego pliku przez EFS, tylko do szyfrowania plików, które tylko właściciel klucza prywatnego może odszyfrować. Zatem przekazanie klucza publicznego nie umożliwi drugiej osobie odszyfrowania pliku chronionego przez EFS. \n\nOpcja \"nie jest to mozliwe\" jest **niepoprawna**. Zgodnie z opisem z początku odpowiedzi wiadomo, iż system EFS umożliwia udostępnienie zaszyfrowanego pliku innym użytkownikom.\n\nOpcja \"pod warunkiem posiadania certyfikatu EFS tego uzytkownika\" jest **poprawna**. Mechanizm EFS w systemie MS Windows umożliwia udostępnianie pliku innym użytkownikom w taki sposób, iż oprócz tego, że my możemy ten plik odszyfrować, to również wybrana przez nas osoba również ma możliwość odszyfrowania pliku. W procesie udostępniania pliku używamy certyfikatu tej osoby. W systemie MS Windows jest to procedura intuicyjna i polega ona na dodaniu danego użytkownika do uprawnień dostępu zaszyfrowanego pliku. System Windows w tym przypadku wyszukuje certyfikat EFS drugiej osoby, używa klucza publicznego z tego certyfikatu do wygenerowania klucza, którym dodatkowo szyfruje plik i umieszcza ten klucz przy pliku. Zatem tylko my i wybrana przez nas osoba będzie miała dostęp do odszyfrowania pliku. Odszyfrowanie odbywa się przy użyciu klucza prywatnego tej osoby.\nW praktyce oznacza to, że aby udostępnić zaszyfrowany plik, musimy posiadać dostęp do certyfikatu EFS użytkownika, któremu chcemy ten plik udostępnić. Proces ten zachodzi automatycznie z poziomu panelu właściwości udostępnianego pliku, po zaznaczeniu opcji _zaawansowane -> szyfruj -> szczegóły -> dodaj_ – gdzie system poprosi nas o nazwę konta użytkownika, któremu chcemy dać dostęp do pliku, a następnie doda do pliku klucz szyfrujący, znany tylko nam i drugiemu użytkownikowi."
    },
    {
        "questionId": 278,
        "title": "W jaki sposob mozna jednoznacznie okreslic, ktore konto w systemie operacyjnym MS Windows jest wbudowanym kontem administracyjnym?:",
        "answers": [
            {
                "text": "Aktualnie nie ma jednego wbudowanego konta administracyjnego- kazde konto uzytkownika moze posiadac takie uprawnienia po odpowiedniej konfiguracji",
                "isCorrect": false
            },
            {
                "text": "konto takie ma zawsze nazwe \"Administrator\"",
                "isCorrect": false
            },
            {
                "text": "czesc wzgledna identyfikatora tego konta ma stala wartosc 500",
                "isCorrect": true
            },
            {
                "text": "czesc wzgledna identyfikatora tego konta ma stala wartosc 0",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Identyfikacja użytkownika w systemach MS Windows opiera się na koncepcji identyfikatorów bezpieczeństwa (ang. Security Identifiers – SID). Każde konto użytkownika, grupa, a nawet obiekt w systemie Windows posiada swój unikatowy SID. SID składa się z trzech części: identyfikatora domeny (w której konto zostało utworzone), oraz dwóch numerów identyfikacyjnych. Drugim z nich jest numer identyfikujący konkretną instancję konta w danej domenie(ang. Relative Identifier RID).  \nDla kont wbudowanych w system operacyjny Windows RID ma zawsze stałe wartości, co pozwala na jednoznaczne zidentyfikowanie takiego konta w systemie bez konieczności analizy jego nazwy. Nazwa konta może zostać zmieniona, natomiast RID pozostaje stały. Identyfikator RID dla wbudowanego konta administratora ma zawsze wartość 500. Wartość tego identyfikatora nie zależy od nazwy konta, stąd jest niezmienna.\n\n**Odpowiedź 1: \"Aktualnie nie ma jednego wbudowanego konta administracyjnego- kazde konto uzytkownika moze posiadac takie uprawnienia po odpowiedniej konfiguracji\"** jest niepoprawna. Chociaż prawda jest, że dowolne konto użytkownika może mieć nadane uprawnienia administracyjne, to wbudowane konto administratora zawsze jest dostępne i posiada określony identyfikator RID (500) oraz jest automatycznie tworzone podczas instalacji systemu, co pozwala je wyróżnić od innych kont.\n\n**Odpowiedź 2: \"konto takie ma zawsze nazwe \"Administrator\"\"** jest niepoprawna. Nazwa konta administratora może zostać zmieniona. Nie jest to jednoznaczny sposób na odróżnienie tego konta od pozostałych. Atakujący, tworząc konto użytkownika w systemie może nadać mu nazwę Administrator i udawać tym samym wbudowane konto. Stąd wniosek, że poleganie tylko na nazwie konta jest niewystarczające, chociaż oczywiście bardzo powszechne.\n\n**Odpowiedź 3: \"czesc wzgledna identyfikatora tego konta ma stala wartosc 500\"** jest poprawna.  Identyfikator RID dla wbudowanego konta administratora ma zawsze wartość 500. Jest to jednoznaczny sposób na odróżnienie tego konta od innych kont, niezależnie od nazwy konta administratora. W praktyce, wiedza ta jest niezbędna administratorom systemów Windows do identyfikacji i zabezpieczania kont uprzywilejowanych, które stanowią bardzo popularny cel ataku.\n\n**Odpowiedź 4: \"czesc wzgledna identyfikatora tego konta ma stala wartosc 0\"** jest niepoprawna. Chociaż w systemach Unixowych UID (User Identifier) o wartości 0 jest zarezerwowany dla superużytkownika root, to w systemach MS Windows RID o wartości 0 nie jest powiązany z kontem administratora. W rzeczywistości system operacyjny Windows tak naprawdę nie posiada konta o RID=0 a ten identyfikator jest wykorzystywany dla innego celu.\n\n**Przykład praktyczny:** Administrator systemu, przeglądając logi zdarzeń, widzi logowanie użytkownika o nazwie \"Administrator\".  Samo istnienie takiego logowania nie musi automatycznie świadczyć o potencjalnym zagrożeniu. Jednak sprawdzenie SID logującego użytkownika i odczytanie RID 500 potwierdza, że na pewno loguje się wbudowane konto administracyjne. Jeśli RID miałby inną wartość, np 1001, system operacyjny wykryłby podszycie się pod nazwę \"Administrator\" .  W praktyce administrator powinien zawsze weryfikować SID i RID (zwłaszcza tych użytkowników którym nadano uprawnienia administracyjne) aby mieć 100% pewność z jakim kontem w systemie ma do czynienia, bowiem podszycie pod wbudowane konto administratora jest najczęstszą metodą ataku wykorzystującą ludzką naiwność i brak dokładnej analizy sytuacji."
    },
    {
        "questionId": 279,
        "title": "Co oznacza termin \"asocjacja bezpieczenstwa\" (ang.Security Association)?:",
        "answers": [
            {
                "text": "Nazwa jednokierunkowego protokolu uwierzytelniania tuneli IPSec",
                "isCorrect": false
            },
            {
                "text": "Jest to zestaw parametrow zabezpieczonego polaczenia niezbedny do poprawnej interpretacji danych plynacych w tunelu VPN",
                "isCorrect": true
            },
            {
                "text": "Jest to wstepny proces zestawiania tunelu VPN, w ktorym negocjowane sa parametry polaczenia",
                "isCorrect": false
            },
            {
                "text": "Jest to nazwa polityki IPsec okreslajace filtry pakietow poddawanych zabezpieczaniu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Asocjacja bezpieczeństwa (ang. Security Association, w skrócie SA) w kontekście protokołu IPsec to zbiór parametrów opisujących zabezpieczone połączenie między dwoma hostami. Parametry te obejmują m.in. użyte algorytmy szyfrowania i autentykacji, tryb pracy (transportowy lub tunelowy) oraz klucze sesyjne. Każda SA jest jednokierunkowa, co oznacza, że dla pełnej komunikacji dwukierunkowej pomiędzy dwoma hostami (np. serwerem i klientem VPN) potrzebne są dwie asocjacje – jedna dla każdego kierunku transmisji. Identyfikatorem SA w nagłówku pakietu IPsec jest indeks parametrów bezpieczeństwa (ang. Security Parameters Index, SPI). SA to nie jest pojedyncza funkcja/protokół tylko kompleks danych konfiguracyjnych opisujących połączenie.\n\n**Odpowiedź 1: \"Nazwa jednokierunkowego protokolu uwierzytelniania tuneli IPSec\"**\nTa odpowiedź jest błędna, ponieważ SA nie jest protokołem, lecz zbiorem parametrów, które są wykorzystywane przez protokoły takie jak ESP lub AH podczas tunelowania IPsec. Uwierzytelnianie, z kolei, choć powiązane z IPsec, jest innym procesem (zwykle wykorzystującym protokół IKE).\n\n**Odpowiedź 2: \"Jest to zestaw parametrow zabezpieczonego polaczenia niezbedny do poprawnej interpretacji danych plynacych w tunelu VPN\"**\nTa odpowiedź jest poprawna. Asocjacja bezpieczeństwa to właśnie taki zbiór parametrów, bez którego prawidłowa interpretacja danych, czyli w szczególności ich odszyfrowanie i uwierzytelnienie nie byłoby możliwe. Bez tych parametrów nie można by w żaden sposób odtworzyć (odszyfrować) przesyłanych danych w tunelu VPN. SA przechowuje informacje o uzgodnionych metodach szyfrowania, typie tunelowania (transportowy, tunelowy), kluczach, które zabezpieczają sesję.\n\n**Odpowiedź 3: \"Jest to wstepny proces zestawiania tunelu VPN, w ktorym negocjowane sa parametry polaczenia\"**\nTa odpowiedź jest niepoprawna.  Choć proces uzgadniania parametrów (ang. key exchange) jest istotną częścią tworzenia tunelu VPN i również jest związany z protokołem IPsec, to nie jest tym czym jest asocjacja bezpieczeństwa. SA jest *wynikiem* tego procesu uzgadniania, a nie samym procesem. Proces negocjacji (np. IKE) ustala parametry SA, ale SA jest zbiorem tych ustalonych parametrów.\n\n**Odpowiedź 4: \"Jest to nazwa polityki IPsec okreslajace filtry pakietow poddawanych zabezpieczaniu\"**\nTa odpowiedź jest niepoprawna. Polityka IPsec określa sposób, w jaki dany host ma reagować na pakiety (np. które pakiety mają być szyfrowane a które nie) a nie definiuje zestaw parametrów połączenia. Polityka to wyższy poziom decyzyjny i operuje na szerszym zakresie niż pojedyncza asocjacja bezpieczeństwa.  SA określa sposób zabezpieczenia konkretnego połączenia, polityka natomiast mówi, jak ma się dany system zachować w przypadku różnych połączeń.\n\n**Przykład praktyczny:** Wyobraźmy sobie, że dwa serwery (A i B) tworzą tunel IPsec. Podczas uzgadniania parametrów (np. w protokole IKE) serwer A proponuje szyfrowanie AES256, uwierzytelnianie SHA256 oraz tryb tunelowy. Serwer B akceptuje te propozycje. Te parametry oraz uzgodnione klucze tworzą w serwerze A i B SA, identyfikowaną przez SPI.  Następnie, gdy serwer A będzie chciał przesłać do serwera B pakiet danych, to dzięki SA będzie wiedział jak pakiet zaszyfrować, i na odwrót, serwer B będzie wiedział jak poprawnie pakiet odszyfrować. Bez SA nie byłoby możliwe ustalenie tych parametrów i prawidłowa interpretacja przesyłanych danych. Zatem SA to nie tylko abstrakcyjne pojęcie, ale realne parametry konkretnego połączenia."
    },
    {
        "questionId": 280,
        "title": "Ktore stwierdzenia dotyczace blokady konta w systemie Windows sa nieprawdziwe:",
        "answers": [
            {
                "text": "prog blokady okresla ilosc kolejnych niepomyslnych prob logowania, po osiagnieciu ktorej dostep do konta bedzie czasowo zablokowany",
                "isCorrect": false
            },
            {
                "text": "licznik prob logowania jest zerowany automatycznie po uplywie czasu blokady konta",
                "isCorrect": false
            },
            {
                "text": "podczas blokady konta, kolejne logowanie bedzie mozliwe dopiero po wyzerowaniu licznika prob (np. przez administratora)",
                "isCorrect": true
            },
            {
                "text": "w czasie okreslonym dlugoscia okresu zerowania licznika prob logowania, uzytkownik nie moze podjac wiecej udanych prob logowania niz okresla prog blokady",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Blokada konta to mechanizm bezpieczeństwa, który chroni konta użytkowników przed atakami brutalnej siły (ang. brute-force attacks). Atak tego typu polega na automatycznym wielokrotnym próbowaniu zalogowania się na dane konto poprzez próbowanie różnych kombinacji haseł. System blokady konta w systemie Windows działa poprzez konfigurację trzech podstawowych parametrów.\n\n**Próg blokady konta** (_ang. account lockout threshold_) określa ile nieudanych prób logowania może nastąpić zanim konto użytkownika zostanie zablokowane. Na przykład, jeżeli próg blokady konta wynosi 5, to po pięciu nieudanych próbach zalogowania się na konto to konto zostanie zablokowane. Próby te musza wystąpić jedna po drugiej, pomiędzy udanymi próbami logowania licznik jest zerowany, o ile ustawiono odpowiedni parametr zerowania licznika prób logowania.\n\n**Czas trwania blokady konta** (_ang. account lockout duration_) określa jak długo konto ma być zablokowane, licznik prób logowania nie jest zerowany po upływie tego czasu. W trakcie trwania blokady ponowna próba zalogowania na dane konto nie powiedzie się.\n\n**Okres zerowania licznika prób logowania** (_ang. reset account lockout counter after_) określa po jakim czasie od wystąpienia nieudanej próby logowania licznik nieudanych prób ma być wyzerowany. Jest to parametr o tyle istotny, że po wyzerowaniu licznika, użytkownik ma ponownie daną szansę, która definiowana jest progiem blokady konta. Przykładowo, użytkownik 2 razy nie podał poprawnego hasła po czym po upływie okresu zerowania, ma możliwość 5 nieudanych prób a nie 3 jak by to było gdyby czas zerowania był bardzo długi. Ten parametr ma ogromne znaczenie przy próbach ataku z użyciem brutalnej siły.\n\nZ analizy powyższego opisu wynika iż, pierwsze stwierdzenie jest poprawne, bo odnosi się do progu blokady konta, i w poprawny sposób opisuje ten parametr. Drugie stwierdzenie jest również poprawne bo odnosi się do okresu zerowania licznika prób i faktycznie po upływie tego czasu licznik jest zerowany automatycznie. Czwarte stwierdzenie jest również poprawne, bo odnosi się do działania licznika prób logowania powiązanego z progiem blokady konta oraz okresem zerowania licznika. Natomiast **trzecie stwierdzenie jest nieprawdziwe**, gdyż po zablokowaniu konta system operacyjny odmawia przyjęcia jakichkolwiek nowych prób logowania, nawet poprawnych. Dopiero po upłynięciu czasu blokady konta kolejne próby logowania będą przyjmowane z powrotem, licznik nieudanych prób logowania nie zostanie wyzerowany przez administratora systemu. W tym stwierdzeniu brak jest elementu automatycznego zerowania licznika, co jest nieprawdą. W rzeczywistości administrator nie musi wyzerować licznika, gdyż czyni to automatycznie system operacyjny po upływie czasu blokady konta. Użycie polecenia wyzerowania licznika przez administratora spowoduje natychmiastową możliwość logowania na zablokowane konto bez potrzeby czekania na upłynięcie czasu blokady.\n\nPrzykładowo: ustawiamy próg blokady na 3, czas trwania blokady na 30 minut i czas zerowania na 15 minut. Użytkownik podaje błędne hasło, po czym po minucie ponownie podaje błędne hasło i kolejny raz po 5 minutach. W tej chwili ma dwie nieudane próby. Po upływie 15 minut(czas zerowania) licznik nieudanych prób zostaje wyzerowany. Jeżeli natomiast użytkownik po upływie 16 minut (po ostatniej nieudanej próbie logowania) ponownie wpisze błędne hasło, to licznik nieudanych prób logowania osiągnie wartość 3, w tym momencie konto zostanie zablokowane na 30 minut(czas trwania blokady), a po upływie 30 minut konto zostanie automatycznie odblokowane. Nie jest potrzebna żadna interwencja administratora, aby wyzerować licznik, gdyż dzieje się to automatycznie."
    },
    {
        "questionId": 281,
        "title": "Zapora sieciowa lokalnego systemu na stanowisku X zablokowala mozliwosc zdalnego odpytywania o dostepnosci X przy pomocy narzedzia ping, pozostawiajac jednak mozliwosc zdalnego dostepu do serwera www w tym systemie. Mogla to osiagnac poprzez:",
        "answers": [
            {
                "text": "wylaczenie ruchu IP na wszystkich interfejsach, ale pozostawienie dostepu do wskazanych portow TCP",
                "isCorrect": false
            },
            {
                "text": "zablokowanie komunikacji z siecia dla programu ping",
                "isCorrect": false
            },
            {
                "text": "wylaczenie obslugi przychodzacych komunikatow ICMP echo",
                "isCorrect": true
            },
            {
                "text": "odrzucenie calego ruchu ICMP",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Zapora sieciowa (firewall) kontroluje ruch sieciowy, analizując nagłówki pakietów danych. Robi to na podstawie zdefiniowanych reguł, a każda reguła filtruje ruch, który jest do niej dopasowany, podejmując z góry ustaloną akcję: akceptację (ACCEPT) lub odrzucenie pakietu (DROP). Zapora sieciowa może działać na różnych poziomach modelu OSI, a ten konkretny problem dotyczy warstwy sieciowej (protokół IP), warstwy transportowej (protokoły TCP i UDP) oraz protokołu ICMP (kontrolnego protokołu internetowego). Zapora sieciowa może blokować całe protokoły lub jedynie wybrane porty protokołu TCP i UDP. Porty umożliwiają wieloprogramowość przy korzystaniu z TCP i UDP. Dzięki tym portom różne usługi (np. poczta, strona www, usługa zdalnego dostępu, itp.) mogą działać na tym samym komputerze. Protokół ICMP nie ma portów. \n\n* **Opcja 1: wylaczenie ruchu IP na wszystkich interfejsach, ale pozostawienie dostepu do wskazanych portow TCP**\nTa odpowiedź jest niepoprawna. Zapora sieciowa, aby zapewnić zdalny dostęp do serwera www w systemie X, musi pozostawić aktywny ruch IP (który jest podstawą protokołów TCP/IP) na interfejsie serwera. Musi również pozostawić aktywny ruch TCP dla portu 80 (domyślny port usługi HTTP) lub 443 (dla HTTPS), aby strony www mogły być udostępniane. Wyłączenie całego ruchu IP uniemożliwiłoby dostęp do serwera www, ponieważ ten transfer danych również opiera się na protokole IP. Zapory sieciowe oferują możliwość rozróżniania protokołów, blokowania całego protokołu IP byłoby bezsensowne dla tego zadania.\n\n* **Opcja 2: zablokowanie komunikacji z siecia dla programu ping**\nTa odpowiedź jest niepoprawna. Zapora sieciowa działa na poziomie warstwy sieciowej lub transportowej. System operacyjny nie udostępnia interfejsu do filtrowania komunikacji sieciowej dla konkretnych programów. Zablokowanie komunikacji dla programu ping wymaga ingerencji w kod źródłowy tego programu lub blokowanie całej komunikacji za pomocą warstwy sieciowej co nie umożliwia dostępu do serwera www.\n\n* **Opcja 3: wylaczenie obslugi przychodzacych komunikatow ICMP echo**\nTa odpowiedź jest poprawna. Narzędzie ping, które służy do sprawdzania dostępności systemów, wykorzystuje protokół ICMP, a dokładniej komunikaty ICMP echo request i echo reply. Poprzez wyłączenie obsługi przychodzących komunikatów ICMP echo system X będzie nieosiągalny z zewnątrz przy użyciu narzędzia ping, jednocześnie nie blokując usługi serwera www (która działa z wykorzystaniem protokołu TCP, na portach 80 lub 443).\n  * Praktyczny przykład: Jeśli zapora sieciowa zablokuje przychodzące ICMP echo request, a pakiety TCP na port 80 będą dozwolone to narzędzie _ping_ w systemie Y nie będzie komunikowało się z systemem X, mimo iż serwer www na X nadal będzie osiągalny dla przeglądarki.\n\n* **Opcja 4: odrzucenie calego ruchu ICMP**\nTa odpowiedź jest niepoprawna. Odrzucenie całego ruchu ICMP zablokuje działanie nie tylko narzędzia _ping_ ale również narzędzi używanych do detekcji sieci. Zablokowanie całego ruchu ICMP, jest również formą ochrony przed niektórymi atakami typu denial of service, a więc jest to jedna z możliwych konfiguracji firewalla. Jednakże nie wyjaśnia ona przyczyny blokady narzędzia ping z zachowaniem dostępności do strony www.\n  * Praktyczny przykład: Jeśli zapora sieciowa odrzuci przychodzące ICMP, to _ping_ nie będzie działał, ale również inne narzędzia bazujące na ICMP również nie będą mogły dotrzeć do systemu."
    },
    {
        "questionId": 282,
        "title": "Ktora z ponizszych uslug aplikacyjnych wykorzystuje mechanizm SSO:",
        "answers": [
            {
                "text": "rlogin",
                "isCorrect": true
            },
            {
                "text": "telnet",
                "isCorrect": true
            },
            {
                "text": "tcpd",
                "isCorrect": false
            },
            {
                "text": "xinetd",
                "isCorrect": false
            },
            {
                "text": "ssh",
                "isCorrect": false
            },
            {
                "text": "rsh",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Single Sign-On (SSO) to mechanizm, który umożliwia użytkownikowi jednokrotne uwierzytelnienie, a następnie dostęp do wielu różnych zasobów i usług bez konieczności ponownego podawania hasła. SSO upraszcza procedurę logowania i zwiększa komfort użytkowników przy jednoczesnym zachowaniu wysokiego poziomu bezpieczeństwa.\n\n* **rlogin:**  `rlogin` to protokół zdalnego logowania. Chociaż użytkownik może uzyskać dostęp do zdalnego systemu bez podawania hasła, to jedynie w przypadku, gdy host, z którego następuje logowanie jest zaufany. To zaufanie opiera się na plikach `.rhosts` lub `/etc/hosts.equiv`. Jest to relacja zaufania niebędąca SSO. `rlogin` *nie* jest SSO, gdyż logowanie do systemu zdalnego odbywa się na podstawie zaufania do konkretnych hostów a nie prawdziwego uwierzytelnienia (np. kluczem kryptograficznym) po stronie użytkownika, to jednak systemy w których wykorzystywany jest `rlogin` mogą tworzyć środowisko w którym użytkownik logując się na hosta głównego może uzyskać dostęp do innych usług bez dodatkowej autoryzacji(klasyczny SSO), dlatego jest to **poprawna** odpowiedź.  Dodatkowo należy podkreślić, że uwierzytelnianie za pomocą `rlogin` odbywa się przy przesłaniu hasła w postaci jawnej.\n\n*   **telnet:** `telnet` jest protokołem umożliwiającym dostęp do zdalnego interfejsu tekstowego. Uwierzytelnienie użytkownika za pomocą protokołu `telnet` wymaga podania loginu i hasła. Hasło przesyłane jest w postaci jawnej i nie można rozszerzyć możliwości tej usługi o SSO. Dlatego `telnet` jest **poprawną** odpowiedzią, gdyż nie wykorzystuje mechanizmów SSO a jedynie zwykłe uwierzytelnianie. Uwierzytelnianie za pomocą `telnet` jest mało bezpieczne z uwagi na jawny przesył haseł.\n\n*   **tcpd:**  `tcpd` (TCP Wrapper) to narzędzie kontroli dostępu do usług sieciowych. Nie jest protokołem uwierzytelniającym. Działa poprzez analizę IP i portów. `tcpd` sam w sobie nie realizuje idei SSO. Zapewnia jedynie *kontrolę dostępu* ograniczając hosty mogące łączyć się z określoną usługą. Dlatego jest to odpowiedź **niepoprawna**.  Aplikacja tcpd zabezpiecza usługę działającą na danym komputerze przed atakami z nieautoryzowanych hostów w ten sposób, że blokuje połączenia, które są niezgodne z regułami bezpieczeństwa zapisanymi w konfiguracji tego programu.\n\n*   **xinetd:** Podobnie jak `tcpd`, `xinetd` (eXtended Internet Daemon) to super-serwer usług sieciowych, służący do uruchamiania usług tylko w przypadku żądania połączenia. `xinetd` również nie jest mechanizmem SSO, a mechanizmem, który monitoruje nasłuchiwanie i uruchamia usługi na żądanie. Zatem odpowiedź jest **niepoprawna**.  `xinetd` nie zapewnia żadnego mechanizmu SSO.\n\n*   **ssh:** `ssh` (Secure Shell) to protokół zdalnego, szyfrowanego dostępu do konta użytkownika na innym komputerze. Mimo, że `ssh` sam w sobie nie jest mechanizmem SSO to  może być skonfigurowany tak aby korzystać z uwierzytelnienia kluczem, w tym również ze specjalnego agenta ssh, który umożliwia dostęp do serwera bez ponownego wpisywania hasła przy każdym nowym połączeniu. Jednakże bez wyżej wspomnianej konfiguracji, `ssh` wymaga autoryzacji na każdym połączeniu i samo w sobie nie jest mechanizmem SSO, w związku z czym odpowiedź jest **niepoprawna**. Warto zaznaczyć, że klucze w SSH mogą być użyte w systemach SSO, ale sam `ssh` nie jest systemem SSO.\n\n*   **rsh:** Podobnie jak `rlogin` i `telnet`, `rsh` (Remote Shell) jest starszym protokołem umożliwiającym wykonywanie komend na zdalnym komputerze. Mechanizm uwierzytelniania użytkownika jest identyczny jak w `rlogin` z plikami `.rhosts`, a więc nie spełnia on definicji SSO, dlatego jest to odpowiedź **niepoprawna**. Podobnie jak `rlogin` `rsh` przesyła hasło w postaci jawnej.\n\nPodsumowując, poprawne odpowiedzi to `rlogin` oraz `telnet` z uwagi na mechanizm relacji zaufania jaki jest zaimplementowany w tych protokołach, w szczególności `rlogin` z uwagi na możliwość utworzenia środowiska w którym użytkownik po zalogowaniu do hosta głównego, może uzyskać dostęp do pozostałych usług i zasobów bez ponownej autoryzacji. Pomimo braku możliwości wdrożenia w każdym przypadku, `rlogin` ma taką możliwość."
    },
    {
        "questionId": 283,
        "title": "Mechanizm sudo umozliwia:",
        "answers": [
            {
                "text": "wskazanie konta, z ktorego mozna wykonac polecenie bez pytania o haslo uzytkownika przypisanego do pliku programu tego polecenia, pod warunkiem przynaleznosci do grupy przypisanego do tego pliku",
                "isCorrect": true
            },
            {
                "text": "okreslenie jaki uzytkownik moze wykonywac konkretne programy z innymi uprawnieniami",
                "isCorrect": true
            },
            {
                "text": "wykonywanie tylko programow nalezacych do uzytkownika root z uprawnieniami biezacego uzytkownika",
                "isCorrect": false
            },
            {
                "text": "uruchamianie innych aplikacji wylacznie z uprawnieniami administratora",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm `sudo` w systemach operacyjnych opartych na jądrze Linux umożliwia użytkownikom uruchamianie poleceń z uprawnieniami innego użytkownika, najczęściej administratora systemu czyli użytkownika `root`. Kluczową rolę w działaniu `sudo` odgrywa plik konfiguracyjny `/etc/sudoers`, w którym administrator definiuje politykę kontroli dostępu. To właśnie zawartość tego pliku określa, który użytkownik, jakie polecenia i z jakimi uprawnieniami może uruchamiać.\n\n*   **Odpowiedź 1: \"wskazanie konta, z ktorego mozna wykonac polecenie bez pytania o haslo uzytkownika przypisanego do pliku programu tego polecenia, pod warunkiem przynaleznosci do grupy przypisanego do tego pliku\"** - **Poprawna.** `sudo` w połączeniu z konfiguracją w pliku `/etc/sudoers` może zezwalać określonym użytkownikom, lub grupom użytkowników, na uruchamianie konkretnych poleceń, z uprawnieniami wskazanego konta, a nie tylko `root`, bez konieczności podawania hasła. Dzieje się tak jeśli w konfiguracji `/etc/sudoers` dany użytkownik, grupa użytkowników ma do tego prawo, co jest oznaczone słowem `NOPASSWD:`. Przykładowo linia: `user1 ALL=(user2) NOPASSWD:/usr/bin/command` oznacza, że użytkownik `user1` z dowolnego hosta (`ALL`) może bez podawania hasła uruchomić komendę `/usr/bin/command` z uprawnieniami użytkownika `user2`. Linia `user1 %group1=(user2) NOPASSWD:/usr/bin/command` oznacza że użytkownik `user1` z grupy `group1` może z dowolnego hosta bez podawania hasła uruchomić komendę `/usr/bin/command` z uprawnieniami użytkownika `user2`. Dodatkowo ta odpowiedź akcentuje że uprawnienia z jakimi ma zostać uruchomiona komenda zależą od użytkownika przypisanego do pliku programu. Oczywiście można wskazać użytkownika który będzie nadawał uprawnienia do uruchomienia aplikacji np. `sudo -u wwwrun /bin/ls /var/www` spowoduje że aplikacja `ls` będzie uruchomiona z uprawnieniami użytkownika `wwwrun`, a nie użytkownika wywołującego polecenie `sudo`.\n\n*   **Odpowiedź 2: \"okreslenie jaki uzytkownik moze wykonywac konkretne programy z innymi uprawnieniami\"** - **Poprawna.**  Plik `/etc/sudoers` definiuje precyzyjnie, którzy użytkownicy mogą uruchamiać które programy (lub grupy programów) i z jakimi uprawnieniami (określonym użytkownikiem lub grupą).  Przykładowo, wpis `user2  ALL=/sbin/shutdown -h now` pozwala użytkownikowi `user2` uruchamiać polecenie wyłączania systemu `shutdown -h now` z uprawnieniami roota (ponieważ `shutdown` w większości przypadków wymaga takich uprawnień).\n\n*   **Odpowiedź 3: \"wykonywanie tylko programow nalezacych do uzytkownika root z uprawnieniami biezacego uzytkownika\"** - **Niepoprawna.**  `sudo` nie ogranicza się tylko do programów będących własnością `root`. `sudo` umożliwia uruchamianie programów z uprawnieniami innego użytkownika, ale konfiguracja tego mechanizmu (w pliku `/etc/sudoers`) określa, które programy mogą być uruchamiane i z jakimi uprawnieniami. Oczywiście bardzo często używa się mechanizmu sudo do wykonywania aplikacji z uprawnieniami administratora systemu jednak mechanizm ten jest o wiele bardziej elastyczny.\n\n*  **Odpowiedź 4: \"uruchamianie innych aplikacji wylacznie z uprawnieniami administratora\"** - **Niepoprawna.** `sudo` co prawda pozwala w większości przypadków na podniesienie uprawnień do poziomu administratora, jednak nie jest to warunek konieczny. `sudo` można skonfigurować tak, aby  określony użytkownik mógł uruchamiać programy z uprawnieniami dowolnego innego użytkownika, a nie tylko roota. Przykładowo: `user3 ALL=(user4) /bin/ps` pozwoli użytkownikowi `user3` uruchamiać polecenie `/bin/ps` z uprawnieniami użytkownika `user4`.\n\nPodsumowując, `sudo` to mechanizm zapewniający elastyczną kontrolę dostępu w systemach Linux/Unix, pozwalając administratorom na precyzyjne definiowanie, kto może wykonywać jakie operacje i z jakimi uprawnieniami. Oprócz tego, `sudo` jest często używane aby wykonywać konkretną aplikację z uprawnieniami innego użytkownika."
    },
    {
        "questionId": 284,
        "title": "Mechanizmem PAM mozna skonfigurowac:",
        "answers": [
            {
                "text": "ograniczenia czasowe dostepu do systemu operacyjnego",
                "isCorrect": true
            },
            {
                "text": "ograniczenie maksymalnego ilosci procesow jakie moze uruchomic uzytkownik",
                "isCorrect": true
            },
            {
                "text": "sposob uwierzytelniania aplikacji",
                "isCorrect": false
            },
            {
                "text": "procedure zmiany danych uwierzytelniajacych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Pluggable Authentication Modules (PAM) to mechanizm w systemach Linux/Unix, który umożliwia konfigurację różnych aspektów związanych z uwierzytelnianiem i kontrolą dostępu do systemu operacyjnego. PAM pozwala administratorom na elastyczne definiowanie polityk bezpieczeństwa poprzez konfigurowanie wielu modułów. Moduły PAM nie realizują samego uwierzytelniania, a modyfikują jego przebieg lub dodają do niego kolejne kroki. \n\n*   **Ograniczenia czasowe dostępu do systemu operacyjnego:** Jest to **poprawna** odpowiedź. Mechanizm PAM, poprzez odpowiednie moduły (np. `pam_time.so`), umożliwia definiowanie reguł ograniczających czas dostępu użytkowników do systemu.  Na przykład można ustawić, że konkretne konto użytkownika może logować się tylko w określonych godzinach lub dniach tygodnia. W praktyce, firma może użyć PAM do ustawienia polityki, która blokuje możliwość logowania pracowników spoza godzin pracy.\n\n*   **Ograniczenie maksymalnej ilości procesów jakie może uruchomić użytkownik:** Jest to **poprawna** odpowiedź. PAM, w połączeniu z odpowiednimi modułami (np. `pam_limits.so`), pozwala konfigurować limity zasobów, takie jak maksymalna liczba procesów, które użytkownik może uruchomić. Na przykład, można ograniczyć liczbę procesów użytkownika 'guest', co zapobiega potencjalnym atakom typu DoS (Denial of Service), gdzie napastnik próbuje uruchomić nadmierną liczbę procesów, aby przeciążyć system.\n\n*   **Sposób uwierzytelniania aplikacji:** Jest to **niepoprawna** odpowiedź. PAM *nie* konfiguruje sposobu uwierzytelniania aplikacji. PAM jest wykorzystywany przez aplikację po to aby przeprowadzić proces uwierzytelniania. Mechanizm ten jest odpowiedzialny jedynie za narzucenie polityki bezpieczeństwa na proces logowania. Decyzje o metodzie uwierzytelniania należą do aplikacji(np. hasło, biometria, jednorazowe hasło). Aplikacja poprzez PAM może wymagać tylko spełnienia pewnych wymagań odnośnie uwierzytelnienia. Na przykład aplikacja logowania do systemu operacyjnego wykorzystuje PAM do sprawdzenia czy hasło użytkownika ma odpowiednią długość lub czy jest wystarczająco złożone, ale to nie PAM realizuje proces weryfikacji hasła, tylko wtyczka dostarczona przez system operacyjny lub niezależną bibliotekę(np. wtyczka systemowa shadow, md5, itp.)\n\n*   **Procedurę zmiany danych uwierzytelniających:** Jest to **niepoprawna** odpowiedź.  PAM nie jest odpowiedzialny za procedurę zmiany danych uwierzytelniających. Ustawienia dotyczące procedury zmiany danych uwierzytelniających mogą być modyfikowane w innych miejscach systemie, na przykład poprzez konfiguracje samego procesu w systemie operacyjnym(np.  /usr/bin/passwd) lub poprzez specjalny program do ustawiania nowych haseł(np.  npasswd, passwd+). PAM, w wypadku procedury zmiany hasła, może pomóc przykładowo poprzez wtyczkę cracklib w kontrolowaniu jakości hasła i uniemożliwiać ustawienia zbyt prostego hasła."
    },
    {
        "questionId": 285,
        "title": "Preshared key to:",
        "answers": [
            {
                "text": "(wstepny) klucz symetryczny",
                "isCorrect": true
            },
            {
                "text": "mechanizm pozwalajacy uwierzytelniac i szyfrowac za pomoca jednego klucza",
                "isCorrect": true
            },
            {
                "text": "silny mechanizm uwierzytelniania wykorzystujacy generowany losowo po obu stronach klucz",
                "isCorrect": false
            },
            {
                "text": "silny mechanizm szyfrowania wykorzystujacy certyfikaty SSL do generacji losowego klucza sesyjnego",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Klucz pre-shared key (PSK) to tajny klucz symetryczny, który jest wcześniej uzgodniony i współdzielony między dwiema stronami komunikacji. Jest on wykorzystywany zarówno do uwierzytelniania, jak i do szyfrowania przesyłanych danych. Szyfrowanie symetryczne, w przeciwieństwie do asymetrycznego, stosuje ten sam klucz do szyfrowania i deszyfrowania. W kontekście sieci VPN, PSK służy do stworzenia początkowego, bezpiecznego kanału, po którym mogą być przesyłane kolejne, bardziej skomplikowane klucze sesyjne.\n\n**Odpowiedź 1: \"(wstępny) klucz symetryczny\" jest poprawna.**  Klucz PSK to w istocie tajny klucz symetryczny. Jest on *wstępny* w tym znaczeniu, że jest ustawiany z wyprzedzeniem (na przykład poprzez ręczną konfigurację urządzeń) i często wykorzystywany jako baza do wygenerowania kolejnych kluczy. Algorytmy symetryczne (np. Blowfish, AES) używają tego samego klucza do szyfrowania i deszyfrowania danych. Klucz ten, w kontekście PSK, musi być identyczny po obu stronach komunikacji.\n\n**Odpowiedź 2: \"mechanizm pozwalający uwierzytelniać i szyfrować za pomocą jednego klucza\" jest poprawna.** PSK realizuje oba te zadania:  uwierzytelnianie (upewnienie, że strona z którą się łączymy posiada ten sam klucz) oraz szyfrowanie (zapewnienie poufności danych). Uwierzytelnianie jest tutaj implikowane samym faktem, że obie strony znają ten sam tajny klucz – i to wiedzą (lub powinny wiedzieć) tylko one. Uwierzytelnienie to w tym przypadku jest *słabe*, bo jeśli klucz dostanie się w niepowołane ręce, to osoba trzecia ma możliwość nawiązania połączenia podając jedynie ten klucz.\n\n**Odpowiedź 3: \"silny mechanizm uwierzytelniania wykorzystujący generowany losowo po obu stronach klucz\" jest niepoprawna.** PSK *nie* wykorzystuje klucza generowanego losowo po obu stronach, lecz *wcześniej uzgodniony* klucz, ustalony w sposób bezpieczny (choć nie przez automatyczny mechanizm generowania klucza).  Uwierzytelnianie jest w tym przypadku *słabe*. Termin *silny mechanizm* odnosi się do uwierzytelniania opartego na protokołach wymiany kluczy i certyfikatów, które to mechanizmy nie stosują PSK. \n\n**Odpowiedź 4: \"silny mechanizm szyfrowania wykorzystujący certyfikaty SSL do generacji losowego klucza sesyjnego\" jest niepoprawna.** Klucz PSK jest mechanizmem *uwierzytelniania i szyfrowania* sam w sobie i nie potrzebuje certyfikatów SSL do jego działania. Certyfikaty SSL są elementem infrastruktury klucza publicznego (PKI) i związane są z asymetryczną kryptografią. Generowanie *losowego* klucza sesyjnego jest istotnym elementem procesów szyfrowania, jednak PSK nie jest generowany losowo na każdym połączeniu. Tak naprawdę PSK jest wykorzystywany jako *wstępny* klucz służący do utworzenia połączenia, które może wykorzystać dodatkowe procedury generowania kluczy sesyjnych.\n\n**Przykład praktyczny:** W domowym routerze WiFi wykorzystywane jest hasło (PSK) do zabezpieczenia sieci bezprzewodowej. Wszystkie urządzenia, które chcą się połączyć z tym routerem muszą podać dokładnie ten sam, wcześniej skonfigurowany (lub uzgodniony) klucz PSK. Protokół WPA2-Personal używa PSK do weryfikacji czy urządzenie ma prawo połączyć się z siecią.  Następnie następuje dynamiczne wygenerowanie klucza sesyjnego dla bezpiecznej komunikacji (które to z kolei jest szyfrowane PSK). Takie rozwiązanie jest bardzo wygodne dla użytkowników, lecz nie zapewnia w pełni bezpieczeństwa, gdy klucz PSK został upubliczniony."
    },
    {
        "questionId": 286,
        "title": "Mechanizm User Account Control (UAC) systemu Windows:",
        "answers": [
            {
                "text": "blokuje konto po zdefiniowanej wczesniej ilosci nieudanych prob logowania",
                "isCorrect": false
            },
            {
                "text": "wprowadza dodatkowa forme ochrony konta administracyjnego m.in. przed koniami trojanskimi i zlosliwym oprogramowaniem",
                "isCorrect": true
            },
            {
                "text": "pozwala administratorowi chwilowo skorzystac z pelnego tokenu administracyjnego",
                "isCorrect": false
            },
            {
                "text": "wirtualizuje dostep do newralgicznych komponentow systemu plikow",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm Kontroli Konta Użytkownika (ang. User Account Control – UAC) w systemie Windows ma na celu ograniczenie uprawnień procesów, nawet tych uruchamianych przez konta administracyjne, aby zapobiegać nieautoryzowanym zmianom w systemie oraz rozprzestrzenianiu się złośliwego oprogramowania. \nUAC działa poprzez różnicowanie między tokenem standardowym, z którym uruchamiane są aplikacje użytkownika, a tokenem administracyjnym, który zapewnia pełną kontrolę nad systemem. Aplikacje uruchamiane z wykorzystaniem tokena standardowego mogą tylko w ograniczonym zakresie wykonywać operacje w systemie. Aplikacje, które wymagają wyższych uprawnień, uruchamiają się z użyciem tokena administracyjnego. Wykorzystanie tokena administracyjnego wymaga każdorazowej zgody użytkownika i odbywa się poprzez tak zwane monity UAC(które zadają pytanie o dostęp). UAC nie jest mechanizmem logowania do systemu, ale procesem podwyższania uprawnień dla poszczególnych aplikacji.\nDodatkowo mechanizm UAC realizuje wirtualizację dostępu do newralgicznych elementów systemu plików. Dzięki tej wirtualizacji aplikacje nie mają dostępu do rzeczywistych plików systemu operacyjnego tylko do ich wirtualnej wersji, dzięki temu szkodliwe oprogramowanie nie może zainfekować plików systemowych, gdyż system operacyjny uważa że proces nie ma do niego prawa dostępu, w tym też sensie jest to ograniczenie dostępu.\n\n*   **\"blokuje konto po zdefiniowanej wczesniej ilosci nieudanych prob logowania\"** - Ta odpowiedź jest *niepoprawna*. Opisuje ona funkcję **blokady konta** (_ang. account lockout_), która jest odrębną funkcją bezpieczeństwa, niezwiązaną z UAC. Blokada konta ma na celu zablokowanie dostępu do konta użytkownika, który przekroczył dopuszczalną liczbę nieudanych prób logowania, jako obrona przed atakiem brutalnej siły. UAC skupia się na kontroli uprawnień wykonywania procesów w systemie, a nie kontroli dostępu do samych kont.\n*   **\"wprowadza dodatkowa forme ochrony konta administracyjnego m.in. przed koniami trojanskimi i zlosliwym oprogramowaniem\"** - Ta odpowiedź jest *poprawna*. UAC działa poprzez uruchamianie procesów z tokenem standardowym, który ma ograniczone prawa, a nie tokenem administracyjnym, który ma pełne prawa. Nawet administrator, domyślnie pracuje w ograniczonym środowisku. Aplikacja żądająca wyższych uprawnień uruchomiana jest w nowym procesie posiadającym token administracyjny, za zgodą użytkownika. Taki schemat działania minimalizuje zagrożenie wynikające z przypadkowego uruchomienia szkodliwego oprogramowania. Przykładowo, jeśli użytkownik administracyjny nieświadomie kliknie zainfekowany link lub uruchomi pobrany plik, złośliwy proces również uruchomi się w standardowym kontekście uprawnień. Jeśli złośliwy kod spróbuje zainfekować ważne pliki systemowe, nastąpi odmowa wykonania operacji i pojawi się monit UAC, dzięki czemu działanie szkodliwego kodu zostaje przerwane.\n*   **\"pozwala administratorowi chwilowo skorzystac z pelnego tokenu administracyjnego\"** - Ta odpowiedź jest *niepoprawna*. Choć UAC pozwala administratorowi na *podnoszenie* uprawnień dla pojedynczych działań lub aplikacji, nie daje możliwości przełączenia się na \"chwilowo\" pełny token administracyjny na stałe. UAC działa tak, że każde działanie wymagające podwyższonych uprawnień generuje monit, który musi być zaakceptowany przez użytkownika, dając mu wybór, czy pozwolić na to działanie, czy je zablokować. Oczywiście, dla uprawnionych administratorów UAC nie jest szczególnie uciążliwe, a dla nieuprawnionych jest bardzo pomocne. Dodatkowo uruchamianie każdej aplikacji, która wymaga wyższych uprawnień wywołuje utworzenie nowego procesu, co samo w sobie zwiększa bezpieczeństwo. \n*   **\"wirtualizuje dostep do newralgicznych komponentow systemu plikow\"** - Ta odpowiedź jest *poprawna*. Mechanizm UAC, prócz wyżej wymienionych funkcji, oferuje również mechanizm **wirtualizacji** zasobów. Dzięki wirtualizacji każda aplikacja, która nie działa z uprawnieniami administracyjnymi, pracuje w symulowanym środowisku z wirtualną wersją plików systemowych. Zatem, jeśli jakiś program zechce wprowadzić zmiany w newralgicznych plikach systemowych lub kluczach rejestru, zostaną one tak naprawdę zapisane do jego wirtualnej kopii, a nie do prawdziwych plików systemowych, co chroni system przed trwałymi uszkodzeniami i zwiększa jego bezpieczeństwo. Przykładowo program nie będąc w stanie zapisać zmian w wirtualnej kopii, będzie usiłował zapisać informacje do rzeczywistego pliku, do którego UAC zablokuje dostęp."
    },
    {
        "questionId": 287,
        "title": "Klucz szyfrowania, ktorym zaszyfrowana zostala tresc pliku (standardowym mechanizmem EFS z systemu NTFS):",
        "answers": [
            {
                "text": "znajduje sie w certyfikacie wlasciciela pliku",
                "isCorrect": true
            },
            {
                "text": "znajduje sie w certyfikacie kazdego agenta DRA w systemie operacyjnym",
                "isCorrect": true
            },
            {
                "text": "jest zapisany wewnatrz zaszyfrowanego pliku",
                "isCorrect": false
            },
            {
                "text": "znajduje sie w certyfikacie administratora systemu operacyjnego",
                "isCorrect": false
            },
            {
                "text": "jest przechowywany wraz z zaszyfrowanym plikiem",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Klucz szyfrowania, którym zaszyfrowana jest treść pliku przy użyciu standardowego mechanizmu EFS (Encrypting File System) w systemie plików NTFS, jest przechowywany w sposób rozproszony i zabezpieczony. Nie jest on zapisywany w całości w jednym miejscu, co ma na celu ochronę przed nieuprawnionym dostępem. Zamiast tego, stosuje się kombinację różnych mechanizmów, które pozwalają na bezpieczne przechowywanie i dostęp do klucza, a nie sam klucz w postaci jawnej.\n\n**Poprawne odpowiedzi:**\n\n*   **znajduje sie w certyfikacie wlasciciela pliku**: Jest to **prawidłowa odpowiedź**. Klucz symetryczny użyty do zaszyfrowania pliku jest generowany losowo. Następnie, klucz ten jest szyfrowany przy użyciu klucza publicznego właściciela pliku i przechowywany w metadanych tego pliku. Klucz publiczny właściciela pliku jest powiązany z certyfikatem właściciela. Takie podejście pozwala właścicielowi na odszyfrowanie pliku. Bez certyfikatu (a konkretnie klucza prywatnego powiązanego z tym certyfikatem) nie będzie można odszyfrować pliku. Praktycznie oznacza to, że pliki zaszyfrowane za pomocą EFS, są przypisane do konkretnego konta użytkownika systemu operacyjnego. W przypadku utraty hasła do tego konta wszystkie zaszyfrowane pliki będą nie możliwe do odzyskania.\n*   **znajduje sie w certyfikacie kazdego agenta DRA w systemie operacyjnym**: Jest to **prawidłowa odpowiedź**. W systemie Windows zaimplementowano koncepcję Data Recovery Agent (DRA). Jest to specjalne konto (lub kilka kont), które ma dostęp do zaszyfrowanych plików EFS na wypadek gdyby użytkownik utracił dostęp do własnego certyfikatu z kluczem prywatnym. Podobnie jak w przypadku właściciela pliku, klucz symetryczny zaszyfrowany jest kluczem publicznym powiązanym z certyfikatem DRA i jest przechowywany w metadanych pliku. Umożliwia to agencji DRA dostęp do zaszyfrowanych danych. W wielu systemach, często z przyczyn oszczędnościowych, DRA jest konfigurowany na konto Administratora systemu operacyjnego. Dostęp do pliku może uzyskać jedynie autoryzowany DRA, czyli użytkownik posiadający dostęp do klucza prywatnego połączonego z certyfikatem DRA.\n*   **jest przechowywany wraz z zaszyfrowanym plikiem:** Jest to **prawidłowa odpowiedź**. Klucz symetryczny nie jest przechowywany jako jawna wartość w pliku, ale w formie zaszyfrowanej przy pomocy klucza publicznego właściciela pliku lub agenta DRA, co oznacza, że zaszyfrowany plik zawiera zaszyfrowany klucz symetryczny. Taka konfiguracja pozwala zachować poufność klucza symetrycznego.\n\n**Niepoprawne odpowiedzi:**\n\n*   **jest zapisany wewnatrz zaszyfrowanego pliku**: Jest to **nieprawidłowa odpowiedź**. Klucz szyfrowania nie jest przechowywany w postaci jawnej w zaszyfrowanym pliku. Klucz szyfrowania jest generowany losowo przy szyfrowaniu pliku, a następnie jest szyfrowany za pomocą klucza publicznego właściciela pliku. Taki zaszyfrowany klucz jest umieszczany w metadanych pliku a nie w samej zaszyfrowanej treści. Takie podejście ma na celu zapewnienie bezpieczeństwa przechowywanemu kluczowi.\n*   **znajduje sie w certyfikacie administratora systemu operacyjnego:** Jest to **nieprawidłowa odpowiedź**, chyba, że administrator systemu operacyjnego został ustawiony jako DRA, w tym przypadku klucz symetryczny zostanie zaszyfrowany kluczem publicznym powiązanym z certyfikatem Administratora (pełniącego rolę DRA) i zapisany w metadanych pliku. Zazwyczaj jednak to nie administrator a właściciel pliku lub specjalne konto DRA mają dostęp do klucza symetrycznego."
    },
    {
        "questionId": 288,
        "title": "Skuteczna weryfikacja w systemie PGP podpisanego cyfrowo listu przeslanego od uzytkownika A do uzytkownika B wymaga:",
        "answers": [
            {
                "text": "wykonania podpisu kluczem prywatnym B",
                "isCorrect": false
            },
            {
                "text": "wykonania podpisu kluczem prywatnym A",
                "isCorrect": true
            },
            {
                "text": "wykonania podpisu kluczem publicznym B",
                "isCorrect": false
            },
            {
                "text": "wykonania podpisu kluczem publicznym A",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Podpis cyfrowy w PGP jest tworzony za pomocą klucza prywatnego nadawcy, a weryfikowany za pomocą klucza publicznego nadawcy. Klucz prywatny służy do podpisania wiadomości, tworząc unikalny \"odcisk palca\" wiadomości, a klucz publiczny jest używany do weryfikacji tego podpisu, potwierdzając autentyczność nadawcy i integralność wiadomości.\n\n**Opcja: wykonania podpisu kluczem prywatnym B**\nNiepoprawna. Klucz prywatny użytkownika B służy do odszyfrowywania wiadomości zaszyfrowanych kluczem publicznym użytkownika B, a nie do tworzenia podpisu cyfrowego listu nadawcy A. Użycie klucza prywatnego B, mogłoby służyć do podpisania wiadomości, ale wiadomości B a nie A. \n\n**Opcja: wykonania podpisu kluczem prywatnym A**\nPoprawna. W PGP, podpis cyfrowy jest generowany przy użyciu klucza prywatnego nadawcy (użytkownika A).  Nadawca A bierze skrót wiadomości i szyfruje go swoim kluczem prywatnym, tworząc podpis. Ten podpis jest dołączany do wiadomości. Odbiorca B, który posiada klucz publiczny użytkownika A, jest w stanie rozszyfrować podpis co potwierdzi autentyczność oraz integralność wiadomości. Klucz prywatny jest unikalny dla nadawcy A, i tylko on jest w stanie wygenerować podpis wiarygodny, który następnie za pomocą jego klucza publicznego jest w stanie zweryfikować odbiorca B.\n\n**Opcja: wykonania podpisu kluczem publicznym B**\nNiepoprawna. Klucz publiczny użytkownika B jest wykorzystywany do szyfrowania wiadomości, które mają być przesłane do użytkownika B i może być użyty do zweryfikowania podpisu użytkownika B. Nie można nim podpisać wiadomości wysyłanej przez użytkownika A i zweryfikować ją kluczem publicznym A. Klucz publiczny z założenia jest przeznaczony do udostępnienia i do weryfikacji czyichś podpisów i odszyfrowywania zaszyfrowanej wiadomości, nie jest tajny. \n\n**Opcja: wykonania podpisu kluczem publicznym A**\nNiepoprawna. Klucz publiczny użytkownika A służy do weryfikacji podpisu cyfrowego lub szyfrowania wiadomości do A, nie można nim podpisać wiadomości wysyłanej przez użytkownika A, podpisywanie wykonuje się tajnym kluczem prywatnym. Klucz publiczny z założenia jest przeznaczony do udostępnienia i do weryfikacji czyichś podpisów i odszyfrowywania zaszyfrowanej wiadomości, nie jest tajny. \n\n**Przykład:**\nWyobraźmy sobie, że Alicja (użytkownik A) chce wysłać ważną umowę do Bolka (użytkownik B) używając PGP. Alicja najpierw tworzy dokument, następnie bierze z niego skrót za pomocą funkcji skrótu i szyfruje go swoim kluczem prywatnym (ma to unikalny podpis) i wysyła umowę wraz z podpisem. Bolek, otrzymując umowę z podpisem, używa klucza publicznego Alicji by odszyfrować podpis i porównać go z nowym wyliczonym skrótem, co potwierdzi autentyczność Alicji i integralność umowy. Gdyby w tym przykładzie Alicja do podpisania dokumentu użyła swojego klucza publicznego, to każdy kto by pozyskał treść podpisu oraz treść dokumentu mógłby to porównać z publicznie znanym kluczem, co nie byłoby żadną weryfikacją poprawności pochodzenia dokumentu."
    },
    {
        "questionId": 289,
        "title": "xinetd to:",
        "answers": [
            {
                "text": "modul jadra Linux, ktory implementuje kontekstowa filtracje pakietow",
                "isCorrect": false
            },
            {
                "text": "prosty mechanizm szyfrowania uzywany przez zapore sieciowa w systemie Linux",
                "isCorrect": false
            },
            {
                "text": "element systemu operacyjnego Linux, odpowiedzialny za dynamiczne uruchamianie uslug sieciowych",
                "isCorrect": true
            },
            {
                "text": "modul jadra Linux, ktory limity zasobowe w stosie TCP/IP",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`xinetd` to rozszerzony demon internetowy, który działa w przestrzeni użytkownika systemu Linux. Służy do dynamicznego uruchamiania usług sieciowych, które są aktywne tylko wtedy, gdy są potrzebne, czyli gdy jest kierowane do nich żądanie z sieci. Oznacza to, że zamiast ciągłego nasłuchiwania na danym porcie sieciowym przez dany program (usługę), demon `xinetd` nasłuchuje i w przypadku pojawienia się żądania do danej usługi uruchamia właściwy program ją obsługujący. Po zakończeniu działania programu demon ponownie wraca do nasłuchiwania na porcie. Takie podejście ma na celu oszczędzanie zasobów systemu. `xinetd` zastępuje starszy demon `inetd` i oferuje bardziej zaawansowane funkcje zarządzania usługami. Konfiguracja `xinetd` odbywa się poprzez pliki konfiguracyjne, w których definiowane są parametry uruchomienia poszczególnych usług. Do takich parametrów należy nazwa pliku wykonywalnego danej usługi, port, protokół oraz inne właściwości danego demona.\n\n*   **\"moduł jadra Linux, ktory implementuje kontekstowa filtracje pakietow\"** - To stwierdzenie jest **nieprawidłowe**. Kontekstowa filtracja pakietów, czyli tzw. _stateful firewall_, jest realizowana przez moduły jądra, takie jak `netfilter`, a nie przez `xinetd`.  `xinetd` nie działa na poziomie jądra, a zarządza usługami w przestrzeni użytkownika i nie analizuje treści pakietów - decyduje jedynie czy program usługi ma zostać uruchomiony czy nie. Użycie `iptables` wraz z modułem `conntrack` do utworzenia firewalla, który zapamiętuje status sesji i na tej podstawie podejmuje decyzje o przepuszczaniu lub blokowaniu ruchu sieciowego jest dobrym przykładem kontekstowej filtracji. Zatem, `xinetd` nie analizuje poszczególnych pakietów na poziomie ich zawartości ani nie filtruje tych pakietów w kontekście nawiązanych sesji.\n    *   **Praktyczne implikacje**: Pomyłka w tym aspekcie może spowodować utworzenie błędnej polityki bezpieczeństwa, myśląc, że system jest chroniony z wykorzystaniem mechanizmów kontekstowej filtracji pakietów.\n\n*   **\"prosty mechanizm szyfrowania uzywany przez zapore sieciowa w systemie Linux\"** - Ta odpowiedź jest **nieprawidłowa**. `xinetd` nie jest mechanizmem szyfrowania ani zaporą sieciową. Zapewnia jedynie środowisko do uruchomienia usług. Szyfrowanie (np. przy użyciu protokołu SSL/TLS) jest oddzielnym mechanizmem, który może być użyty przez aplikację (usługę) uruchamianą przez `xinetd`. Podobnie działa firewall, jest on mechanizmem, który filtruje pakiety nie wykorzystując mechanizmu `xinetd`. Bezpieczeństwo systemu osiąga się przez warstwowe łączenie ze sobą tych mechanizmów.\n    *   **Praktyczne implikacje:** Uważanie `xinetd` za mechanizm szyfrujący to niebezpieczne uproszczenie, może prowadzić do błędnego oszacowania ryzyka i wystawienia systemu na ataki w sieci.\n\n*   **\"element systemu operacyjnego Linux, odpowiedzialny za dynamiczne uruchamianie uslug sieciowych\"** - Ta odpowiedź jest **poprawna**. `xinetd` jest demonem, czyli programem działającym w tle, który nasłuchuje na portach. Po otrzymaniu żądania dla danej usługi, demon uruchamia odpowiedni program z odpowiednimi argumentami oraz parametrami. Usługi takie jak ftp, telnet, rlogin i inne są uruchamiane gdy jest potrzeba z wykorzystaniem mechanizmu `xinetd`.\n    *   **Praktyczne implikacje:** Poprawna konfiguracja `xinetd` i wiedza na temat jego funkcjonowania jest kluczowa dla administrowania systemami Linux, zwłaszcza serwerami. Pozwala on na oszczędność zasobów systemowych poprzez nie uruchamianie nieużywanych usług.\n\n*   **\"moduł jadra Linux, ktory limity zasobowe w stosie TCP/IP\"** - Ta odpowiedź jest **nieprawidłowa**. `xinetd` nie jest modułem jądra systemu Linux. Ponadto moduł ten nie służy do limitowania zasobów wykorzystywanych przez usługi sieciowe, chociaż mechanizm ten może zostać wykorzystany przez moduły PAM (Pluggable Authentication Modules) poprzez wtyczkę _pam_limits.so_. Limity zasobów ustawiane są np. za pomocą polecenia `ulimit`, z poziomu powłoki systemowej lub przez mechanizm PAM.\n    *   **Praktyczne implikacje:** Pomylenie `xinetd` z mechanizmem limitów może doprowadzić do sytuacji gdy zasoby systemowe będą wyczerpywane przez procesy, do których nie nałożono żadnych ograniczeń."
    },
    {
        "questionId": 290,
        "title": "Przy kopiowaniu zaszyfrowanego pliku z NTFS na partycje FAT:",
        "answers": [
            {
                "text": "plik bedzie mozliwy do odczytu tylko na systemie, na ktorym zostal zaszyfrowany",
                "isCorrect": false
            },
            {
                "text": "plik zostaje odszyfrowany",
                "isCorrect": false
            },
            {
                "text": "plik bedzie pozniej wymagal recznego odszyfrowania",
                "isCorrect": false
            },
            {
                "text": "plik moze byc skopiowany tylko przez uzytkownika \"Data Recovery Agent\"",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie plików w systemie plików NTFS za pomocą EFS (Encrypting File System) jest funkcją specyficzną dla tego systemu plików. Metadane szyfrowania, klucze i powiązania z certyfikatami użytkowników są przechowywane w strukturach danych NTFS. FAT (File Allocation Table) jest natomiast starszym, prostszym systemem plików, który nie obsługuje tych zaawansowanych funkcji, takich jak szyfrowanie.\n\n**Odpowiedź 1 (niepoprawna):** \"plik będzie możliwy do odczytu tylko na systemie, na którym został zaszyfrowany\" - Ta odpowiedź jest niepoprawna, ponieważ szyfrowanie w EFS jest związane z systemem plików NTFS a nie z danym systemem operacyjnym. Jeżeli skopiujemy plik z partycji NTFS na partycję NTFS na innej maszynie to jeżeli klient będzie posiadał odpowiednie uprawnienia (klucz) to odczyta plik. \n\n**Odpowiedź 2 (niepoprawna):** \"plik zostaje odszyfrowany\" - Ta odpowiedź jest niepoprawna, ponieważ skopiowanie zaszyfrowanego pliku z NTFS na FAT nie powoduje automatycznego odszyfrowania pliku. Dane w tym pliku będą nadal zaszyfrowane. Jednak sam system FAT nie będzie już wiedział, jak interpretować tak zaszyfrowane dane.  \n\n**Odpowiedź 3 (niepoprawna):** \"plik będzie później wymagał ręcznego odszyfrowania\" - Ta odpowiedź jest niepoprawna, gdyż nie można ręcznie odszyfrować pliku po skopiowaniu go z NTFS na partycję FAT, ponieważ dane są zapisane w formacie zaszyfrowanym ale system FAT nie obsługuje mechanizmów służących do odczytu takich danych. System FAT potraktuje plik jak zwykłe dane i nie będzie można go odczytać ani go odszyfrować. \n\n**Odpowiedź 4 (poprawna):** \"plik może być skopiowany tylko przez użytkownika \"Data Recovery Agent\"\" - Ta odpowiedź jest poprawna, ponieważ pliki zaszyfrowane przez EFS mogą być w normalnej sytuacji odszyfrowane jedynie przez użytkownika, który je zaszyfrował, lub przez Data Recovery Agent. Data Recovery Agent (agent odzyskiwania danych) jest specjalnym kontem w systemie Windows, które posiada uprawnienia do deszyfrowania plików zaszyfrowanych za pomocą EFS. Gdy zwykły użytkownik próbuje skopiować zaszyfrowany plik z NTFS na partycję FAT, system operacyjny Windows blokuje taka operacje, ponieważ na partycji FAT nie jest obsługiwana ochrona za pomocą szyfrowania EFS. Wyjątkiem jest sytuacja gdy zadania kopiowania zaszyfrowanego pliku na partycję FAT podejmie się użytkownik Data Recovery Agent. W praktyce użytkownik taki może potrzebować w kryzysowej sytuacji (awaria, utrata hasła) dokonać archiwizacji zaszyfrowanych danych na nośniku np. pendrive, który z reguły jest sformatowany systemem FAT. \n\n**Konkretny przykład:** Załóżmy, że użytkownik 'Janek' ma zaszyfrowany plik 'dane.txt' na dysku C (NTFS). Jeśli Janek spróbuje skopiować ten plik bezpośrednio na pendrive (FAT), Windows uniemożliwi wykonanie tej operacji. Jeżeli jednak użytkownik ‘Data Recovery Agent’ wykona ta samą czynność, skopiowanie zaszyfrowanego pliku powiedzie się, jednak zawartość pliku na pendrive pozostanie zaszyfrowana, ale nie będzie możliwe jego odszyfrowanie na innym systemie. Jest to kluczowe z punktu widzenia zabezpieczenia systemów, ponieważ utrudnia nieautoryzowane przeglądanie danych w przypadku niepowodzenia standardowej ochrony.\n\nPodsumowując, pytanie to zwraca uwagę na fakt, że szyfrowanie EFS zależy od systemu plików NTFS i nie zapewnia ochrony danych, jeśli dane są przenoszone poza to środowisko. Kluczowe jest tutaj zrozumienie roli Data Recovery Agent, jako narzędzia do odzyskiwania danych, a nie jako domyślnego narzędzia do przenoszenia zaszyfrowanych plików poza system plików NTFS."
    },
    {
        "questionId": 291,
        "title": "Zaznacz poprawne warunki, ktorych spelnienie w systemie plikow NTFS pozwoli by uzytkownik U  nalezacy do grupy G mogl odczytac zawartosc pliku P w katalogu K:",
        "answers": [
            {
                "text": "U lub G dziedzicza dostep do odczytu z katalogu K",
                "isCorrect": true
            },
            {
                "text": "U jawnie odebrano prawo odczytu P, ale U dziedziczy to prawo z katalogu K",
                "isCorrect": false
            },
            {
                "text": "U jawnie odebrano prawo odczytu P, ale G dziedziczy to prawo z katalogu K",
                "isCorrect": false
            },
            {
                "text": "U lub G maja jawnie nadane prawo odczytu pliku P",
                "isCorrect": true
            },
            {
                "text": "tylko U ma jawnie nadany dostep do P i K, G nie nadano zadnych praw ani do K, ani do P",
                "isCorrect": true
            },
            {
                "text": "tylko U dziedziczy dostep do P i K, G nie dziedziczy zadnych praw ani do K, ani do P",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "W systemie plików NTFS, kontrola dostępu opiera się na modelu Uznaniowej Kontroli Dostępu (DAC, Discretionary Access Control). Oznacza to, że właściciel zasobu (pliku lub katalogu) może decydować, kto ma do niego dostęp. Uprawnienia są przypisywane użytkownikom i grupom. Kluczowym elementem w systemie NTFS jest mechanizm dziedziczenia uprawnień, gdzie uprawnienia nadane katalogowi są domyślnie dziedziczone przez pliki i podkatalogi w nim zawarte. Oprócz tego, uprawnienia mogą być nadane lub odebrane jawnie dla konkretnego obiektu (pliku lub katalogu).\n\n* **\"U lub G dziedziczą dostęp do odczytu z katalogu K\" - Poprawna**. W systemie plików NTFS, uprawnienia są dziedziczone hierarchicznie. Jeśli użytkownik U należy do grupy G, to może odczytać plik P, jeśli U lub G dziedziczą z katalogu K prawo do odczytu pliku P. Dziedziczenie pozwala na ustawianie uprawnień na poziomie katalogu i propagowanie tych ustawień na jego zawartość, co bardzo upraszcza administrowanie uprawnieniami.  Na przykład, jeśli w katalogu `K` ustawimy uprawnienia odczytu dla grupy `G`, to wszystkie pliki i podkatalogi wewnątrz `K` (chyba, że explicite im to prawo odbierzemy)  będą domyślnie dostępne do odczytu dla członków tej grupy,  a także pojedynczego użytkownika `U`, który należy do tej grupy.\n\n* **\"U jawnie odebrano prawo odczytu P, ale U dziedziczy to prawo z katalogu K\" - Niepoprawna**. Jawne odebranie prawa dostępu zawsze ma pierwszeństwo przed prawem dziedziczonym. Jeżeli użytkownik U ma jawnie odebrane prawo odczytu pliku P, to fakt, że użytkownik U dziedziczy to prawo z katalogu K nie zmieni tego faktu, dalej nie będzie miał prawa do odczytu pliku P.  W praktyce, jeśli na pliku `P` ustawimy dla użytkownika `U` explicitnie brak uprawnienia odczytu, to nawet jeśli katalog `K` nadrzędny ma odczyt dla `U`,  ten użytkownik dalej nie przeczyta pliku.\n\n* **\"U jawnie odebrano prawo odczytu P, ale G dziedziczy to prawo z katalogu K\" - Niepoprawna**. Jawne odebranie prawa dostępu dla użytkownika `U`, zawsze ma pierwszeństwo przed prawem dziedziczonym. Członkostwo `U` w grupie `G`, która z katalogu K dziedziczy prawo odczytu, nie wpływa na jawnie odebrane uprawnienie dla `U`. W tej sytuacji dostęp dla użytkownika `U` będzie dalej zablokowany, natomiast pozostali członkowie grupy `G`, nie posiadający jawnie odebranego dostępu do pliku `P`, będą mogli go odczytać.  Ta opcja ilustruje konflikt między uprawnieniami użytkownika `U` oraz grupy do której należy. Uprawnienie ustawione explicitnie dla użytkownika wygrywa.\n\n* **\"U lub G maja jawnie nadane prawo odczytu pliku P\" - Poprawna**. Jest to również poprawna odpowiedź. Jeśli użytkownik U lub grupa G ma jawnie przypisane prawo do odczytu pliku P, to U jako członek G lub jako indywidualny podmiot ma takie uprawnienie. Jawne ustawienie uprawnień ma wyższy priorytet niż domyślne dziedziczenie. Wyobraźmy sobie sytuacje w której administrator dodaje nową grupę która ma mieć prawo do odczytu plików. Utworzenie grupy i dodanie jej uprawnień nie powoduje automatycznie przypisania uprawnień z tej grupy dla użytkowników.  Konieczne jest wyraźne nadanie użytkownikowi  lub grupy uprawnienia do odczytu pliku `P`.\n\n* **\"tylko U ma jawnie nadany dostep do P i K, G nie nadano zadnych praw ani do K, ani do P\" - Poprawna**.  Ta opcja również jest poprawna. Jeżeli tylko użytkownik `U` ma jawnie nadane uprawnienia, bez jakichkolwiek ustawień dla grupy `G`,  użytkownik U  będzie mógł odczytać plik P. System NTFS w pierwszej kolejności sprawdza prawa dostępu dla użytkownika. Dopiero w przypadku braku definiowanego uprawnienia dla użytkownika jest sprawdzane uprawnienie dla grupy, do której należy dany użytkownik, a w ostateczności dopiero uprawnienia dla wszystkich pozostałych użytkowników. \n\n*  **\"tylko U dziedziczy dostep do P i K, G nie dziedziczy zadnych praw ani do K, ani do P\" - Poprawna**. Jeśli tylko użytkownik `U` dziedziczy dostęp, a grupa `G` nie, to uprawnienia dziedziczone przez użytkownika z katalogu `K` pozwolą na odczyt pliku `P`. Ta opcja jest bardzo podobna do poprzedniej. W systemie Windows, dziedziczone prawa dostępu użytkownika mają pierwszeństwo przed prawami do których użytkownik jest przypisany na podstawie członkostwa w danej grupie. Ta opcja przedstawia przypadek, w którym to użytkownik `U`, sam bez pomocy członkostwa w grupie, będzie miał prawo do odczytu pliku `P`."
    },
    {
        "questionId": 292,
        "title": "Wskaz to z ustawien parametrow hasel (tylko jedno), ktore jest najkorzystniejsze dla bezpieczenstwa konta:",
        "answers": [
            {
                "text": "okres waznosci hasla: nieskonczony",
                "isCorrect": false
            },
            {
                "text": "maksymalna dlugosc: 14 znakow",
                "isCorrect": false
            },
            {
                "text": "minimalna dlugosc: 10 znakow",
                "isCorrect": true
            },
            {
                "text": "odwracalne szyfrowanie hasel: wlaczone",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Minimalna długość hasła jest kluczowym elementem polityki bezpieczeństwa, ponieważ wpływa bezpośrednio na poziom trudności odgadnięcia lub złamania hasła przez niepowołane osoby lub narzędzia. Zbyt krótkie hasło jest podatne na ataki typu brute-force (przeszukiwanie wszystkich możliwych kombinacji) oraz ataki słownikowe (próby odgadnięcia hasła na podstawie popularnych haseł). Zwiększenie minimalnej długości hasła znacząco podnosi liczbę potencjalnych kombinacji znaków, przez co staje się ono bardziej odporne na ataki.\n\n**okres ważności hasła: nieskończony** - Jest to ustawienie niekorzystne z punktu widzenia bezpieczeństwa. Zbyt długi okres ważności hasła zwiększa ryzyko jego kompromitacji. Użytkownik może zapomnieć hasło, zapisać je w niezabezpieczonym miejscu, a haker może zyskać czas na jego złamanie. Okresowe zmiany hasła, zmuszają użytkownika do stosowania nowych i trudniejszych haseł. Idealnie hasło powinno być zmieniane co 30-90 dni.\n**maksymalna długość: 14 znaków** - Określenie maksymalnej długości hasła jest mniej istotne z punktu widzenia bezpieczeństwa w porównaniu z określeniem minimalnej długości. Z punktu widzenia bezpieczeństwa, bardziej istotne jest to, że system wymusza trudne hasło (długie i skomplikowane) niż ogranicza jego maksymalną długość. Oczywiście zbyt długa długość hasła może być uciążliwa i tym samym może obniżyć użyteczność systemu, a nie podnosić jego bezpieczeństwo (użytkownik np. będzie zapisywać hasło na kartce). Z punktu widzenia bezpieczeństwa, hasło o długości powyżej 15 znaków jest wystarczające.\n**minimalna długość: 10 znaków** - Jest to ustawienie najkorzystniejsze dla bezpieczeństwa. Zwiększanie minimalnej długości hasła podnosi poziom trudności jego złamania. Hasło o minimalnej długości 10 znaków, składające się z dużych i małych liter, cyfr oraz znaków specjalnych jest już wystarczająco odporne na ataki. Zbyt krótki hasło jest natomiast łatwe do złamania.\n**odwracalne szyfrowanie hasel: włączone** - Jest to ustawienie najgorsze z możliwych z punktu widzenia bezpieczeństwa. Odwracalne szyfrowanie, z definicji, umożliwia odzyskanie pierwotnej postaci hasła. Jeśli hasło da się odzyskać w postaci jawnej to znaczy, że można je pozyskać. W efekcie każde hasło tak zabezpieczone może być pozyskane przez hakera. Do przechowywania haseł powinny być stosowane funkcje jednokierunkowe, których nie można odwrócić (np. funkcja skrótu kryptograficznego). System powinien uniemożliwiać odzyskiwanie hasła, natomiast powinien tylko weryfikować czy podane hasło odpowiada skrótowi zapisanemu w systemie.\n\n**Przykład praktyczny:** Wyobraźmy sobie system bankowości internetowej, gdzie hasła użytkowników są stosunkowo krótkie (np. 6 znaków). Haker, przechwytując zaszyfrowany skrót takiego hasła, może spróbować wygenerować wszystkie możliwe kombinacje 6-znakowych haseł i sprawdzić, czy któryś ze skrótów pasuje do przechwyconego skrótu hasła. Jeżeli dodatkowo system bankowy pozwalałby na stosowanie tylko małych liter i cyfr, to haker mógłby w relatywnie krótkim czasie (liczone w godzinach lub dniach) złamać takie hasło. W przypadku haseł o minimalnej długości 10 znaków (duże i małe litery, cyfry i znaki specjalne), nawet przy takim ataku, prawdopodobieństwo powodzenia ataku jest znikome."
    },
    {
        "questionId": 293,
        "title": "getfacl --omit-header test user::rwx user:jbond:rwx group::r-- group:agents:r-x mask::r-x other::--- default:user::rwx default:user:jbond:r-x default:group::-wx default:group:agents:-wx default:mask::--x default:other::r-x Oznacza, ze:",
        "answers": [
            {
                "text": "grupa \"agents\" moze modyfikowac zawartosc obiektu test",
                "isCorrect": false
            },
            {
                "text": "wlasciciel moze tworzyc pliki w katalogu test",
                "isCorrect": true
            },
            {
                "text": "uzytkownik \"jbond\" moze modyfikowac zawartosc obiektu test",
                "isCorrect": false
            },
            {
                "text": "uzytkownik \"jbond\" moze przegladac liste plikow w katalogu test",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "`getfacl --omit-header test user::rwx user:jbond:rwx group::r-- group:agents:r-x mask::r-x other::--- default:user::rwx default:user:jbond:r-x default:group::-wx default:group:agents:-wx default:mask::--x default:other::r-x`  to wywołanie polecenia `getfacl` z opcją `--omit-header` dla obiektu `test`. Polecenie to wyświetla rozszerzone uprawnienia (ACL - Access Control List) dla pliku lub katalogu. Opcja `--omit-header` pomija nagłówek w wyniku. Poniżej opisujemy kolejne elementy ACL.\n\n*   `user::rwx`: Właściciel obiektu ma prawa odczytu (r), zapisu (w) i wykonania/przeszukiwania (x).\n*   `user:jbond:rwx`: Użytkownik o nazwie `jbond` ma prawa odczytu (r), zapisu (w) i wykonania/przeszukiwania (x).\n*   `group::r--`: Grupa, do której należy właściciel, ma prawo tylko odczytu (r).\n*   `group:agents:r-x`: Grupa o nazwie `agents` ma prawa odczytu (r) i wykonania/przeszukiwania (x).\n*    `mask::r-x` : Maska praw. Maksymalne uprawnienia jakie moga posiadac użytkownicy i grupy nazwane. W tym wypadku prawa zapisu zostają zablokowane.\n*   `other::---`: Pozostali użytkownicy nie mają żadnych uprawnień.\n*   `default:user::rwx`: Domyślnie, właściciel nowo tworzonych obiektów w tym katalogu będzie miał prawa odczytu, zapisu i wykonania/przeszukiwania.\n*  `default:user:jbond:r-x`: Domyślnie, użytkownik jbond będzie miał uprawnienia do odczytu i wykonywania w nowo utworzonych obiektach w tym katalogu\n*   `default:group::-wx`: Domyślnie grupa właściciela nowo utworzonych obiektów będzie miała prawa zapisu i wykonywania/przeszukiwania.\n*   `default:group:agents:-wx`: Domyślnie grupa `agents` będzie miała prawa zapisu i wykonywania/przeszukiwania, do nowo utworzonych plików/katalogów w tym katalogu.\n*   `default:mask::--x`: Domyslna maska dla plików/katalogów tworzonych w tym katalogu.\n*   `default:other::r-x`: Domyślnie inni użytkownicy będą mogli odczytywać i przszykiwać nowo utworzone obiekty.\n\n**Odpowiedź 1: \"grupa \"agents\" moze modyfikowac zawartosc obiektu test\"**\n\n*   **Incorrect.** Uprawnienia grupy `agents` dla bieżącego obiektu `test` wynoszą `r-x`, czyli ma ona tylko uprawnienie odczytu i wykonania/przeszukiwania, a nie uprawnienia do zapisu. Modyfikowanie zawartości wymagałoby uprawnienia do zapisu (w). Dodatkowo warto zwrócić uwagę, że grupa agents, może mieć możliwość zapisu do innych plików niż do pliku _test_, a mianowicie do plików tworzonych w katalogu _test_ dzięki ustawieniom default.\n\n**Odpowiedź 2: \"wlasciciel moze tworzyc pliki w katalogu test\"**\n\n*   **Correct.** Default permissions `default:user::rwx` for the *owner* mean that whenever new files/directories are created inside the `test` directory, the *owner* of these newly created items will have *read*, *write*, and *execute* rights.  This is not about modifying `test` itself, but creating other things *inside* it. Ta opcja zakłada, że _test_ jest katalogiem. Jeśli byłby to zwykły plik to opcja ta byłaby niepoprawna.\n\n**Odpowiedź 3: \"uzytkownik \"jbond\" moze modyfikowac zawartosc obiektu test\"**\n\n*   **Incorrect.** Mimo, że użytkownik jbond ma prawa `rwx` dla obiektu `test` nie oznacza to, że ma on prawo modyfikować *zawartość*. Uprawnienie `x` oznacza w przypadku katalogu możliwość jego przeszukiwania. Dodatkowo prawa dla użytkownika jbond odnoszą się do *samego obiektu* test a nie do obiektów, które zostaną utworzone w _test_, te obiekty będą miały uprawnienia opisane przez opcję _default_.\n\n**Odpowiedź 4: \"uzytkownik \"jbond\" moze przegladac liste plikow w katalogu test\"**\n\n*   **Correct.** Uprawnienia `user:jbond:rwx` umożliwiają odczyt (r), zapis (w), i wykonywanie/przeszukiwania (x) obiektu. W przypadku, gdy obiektem jest katalog, uprawnienie x umożliwia przeglądanie listy plików w danym katalogu."
    },
    {
        "questionId": 294,
        "title": "Stosowany w sieciach VPN preshared key to:",
        "answers": [
            {
                "text": "klucz publiczny z predefiniowanego certyfikatu SSL sluzacy do generacji asymetrycznego klucza szyfrowania danych",
                "isCorrect": false
            },
            {
                "text": "statycznie ustalony po obu stronach tunelu klucz symetryczny",
                "isCorrect": true
            },
            {
                "text": "mechanizm uwierzytelniania wykorzystujacy generowane losowo po obu stronach wstepne klucze asymetryczne D-H",
                "isCorrect": false
            },
            {
                "text": "mechanizm pozwalajacy uwierzytelniac strony tunelu",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Preshared key (PSK), wykorzystywany w sieciach VPN, to symetryczny klucz kryptograficzny, który musi być statycznie skonfigurowany po obu stronach tunelu VPN. Klucz symetryczny oznacza, że ten sam klucz jest używany zarówno do szyfrowania jak i deszyfrowania danych. Zatem obie strony połączenia muszą wcześniej w bezpieczny sposób pozyskać klucz i w trakcie komunikacji wykorzystywać ten klucz do ochrony poufności. \n\nOdpowiedź 1 jest niepoprawna, ponieważ klucz publiczny jest wykorzystywany w mechanizmach kryptografii asymetrycznej, gdzie występują pary kluczy: publiczny i prywatny. Klucz publiczny jest używany do szyfrowania danych, a klucz prywatny jest wykorzystywany do deszyfrowania danych, ten mechanizm ma za zadanie zapewnienie poufności przesyłanych danych. PSK natomiast nie jest generowany dynamicznie w oparciu o certyfikat SSL, który zawiera klucz publiczny. W praktyce certyfikaty SSL są wykorzystywane w połączeniach VPN w konfiguracji opartej na protokole TLS. Certyfikaty stanowią rozszerzenie idei uwierzytelniania, w którym oprócz weryfikacji istnienia i poufności kluczy kryptograficznych, weryfikowana jest również tożsamość danej strony połączenia. \n\nOdpowiedź 2 jest poprawna, ponieważ PSK jest rzeczywiście kluczem symetrycznym, który musi być statycznie ustalony i znany obu stronom tunelu VPN przed rozpoczęciem bezpiecznej transmisji. Ten klucz symetryczny jest wykorzystywany do szyfrowania i odszyfrowywania danych przesyłanych w tunelu VPN. Wymiana danych za pomocą mechanizmu PSK opiera się na algorytmach symetrycznych (np. AES), które cechują się szybkością działania. Należy pamiętać, że ten klucz symetryczny jest ustalany poza mechanizmami kryptografii asymetrycznej i nie jest tworzony dynamicznie w momencie zestawienia połączenia. PSK to mechanizm uproszczony, wykorzystywany w mniejszych środowiskach (dla relatywnie małej liczby punktów końcowych) albo jako wstęp do negocjacji parametrów bardziej złożonych mechanizmów (np. wykorzystujących certyfikaty w protokole IKE). \n\nOdpowiedź 3 jest niepoprawna, ponieważ opisuje mechanizm wymiany kluczy w algorytmie Diffiego-Hellmana (DH) który wykorzystuje algorytmy asymetryczne. W algorytmie tym obie strony wymieniają się informacjami publicznymi, które to informacje są następnie wykorzystywane do wygenerowania tajnego klucza symetrycznego, który wykorzystywany jest do bezpiecznej transmisji w protokole SSL. Mechanizm ten jest bardzo istotny w przypadku protokołów, w których nie przewidziano wstępnego etapu negocjacji klucza, a chcemy osiągnąć duży stopień poufności bez uprzedniej konieczności wymiany klucza poza kanałem transmisyjnym. \n\nOdpowiedź 4 jest poprawna, ponieważ PSK oprócz szyfrowania danych służy również do uwierzytelnienia stron tunelu VPN. Obie strony, mając wiedzę o współdzielonym kluczu, mogą stwierdzić wiarygodność strony z którą prowadzą komunikację. Jeżeli strona nie potrafi poprawnie użyć współdzielonego klucza, wówczas dostęp nie zostaje przyznany, a komunikacja zostaje przerwana. Należy jednak pamiętać o istotnej wadzie tego rozwiązania - strony komunikujące się mogą udawać jedną z stron połączenia ponieważ klucz używany jest symetrycznie i tak naprawdę nie posiadamy wiarygodnej informacji odnośnie tożsamości drugiej strony, gdyż współdzielony klucz jest znany obu stronom połączenia. W celu bardziej wyrafinowanego mechanizmu uwierzytelniania stosuje się infrastrukturę klucza publicznego i certyfikaty SSL."
    },
    {
        "questionId": 295,
        "title": "Czego nie mozna ograniczyc za pomoca komendy ulimit (mechanizmu limitow zasobowych)?",
        "answers": [
            {
                "text": "wielkosci pliku zrzutu pamieci",
                "isCorrect": false
            },
            {
                "text": "ilosci otwartych deskryptorow",
                "isCorrect": false
            },
            {
                "text": "ilosci tworzonych procesow",
                "isCorrect": false
            },
            {
                "text": "sumy zajmowanej przestrzeni dyskowej przez pliki",
                "isCorrect": false
            },
            {
                "text": "ilosci zalogowanych rownoczesnie uzytkownikow",
                "isCorrect": true
            },
            {
                "text": "ilosci wykorzystanej pamieci operacyjnej przez proces",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`ulimit` to polecenie w systemach Linux/Unix, które pozwala kontrolować zasoby systemowe dostępne dla procesu lub użytkownika. Mechanizm ten narzuca ograniczenia dotyczące ilości zasobów, które może wykorzystać dany proces czy użytkownik, co pomaga w utrzymaniu stabilności i bezpieczeństwa systemu. Limity te nie działają globalnie, lecz lokalnie. Ustawiając dany limit przy pomocy polecenia `ulimit` działamy tylko na sesję danego użytkownika, ewentualnie możemy zmienić limity domyślne, które będą obowiązywać dla wszystkich nowo-utworzonych sesji.\n\n* **\"wielkości pliku zrzutu pamięci\"**: Polecenie `ulimit` z opcją `-c`  (lub `--core-size`) pozwala na ustawienie maksymalnej wielkości pliku zrzutu pamięci. Plik taki powstaje gdy program zakończy się z powodu błędu, przez co może być nieocenioną pomocą podczas szukania źródła błędów w programach. Jest to limit związany z sesją, czyli **można to ograniczyć za pomocą komendy `ulimit`**.\n\n* **\"ilości otwartych deskryptorów\"**: Opcja `-n` lub `--open-files` w `ulimit` umożliwia ustawienie maksymalnej ilości otwartych deskryptorów plików. Deskryptor pliku to identyfikator numeryczny, który reprezentuje otwarty plik lub gniazdo w systemie, dlatego ta opcja **może być ograniczana przez `ulimit`**. Ograniczenie liczby deskryptorów plików pozwala zapobiegać niekontrolowanemu otwieraniu plików, co mogłoby prowadzić do wyczerpania zasobów systemu. Na przykład, serwer WWW może otwierać wiele połączeń sieciowych; `ulimit -n` może ograniczyć ich liczbę.\n\n*  **\"ilości tworzonych procesów\"**: Limit ilości tworzonych procesów jest ustawiany za pomocą opcji `-u` lub `--processes`. Ograniczenie to pozwala zapobiegać nadmiernemu tworzeniu procesów przez użytkownika lub aplikację, co mogłoby przeciążyć system i doprowadzić do odmowy usługi. Przykładowo, użytkownik uruchamiający zbyt wiele procesów mógłby wyczerpać zasoby systemu, dlatego to ograniczenie **można ustawić przez `ulimit`**.\n\n* **\"sumy zajmowanej przestrzeni dyskowej przez pliki\"**: Polecenie `ulimit` nie pozwala ustawić globalnego ograniczenia na użycie dysku. Zamiast tego w systemach Linux do zarządzania przestrzenią dyskową na poziomie użytkownika wykorzystywane są systemy kwot dyskowych. Mechanizm `ulimit` nie ustawia limitów na sumę wielkości plików tylko na maksymalną wielkość pojedyńczego pliku. Zatem opcja ta **nie może być ograniczana za pomocą polecenia `ulimit`**. \n   \n* **\"ilości zalogowanych równocześnie użytkowników\"**: Ograniczenie liczby równocześnie zalogowanych użytkowników w systemie nie jest regulowane przez `ulimit`, ale przez inne narzędzia systemowe. Ustawienie tego limitu wymaga modyfikacji pliku konfiguracyjnego PAM (pluggable authentication modules), który reguluje uwierzytelnianie użytkowników w systemie, a nie przez `ulimit`.  Zatem opcja ta **nie jest ograniczana za pomocą komendy `ulimit`**.\n\n* **\"ilości wykorzystanej pamięci operacyjnej przez proces\"**: `ulimit` z opcją `-m` lub `--max-memory` ogranicza maksymalną wielkość pamięci RAM, która może być przydzielona dla pojedynczego procesu. Oznacza to, że jeden proces nie będzie mógł wykorzystać więcej pamięci niż mu przyznano, chroniąc tym samym inne procesy. Jest to przydatne w zapobieganiu nieoczekiwanemu wyczerpaniu zasobów przez wadliwe lub złośliwe aplikacje. Ten limit **można kontrolować za pomocą `ulimit`**.\n\nPodsumowując, `ulimit` jest narzędziem kontroli zasobów przydzielanych użytkownikom oraz procesom na poziomie sesji, oferuje elastyczność w ustawianiu limitów, jednak nie pozwala na kontrolę wszystkich aspektów działania systemu. Kluczowym aspektem tego polecenia jest, że nie działa na całym systemie, tylko na daną sesję użytkownika."
    },
    {
        "questionId": 296,
        "title": "Asocjacja bezpieczenstwa (ang. Security Association) IPsec w systemie Windows:",
        "answers": [
            {
                "text": "to protokol zestawiania tunelu IPsec, w ktorym negocjowane sa parametry tunelu",
                "isCorrect": false
            },
            {
                "text": "moze byc monitorowana przez systemowa zapore sieciowa",
                "isCorrect": false
            },
            {
                "text": "obejmuje zestaw parametrow niezbednych do komunikacji w tunelu IPsec",
                "isCorrect": true
            },
            {
                "text": "to polityka IPsec okreslajaca filtry pakietow poddawanych tunelowaniu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Asocjacja Bezpieczeństwa (ang. Security Association, SA) w IPsec to zbiór parametrów, które są niezbędne do bezpiecznej komunikacji między dwoma punktami końcowymi IPsec. Te parametry opisują, jak dane mają być szyfrowane, uwierzytelniane i jakiego rodzaju klucze kryptograficzne będą używane w tunelu IPsec. SA jest koncepcją fundamentalną w IPsec, ponieważ to właśnie na podstawie SA protokół IPsec wie jak ma przebiegać bezpieczna komunikacja. Bez poprawnie zdefiniowanej SA nie jest możliwe utworzenie tunelu IPsec. Każde połączenie IPsec wymaga co najmniej dwóch asocjacji bezpieczeństwa, jednej dla ruchu w kierunku z A do B i jednej dla ruchu w kierunku z B do A.\n\n**Odpowiedź 1 (niepoprawna): \"to protokol zestawiania tunelu IPsec, w ktorym negocjowane sa parametry tunelu\"** - Jest to błędna odpowiedź, ponieważ SA nie jest protokołem, lecz zbiorem parametrów uzgodnionych podczas negocjacji tunelu. Protokół odpowiedzialny za negocjację parametrów tunelu to IKE (Internet Key Exchange). IKE jest oddzielnym protokołem, który używa SA do ochrony kluczy sesyjnych oraz ich dystrybucji, ale sama SA jest efektem negocjacji IKE. Wyobraźmy sobie, że IKE to handlarz, który uzgadnia z kupcem jak ma wyglądać dostawa towaru. A SA to umowa, którą podpisuje się na podstawie tych uzgodnień, określająca szczegóły tej dostawy.\n\n**Odpowiedź 2 (niepoprawna): \"moze byc monitorowana przez systemowa zapore sieciowa\"** - Chociaż zapory sieciowe mogą monitorować ruch IPsec, to nie monitorują bezpośrednio samej SA. Zapora może filtrować ruch na podstawie parametrów takich jak adresy IP, porty, czy protokoły - a więc na podstawie już utworzonego tunelu. Natomiast sama SA opisuje parametry w jaki sposób ma być to połączenie utworzone. Czyli zapora analizuje ruch w tunelu na podstawie danych zdefiniowanych w SA ale nie analizuje samej struktury SA. Przykładowo, zapora sieciowa może sprawdzić, czy pakiet pasuje do istniejącego tunelu IPsec (czyli jest zgodny z istniejącą SA), ale nie ma wglądu do wewnętrznej struktury SA.\n\n**Odpowiedź 3 (poprawna): \"obejmuje zestaw parametrow niezbednych do komunikacji w tunelu IPsec\"** - To jest poprawna odpowiedź. SA faktycznie zawiera zbiór parametrów definiujących, jak tunel IPsec ma działać. Parametry te obejmują algorytmy szyfrowania (np. AES, 3DES), algorytmy uwierzytelniania (np. HMAC-SHA1, HMAC-MD5), długości kluczy, jak również klucze sesyjne. SA to konkretna umowa pomiędzy dwoma stronami, która musi być po obu stronach identyczna, aby komunikacja była możliwa.\n\n**Odpowiedź 4 (niepoprawna): \"to polityka IPsec okreslajaca filtry pakietow poddawanych tunelowaniu\"** - To błędna odpowiedź. Polityka IPsec opisuje, które typy ruchu powinny być chronione przez IPsec i jakie SA mają być użyte. SA natomiast to konkretna konfiguracja bezpieczeństwa stosowana do ochrony danego ruchu, która jest uzgodniona w czasie nawiązywania połączenia, a nie definicja filtra. Zatem polityka bezpieczeństwa jest koncepcją ogólną i definiuje jakie elementy sieci będą wykorzystywały ochronę IPsec, a sama SA jest konkretną realizacją zdefiniowanej polityki bezpieczeństwa. Polityka jest planem a SA jego realizacją."
    },
    {
        "questionId": 297,
        "title": "Mechanizm sudo:",
        "answers": [
            {
                "text": "zawsze wymaga podania hasla docelowego uzytkownika",
                "isCorrect": false
            },
            {
                "text": "mozna tak skonfigurowac by wymagal podania hasla biezacego uzytkownika",
                "isCorrect": true
            },
            {
                "text": "mozna tak skonfigurowac by nie wymagal podania hasla docelowego uzytkownika",
                "isCorrect": true
            },
            {
                "text": "nigdy nie wymaga podania hasla docelowego uzytkownika",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm `sudo` w systemach Linux/Unix to narzędzie, które pozwala użytkownikom na wykonywanie poleceń z uprawnieniami innego użytkownika, zwykle administratora systemu (root). Kluczową cechą `sudo` jest jego elastyczność konfiguracji, która pozwala na precyzyjne określenie, kto, jakie polecenia i z jakimi uprawnieniami może wykonywać. Konfiguracja `sudo` znajduje się w pliku `/etc/sudoers`.\n\n**Opcja \"zawsze wymaga podania hasła docelowego użytkownika\" jest nieprawidłowa.** Domyślnie, `sudo` wymaga hasła *bieżącego* użytkownika, czyli tego, który wywołuje `sudo`. Nie musi jednak wymagać hasła użytkownika, którego uprawnienia zamierzamy wykorzystać.  Przykładowo, polecenie `sudo ls`  domyślnie wymaga podania hasła użytkownika wywołującego polecenie (np. Jan). Nie wymaga ono hasła użytkownika root, pomimo że po udanym uwierzytelnieniu polecenie `ls` będzie wykonane z uprawnieniami root. To polecenie nie ma na celu zalogowania się na konto użytkownika root, ale jedynie wykonanie polecenia `ls` z jego uprawnieniami.\n\n**Opcja \"można tak skonfigurować by wymagał podania hasła bieżącego użytkownika\" jest prawidłowa.** To jest domyślne zachowanie `sudo`. W konfiguracji `/etc/sudoers` można ustawić, że użytkownik musi podać swoje hasło, aby móc skorzystać z `sudo`. Przykładowo, linijka `jan ALL = /usr/bin/ls` pozwala użytkownikowi jan uruchomić polecenie `ls` z uprawnieniami root *po podaniu swojego hasła*. Jest to najczęściej spotykany schemat działania, gdyż chroni system przed nieuprawnionym dostępem z zewnątrz.\n\n**Opcja \"można tak skonfigurować by nie wymagał podania hasła docelowego użytkownika\" jest prawidłowa.** To jest kluczowa cecha `sudo`, która odróżnia go od `su` (które zawsze wymaga hasła docelowego użytkownika). W pliku `/etc/sudoers` można zdefiniować, że dane polecenie (lub grupa poleceń) może być wykonana przez danego użytkownika bez podawania jego hasła. Na przykład, `jan ALL = NOPASSWD: /usr/bin/ls`  pozwala użytkownikowi `jan` na wykonanie polecenia `ls` z uprawnieniami root *bez konieczności podawania hasła*. Ma to praktyczne zastosowanie, gdy potrzebujemy aby program lub skrypt uruchomiony przez użytkownika jan miał prawo modyfikować zasoby systemu, ale jednocześnie użytkownik jan nie ma uprawnień do wykonywania tego polecenia. Wówczas nie trzeba podawać hasła użytkownika root do wykonania prostego polecenia.\n\n**Opcja \"nigdy nie wymaga podania hasła docelowego użytkownika\" jest nieprawidłowa.**  Jak wyjaśniono powyżej, `sudo` z definicji nie ma na celu logowania się na konto innego użytkownika, a jedynie nadawania tymczasowych uprawnień do wykonania konkretnego polecenia. `sudo` domyślnie pyta o hasło osoby wykonującej dane polecenie lub w konfiguracji, gdy tego hasła w ogóle nie pyta. Nie można jednakże użyć polecenia `sudo` podając hasło użytkownika innego niż bieżący. Polecenie to ma zupełnie inne zastosowanie niż su.\n\nPodsumowując, `sudo` nie jest prostym narzędziem zastępującym polecenie `su`. Jest ono bardzo elastycznym narzędziem pozwalającym precyzyjnie kontrolować jaki użytkownik ma prawo do używania jakiego polecenia i z jakimi uprawnieniami."
    },
    {
        "questionId": 298,
        "title": "Szyfrowanie asymetryczne w PGP:",
        "answers": [
            {
                "text": "jest wykorzystywane do zaszyfrowania tresci wiadomosci",
                "isCorrect": false
            },
            {
                "text": "jest wykorzystywane przy podpisywaniu wiadomosci",
                "isCorrect": true
            },
            {
                "text": "to uzywanie dwoch matematycznie zaleznych kluczy",
                "isCorrect": true
            },
            {
                "text": "wymaga uzycia klucza publicznego nadawcy do rozszyfrowania listu",
                "isCorrect": false
            },
            {
                "text": "wymaga uzycia klucza publicznego odbiorcy do zaszyfrowania listu",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Kryptografia asymetryczna, używana w PGP, wykorzystuje parę kluczy: klucz publiczny i klucz prywatny. Klucze te są ze sobą powiązane matematycznie, co umożliwia szyfrowanie lub podpisywanie danych, jednak treść zaszyfrowana kluczem publicznym może być rozszyfrowana wyłącznie kluczem prywatnym, a podpis utworzony kluczem prywatnym może być zweryfikowany tylko kluczem publicznym i odwrotnie. \n\n* **\"jest wykorzystywane do zaszyfrowania tresci wiadomosci\"**: To stwierdzenie jest **nieprawidłowe**. W PGP szyfrowanie wiadomości realizowane jest przy pomocy klucza symetrycznego wygenerowanego losowo dla danej wiadomości, ten klucz symetryczny jest następnie szyfrowany kluczem publicznym odbiorcy i dołączany do wiadomości. Klucze asymetryczne są w PGP używane do szyfrowania klucza symetrycznego, a nie całej treści wiadomości. Bezpośrednie szyfrowanie wiadomości kluczem asymetrycznym, chociaż możliwe, jest rzadko stosowane ze względu na dużą złożoność obliczeniową i złą wydajność.\n* **\"jest wykorzystywane przy podpisywaniu wiadomosci\"**: To stwierdzenie jest **prawidłowe**. W PGP, aby stworzyć podpis cyfrowy, nadawca używa *klucza prywatnego* do podpisania hasha wiadomości (zwykle MD5 lub SHA-1).  Odbiorca używa *klucza publicznego* nadawcy, aby zweryfikować podpis.  Potwierdza to, że wiadomość nie została zmodyfikowana oraz że pochodzi od nadawcy, który dysponuje odpowiednim kluczem prywatnym, a więc jest nadawcą, za którego się podaje.  Na przykład: Alicja chce podpisać wiadomość dla Bolka. Alicja tworzy hash wiadomości a następnie szyfruje hash swoim kluczem prywatnym. Tak zaszyfrowany hash jest dołączany do wiadomości. Bolek po odebraniu wiadomości odszyfrowuje hash kluczem publicznym Alicji, następnie tworzy hash z treści wiadomości i porównuje te hashe, gdy są identyczne to ma pewność, że wiadomość nie została zmieniona i pochodzi od Alicji.\n*  **\"to uzywanie dwoch matematycznie zaleznych kluczy\"**: To stwierdzenie jest **prawidłowe**. Kryptografia asymetryczna opiera się na parze kluczy – kluczu publicznym i kluczu prywatnym – które są powiązane matematycznie.  Dane zaszyfrowane jednym kluczem z pary mogą być rozszyfrowane tylko przy użyciu drugiego klucza z tej samej pary i odwrotnie. Ta cecha jest fundamentem bezpieczeństwa systemów takich jak PGP.\n* **\"wymaga uzycia klucza publicznego nadawcy do rozszyfrowania listu\"**: To stwierdzenie jest **nieprawidłowe**. Do odszyfrowania wiadomości zaszyfrowanej w PGP, odbiorca używa *własnego klucza prywatnego*.  Klucz publiczny nadawcy służy do weryfikacji podpisu wiadomości, ale nie do rozszyfrowania samej treści wiadomości. Na przykład: Alicja wysyła do Bolka zaszyfrowaną wiadomość. Wiadomość jest szyfrowana przy pomocy klucza symetrycznego, który zostaje zaszyfrowany kluczem publicznym Bolka, tylko Bolek używając swojego klucza prywatnego jest w stanie rozszyfrować wiadomość.\n* **\"wymaga uzycia klucza publicznego odbiorcy do zaszyfrowania listu\"**: To stwierdzenie jest **prawidłowe**. W PGP, aby zaszyfrować wiadomość tak aby jedynie jej odbiorca mógł ją przeczytać, nadawca musi użyć *klucza publicznego* odbiorcy. Klucz publiczny jest ogólnodostępny, a do rozszyfrowania wiadomości jest wymagany klucz prywatny, który jest znany tylko odbiorcy. Na przykład: Alicja wysyła do Bolka zaszyfrowaną wiadomość. Alicja szyfruje losowy klucz symetryczny, za pomocą klucza publicznego Bolka. Tak zaszyfrowany klucz symetryczny jest przekazywany Bolkowi wraz z zaszyfrowaną wiadomością. Tylko Bolek z użyciem swojego klucza prywatnego jest w stanie rozszyfrować klucz symetryczny a następnie treść wiadomości."
    },
    {
        "questionId": 299,
        "title": "Wskaz mozliwe sposoby uwierzytelniania tunelu IPsec w systemie Windows:",
        "answers": [
            {
                "text": "certyfikat X.509",
                "isCorrect": true
            },
            {
                "text": "haslo",
                "isCorrect": true
            },
            {
                "text": "klucz RSA",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół IPsec (Internet Protocol Security) jest zestawem protokołów, które umożliwiają zapewnienie poufności, integralności i autentyczności komunikacji na poziomie warstwy sieciowej. Kluczowym elementem bezpiecznego tunelu IPsec jest uwierzytelnienie, które pozwala zweryfikować tożsamość stron komunikacji. W systemie Windows, uwierzytelnianie tunelu IPsec może odbywać się na kilka sposobów.\n\n**certyfikat X.509:** Jest to poprawna metoda. Certyfikaty X.509 są szeroko stosowanym standardem dla certyfikatów klucza publicznego i służą do weryfikacji tożsamości w wielu protokołach kryptograficznych, w tym również w IPsec. Użycie certyfikatów opiera się o infrastrukturę klucza publicznego (PKI). W procesie uwierzytelniania serwer wysyła swój certyfikat klientowi. Klient weryfikuje, czy certyfikat został wystawiony przez zaufane centrum certyfikacji (CA), i czy jest ważny. Certyfikat zawiera klucz publiczny serwera, który jest używany do późniejszych etapów nawiązania tunelu. W systemie Windows, certyfikaty X.509 są powszechnie wykorzystywane w połączeniach IPsec, szczególnie w bardziej złożonych konfiguracjach, takich jak połączenia między sieciami lub tunelami VPN. W praktyce, administratorzy systemów wykorzystują certyfikaty aby zapewnić silniejsze uwierzytelnienie i elastyczne zarządzanie tożsamością.\n\n**hasło:** To także jest poprawna metoda. Uwierzytelnianie na podstawie hasła w IPsec zazwyczaj odbywa się poprzez algorytm PSK (_Pre-Shared Key_). Klucz symetryczny (hasło), jest współdzielony przez obie strony komunikacji. Hasło jest używane do wygenerowania klucza sesyjnego, którym będzie szyfrowany tunel. Ten mechanizm jest stosunkowo prosty do skonfigurowania, i dobrze nadaje się do zabezpieczenia połączeń między zaufanymi hostami. Wadą tego rozwiązania jest słaba skalowalność. W praktyce, jeśli wielu użytkowników z różnych stacji ma mieć możliwość łączenia się poprzez dany tunel, to współdzielenie jednego hasła staje się trudne do zarządzania. Trudnością jest również wymiana hasła pomiędzy stronami w sposób bezpieczny. Hasło powinno być wystarczająco długie i skomplikowane, co może również powodować problemy z jego zapamiętaniem.\n\n**klucz RSA:** To jest niepoprawna odpowiedź. Klucz RSA jest algorytmem kryptograficznym klucza publicznego. Klucze RSA służą do tworzenia podpisu cyfrowego i szyfrowania danych, a konkretnie klucza sesyjnego wykorzystywanego w tunelu IPsec. Natomiast klucz RSA nie jest elementem uwierzytelniania. Zastosowanie kluczy RSA w protokole IPsec jest składową procesu uwierzytelniania, w którym jedna strona używa klucza prywatnego RSA, aby podpisać informację, którą druga strona może zweryfikować przy użyciu jej publicznego klucza RSA. W przypadku tunelu IPsec najczęściej klucze RSA używane są w certyfikatach cyfrowych, a więc odpowiedź \"certyfikat X.509\" lepiej opisuje ten aspekt bezpieczeństwa tunelu. Sam klucz RSA nie wystarcza, aby dokonać uwierzytelnienia. Do tego konieczne jest użycie go w ramach jakiegoś protokołu wymiany i weryfikacji kluczy."
    },
    {
        "questionId": 300,
        "title": "Jak czesto sudo bedzie pytac uzytkownika o haslo? ",
        "answers": [
            {
                "text": "co okreslony czas od ostatniego uzycia",
                "isCorrect": true
            },
            {
                "text": "nigdy, jesli sudo wykorzystuje SSO",
                "isCorrect": false
            },
            {
                "text": "tylko przy pierwszym uzyciu po zalogowaniu",
                "isCorrect": false
            },
            {
                "text": "za kazdym razem, kiedy zostanie wywolane",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`sudo` to narzędzie w systemach uniksowych (jak Linux czy macOS), które pozwala użytkownikom na wykonywanie poleceń z uprawnieniami innego użytkownika, najczęściej administratora (root). Domyślnie `sudo` nie wymaga podawania hasła przy każdym wywołaniu. Zamiast tego, `sudo` przechowuje hasło użytkownika przez pewien czas w pamięci podręcznej (ang. _password caching_). Dzięki temu użytkownik nie musi wpisywać hasła za każdym razem, gdy chce użyć `sudo`. Czas ważności hasła w pamięci podręcznej jest konfigurowalny. Standardowo jest to 5 minut, ale administrator systemu może to zmienić. Celem tego mechanizmu jest zwiększenie wygody użytkowania systemu. \n\n*   **\"co okreslony czas od ostatniego uzycia\"** - **Prawidłowa odpowiedź.** `sudo` zapamiętuje hasło użytkownika na pewien okres, który liczy się od momentu ostatniego, poprawnego podania hasła. Oznacza to, że po pierwszym poprawnym użyciu `sudo`, kolejne wywołania w tym okresie nie będą wymagały ponownego podawania hasła. Po upłynięciu określonego czasu (domyślnie 5 minut), kolejne wywołanie `sudo` wymusi ponowne podanie hasła. Wartość czasu buforowania hasła jest definiowana przez parametr `timestamp_timeout` w pliku `/etc/sudoers`. Ta opcja minimalizuje wielokrotne uwierzytelnianie bez całkowitego rezygnowania z zasad bezpieczeństwa. Praktyczny przykład: Użytkownik administracyjny chce zrestartować usługę przez polecenie `sudo systemctl restart apache2`. Po wpisaniu hasła po raz pierwszy kolejne wywołania przez kilka minut nie będą wymagały hasła, co jest wygodne przy pracy z kilkoma poleceniami administracyjnymi.\n*   **\"nigdy, jesli sudo wykorzystuje SSO\"** - **Nieprawidłowa odpowiedź.** SSO (Single Sign-On, pojedyncze logowanie) to mechanizm, który pozwala użytkownikowi na logowanie do wielu systemów lub aplikacji przy użyciu jednych danych uwierzytelniających. SSO można integrować z systemami unixowymi, jednak `sudo` nie polega na nim do zapamiętywania haseł. Nawet przy korzystaniu z SSO `sudo` nadal będzie pytał o hasło z określoną częstotliwością, zgodnie z konfiguracją. Pamięć podręczna haseł `sudo` jest niezależna od systemów SSO. Praktyczny przykład: Użytkownik może być uwierzytelniony przez SSO w środowisku Windows, co pozwoli mu na dostęp do wielu zasobów. Jeżeli użytkownik będzie chciał użyć polecenia `sudo` w systemie Linux to i tak będzie musiał podać swoje hasło, które będzie przechowywane lokalnie przez `sudo`.\n*   **\"tylko przy pierwszym uzyciu po zalogowaniu\"** - **Nieprawidłowa odpowiedź.**  Domyślnie `sudo` używa mechanizmu zapamiętywania haseł na określony czas, nie tylko przy pierwszym użyciu po zalogowaniu. W ten sposób, gdy użytkownik wywoła kilka poleceń `sudo` w małych odstępach czasu, nie będzie musiał podawać hasła przy każdym wywołaniu. Ta opcja nie oddaje wiernie działania `sudo`. Praktyczny przykład: Administrator po zalogowaniu na serwer chce przejrzeć logi i wywołuje `sudo tail /var/log/syslog`, a potem `sudo systemctl status apache2`. Zgodnie z tą odpowiedzią podawałby hasło tylko raz.\n*   **\"za kazdym razem, kiedy zostanie wywolane\"** - **Nieprawidłowa odpowiedź.** Gdyby tak było, używanie `sudo` byłoby bardzo uciążliwe i niepraktyczne. `sudo` zostało zaprojektowane, aby redukować konieczność wielokrotnego wpisywania hasła, zachowując pewien poziom bezpieczeństwa. Użycie tej opcji uczyniłoby sudo bardzo trudne w użyciu. Praktyczny przykład: Administrator chcąc zainstalować pakiet poleceniem `sudo apt install pakiet1` i następne `sudo apt install pakiet2` nie musi przy każdej instalacji wpisywać hasła."
    },
    {
        "questionId": 301,
        "title": "Mechanizm POSIX ACL umozliwia: ",
        "answers": [
            {
                "text": "nadawanie praw do zasobow plikowych poszczegolnych uzytkownikom i grupom",
                "isCorrect": true
            },
            {
                "text": "odtwarzanie skasowanych plikow pod warunkiem posiadania praca C",
                "isCorrect": false
            },
            {
                "text": "szyfrowania plikow metoda symetryczna",
                "isCorrect": false
            },
            {
                "text": "automatyczne sumowanie uprawnien uzytkownika ze wszystkich grup, do ktorych nalezy",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "POSIX ACL (Access Control Lists) to mechanizm rozszerzonej kontroli dostępu w systemach operacyjnych typu Unix i Linux. Standardowe uprawnienia plików w tych systemach (odczyt, zapis, wykonanie) odnoszą się jedynie do właściciela pliku, grupy, do której plik jest przypisany oraz pozostałych użytkowników systemu. POSIX ACL rozszerza ten model, umożliwiając przypisywanie uprawnień do poszczególnych plików i katalogów, określonym użytkownikom i grupom. Umożliwia również bardziej precyzyjne określanie, jakie uprawnienia (odczyt, zapis, wykonanie) mają przypisane dany użytkownik lub grupa do danego pliku. Zatem uprawnienia mogą być powiązane z konkretnymi identyfikatorami użytkowników (UID), jak i identyfikatorami grup (GID), a nie tylko kategoriami właściciel, grupa, inni.\n\n**Odpowiedź 1: \"nadawanie praw do zasobow plikowych poszczegolnych uzytkownikom i grupom\"**\n\nJest to **poprawna** odpowiedź. Mechanizm POSIX ACL (ang. Access Control List) jest precyzyjnym rozszerzeniem uprawnień dostępu w systemach typu Unix/Linux. Pozwala na nadawanie praw (odczyt, zapis, wykonanie) do konkretnych plików i katalogów, nie tylko właścicielowi, grupie i innym, ale również pojedynczym użytkownikom i grupom, co nie jest możliwe w przypadku podstawowych uprawnień. Na przykład, administrator może przyznać konkretnemu użytkownikowi uprawnienie do zapisu w określonym katalogu, a jednocześnie zabronić go wszystkim innym użytkownikom, którzy nie są przypisani do żadnej grupy, do której dany katalog jest przypisany. Jest to bardzo precyzyjna forma kontroli dostępu.\n\n**Odpowiedź 2: \"odtwarzanie skasowanych plikow pod warunkiem posiadania praca C\"**\n\nJest to **niepoprawna** odpowiedź. POSIX ACL nie ma nic wspólnego z odtwarzaniem skasowanych plików. Odzyskiwanie danych, w tym plików, jest odrębnym zagadnieniem, często zależnym od używanego systemu plików oraz narzędzi do odzyskiwania. Termin \"praca C\" jest nieprecyzyjny i prawdopodobnie odnosi się do uprawnień \"praca z systemem\" czy znajomości języka programowania C. Nie ma związku z mechanizmem ACL. Pliki można odzyskać na kilka sposobów, ale nie ma to powiązania z prawami dostępu.\n\n**Odpowiedź 3: \"szyfrowania plikow metoda symetryczna\"**\n\nJest to **niepoprawna** odpowiedź. POSIX ACL nie służy do szyfrowania plików. Szyfrowanie jest odrębnym procesem, który polega na przekształceniu danych w postać nieczytelną dla niepowołanych osób za pomocą algorytmów i kluczy. Pliki mogą być szyfrowane na wiele różnych sposobów, często z użyciem niezależnych narzędzi. System plików NTFS na przykład oferuje wbudowaną możliwość szyfrowania danych o nazwie EFS. Natomiast POSIX ACL służy wyłącznie do kontroli dostępu, czyli decydowania, kto może czytać, modyfikować lub uruchamiać pliki.\n\n**Odpowiedź 4: \"automatyczne sumowanie uprawnien uzytkownika ze wszystkich grup, do ktorych nalezy\"**\n\nJest to **niepoprawna** odpowiedź. POSIX ACL *nie* sumuje uprawnień automatycznie. Użytkownik może należeć do kilku grup, a prawa dostępu wynikające z ACL są wyznaczane w konkretnej kolejności. Mechanizm ACL najpierw sprawdza czy są uprawnienia dla konkretnego użytkownika, potem dla konkretnej grupy, do której należy użytkownik i na końcu dla pozostałych. To uprawnienia przypisane do konkretnego użytkownika są nadrzędne w stosunku do wszystkich pozostałych. Uprawnienia sumowane są tylko w obrębie jednej kategorii podmiotu (właściciela, grupy i pozostałych), a nie wszystkich, z którymi jest powiązany użytkownik. Na przykład, jeśli użytkownik ma jawnie przyznane uprawnienie tylko do odczytu pliku (ACL), to nie uzyska prawa zapisu tego pliku, nawet jeśli należy do grupy, która takie uprawnienie ma. Musi istnieć jawny wpis w liście ACL dla tego użytkownika lub konkretnej grupy, której jest członkiem."
    },
    {
        "questionId": 302,
        "title": "Historia hasel jest przechowywana przez system operacyjny: ",
        "answers": [
            {
                "text": "aby wykluczyc ponowne uzycie tego samego hasla jednorazowego",
                "isCorrect": false
            },
            {
                "text": "aby wykluczyc ustawienie nowego hasla identycznego z jakimkolwiek wczesniej wybranych przez tego samego uzytkownika od poczatku",
                "isCorrect": false
            },
            {
                "text": "w polaczeniu z minimalnym okresem waznosci hasla, aby wykluczyc zbyt czeste wybieranie przez uzytkownika tego samego nowego hasla",
                "isCorrect": true
            },
            {
                "text": "aby umozliwic tzw. przypomnienie hasel uzytkownikow (szczegolnie uzyteczne w przypadku aplikacji nieobslugujacych funkcji jednokierunkowych)",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm historii haseł, przechowywany przez system operacyjny, jest zabezpieczeniem mającym na celu ograniczenie możliwości ponownego użycia hasła przez użytkownika. Nie chodzi tu o jednorazowe hasła, które z definicji są używane tylko raz i nie są w żaden sposób zapamiętywane przez system. Chodzi o ochronę przed cyklicznym powracaniem do tego samego hasła w dłuższym okresie czasu. Hasła nie są przechowywane w jawnej postaci w systemie, tylko za pomocą specjalnej funkcji skrótu kryptograficznego, tworzącej hasz z hasła, stąd nie można ich w prosty sposób odtworzyć i przywrócić. \n\n**Opcja 1: \"aby wykluczyć ponowne użycie tego samego hasła jednorazowego\"**\n\nTa opcja jest **niepoprawna**. Hasła jednorazowe, z definicji, są używane tylko raz. System nie przechowuje ich w historii. Historia haseł dotyczy standardowych haseł używanych wielokrotnie i ma na celu uniemożliwienie ich powtarzania.\n\n**Opcja 2: \"aby wykluczyć ustawienie nowego hasła identycznego z jakimkolwiek wcześniej wybranych przez tego samego użytkownika od początku\"**\n\nTa opcja jest **niepoprawna**. Historia haseł ma ograniczoną długość – zazwyczaj przechowuje kilka do kilkudziesięciu ostatnich haseł. Nie ma możliwości aby system przechowywał nieograniczoną ilość haseł, które użytkownik użył od samego początku. Poza tym pamięć potrzebna do przechowywania tych informacji szybko by się wyczerpała. Dodatkowo w praktyce mała liczba haseł z historii użytkownika jest wystarczająca aby wyeliminować proste i słabe hasła.\n\n**Opcja 3: \"w połączeniu z minimalnym okresem ważności hasła, aby wykluczyć zbyt częste wybieranie przez użytkownika tego samego nowego hasła\"**\n\nTa opcja jest **poprawna**. Historia haseł ma na celu uniemożliwienie użytkownikowi powracania do haseł używanych w przeszłości. Łączy się to z koncepcją minimalnego okresu ważności hasła. Minimalny okres ważności hasła to parametr, który określa, jak długo hasło musi być ustawione, zanim będzie można je zmienić. W powiązaniu z historią haseł uniemożliwia to cykliczne i szybkie zmienianie haseł na te same, a potem na te same. Przykładowo, jeśli minimalny okres ważności to 2 dni, a historia haseł przechowuje 20 ostatnich haseł, użytkownik nie będzie mógł w nieskończoność wpisywać nowego hasła i wracać do haseł z przeszłości. Musi on użyć kolejnych 20 unikalnych haseł, zanim będzie mógł ponownie użyć hasła, które kiedyś było przez niego używane. System dzięki temu blokuje możliwość ciągłego i szybkiego zmieniania hasła na poprzednie. Takie podejście wymusza na użytkowniku poszukiwanie nowych haseł, co w rezultacie prowadzi do tego, że hasła te będą dłuższe i bardziej skomplikowane.\n\n**Opcja 4: \"aby umożliwić tzw. przypomnienie haseł użytkowników (szczególnie użyteczne w przypadku aplikacji nieobsługujących funkcji jednokierunkowych)\"**\n\nTa opcja jest **niepoprawna**. System nie przechowuje haseł w postaci jawnej, z której można by je przypomnieć użytkownikowi. Hasła są szyfrowane specjalnymi algorytmami kryptograficznymi, które mają własność jednokierunkową. Oznacza to, że system nie jest w stanie odtworzyć na podstawie zaszyfrowanego hasła, hasła w postaci jawnej."
    },
    {
        "questionId": 303,
        "title": "Pojedyncza regula zapory sieciowej Windows: ",
        "answers": [
            {
                "text": "moze dotyczyc jednoczesnie ruchu przychodzacego i wychodzacego",
                "isCorrect": false
            },
            {
                "text": "moze dotyczyc wszystkich 3 profili sieciowych jednoczesnie",
                "isCorrect": true
            },
            {
                "text": "moze byc ustawiona z uzyciem polecenia netsh",
                "isCorrect": true
            },
            {
                "text": "moze dotyczyc tylko wskazanego programu",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Zapora sieciowa systemu Windows, w odróżnieniu od wielu innych zapor, pozwala na tworzenie reguł o dużej elastyczności. Pojedyncza reguła nie jest ograniczona tylko do określonego ruchu (przychodzący lub wychodzący) lub do określonego profilu sieciowego. Reguły mogą być również tworzone za pomocą graficznego interfejsu użytkownika ale również z wykorzystaniem wiersza poleceń i programu `netsh`.\n\nOpcja *\"może dotyczyć jednoczesnie ruchu przychodzacego i wychodzacego\"* jest **niepoprawna**, ponieważ reguła zapory może zostać skonfigurowana tak, aby dotyczyła obydwu kierunków ruchu sieciowego naraz. Oznacza to, że ta sama reguła może kontrolować zarówno pakiety przychodzące, jak i wychodzące z komputera. Dla przykładu, możemy mieć regułę zezwalającą na ruch HTTP, która będzie akceptować ruch na porcie 80 zarówno przychodzący, jak i wychodzący. Nie jesteśmy ograniczeni do definiowania osobnych reguł dla każdego kierunku. W praktyce takie uproszczenie konfiguracji zapory sieciowej jest bardzo użyteczne, gdyż można w ten sposób zaoszczędzić czas i uniknąć błędów przy konfigurowaniu, gdyż mniej reguł jest łatwiejszych w utrzymaniu.\n\nOpcja *\"może dotyczyć wszystkich 3 profili sieciowych jednoczesnie\"* jest **poprawna**, ponieważ zapora sieciowa systemu Windows umożliwia przypisanie pojedynczej reguły do wszystkich trzech profili sieciowych jednocześnie. Profile sieciowe, w Windows są to ustawienia zapory sieciowej zależne od środowiska sieciowego, w którym pracuje komputer (profil domowy, profil publiczny i profil domenowy). Dzięki temu można zapewnić spójność ochrony niezależnie od aktualnie aktywnego profilu. Przykładowo, reguła blokująca port 23 (Telnet) może być przypisana do wszystkich trzech profili. W ten sposób, niezależnie od tego, czy jesteśmy połączeni z siecią firmową, domową, czy publiczną, Telnet będzie zawsze zablokowany.\n\nOpcja *\"może byc ustawiona z uzyciem polecenia netsh\"* jest **poprawna**, ponieważ narzędzie `netsh` (Network Shell) w systemie Windows umożliwia konfigurowanie zapory sieciowej z poziomu wiersza poleceń. Używając poleceń `netsh advfirewall firewall add rule` można dodawać nowe reguły, modyfikować istniejące oraz usuwać niepotrzebne. Takie podejście pozwala na automatyzację procesu konfiguracji zapory sieciowej przy użyciu np. skryptów .bat lub .ps1. Polecenie `netsh` pozwala również eksportować reguły zapory do pliku i importować je z pliku co znacząco upraszcza wdrażanie reguł na większą skalę. \nPrzykładowe polecenie, które tworzy regułę zezwalającą na ruch przychodzący na porcie 80 dla wszystkich trzech profili to:\n```\nnetsh advfirewall firewall add rule name=\"HTTP In\" dir=in action=allow protocol=TCP localport=80 profile=any\n```\nOpcja *\"moze dotyczyc tylko wskazanego programu\"* jest **poprawna**, ponieważ zapora sieciowa w systemie Windows pozwala powiązać daną regułę z konkretną aplikacją, przez podanie ścieżki do pliku wykonywalnego programu .exe. W takiej sytuacji dana reguła odnosi się tylko do wybranej aplikacji, blokując jej połączenia lub umożliwiając komunikację z siecią. Na przykład, reguła zezwalająca na komunikację przez port 80 może być powiązana tylko z przeglądarką internetową, blokując tym samym podobny ruch dla innych aplikacji."
    },
    {
        "questionId": 304,
        "title": "Grupa uzytkownikow w systemie MS Windows o nazwie Uzytkownicy uwierzytelnieni: ",
        "answers": [
            {
                "text": "jest identyczna z grupa Wszyscy",
                "isCorrect": false
            },
            {
                "text": "jest podzbiorem grupy Wszyscy",
                "isCorrect": true
            },
            {
                "text": "obejmuje wszystkich uzytkownikow lokalnych",
                "isCorrect": false
            },
            {
                "text": "nie obejmuje konta Gosc",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "W systemie operacyjnym MS Windows grupa \"Użytkownicy uwierzytelnieni\" (ang. Authenticated Users) jest predefiniowaną grupą zabezpieczeń, która zawiera wszystkich użytkowników, którzy pomyślnie zalogowali się do systemu używając poprawnej nazwy użytkownika oraz hasła. Nie obejmuje ona użytkowników anonimowych, ani tych, którzy próbują logować się zdalnie bez uprzedniego uwierzytelnienia.\n\nOpcja 1: \"jest identyczna z grupą Wszyscy\" jest niepoprawna. Grupa \"Wszyscy\" (ang. Everyone) obejmuje **wszystkich** użytkowników, także anonimowych i niezalogowanych, oraz gości. Jest to szersza grupa niż \"Użytkownicy uwierzytelnieni\". Na przykład, pliki z prawami dostępu ustawionymi dla grupy \"Wszyscy\" mogą być dostępne (w trybie odczytu) nawet bez konieczności logowania się w systemie Windows.\n\nOpcja 2: \"jest podzbiorem grupy Wszyscy\" jest poprawna. Jak wyjaśniono powyżej, grupa \"Użytkownicy uwierzytelnieni\" jest węższą grupą niż \"Wszyscy\", ponieważ obejmuje tylko użytkowników, którzy przeszli pomyślnie proces uwierzytelnienia. Użytkownicy \"Uwierzytelnieni\" są elementami grupy \"Wszyscy\". Nie każdy użytkownik grupy \"Wszyscy\" należy do grupy \"Uwierzytelnieni\"\n\nOpcja 3: \"obejmuje wszystkich użytkowników lokalnych\" jest niepoprawna. Grupa \"Użytkownicy uwierzytelnieni\" **nie** obejmuje **wszystkich** użytkowników lokalnych. Przykładowo, gdy konto użytkownika jest wyłączone, to ten użytkownik nie należy do tej grupy. Użytkownik _Gość_(_ang. Guest_) również nie należy do tej grupy.\n\nOpcja 4: \"nie obejmuje konta Gość\" jest poprawna. Konto \"Gość\" (_ang. Guest_) jest specjalnym kontem o ograniczonych uprawnieniach, wykorzystywanym głównie do tymczasowego, anonimowego dostępu do systemu. Użytkownik zalogowany na konto Gość **nie jest** uważany za \"Użytkownika uwierzytelnionego\", z tego powodu, mimo iż konto gościa jest aktywne i zalogowane w systemie, to nie należy ono do tej grupy.\n\nPrzykłady:\n- Administrator sieci konfigurując uprawnienia do współdzielonego katalogu, może ustawić prawa dostępu dla grupy \"Użytkownicy uwierzytelnieni\", aby dostęp miały tylko osoby, które zalogowały się do systemu za pomocą hasła. Dzięki temu osoby niezalogowane nie będą miały możliwości dostępu do tego katalogu.\n- Aplikacja, która potrzebuje dostępu do danych użytkownika może żądać uprawnień od użytkownika należącego do grupy \"Użytkownicy Uwierzytelnieni\", aby mieć pewność że ma do czynienia z poprawnym użytkownikiem. Z poziomu systemu operacyjnego Windows to aplikacja może zweryfikować tożsamość użytkownika z uprawnieniami lokalnymi."
    },
    {
        "questionId": 305,
        "title": "Mechanizm mandatory Integrity Control (MIC) system Windows: ",
        "answers": [
            {
                "text": "przypisuje procesowi jeden z 5 poziomow uprawnien uwzglednianych dodatkowo w kontroli dostepu",
                "isCorrect": false
            },
            {
                "text": "pozwala ograniczyc dostep do odczytu dla wybranych plikow",
                "isCorrect": false
            },
            {
                "text": "pozwala ograniczyc dostep do zapisu w systemie plikow",
                "isCorrect": true
            },
            {
                "text": "pozwala ograniczyc swobode komunikacji miedzy procesami",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm Mandatory Integrity Control (MIC) w systemie Windows jest formą kontroli dostępu, która działa w sposób ścisły (mandatory), a nie uznaniowy (discretionary). Oznacza to, że nie jest oparta na uprawnieniach nadanych przez użytkownika, tylko na regułach narzuconych przez system, które są poza kontrolą właściciela zasobu. Głównym celem MIC jest ochrona przed nieautoryzowanymi modyfikacjami danych i systemowych ustawień. MIC realizuje to poprzez przypisanie każdemu procesowi w systemie poziomu integralności (ang. integrity level) oraz ograniczenie dostępu do zapisu w systemie plików, a także do komunikacji pomiędzy procesami, w zależności od poziomu integralności.\n\n**Odpowiedź 1:** \"przypisuje procesowi jeden z 5 poziomow uprawnien uwzglednianych dodatkowo w kontroli dostepu\" - jest **niepoprawna**. MIC nie działa na zasadzie poziomów uprawnień, w sensie przypisywania dodatkowych praw do tych, które są nadane przez DAC. MIC przypisuje *poziom integralności*, który jest metadaną, a nie uprawnieniem. Pięć poziomów integralności to low, medium, high, system, and protected. Kontrola dostępu w MIC uwzględnia poziom integralności. Im wyższy poziom integralności procesu, tym mniej ograniczeń w dostępie do zapisu.  Więc chociaż faktycznie MIC operuje na poziomach, to nie są one uprawnieniami w sensie klasycznym. Na przykład proces z poziomem \"medium\" nie będzie mógł modyfikować zasobów, które wymagają poziomu \"high\".\n\n**Odpowiedź 2:** \"pozwala ograniczyc dostep do odczytu dla wybranych plikow\" - jest **niepoprawna**. Chociaż MIC w teorii może być rozszerzony o pewne kontroli odczytu, to nie jest to jego pierwotnym i podstawowym zadaniem. MIC skupia się na kontroli integralności poprzez ograniczenie *zapisu*. Kontrola odczytu należy do mechanizmów DAC(ang. Discretionary Access Control) oraz mechanizmów oferowanych przez system plików.\n\n**Odpowiedź 3:** \"pozwala ograniczyc dostep do zapisu w systemie plikow\" - jest **poprawna**. To jest *kluczowa* funkcja MIC. Procesy z niskim poziomem integralności (np. procesy uruchomione z sieci) nie mogą zapisywać do plików wymagających wyższego poziomu. Przykładem tego jest ograniczanie możliwości zapisu do folderów systemowych. Pozwala to uniemożliwić malware'owi trwale infekować system poprzez zapisanie szkodliwego kodu w ważnych plikach systemowych. Załóżmy, że przeglądarka WWW(proces ma poziom medium) pobierze program, który ma przejąć kontrolę nad systemem. Program ten, aby trwale infekować system musi zapisać swoją kopię w katalogu Windows, chronionym przez MIC (wymagającym poziomu system, w naszym przykładzie wysokiego poziomu). W tym przypadku MIC zadziała, blokując taką próbę zapisu.\n\n**Odpowiedź 4:** \"pozwala ograniczyc swobode komunikacji miedzy procesami\" - jest **poprawna**. MIC nie tylko kontroluje dostęp do systemu plików ale również kontroluje dostęp do komunikacji międzyprocesowej. Procesy o niższym poziomie integralności nie mają prawa wysyłać komunikatów do procesów z wyższym poziomem. Wykorzystanie tego mechanizmu utrudnia np. atak typu _process injection_, w którym intruz wstrzykuje szkodliwy kod do uruchomionego procesu o wyższym poziomie uprawnień, uzyskując nieautoryzowany dostęp do zasobów lub danych. Przykładowo: proces przeglądarki z poziomem \"medium\" nie może z łatwością \"wstrzyknąć\" kodu do antywirusa działającego z poziomem \"high\"."
    },
    {
        "questionId": 306,
        "title": "Wskaz pliki zaangazowane w konfiguracje TCP wrappera w systemie Unix: ",
        "answers": [
            {
                "text": "/etc/hosts.allow",
                "isCorrect": true
            },
            {
                "text": "/etc/hosts",
                "isCorrect": false
            },
            {
                "text": "/etc/hosts.deny",
                "isCorrect": true
            },
            {
                "text": "/etc/hosts.equiv",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "TCP Wrappers to mechanizm kontroli dostępu na poziomie hosta w systemach Unix-like, który pozwala administratorom kontrolować, które maszyny mogą łączyć się z konkretnymi usługami sieciowymi działającymi na danym komputerze.  Działa on jako \"warstwa ochronna\" otaczająca proces usługi sieciowej.  Główną funkcją TCP Wrappers jest filtrowanie połączeń TCP na podstawie adresu IP źródła, a mechanizm ten jest konfigurowany za pomocą dwóch plików: `/etc/hosts.allow` oraz `/etc/hosts.deny`.  Te pliki zawierają listę reguł określających, które hosty mają dostęp do konkretnych usług.\n\n`/etc/hosts.allow` jest plikiem konfiguracyjnym TCP Wrappers, w którym definiuje się hosty lub sieci, którym *jest* dozwolony dostęp do wybranych usług sieciowych.  Każda linia w pliku reprezentuje regułę dostępu, która składa się z nazwy usługi, dwukropka, oraz listy nazw hostów lub adresów IP (lub zakresów adresów IP) rozdzielonych przecinkami. Na przykład,  `sshd : 192.168.1.0/24`  pozwala na dostęp do usługi sshd wszystkim komputerom w sieci 192.168.1.0/24.  `sshd : 192.168.1.10 10.0.0.5` zezwala na dostęp do sshd tylko komputerom o adresach IP 192.168.1.10 i 10.0.0.5.\n\n`/etc/hosts.deny` jest plikiem konfiguracyjnym TCP Wrappers, w którym definiuje się hosty lub sieci, którym *nie jest* dozwolony dostęp do wybranych usług sieciowych. Plik ten działa w połączeniu z /etc/hosts.allow - jeśli host nie jest jawnie dozwolony w /etc/hosts.allow, a jest zablokowany w /etc/hosts.deny, to dostęp jest odrzucany.  Podobnie jak w `/etc/hosts.allow`, każda linia składa się z nazwy usługi, dwukropka, oraz listy nazw hostów lub adresów IP.  Linia `sshd : ALL`  blokuje dostęp do usługi sshd wszystkim adresom ip, natomiast linia `ALL : ALL` blokuje dostęp do wszystkich usług.  \n\n`/etc/hosts` jest plikiem konfiguracyjnym systemu operacyjnego, służącym do mapowania nazw domenowych na adresy IP. Jest to plik używany przez system do rozstrzygania nazw hostów na lokalnym komputerze, a jego konfiguracja nie ma związku z TCP Wrappers. Na przykład linia `127.0.0.1 localhost` mapuje nazwę `localhost` na adres lokalnej pętli zwrotnej `127.0.0.1`.\n\n`/etc/hosts.equiv`  jest plikiem, który służy do konfigurowania zaufania między hostami w systemach Unix-like, a jego konfiguracja ma powiązanie z usługami takimi jak rlogin, rsh czy rcp. Plik ten nie jest wykorzystywany przez TCP Wrappers. Plik `/etc/hosts.equiv` zawiera listę nazw hostów lub nazw użytkowników na tych hostach, którym zezwala się na zdalne logowanie (z użyciem rlogin) bez potrzeby podawania hasła. Jest to mechanizm potencjalnie niebezpieczny, gdyż jeśli choć jeden host z listy zostanie przejęty przez intruza, to wszystkie pozostałe mogą być potencjalnie narażone na zdalne wtargnięcie."
    },
    {
        "questionId": 307,
        "title": "Wybierz prawdziwa kolejnosc operacji NAT: ",
        "answers": [
            {
                "text": "PREROUTING(mangle) PREROUTING(nat) FILTERING POSTROUTING(nat) POSTROUTING(mangle)",
                "isCorrect": false
            },
            {
                "text": "PREROUTING(nat) PREROUTING(mangle) FILTERING POSTROUTING(nat) POSTROUTING(mangle)",
                "isCorrect": false
            },
            {
                "text": "PREROUTING(nat) PREROUTING(mangle) FILTERING POSTROUTING(mangle) POSTROUTING(nat)",
                "isCorrect": false
            },
            {
                "text": "PREROUTING(mangle) PREROUTING(nat) FILTERING POSTROUTING(mangle) POSTROUTING(nat)",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Translacja Adresów Sieciowych (NAT) w systemie Linux, a dokładniej w module netfilter, wykorzystuje różne łańcuchy w celu realizacji różnych funkcji. Tablice (`table`) nat i mangle działają w różnych momentach przepływu pakietu. Kluczowe jest zrozumienie, że najpierw modyfikowane są adresy docelowe, potem wykonywana jest filtracja, a dopiero na końcu modyfikowane są adresy źródłowe. Domyślnie w programie `iptables` pakiety przechodzą przez filtry zgodnie z następującą logiką: \n\n1.  **PREROUTING (mangle):** Pierwszym etapem, przez który przechodzi pakiet wchodzący do systemu, jest `PREROUTING` w tablicy `mangle`. Tablica `mangle` służy do modyfikacji nagłówków pakietów. Na tym etapie można np. zmienić pole TTL (Time To Live) pakietu. Może wystąpić sytuacja w której chcemy aby ruch dochodzący z pewnej sieci był oznaczony odpowiednim znacznikiem do późniejszego wykorzystania.\n\n2.  **PREROUTING (nat):** Następnie, pakiet przechodzi przez łańcuch `PREROUTING` w tablicy `nat`. Tutaj wykonywane są operacje DNAT (ang. _Destination Network Address Translation_), czyli translacja adresów docelowych. Oznacza to zmianę docelowego adresu IP pakietu, na przykład aby przekierować ruch przychodzący na port 80 na port 8080. Po wykonaniu translacji adres docelowy jest ustalony i wiadomo do jakiej maszyny z sieci wewnętrznej ma być skierowany ruch.\n\n3.  **FILTERING:** Po modyfikacji nagłówka IP i adresów w łańcuchu `PREROUTING` w obu tablicach pakiet przechodzi przez tablicę `filter` i łańcuch `FORWARD` (jeśli pakiet jest rutowany). Na tym etapie podejmowane są decyzje dotyczące tego czy pakiet powinien zostać przepuszczony, odrzucony lub zalogowany. Jeżeli pakiet został sklasyfikowany jako niebezpieczny, to nie ma potrzeby go dalej przetwarzać. W tym miejscu blokujemy niebezpieczny ruch w oparciu o znane numery portów, adresy IP. \n\n4.  **POSTROUTING (mangle):** Po przejściu przez tablicę `filter` i łańcuch `FORWARD`, pakiety trafiają do tablicy `mangle` w łańcuchu `POSTROUTING`, gdzie ponownie można modyfikować nagłówki pakietów. Na tym etapie również może nastąpić operacja nadpisywania znaczników, ustawionych wcześniej.\n\n5.  **POSTROUTING (nat):** Ostatnim etapem, przez który przechodzi pakiet w tablicy `nat` jest łańcuch `POSTROUTING`.  Tutaj odbywa się SNAT (ang. _Source Network Address Translation_), czyli translacja adresów źródłowych. Oznacza to zamianę adresu źródłowego pakietu wychodzącego z naszej sieci, na adres publiczny interfejsu rutera, w celu umożliwienia odpowiedzi na zadane zapytanie przez użytkownika w sieci lokalnej, bez obawy, że pakiet odpowiedzi nie wróci do właściwej maszyny.\n\n**Analiza odpowiedzi:**\n*   **\"PREROUTING(mangle) PREROUTING(nat) FILTERING POSTROUTING(nat) POSTROUTING(mangle)\"** - Ta odpowiedź jest **poprawna**. Odzwierciedla prawidłową kolejność operacji, gdzie modyfikacja adresu docelowego i inne modyfikacje nagłówków odbywają się przed filtracją a zmiana adresu źródłowego po filtracji. Pierwsze wystąpienie `mangle` służy modyfikacji przed trasowaniem, a ostatnie do potencjalnych modyfikacji po wyborze trasy.\n\n*   **\"PREROUTING(nat) PREROUTING(mangle) FILTERING POSTROUTING(nat) POSTROUTING(mangle)\"** - Ta odpowiedź jest **niepoprawna**. Kolejność wykonywania operacji w tablicach nat i mangle jest odwrotna, a to w praktyce spowodowałoby, że pakiet na samym początku nie mógłby być poprawnie przetrasowany na sieć wewnętrzną (brak znalezienia celu). \n\n*    **\"PREROUTING(nat) PREROUTING(mangle) FILTERING POSTROUTING(mangle) POSTROUTING(nat)\"** - Ta odpowiedź jest **niepoprawna**. Jak wyżej, kolejność w tablicy `nat` jest odwrotna.\n\n*    **\"PREROUTING(mangle) PREROUTING(nat) FILTERING POSTROUTING(nat) POSTROUTING(mangle)\"** - Ta odpowiedź jest **niepoprawna**. Na etapie `POSTROUTING` najpierw dokonywana jest zmiana adresu docelowego(przez `nat`), a dopiero potem wykonywana jest modyfikacja nagłówków(przez `mangle`).\n\n**Przykład:**\n\nWyobraźmy sobie serwer HTTP w sieci prywatnej (adres 192.168.1.100) za ruterem z publicznym adresem IP 203.0.113.1. Klient z internetu wysyła żądanie do 203.0.113.1 port 80.\n\n1.  Pakiet trafia do rutera. W tablicy `mangle`  w łańcuchu `PREROUTING` na przykład jest sprawdzane, czy priorytet pakietu jest odpowiednio ustawiony i ewentualnie jest on zmieniany\n2.  Następnie, w tablicy `nat`  w łańcuchu `PREROUTING` pakiet jest modyfikowany. Następuje translacja adresu docelowego (DNAT): 203.0.113.1:80 jest zmieniane na 192.168.1.100:80. Ruter wie już, do którego komputera w sieci lokalnej ma wysłać ten pakiet.\n3.  Pakiet wchodzi do tablicy `filter` i łańcuch `FORWARD` gdzie, na podstawie określonych wcześniej zasad, jest podejmowana decyzja czy dany pakiet powinien trafić do komputera o adresie 192.168.1.100.\n4.  W tablicy `mangle` w łańcuchu `POSTROUTING` ewentualnie zmieniamy pola pakietu(np. flagi TCP).\n5.  Pakiet wchodzi do tablicy `nat` i łańcuch `POSTROUTING`, gdzie  następuje translacja adresu źródłowego (SNAT). Prywatny adres IP 192.168.1.100 zostaje zamieniony na adres 203.0.113.1. Klient z internetu, który dostanie odpowiedz z serwera zobaczy tylko adres zewnętrzny interfejsu rutera jako adres serwera, a nie adres wewnętrznego serwera.\n\nPowyższy przykład pokazuje, dlaczego ważna jest poprawna kolejność operacji, a w szczególności operacji translacji w celu uzyskania oczekiwanego rezultatu."
    },
    {
        "questionId": 308,
        "title": "Wskaz roznice miedzy dwoma komendami sudo su oraz su: ",
        "answers": [
            {
                "text": "jedyna roznica jest to, ze aby wykonac polecenie sudo su uzytkownik musi nalezec do grupy whels",
                "isCorrect": false
            },
            {
                "text": "sudo su moze wymagac podania hasla biezacego uzytkownika, su natomiast root'a",
                "isCorrect": true
            },
            {
                "text": "su bedzie wymagac podania hasla biezacego uzytkownika, sudo su natomiast root'a",
                "isCorrect": false
            },
            {
                "text": "nie ma zadnej roznicy, sudo su jest aliasem na su OpenVPN",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`su` (substitute user) to polecenie, które umożliwia zmianę bieżącego użytkownika na innego użytkownika, domyślnie na użytkownika `root`, czyli superużytkownika posiadającego wszelkie uprawnienia w systemie. Po wykonaniu `su`, system wymaga podania hasła konta, na które chcemy się przełączyć, czyli hasła użytkownika `root` w przypadku domyślnej zmiany użytkownika.\n\n`sudo` (substitute user do) natomiast, pozwala na wykonanie pojedynczej komendy jako inny użytkownik (domyślnie też root), ale w przeciwieństwie do `su` wymaga podania hasła bieżącego użytkownika(czyli osoby która wydaje polecenie `sudo`). Z tego względu `sudo` nie umożliwia bezpośredniego przełączenia do konta root, a jedynie wykonanie pojedynczej komendy z podwyższonymi uprawnieniami. Zazwyczaj używa się polecenia `sudo` do wykonywania pojedynczych poleceń, do których uprawnienia ma tylko root, bez potrzeby pełnego przełączania się na konto root.\n\nPolecenie `sudo su` łączy oba mechanizmy. Najpierw `sudo` weryfikuje uprawnienia i tożsamość bieżącego użytkownika poprzez zażądanie hasła bieżącego użytkownika, a następnie uruchamia `su`, które domyślnie zmienia użytkownika na `root`. W kolejnym kroku polecenie `su` poprosi o podanie hasła root, czyli hasła konta, na które chcemy się przełączyć.\n\n**Odpowiedź 1:**\n\"jedyna roznica jest to, ze aby wykonac polecenie sudo su uzytkownik musi nalezec do grupy whels\" jest **niepoprawna**. Owszem, domyślnie użytkownik, który chce używać `sudo` musi należeć do grupy `wheel` lub jego nazwa musi być zdefiniowana w pliku konfiguracyjnym `/etc/sudoers`. Natomiast, samo `su` nie ma takich wymagań. Dodatkowo, odpowiedź jest niepoprawna, gdyż nie jest to *jedyna* różnica między `sudo su` i `su`.\n\n**Odpowiedź 2:**\n\"sudo su moze wymagac podania hasla biezacego uzytkownika, su natomiast root'a\" jest **poprawna**. `sudo su` najpierw poprosi o hasło użytkownika wykonującego to polecenie, a następnie hasła użytkownika root (ponieważ sudo wywołuje su bez podania argumentu czyli z domyślnym przełączeniem na root). Natomiast samo `su` domyślnie zażąda hasła root. Jest to kluczowa różnica w sposobie uwierzytelniania tych dwóch poleceń. Przykładowo: w systemie Linux z zainstalowanym poleceniem `sudo`, wpisanie `su` po prostu zażąda hasła root. Jeśli jednak wpiszemy `sudo su` , to po wpisaniu hasła bieżącego użytkownika system *jeszcze raz* zapyta o hasło, ale już hasło roota, bo tego wymaga `su` uruchomione przez `sudo`.\n\n**Odpowiedź 3:**\n\"su bedzie wymagac podania hasla biezacego uzytkownika, sudo su natomiast root'a\" jest **niepoprawna**, ponieważ odwraca rolę, jeśli chodzi o to jakie hasło jest wymagane przy `su` a jakie przy `sudo su`.\n\n**Odpowiedź 4:**\n\"nie ma zadnej roznicy, sudo su jest aliasem na su OpenVPN\" jest **niepoprawna**, gdyż `sudo su` to oddzielne polecenie a nie alias i ma inną funkcjonalność. Nie jest też prawdą, że dotyczy to openvpn, tylko ogólnie systemu operacyjnego."
    },
    {
        "questionId": 309,
        "title": "Ktore konfiguracje tuneli obsluguje system OpenVPN: ",
        "answers": [
            {
                "text": "1 do wielu przy uwierzytelnianiu poprzez wspolny klucz",
                "isCorrect": true
            },
            {
                "text": "1 do 1 przy uwierzytelnianiu poprzez certyfikaty X.509",
                "isCorrect": true
            },
            {
                "text": "1 do 1 przy uwierzytelnianiu poprzez wspolny klucz",
                "isCorrect": false
            },
            {
                "text": "1 do wielu przy uwierzytelnianiu poprzez certyfikaty X.509",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "OpenVPN to elastyczne oprogramowanie VPN, które obsługuje różne konfiguracje tuneli w zależności od użytej metody uwierzytelniania. Uwierzytelnianie to proces weryfikacji tożsamości użytkownika lub urządzenia. Metoda uwierzytelniania wpływa na to, jak wiele stron może być jednocześnie podłączonych do tunelu VPN.\n\n* **Uwierzytelnianie poprzez współdzielony klucz:** W tym przypadku, obie strony tunelu VPN (klient i serwer) używają tego samego tajnego klucza do uwierzytelnienia. Jest to prostsza metoda, ale ma ograniczenia w zakresie skalowalności i dystrybucji klucza.\n * **Poprawna odpowiedź „1 do wielu przy uwierzytelnianiu poprzez wspólny klucz”:** OpenVPN może być skonfigurowany do obsługi wielu klientów łączących się z jednym serwerem z użyciem współdzielonego klucza. Jednakże, współdzielenie tego samego klucza między wieloma użytkownikami stanowi potencjalne zagrożenie bezpieczeństwa, ponieważ kompromitacja klucza przez jednego użytkownika naraża całą grupę. W praktyce wykorzystywane jest to przy tworzeniu niezbyt złożonych i małych sieci VPN w których nie przewiduje się przyszłego zwiększenia liczby użytkowników.\n  * **Niepoprawna odpowiedź „1 do 1 przy uwierzytelnianiu poprzez wspólny klucz”:** Chociaż połączenie jeden-do-jednego jest możliwe przy współdzielonym kluczu, to nie jest to jedyne możliwe rozwiązanie. Mechanizm współdzielenia klucza nie narzuca z góry jednego klienta, a można udostępnić ten sam klucz większej liczbie użytkowników.\n  * **Poprawna odpowiedź „1 do 1 przy uwierzytelnianiu poprzez certyfikaty X.509”:** OpenVPN umożliwia tworzenie tuneli VPN jeden-do-jednego przy użyciu certyfikatów X.509, gdzie każdy klient posiada swój własny certyfikat, a serwer również swój certyfikat oraz zna publiczny klucz klienta, lub listę zaufanych urzędów certyfikacji (CA). Ta metoda jest bezpieczniejsza, ponieważ każdy klient posiada swój własny tajny klucz i jest identyfikowany osobno. W praktyce jest to dobre rozwiązanie dla połączeń VPN typu \"host-to-host\" oraz \"host-to-net\".\n *  **Niepoprawna odpowiedź „1 do wielu przy uwierzytelnianiu poprzez certyfikaty X.509”:** Certyfikaty X.509 zostały opracowane w taki sposób, aby każdy podmiot posiadał własny certyfikat do identyfikacji. Uwierzytelnianie oparte o certyfikaty, choć bezpieczniejsze od metody opartej o współdzielony klucz, jest z reguły używane w połączeniach typu punkt-punkt. Zastosowanie certyfikatów w konfiguracji jeden-do-wielu jest możliwe, aczkolwiek znacznie komplikuje proces zarządzania dostępem do zasobów. Jest to możliwe jedynie poprzez centralne zarządzenie certyfikatami wszystkich klientów i wykorzystywanie technologii znanej jako „Certificate Revocation List”(CRL).\n\n**Konkretne Przykłady:**\n\n*   **Shared Key (1-to-many):** Firma ma oddział z 5 pracownikami, którzy potrzebują zdalnego dostępu do zasobów firmy. Używają OpenVPN z jednym współdzielonym kluczem. W tym przypadku, wszyscy pracownicy łączą się do jednego serwera używając tego samego klucza, a więc istnieje zwiększone ryzyko kompromitacji klucza.\n*  **X.509 Certificates (1-to-1):** Bank łączy się z serwerem giełdowym. Używają OpenVPN z certyfikatami X.509, gdzie bank i giełda posiadają swoje certyfikaty wydane przez zaufane centrum certyfikacji. Mechanizm ten ułatwia wzajemne rozpoznanie się, i jest stosowany głównie dla dedykowanych połączeń. W praktyce z użyciem OpenVPN oraz mechanizmu certyfikatów jest budowanych wiele tuneli punkt-punkt.\n\n**Podsumowanie:** OpenVPN zapewnia elastyczność konfiguracji sieci VPN, pozwalając na różne konfiguracje tuneli w zależności od potrzeb. Uwierzytelnianie współdzielonym kluczem jest łatwiejsze do skonfigurowania, ale mniej bezpieczne i skalowalne niż uwierzytelnianie z użyciem certyfikatów. Certyfikaty X.509 oferują lepsze bezpieczeństwo i skalowalność, ale wiążą się z większą złożonością konfiguracji. Wybór odpowiedniej metody zależy od specyficznych wymagań środowiska sieciowego."
    },
    {
        "questionId": 310,
        "title": "Wskaz elementy konfiguracji klienta ssh niezbedne do uwierzytelnienia bez koniecznosci interakcji z uzytkownikiem: ",
        "answers": [
            {
                "text": "klucz publiczny uzytkownika musi zostac dopisany do pliku authorized_keys w wezle docelowym",
                "isCorrect": true
            },
            {
                "text": "klucz prywatny uzytkownika musi zostac dopisany do pliku authorized_keys w wezle docelowym",
                "isCorrect": false
            },
            {
                "text": "w lokalnym pliku known_hosts zapisany musi byc klucz publiczny docelowego wezla",
                "isCorrect": true
            },
            {
                "text": "w lokalnym katalogu .ssh znajdowac sie musi klucz prywatny docelowego wezla",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) umożliwia bezpieczne połączenie zdalne, ale jego użycie bez interakcji użytkownika wymaga odpowiedniej konfiguracji opartej na kryptografii asymetrycznej. Klucz publiczny i klucz prywatny tworzą parę, gdzie klucz publiczny może być udostępniany (np. klientowi), natomiast klucz prywatny musi być zawsze przechowywany w tajemnicy.\nW celu umożliwienia uwierzytelnienia bez konieczności podawania hasła na kliencie SSH, należy poprawnie skonfigurować te klucze na obu końcach połączenia.\n\n**Poprawna odpowiedź 1:** „klucz publiczny uzytkownika musi zostac dopisany do pliku authorized\\_keys w wezle docelowym” - Jest to **poprawna** konfiguracja. Aby klient mógł zalogować się bez hasła, jego klucz *publiczny* musi być dodany do pliku `~/.ssh/authorized_keys` na serwerze (węźle docelowym), w koncie użytkownika, z którego logowanie ma być wykonywane. Każdy klucz publiczny w tym pliku, uprawnia odpowiadający mu klucz prywatny do logowania do tego konta bez podania hasła.  Klucz publiczny służy do *weryfikacji* tożsamości klienta, potwierdzając że tylko posiadacz *odpowiedniego* klucza prywatnego(którego nigdy nie wysyłamy przez sieć) ma uprawnienia logowania.\n\n**Niepoprawna odpowiedź 2:** „klucz prywatny uzytkownika musi zostac dopisany do pliku authorized\\_keys w wezle docelowym” - Jest to **niepoprawna** konfiguracja. Klucz prywatny *nigdy* nie powinien być przesyłany ani przechowywany na serwerze, ponieważ narażałoby to serwer na poważne niebezpieczeństwo. Klucz prywatny *musi być* przechowywany w tajemnicy i tylko u właściciela klucza. W pliku `authorized_keys` umieszczamy *tylko* klucze publiczne użytkowników, którym chcemy dać możliwość logowania się bez hasła. \n\n**Poprawna odpowiedź 3:** „w lokalnym pliku known\\_hosts zapisany musi byc klucz publiczny docelowego wezla” - Jest to **poprawna** konfiguracja. Plik `~/.ssh/known_hosts` jest umieszczony w lokalnym systemie. Przechowywane są w nim klucze publiczne serwerów (węzłów zdalnych) do których logowaliśmy się, co pozwala na weryfikację tożsamości serwera. Przy kolejnym połączeniu z serwerem klient sprawdza czy przesłany klucz publiczny serwera jest taki sam, jak zapamiętany w pliku `known_hosts`. Jeżeli klucze się różnią, klient ostrzega przed potencjalnym atakiem \"man-in-the-middle\". Zapisany klucz publiczny serwera w tym pliku pomaga również wyeliminować problem pierwszego połączenia z nowym serwerem (gdy nie mamy jeszcze klucza publicznego i ostrzeżenie o braku klucza może mylnie zasugerować, iż atak ma miejsce, gdy sytuacja jest całkiem normalna).\n\n**Niepoprawna odpowiedź 4:** „w lokalnym katalogu .ssh znajdowac sie musi klucz prywatny docelowego wezla” - Jest to **niepoprawna** konfiguracja. Klucz prywatny *serwera* nie powinien znajdować się u klienta. Przechowywanie klucza prywatnego serwera na kliencie jest niebezpieczne i niepotrzebne. Klient potrzebuje tylko klucza *publicznego* serwera, aby potwierdzić, że serwer, z którym się łączy, to na pewno ten, za którego się podaje. Klucz *prywatny* serwera służy tylko *serwerowi* do deszyfrowania wiadomości zaszyfrowanych jego kluczem publicznym i nie jest wymagany na kliencie do nawiązania bezpiecznego połączenia. \n\nNa przykładzie, wyobraźmy sobie administratora systemu, który chce mieć możliwość bezhasłowego logowania na serwer `serwer1.example.com` z lokalnego komputera. \n1.  Administrator generuje parę kluczy na swoim komputerze (`ssh-keygen`): klucz publiczny i prywatny.\n2.  Klucz publiczny zostaje dodany do `~/.ssh/authorized_keys` na `serwer1.example.com` w profilu użytkownika, z którego logowanie ma się odbywać.\n3.  Klucz publiczny serwera `serwer1.example.com` zostanie zapisany automatycznie w `~/.ssh/known_hosts` na komputerze administratora w trakcie pierwszego, interakcyjnego połączenia z tym serwerem.\n4. Od tej chwili administrator może logować się na `serwer1.example.com` ze swojego komputera bez podawania hasła.\nTen przykład obrazuje, jak klucze publiczne i prywatne współpracują, aby zapewnić bezpieczne uwierzytelnianie bez hasła."
    },
    {
        "questionId": 311,
        "title": "Definicji zaufania (single-sign-on) dla uslug rgwiazdka mbozna dokonywac w: ",
        "answers": [
            {
                "text": "~/.rhosts",
                "isCorrect": true
            },
            {
                "text": "/etc/rhosts",
                "isCorrect": false
            },
            {
                "text": "~/.sso_hosts",
                "isCorrect": false
            },
            {
                "text": "/etc/hosts.allow",
                "isCorrect": false
            },
            {
                "text": "/etc/hosts.equiv",
                "isCorrect": true
            },
            {
                "text": "/etc/hosts",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Uwierzytelnianie w usługach typu r (rlogin, rsh, rcp) często opiera się na koncepcji zaufania (single sign-on), gdzie użytkownik na jednym komputerze może uzyskać dostęp do zasobów innego komputera bez ponownego podawania hasła. Ten proces opiera się na konfiguracjach określających, które hosty są zaufane.\n\n*   **~/.rhosts:** Jest to poprawna odpowiedź. Plik ten, znajdujący się w katalogu domowym użytkownika, umożliwia zdefiniowanie, które zdalne hosty (a także użytkownicy na tych hostach) mogą logować się na konto lokalne użytkownika bez podawania hasła. Jest to mechanizm osobistego zaufania, stosowany w przypadku usług typu \"r\". Na przykład, jeśli użytkownik \"ala\" na komputerze \"local\" ma wpis na swoim ~/.rhosts taki jak `zdalny.example.com`, to użytkownik \"ala\" z komputera \"zdalny.example.com\" może zalogować się na konto \"ala\" na komputerze \"local\" używając rlogin bez podawania hasła. Konkretny użytkownik sam decyduje o tym, którym systemom zdalnym ufa.\n\n*   **/etc/rhosts:** Jest to niepoprawna odpowiedź. Plik o tej nazwie nie jest używany przez usługi r. Studenci mogą mylnie myśleć, że istnieje odpowiednik pliku ~/.rhosts dla konfiguracji globalnej.\n\n*   **~/.sso_hosts:** Jest to niepoprawna odpowiedź. Plik o tej nazwie nie istnieje i nie jest używany do konfigurowania zaufania dla usług typu r. Studenci mogą mylnie zakładać istnienie jakiegoś standardowego pliku związanego z mechanizmem Single Sign-On.\n\n*   **/etc/hosts.allow:** Jest to niepoprawna odpowiedź. Plik ten jest używany przez `tcpd` (TCP Wrappers) do kontrolowania dostępu do usług sieciowych na poziomie adresów IP i portów, a nie do określania zaufania dla usług r. Przykład użycia: `sshd : 192.168.1.0/24 : allow` zezwala tylko na ruch ssh z sieci 192.168.1.0/24 na poziomie IP.\n\n*   **/etc/hosts.equiv:** Jest to poprawna odpowiedź. Plik ten, dostępny w całym systemie, umożliwia administratorowi zdefiniowanie, które zdalne hosty są domyślnie zaufane przez wszystkich użytkowników w systemie dla usług typu \"r\". Jeśli na komputerze \"local\" w pliku `/etc/hosts.equiv` jest wpisane `zdalny.example.com`, to każdy użytkownik z komputera `zdalny.example.com` może zalogować się na swoje konto na komputerze `local` przy użyciu rlogin bez podawania hasła. Daje to administratorowi kontrolę nad tym, którym hostom cała instalacja ufa, z pewnym osłabieniem bezpieczeństwa, bo nie wymusza konieczności podawania hasła.\n\n*   **/etc/hosts:** Jest to niepoprawna odpowiedź. Plik ten służy głównie do mapowania nazw hostów na adresy IP i nie ma nic wspólnego z konfiguracją zaufania dla usług r. Zapis typu `127.0.0.1 localhost` pozwala komputerowi na odniesienie się do samego siebie, poprzez domenę `localhost`.\n\nTe pliki (`~/.rhosts`, `/etc/hosts.equiv`) stanowią historyczne mechanizmy zaufania, które często są podatne na ataki i obecnie nie są uznawane za najlepsze praktyki bezpieczeństwa. W nowoczesnych systemach, usługi r są zastępowane przez bezpieczniejsze alternatywy, takie jak SSH, które wykorzystują klucze kryptograficzne. Jednak zrozumienie działania tych starszych metod może pomóc w diagnozowaniu problemów w starszych systemach lub zrozumieniu historycznych uwarunkowań w dziedzinie bezpieczeństwa systemów komputerowych."
    },
    {
        "questionId": 312,
        "title": "W jaki sposob przebiega uwierzytelnianie w usludze rlogin: ",
        "answers": [
            {
                "text": "uwierzytelnienie obu stron polaczenia nastepuje mechanizmem Challenge-Response",
                "isCorrect": false
            },
            {
                "text": "zawsze wymagane jest uwierzytelnianie bez hasla",
                "isCorrect": false
            },
            {
                "text": "mozliwe jest wykorzystanie SSO by nie podawac hasla",
                "isCorrect": true
            },
            {
                "text": "zawsze wymagane jest haslo",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół `rlogin` (remote login) służy do zdalnego logowania do systemów operacyjnych Linux/Unix. Standardowo, uwierzytelnianie w `rlogin` nie używa mechanizmu challenge-response. Polega ono na przesłaniu hasła w postaci jawnej. Jednakże system `rlogin` posiada możliwość konfiguracji tak zwanej domeny zaufania, w której można wykorzystać uwierzytelnianie jednokrotne (_Single Sign-On_, SSO). \nTa funkcjonalność pozwala na pominięcie pytania o hasło przy logowaniu do systemu zdalnego jeśli wcześniej zostało wykonane logowanie na zaufanym komputerze.\n\n* **\"uwierzytelnienie obu stron polaczenia nastepuje mechanizmem Challenge-Response\"**\n    - Ta odpowiedź jest **niepoprawna**.  Uwierzytelnianie w usłudze `rlogin` domyślnie nie korzysta z mechanizmu _challenge-response_. Mechanizm _challenge-response_ polega na tym, że serwer wysyła losowe wyzwanie, na które klient musi odpowiedzieć przy użyciu hasła i funkcji kryptograficznej. W przypadku `rlogin`, domyślne uwierzytelnianie polega na przesłaniu hasła w postaci jawnej (co czyni go bardzo podatnym na ataki typu _man-in-the-middle_). Chociaż SSH (Secure Shell) używa _challenge-response_, a w szczególnych przypadkach `rlogin` może użyć _Kerberos_, to nie jest to domyślne i standardowe zachowanie usługi `rlogin`.\n\n* **\"zawsze wymagane jest uwierzytelnianie bez hasla\"**\n    - Ta odpowiedź jest **niepoprawna**. Nie jest to prawdą, gdyż domyślnie wymagane jest hasło. Uwierzytelnianie bez hasła może być osiągnięte tylko poprzez specjalną konfigurację, na przykład używając zaufanej listy hostów.\n\n*  **\"mozliwe jest wykorzystanie SSO by nie podawac hasla\"**\n    - Ta odpowiedź jest **poprawna**. System `rlogin` wspiera jednokrotne uwierzytelnianie (SSO), co pozwala uniknąć podawania hasła, jeśli dostęp do konta użytkownika jest uzyskiwany z zaufanego komputera.  Mechanizm ten opiera się na plikach `/etc/hosts.equiv` i `~/.rhosts`. Jeśli klient logujący się za pomocą `rlogin` jest zaufany dla serwera, to serwer nie zażąda podania hasła. Zaufanie jest nawiązywane poprzez wpisanie nazwy hosta w systemowym pliku `/etc/hosts.equiv` lub indywidualnym pliku użytkownika `~/.rhosts`. Np.: jeśli na komputerze `local` użytkownik `michal` ma w swoim pliku `~/.rhosts` wpis `\"remote\"`, to gdy z komputera `remote` loguje się użytkownik `michal`, serwer `local` nie poprosi go o hasło, gdyż zaufa komputerowi `remote` w kwestii autentyczności użytkownika. Podobny mechanizm działa, gdy w pliku `/etc/hosts.equiv` na serwerze `local` widnieje nazwa komputera `remote`. SSO to mechanizm pozwalający użytkownikom na korzystanie z różnych usług bez konieczności wielokrotnego wpisywania hasła, a to zwiększa wygodę i w pewnym sensie również bezpieczeństwo. Zamiast zapamiętywać wiele haseł, użytkownik musi pamiętać jedynie hasło do hosta, który jest \"twierdzą\", czyli hostem pośredniczącym w uwierzytelnianiu.\n\n* **\"zawsze wymagane jest haslo\"**\n    - Ta odpowiedź jest **niepoprawna**. Nie jest to prawdą, gdyż domyślnie wymagane jest hasło, jednak można to ominąć konfigurując mechanizm zaufania.\n\nPodsumowując, choć domyślnie `rlogin` wymaga hasła, to koncepcja zaufanych hostów pozwala na pominięcie tej procedury poprzez mechanizm SSO. Należy jednak pamiętać o zagrożeniach związanych z tą opcją.  Użycie `rlogin` w większości systemów operacyjnych jest wyłączona, gdyż jest to usługa stwarzająca poważne zagrożenia bezpieczeństwa. Lepszą alternatywą dla `rlogin` jest `ssh`, które domyślnie wspiera kryptografie i oferuje dużo bezpieczniejszą transmisje."
    },
    {
        "questionId": 313,
        "title": "Udzial C$ jest to: ",
        "answers": [
            {
                "text": "udzial domyslny kontrolera domeny sluzacy do obslugi logowania w sieci",
                "isCorrect": false
            },
            {
                "text": "udzial sluzacy do dostepu do dysku C w celach zdalnej administracji",
                "isCorrect": true
            },
            {
                "text": "udzial komunikacji miedzyprocesowej w systemie operacyjnym",
                "isCorrect": false
            },
            {
                "text": "udzial do komunikacji IPsec",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Udostępnienie administracyjne C$ w systemach Windows jest mechanizmem automatycznie tworzonym przez system, umożliwiającym zdalny dostęp do dysku C komputera. Te ukryte udziały, oznaczone znakiem '$' na końcu nazwy, nie są widoczne w normalnym przeglądaniu udostępnionych zasobów, a ich głównym celem jest ułatwienie zdalnego zarządzania systemem. Dostęp do nich posiadają domyślnie jedynie użytkownicy z uprawnieniami administratora.\n\n* **\"udzial domyslny kontrolera domeny sluzacy do obslugi logowania w sieci\"** - Jest to **niepoprawna** odpowiedź. Udziały C$ nie są związane bezpośrednio z kontrolerem domeny i nie służą do obsługi procesu logowania w sieci. Udostępnienia administracyjne działają niezależnie od tego czy serwer jest kontrolerem domeny czy też nie. Uwierzytelnianie przy dostępie do udziału C$ opiera się o lokalną bazę kont użytkowników. \n\n* **\"udzial sluzacy do dostepu do dysku C w celach zdalnej administracji\"** - To jest **poprawna** odpowiedź. Udział C$ jest faktycznie tworzony automatycznie przez system Windows, aby administratorzy mogli zdalnie uzyskać dostęp do dysku C serwera. Ułatwia to zdalne wykonywanie zadań administracyjnych. Przykładowo, administrator z innego komputera może zdalnie przeglądać pliki na dysku C, uruchamiać aplikacje lub instalować aktualizacje. Jest to często stosowane, a brak takiej możliwości może znacznie utrudnić zarządzanie rozproszonym środowiskiem sieciowym.\n\n* **\"udzial komunikacji miedzyprocesowej w systemie operacyjnym\"** - Jest to **niepoprawna** odpowiedź. Udział C$ nie służy do komunikacji między procesami w systemie operacyjnym. Komunikacja międzyprocesowa to mechanizm komunikacji pomiędzy aplikacjami działającymi na jednym systemie operacyjnym w celu przesyłania informacji między nimi a C$ jest udostępnieniem danych dla celów zdalnego administracji. Udostępnienie C$ wykorzystuje protokół SMB(ang. Server Message Block) do udostępniania zasobów sieciowych.\n\n* **\"udzial do komunikacji IPsec\"** - To jest **niepoprawna** odpowiedź. Udział C$ nie ma żadnego związku z protokołem IPsec, który służy do ustanawiania bezpiecznych połączeń VPN(ang. Virtual Private Network) szyfrując cały ruch sieciowy, natomiast C$ wykorzystuje protokół SMB i nie szyfruje przesyłanych danych, z wyjątkiem sytuacji w której do udostępniania zasobu wykorzystywany jest protokół TLS/SSL, jednak w takim przypadku protokół TLS/SSL chroni ruch całego protokołu SMB a nie tylko C$. \n\nPodsumowując, C$ jest udostępnieniem domyślnym, służącym do zdalnego dostępu do dysku C. Jego celem jest zdalne zarządzanie serwerem i ułatwienie pracy administratorom. Nie jest natomiast związane z uwierzytelnianiem domenowym, komunikacją międzyprocesową, ani protokołem IPsec. Należy pamiętać, że niepoprawnie skonfigurowane udostępnienie C$ jest poważną luką bezpieczeństwa."
    },
    {
        "questionId": 314,
        "title": "Jaka jest kolejnosc sprawdzania regul w plikach hosts.deny hosts.allow: ",
        "answers": [
            {
                "text": "jesli znajdzie sie najpierw dopasowanie w deny to allow w ogole nie jest sprawdzane",
                "isCorrect": false
            },
            {
                "text": "najpierw deny do pierwszego dopasowania",
                "isCorrect": false
            },
            {
                "text": "najpierw allow do pierwszego dopasowania",
                "isCorrect": true
            },
            {
                "text": "jesli znajdzie sie najpierw dopasowanie w allow to deny w ogole nie jest sprawdzane",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Program `tcpd` (TCP wrappers) wykorzystuje pliki `hosts.allow` i `hosts.deny` do kontrolowania dostępu do usług sieciowych na podstawie adresu IP lub nazwy hosta klienta. Mechanizm ten działa na zasadzie „pierwsze dopasowanie wygrywa” - *first match wins*, co oznacza że jeśli pakiet pasuje do reguły to nie jest już sprawdzany przez pozostałe reguły.\n\nW celu udzielenia lub odmówienia dostępu, `tcpd` *najpierw* sprawdza plik `/etc/hosts.allow`. W tym pliku znajdują się definicje adresów IP lub nazw hostów, które *mają* prawo korzystać z określonych usług.  Jeśli pakiet pasuje do którejkolwiek z reguł w `/etc/hosts.allow`, dostęp zostaje przyznany i dalsze reguły nie są już analizowane - system `hosts.deny` nie jest sprawdzany. \nNa przykład, jeśli w pliku `/etc/hosts.allow` znajduje się reguła `sshd: 192.168.1.0/24` oznacza to, że każda próba dostępu do usługi ssh z adresów z zakresu 192.168.1.0/24 zostanie zaakceptowana bez sprawdzania pliku `/etc/hosts.deny`.\n\nJeśli pakiet nie pasuje do *żadnej* reguły w `/etc/hosts.allow`,  wówczas `tcpd` *dopiero* sprawdza plik `/etc/hosts.deny`. W tym pliku znajdują się definicje adresów IP lub nazw hostów, które mają *zakaz* korzystania z określonych usług.  Jeśli pakiet pasuje do reguły z pliku  `/etc/hosts.deny` dostęp zostaje zablokowany i dalsze reguły nie są analizowane. \nNa przykład, jeśli w pliku `/etc/hosts.deny` znajduje się reguła `sshd: ALL`, wówczas jakakolwiek próba nawiązania połączenia z usługą `sshd` z jakiegokolwiek adresu zostanie zablokowana.\n\nW przypadku, gdy nie wystąpi dopasowanie w pliku `/etc/hosts.allow` oraz `/etc/hosts.deny`, to dostęp jest przyznawany domyślnie.\n\n*   **Odpowiedź 1: \"jesli znajdzie sie najpierw dopasowanie w deny to allow w ogole nie jest sprawdzane\"** - **Niepoprawna.** Dopasowanie w deny występuje tylko wtedy, gdy w allow nie ma dopasowania. A nawet, gdyby jakimś cudem doszło do dopasowania w deny, to i tak nie ma znaczenia czy allow będzie sprawdzone czy nie ponieważ jeśli doszło do dopasowania w deny to dostęp nie jest przyznawany niezależnie co znajduje się w pliku allow.\n*   **Odpowiedź 2: \"najpierw deny do pierwszego dopasowania\"** - **Niepoprawna.** `tcpd` sprawdza `hosts.deny` tylko wtedy, gdy pakiet nie pasuje do żadnej reguły w `hosts.allow`.\n*   **Odpowiedź 3: \"najpierw allow do pierwszego dopasowania\"** - **Poprawna.** Jak opisano powyżej, `tcpd` najpierw sprawdza `/etc/hosts.allow` do pierwszego dopasowania, w takiej sytuacji proces sprawdzania `hosts.deny` nie będzie kontynuowany, gdyż proces sprawdzania został zatrzymany.\n*   **Odpowiedź 4: \"jesli znajdzie sie najpierw dopasowanie w allow to deny w ogole nie jest sprawdzane\"** - **Poprawna.** Jeśli pakiet pasuje do jakiejkolwiek reguły w pliku `/etc/hosts.allow`, system nie analizuje pliku `/etc/hosts.deny` i dostęp jest przyznawany.\n\n**Przykład:**\n\nZałóżmy, że plik `/etc/hosts.allow` zawiera regułę:\n`sshd: 192.168.1.0/24`\ni plik `/etc/hosts.deny` zawiera regułę:\n`sshd: 192.168.1.10`\n\nW tej sytuacji:\n*   Próba połączenia ssh z adresu 192.168.1.15 (który zawiera się w zakresie adresów 192.168.1.0/24) spowoduje *przyznanie* dostępu na podstawie reguły z `/etc/hosts.allow`, bez sprawdzania `/etc/hosts.deny`.\n*   Próba połączenia z adresu 192.168.1.10  zostanie dopasowana do reguły w `/etc/hosts.allow` i dostęp zostanie przyznany. Jeżeli reguła w allow by nie istniała dla takiego adresu to dostęp byłby zablokowany z uwagi na znalezienie dopasowania w pliku `/etc/hosts.deny`.\n\nTakie rozwiązanie, w którym to plik `allow` ma pierwszeństwo przed plikiem `deny` jest podyktowane tym, że w praktyce zazwyczaj określamy jakiego rodzaju pakiety mają być przepuszczone."
    },
    {
        "questionId": 315,
        "title": "Co mozna ustawic w zasadach kont w MS Windows: ",
        "answers": [
            {
                "text": "minimalna dlugosc nazwy uzytkownika",
                "isCorrect": false
            },
            {
                "text": "maksymalna dlugosc nazwy uzytkownika",
                "isCorrect": false
            },
            {
                "text": "minimalna dlugosc hasla",
                "isCorrect": true
            },
            {
                "text": "maksymalna dlugosc hasla",
                "isCorrect": false
            },
            {
                "text": "zlozonosc hasla",
                "isCorrect": true
            },
            {
                "text": "szyfrowanie AES",
                "isCorrect": false
            },
            {
                "text": "Minimalny czas waznosci hasla",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "W systemie Microsoft Windows, zasady kont (ang. *Account Policies*) to zbiór ustawień konfiguracyjnych, które pozwalają administratorom na kontrolę sposobu, w jaki użytkownicy uzyskują dostęp do systemu i jego zasobów. Jednym z podzbiorów tych ustawień są zasady haseł, które pozwalają wymuszać odpowiednie standardy siły haseł używanych przez użytkowników. \n\n*   **minimalna długość nazwy użytkownika**: To ustawienie **nie jest** dostępne w zasadach kont w MS Windows. Nazwy użytkowników są ustalane przy ich tworzeniu i nie podlegają ograniczeniom minimalnej długości z poziomu zasad haseł. Jest to oddzielna konfiguracja definiowana podczas tworzenia konta użytkownika. W praktyce, nazwa użytkownika nie ma bezpośredniego wpływu na bezpieczeństwo hasła.\n\n*   **maksymalna długość nazwy użytkownika**: To ustawienie również **nie jest** częścią zasad kont w MS Windows. Podobnie jak w poprzednim przypadku, długość nazwy użytkownika jest ustalana podczas tworzenia konta i nie jest kontrolowana przez zasady haseł. Zbyt długie nazwy mogą być niepraktyczne, ale nie są problemem bezpieczeństwa, który rozwiązują zasady haseł.\n\n*   **minimalna długość hasła**: To **poprawne** ustawienie w zasadach kont w MS Windows. Określa minimalną liczbę znaków, które musi zawierać hasło, aby zostało zaakceptowane przez system. Na przykład, ustawienie \"minimalna długość hasła\" na 8 znaków, zmusza użytkowników do tworzenia haseł o długości przynajmniej 8 znaków, co zwiększa ich odporność na ataki brute-force. W praktyce, im dłuższe hasło tym trudniej jest je złamać, dlatego rekomenduje się ustawianie co najmniej 12 znaków minimalnej długości.\n\n*   **maksymalna długość hasła**: To ustawienie **nie jest** dostępne w zasadach kont. Zamiast tego, konfiguruje się minimalną długość hasła i jego złożoność. Maksymalna długość hasła jest w zasadzie nieograniczona. Długie hasła są trudniejsze do zapamiętania i rzadziej stosowane przez użytkowników. System nie posiada mechanizmu wymuszającego maksymalną długość hasła.\n\n*   **złożoność hasła**: To **poprawne** ustawienie, które definiuje, jakie typy znaków (małe litery, wielkie litery, cyfry, znaki specjalne) są wymagane w haśle. Ustawienie wymogu złożoności hasła zmusza użytkowników do używania bardziej skomplikowanych haseł, które są odporne na ataki słownikowe i zwiększają czas potrzebny do ich złamania metodą brute-force. Bez tego mechanizmu użytkownicy mogą ustawiać proste hasła, na przykład „haslo123”. W praktyce ustawienie tej opcji w systemach produkcyjnych jest niezbędne do utrzymania odpowiedniego poziomu bezpieczeństwa.\n\n*  **szyfrowanie AES**: To **niepoprawne** ustawienie. Chociaż AES (Advanced Encryption Standard) jest algorytmem szyfrowania i jest wykorzystywane w systemie Windows do szyfrowania danych przechowywanych np. systemem EFS, to nie jest on stosowany w mechanizmach przechowywania lub weryfikacji haseł. Zamiast tego do skrótu hasła używana jest funkcja MD5 lub SHA oraz AES do szyfrowania klucza. Wybór algorytmu skrótu hasła nie jest udostępniony administratorom.\n\n*   **minimalny czas ważności hasła**: To **poprawne** ustawienie. Definiuje, jak długo hasło musi być używane zanim użytkownik będzie mógł je zmienić. To ustawienie minimalnego okresu ważności hasła, wymusza jego dłuższe używanie, co uniemożliwia użytkownikom ustawienie nowego i natychmiastowego powrotu do starego hasła. W praktyce utrudnia to omijanie wymogu złożoności hasła. Standardowo ustawia się minimum 2 dni ważności hasła.\n\nW praktyce wszystkie te ustawienia działają razem, aby zmusić użytkowników do używania silnych haseł, które są regularnie zmieniane. Im większe wymagania tym trudniej jest złamać hasła użytkowników."
    },
    {
        "questionId": 316,
        "title": "Czy maska uprawnien POSIX ACL jest definiowana dla kazdego uzytkownika osobno?: ",
        "answers": [
            {
                "text": "tak, z priorytetem maski domyslnej (logiczny AND)",
                "isCorrect": false
            },
            {
                "text": "nie, maske mozna zdefiniowac tylko dla grup uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "tak, jesli jawnie wskazemy nazwe uzytkownika",
                "isCorrect": false
            },
            {
                "text": "nie, istnieje tylko jedna obowiazujaca maska",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Maska uprawnień w POSIX ACL (Access Control List) to mechanizm kontroli dostępu, który definiuje *maksymalne* uprawnienia, jakie mogą zostać przyznane *jakimkolwiek* użytkownikom, grupom lub innym wpisom w ramach danej listy ACL dla konkretnego obiektu systemu plików (pliku lub katalogu). Nie jest to zatem mechanizm pozwalający na definiowanie uprawnień per-user lub per-group, ale raczej „ogranicznik” dozwolonej kombinacji uprawnień.\n\n**Poprawna odpowiedź:**\n*   **nie, istnieje tylko jedna obowiązująca maska.**  To jest poprawne. POSIX ACL używa pojedynczej maski, która działa jako filtr na *wszystkie* pozostałe wpisy ACL. Maska nie jest specyficzna dla żadnego użytkownika ani grupy, lecz jest *globalna* dla danego ACL. Określa maksymalne uprawnienia jakie można nadać danemu użytkownikowi czy grupie.  Na przykład, jeśli maska ma uprawnienia odczytu i zapisu, to wpis ACL, który próbuje nadać pełne uprawnienia (odczyt, zapis, wykonywanie) zostanie ograniczony przez maskę do odczytu i zapisu. Praktycznie oznacza to, że jeśli zdefiniujemy maskę uprawnień  jako \"rw-\", to żaden użytkownik (czy grupa) nie dostanie uprawnienia do wykonania pliku, nawet gdy jego wpis ACL *jawnie* zawiera takie uprawnienie.\n\n**Niepoprawne odpowiedzi:**\n*   **tak, z priorytetem maski domyślnej (logiczny AND).** To nie jest prawda, ponieważ istnieje tylko jedna maska, która ma zastosowanie do wszystkich rozszerzonych uprawnień. Maska domyślna odnosi się do ustawień dla nowo tworzonych obiektów, a nie do maski dla już istniejącego obiektu. Poza tym maska nie jest łączona z innymi uprawnieniami przy pomocy logicznego AND, a raczej działa jako \"filtr\" czy też \"ogranicznik\" dostępnych uprawnień\n*   **nie, maskę można zdefiniować tylko dla grup użytkowników.** To nie jest prawdą, ponieważ maskę w systemie POSIX ACL definiuje się raz dla konkretnego zasobu, a nie dla grup użytkowników. To, do kogo lista odnosi się na poziomie wpisów ACL (użytkownik lub grupa) to oddzielna kwestia i nie ma to związku z maską.\n*   **tak, jeśli jawnie wskażemy nazwę użytkownika.** To nie jest prawdą, ponieważ maska jest globalna dla całego ACL i ma zastosowanie do wszystkich wpisów, niezależnie od tego czy są to wpisy ogólne czy też dla konkretnych użytkowników. Nie można więc zdefiniować maski dla użytkownika wskazując jego imię (ang. username).\n\n**Przykład praktyczny:**\nZałóżmy, że dla pliku `dokument.txt` ustawiamy ACL z następującymi uprawnieniami:\n  * Właściciel: `wlasciciel` (odczyt, zapis, wykonywanie) - `rwx`\n  * Użytkownik: `kasia` (odczyt, zapis, wykonywanie) - `rwx`\n  * Grupa: `redaktorzy` (odczyt, zapis) - `rw-`\n  * Maska: `rw-`\n  * Inni: (odczyt) - `r--`\n\nW takim przypadku:\n*   `wlasciciel` otrzyma *efektywne* uprawnienia `rw-` (a nie rwx), gdyż maska obcina uprawnienie wykonywania `x`.\n*   `kasia` otrzyma *efektywne* uprawnienia `rw-` (a nie rwx) z tego samego powodu.\n*   `redaktorzy` otrzymają *efektywne* uprawnienia `rw-`.\n*   inni otrzymają  *efektywne* uprawnienia `r--`.\n\nMaska `rw-` ogranicza  dostęp do odczytu i zapisu do wszystkich, oprócz innych (oni mają dostęp tylko do odczytu). Maska jest jedna i wspólna dla wszystkich."
    },
    {
        "questionId": 317,
        "title": "Przeslanie i zweryfikowanie podpisanego cyfrowo listu w standardzie S/MIME od uzytkownika A do uzytkownika B wymaga: ",
        "answers": [
            {
                "text": "pozyskania przez uzytkownika B tajnego klucza symetrycznego od A",
                "isCorrect": false
            },
            {
                "text": "pozyskania przez B certyfikatu klucza publicznego A",
                "isCorrect": true
            },
            {
                "text": "pozyskania certyfikatow kluczy publicznych wzajemnie przez obu uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "pozyskania przez A certyfikatu klucza publicznego B",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Podpis cyfrowy w standardzie S/MIME wykorzystuje kryptografię asymetryczną. W tym modelu każdy użytkownik posiada dwie powiązane ze sobą wartości: klucz prywatny i klucz publiczny. Klucz prywatny jest znany tylko właścicielowi i służy do składania podpisu. Natomiast klucz publiczny jest dostępny dla każdego i służy do weryfikacji podpisu. Dodatkowo, w przypadku standardu S/MIME, klucz publiczny jest powiązany z tożsamością właściciela poprzez certyfikat cyfrowy. Certyfikat to podpisany cyfrowo dokument elektroniczny, który potwierdza, że klucz publiczny należy do określonego użytkownika. Wydawaniem certyfikatów zajmują się centra certyfikacji (CA).\n\n**Poprawna odpowiedź:** \"pozyskania przez B certyfikatu klucza publicznego A\"\n\nAby użytkownik B mógł zweryfikować podpis cyfrowy użytkownika A, użytkownik B potrzebuje **certyfikatu klucza publicznego A**. Klucz publiczny jest zawarty w certyfikacie, co pozwala użytkownikowi B na weryfikację podpisu, potwierdzając tożsamość użytkownika A i integralność listu.  Bez klucza publicznego A, w postaci certyfikatu, niemożliwa jest weryfikacja podpisu. Wykorzystanie certyfikatu, a nie samego klucza publicznego, pozwala ufać że ten klucz rzeczywiście należy do użytkownika A.\n\n**Niepoprawne odpowiedzi:**\n\n*   **\"pozyskania przez uzytkownika B tajnego klucza symetrycznego od A\"** \n    Ta odpowiedź odnosi się do szyfrowania symetrycznego, a nie do podpisywania cyfrowego. W podpisie cyfrowym, to nadawca (A) wykorzystuje swój klucz *prywatny* do podpisania wiadomości. Odbiorca (B) wykorzystuje klucz *publiczny* nadawcy, aby zweryfikować podpis, a nie klucz symetryczny, który jest tajny i nie jest wykorzystywany do podpisywania. Szyfrowanie symetryczne dotyczy ochrony poufności wiadomości. W S/MIME, dane są szyfrowane kluczem symetrycznym a klucz symetryczny jest szyfrowany kluczem publicznym adresata wiadomości.\n\n*   **\"pozyskania certyfikatow kluczy publicznych wzajemnie przez obu uzytkownikow\"**\n   Choć w praktyce użytkownicy często wymieniają się certyfikatami, to w przypadku weryfikacji *podpisu* cyfrowego, B musi *wyłącznie* dysponować certyfikatem A. Odbiorca B nie używa swojego klucza prywatnego do weryfikacji podpisu nadawcy A. Takie certyfikaty są potrzebne do *szyfrowania* wiadomości.  Do odszyfrowania wiadomości użytkownik B wykorzystuje swój klucz prywatny i do tego działania potrzebny jest certyfikat użytkownika B zawierający jego klucz publiczny, który został użyty do szyfrowania tajnego klucza szyfrującego list.\n\n*   **\"pozyskania przez A certyfikatu klucza publicznego B\"**\n    Użytkownik A potrzebuje klucza publicznego B, aby zaszyfrować wiadomość do B, ale nie do jej podpisania. Podpis cyfrowy tworzony jest za pomocą klucza prywatnego, który jest znany tylko A. Klucz publiczny B nie jest potrzebny do podpisania listu przez A. \n\n**Praktyczny przykład:**\nZałóżmy, że firma X wysyła fakturę do firmy Y. Firma X używa swój klucz prywatny aby podpisać cyfrowo fakturę.  Firma Y w swoim oprogramowaniu pocztowym używa certyfikatu publicznego firmy X aby zweryfikować podpis i potwierdzić że faktura rzeczywiście pochodzi od firmy X i nie była po drodze modyfikowana. Certyfikat publiczny firmy Y nie ma nic wspólnego z tą procedurą."
    },
    {
        "questionId": 318,
        "title": "Szyfrowanie symetryczne plikow mechanizmem EFS systemu NTFS: ",
        "answers": [
            {
                "text": "moze byc realizowane po zainstalowaniu dodatkowego oprogramowania DRA",
                "isCorrect": false
            },
            {
                "text": "moze byc realizowane pod warunkiem posiadania przez uzytkownika certyfikatu klucza publicznego",
                "isCorrect": true
            },
            {
                "text": "szyfruje pliki uzytkownika jego kluczem prywatnym",
                "isCorrect": false
            },
            {
                "text": "nie jest realizowane przez system operacyjny starszy niz Windows 10",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfrowanie symetryczne w kontekście systemu plików EFS (Encrypting File System) w NTFS (New Technology File System) polega na wykorzystaniu jednego klucza do szyfrowania i deszyfrowania danych. EFS, będący integralną częścią systemów operacyjnych Microsoft Windows, zapewnia ochronę danych na poziomie plików i folderów poprzez ich szyfrowanie. Proces ten nie wykorzystuje bezpośrednio klucza prywatnego użytkownika do szyfrowania treści pliku. Zamiast tego EFS generuje losowy klucz symetryczny, który jest następnie wykorzystywany do szyfrowania zawartości pliku. Klucz symetryczny jest chroniony poprzez jego zaszyfrowanie przy pomocy klucza publicznego zawartego w certyfikacie użytkownika. W procesie deszyfrowania użytkownik posługuje się swoim kluczem prywatnym, który pozwala na odszyfrowanie klucza symetrycznego, a następnie odszyfrowanie zawartości pliku.\n\nOpcja **\"moze byc realizowane po zainstalowaniu dodatkowego oprogramowania DRA\"** jest **nieprawidłowa**. Mechanizm EFS jest wbudowany w systemy operacyjne MS Windows oparte na architekturze NT (Windows 2000, XP, Vista, 7, 8, 10 i nowsze) i nie wymaga dodatkowego oprogramowania do podstawowego szyfrowania. DRA (Data Recovery Agent) jest opcjonalnym mechanizmem i  polega na wyznaczeniu  dodatkowego konta uprzywilejowanego, którego klucz publiczny jest wykorzystany  dodatkowo  do zaszyfrowania klucza symetrycznego. Jest to mechanizm odzyskiwania danych, na wypadek gdyby użytkownik zgubił swój klucz. Jest to opcja, którą można skonfigurować, ale nie jest konieczna do podstawowej operacji szyfrowania pliku.\n\nOpcja **\"moze byc realizowane pod warunkiem posiadania przez uzytkownika certyfikatu klucza publicznego\"** jest **prawidłowa**. Aby mechanizm szyfrowania EFS mógł zabezpieczyć pliki,  użytkownik musi posiadać certyfikat zawierający jego klucz publiczny. Ten certyfikat jest używany do zaszyfrowania losowo wygenerowanego klucza symetrycznego, którym szyfrowana jest treść pliku. Praktycznie oznacza to, że proces szyfrowania  opiera się o wykorzystanie certyfikatu do ochrony klucza symetrycznego, a nie bezpośrednio do szyfrowania pliku.  Certyfikat użytkownika jest jak cyfrowa wizytówka, która poświadcza jego tożsamość oraz klucz publiczny wykorzystywany do zaszyfrowania klucza symetrycznego. \n\nOpcja **\"szyfruje pliki uzytkownika jego kluczem prywatnym\"** jest **nieprawidłowa**.  EFS nie używa klucza prywatnego użytkownika do samego szyfrowania plików. Jak wspomniano na początku  do szyfrowania plików  używa losowo generowany  klucz symetryczny, a klucz prywatny jest wykorzystywany tylko do odszyfrowania wcześniej zaszyfrowanego klucza symetrycznego. Klucz prywatny użytkownika nigdy nie jest używany bezpośrednio do szyfrowania danych,  służy  jedynie do odszyfrowania klucza symetrycznego.\n\nOpcja **\"nie jest realizowane przez system operacyjny starszy niz Windows 10\"** jest **nieprawidłowa**. EFS jest dostępny od systemu Windows 2000 do najnowszych wydań systemu Windows. System Windows 10 nie jest pierwszym systemem w którym EFS jest dostępny, technologia ta istniała już wcześniej.\n\nPodsumowując, EFS to system szyfrowania symetrycznego oparty o infrastrukturę klucza publicznego. Do szyfrowania danych używany jest klucz symetryczny. Bezpieczeństwo tego klucza jest oparte o klucz publiczny z certyfikatu użytkownika. Użytkownik natomiast do odszyfrowania klucza symetrycznego używa swój klucz prywatny."
    },
    {
        "questionId": 319,
        "title": "Mechanizm impersonation systemu Windows: ",
        "answers": [
            {
                "text": "jest wykorzystywany przez polecenie <code>runas</code>",
                "isCorrect": true
            },
            {
                "text": "pozwala zdefiniowac dla uzytkownika inna nazwe wyswietlana (np. imie i nazwisko) niz nazwe konta",
                "isCorrect": false
            },
            {
                "text": "definiuje 5 dodatkowych poziomow kontroli dostepu do danych i procesow",
                "isCorrect": false
            },
            {
                "text": "pozwala procesowi uzyc chwilowo innego niz biezacy tokenu zabezpieczen",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Impersonacja w systemie Windows to mechanizm, który pozwala procesowi (aplikacji) tymczasowo przyjąć tożsamość innego użytkownika lub innego konta (ang. _security principal_). W systemie Windows, tożsamość jest reprezentowana przez token zabezpieczeń (ang. _access token_), który zawiera informacje o użytkowniku, jego uprawnieniach oraz o członkostwie w grupach.  Gdy proces wykonuje się bez impersonacji, działa on z uprawnieniami użytkownika, który go uruchomił. W sytuacji gdy proces działa z uprawnieniami innego użytkownika - impersonuje innego użytkownika. Mechanizm ten pozwala na wykonywanie operacji, do których dany użytkownik zazwyczaj nie ma dostępu.\n\nOpcja pierwsza \"jest wykorzystywany przez polecenie `runas`\" jest **poprawna**. Polecenie `runas` w systemie Windows służy właśnie do uruchamiania procesów z uprawnieniami innego użytkownika. Wykonanie polecenia `runas /user:administrator program.exe` powoduje uruchomienie programu `program.exe` w kontekście użytkownika `administrator`, co jest właśnie przykładem impersonacji. To polecenie ma szerokie zastosowanie w administracji systemem, umożliwiając użytkownikowi o ograniczonych uprawnieniach wykonywanie zadań wymagających wyższych uprawnień (na przykład uruchamianie aplikacji administracyjnych)\n\nOpcja druga \"pozwala zdefiniować dla użytkownika inną nazwę wyświetlaną (np. imię i nazwisko) niż nazwę konta\" jest **niepoprawna**. Mechanizm impersonacji nie zmienia nazwy wyświetlanej użytkownika, a jedynie token zabezpieczeń procesu. Informacje o wyświetlanej nazwie, są przechowywane w innych miejscach (np. w Active Directory), i nie są zmieniane podczas impersonacji. Zmiana nazwy użytkownika odbywa się przez panel sterowania konta użytkownika, a nie przez proces impersonacji.\n\nOpcja trzecia \"definiuje 5 dodatkowych poziomów kontroli dostępu do danych i procesów\" jest **niepoprawna**. Impersonacja jest mechanizmem kontroli *tożsamości*, a nie *dostępu*. Ustawianie uprawnień do obiektów oraz definicji dodatkowych poziomów dostępu to elementy kontroli dostępu, często powiązane z mechanizmem MAC (Mandatory Access Control). Mechanizm kontroli dostępu definiuje prawa do plików i innych zasobów systemu, a nie pozwala na tymczasowe przyjęcie tożsamości innego użytkownika.\n\nOpcja czwarta \"pozwala procesowi użyć chwilowo innego niż bieżący tokenu zabezpieczeń\" jest **poprawna**. Mechanizm impersonacji  pozwala tymczasowo zamienić token zabezpieczeń danego procesu na token innego użytkownika. Jest to podstawowa zasada działania impersonacji. Po zakończeniu operacji wykonywanej w ramach impersonacji, proces automatycznie powraca do korzystania z oryginalnego tokena. W praktyce, serwer WWW, po uwierzytelnieniu klienta, może zacząć wykonywać operacje z uprawnieniami tego klienta, co pozwala na dostęp do plików tylko tego konkretnego klienta."
    },
    {
        "questionId": 320,
        "title": "Mozliwosci uwierzytelniania sie przy uzyciu SSH2 to: ",
        "answers": [
            {
                "text": "mechanizm zaufania (.rhosts)",
                "isCorrect": false
            },
            {
                "text": "symetryczne klucze uzytkownika",
                "isCorrect": false
            },
            {
                "text": "haslo uzytkownika",
                "isCorrect": true
            },
            {
                "text": "asymetryczne klucze uzytkownika",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH2 (Secure Shell version 2) oferuje różne metody uwierzytelniania użytkownika, które mają na celu bezpieczne potwierdzenie tożsamości osoby próbującej uzyskać dostęp do zdalnego systemu. Uwierzytelnianie, w kontekście bezpieczeństwa systemów komputerowych, to proces weryfikacji czy dana osoba lub system są tymi, za które się podają.\n\n**\"mechanizm zaufania (.rhosts)\"** - Jest to przestarzała metoda uwierzytelniania, polegająca na zaufaniu do hosta, który próbuje uzyskać dostęp do innego. Plik .rhosts zawiera listę zaufanych hostów, z których, jeżeli użytkownik próbuje się zalogować, to nie jest wymagane hasło. Metoda ta jest **niepoprawna**, ponieważ SSH2 nie stosuje mechanizmu zaufania opartego na plikach .rhosts i podobnych. SSH2 preferuje silniejsze metody uwierzytelniania, aby uniknąć potencjalnych ataków. Na przykład, jeśli atakujący przejmie kontrolę nad zaufanym hostem, to może łatwo uzyskać dostęp do każdego systemu który mu zaufał.\n\n**\"symetryczne klucze uzytkownika\"** - Klucze symetryczne to klucze używane zarówno do szyfrowania, jak i do deszyfrowania danych. SSH2 *nie używa* kluczy symetrycznych bezpośrednio do uwierzytelniania użytkownika. Klucze symetryczne w SSH2 używane są po uwierzytelnieniu do szyfrowania danych, ale nie są używane bezpośrednio do weryfikacji tożsamości użytkownika. Ta odpowiedź jest **niepoprawna**, ponieważ klucze symetryczne służą do ochrony poufności danych, a nie do uwierzytelnienia użytkownika.\n\n**\"haslo uzytkownika\"** - Uwierzytelnianie hasłem jest jedną z *poprawnych* metod uwierzytelniania w SSH2. Użytkownik, przy próbie połączenia z serwerem SSH, podaje swoją nazwę użytkownika oraz hasło. Po podaniu hasło jest przesyłane zaszyfrowanym kanałem i weryfikowane na serwerze. Choć to proste, hasła są podatne na ataki brute-force lub podsłuch. Dlatego nie jest to zalecana metoda autoryzacji, szczególnie w środowisku sieciowym o zwiększonym poziomie zagrożeń. Ta odpowiedź jest **poprawna**, ale nie jedyna.\n\n**\"asymetryczne klucze uzytkownika\"** - Uwierzytelnianie kluczem asymetrycznym jest inną *poprawną* i znacznie bezpieczniejszą metodą uwierzytelniania w SSH2. Wykorzystuje parę kluczy: klucz prywatny, który jest znany tylko użytkownikowi i nie powinien być udostępniany nikomu, i klucz publiczny, który może być udostępniony każdemu. Podczas połączenia, serwer sprawdza, czy użytkownik posiada klucz prywatny odpowiadający kluczowi publicznemu przypisanemu do jego konta. Klucz prywatny jest używany do podpisania losowej wartości przesyłanej przez serwer, a serwer jest w stanie zweryfikować autentyczność podpisu dzięki wcześniej udostępnionemu kluczowi publicznemu. Ta odpowiedź jest **poprawna**, oferując znacznie lepszy poziom bezpieczeństwa niż uwierzytelnianie hasłem.\n\nPodsumowując, SSH2 wspiera uwierzytelnianie hasłem oraz za pomocą kluczy asymetrycznych. Mechanizmy oparte na .rhosts lub symetrycznych kluczach *nie są* wykorzystywane do uwierzytelnienia użytkowników."
    },
    {
        "questionId": 321,
        "title": "W jakim celu mozna weksportowac certyfikat do formatu PKCS #12: ",
        "answers": [
            {
                "text": "W celu wyekstraktowania klucza do szyfrowania wiadomosci",
                "isCorrect": false
            },
            {
                "text": "W celu wyekstraktowania klucza aby przekazac go drugiej stronie",
                "isCorrect": false
            },
            {
                "text": "W celu stworzenia kopii zapasowej certyfikatu",
                "isCorrect": true
            },
            {
                "text": "zaimportowac w kliencie pocztowym - ze skryptu z labow",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Format PKCS #12 (czasami nazywany PFX) jest to format pliku, który służy jako kontener do przechowywania certyfikatu cyfrowego wraz z odpowiadającym mu kluczem prywatnym. Format ten stosowany jest głównie do tworzenia kopii zapasowych certyfikatów oraz do przenoszenia ich między różnymi systemami lub aplikacjami. Plik PKCS #12 jest chroniony hasłem, co zapewnia dodatkową warstwę ochrony klucza prywatnego.\n\n**Odpowiedź 1: \"W celu wyekstraktowania klucza do szyfrowania wiadomości\"** - jest **niepoprawna**. Chociaż format PKCS #12 *zawiera* klucz prywatny, nie jest on stworzony do bezpośredniego wyciągania go, aby szyfrować nim wiadomości. Pliki te są przeznaczone do bezpiecznego przechowywania par kluczy a nie do ich wyciągania dla innych osób. Zamiast tego, klucz prywatny wykorzystywany jest przez aplikację lub system, który zaimportował certyfikat z formatu PKCS #12 do szyfrowania. Prawidłowy proces szyfrowania wiadomości wymaga odczytania certyfikatu z formatu PKCS #12 a następnie użycie powiązanych kluczy przez aplikację, która to wywołała procedurę odczytu certyfikatu.\n\n**Odpowiedź 2: \"W celu wyekstraktowania klucza aby przekazac go drugiej stronie\"** - jest **niepoprawna**. Format PKCS #12 przechowuje klucz *prywatny*, który *nigdy* nie powinien być przekazywany innym osobom. Klucz publiczny z certyfikatu można swobodnie rozpowszechniać a klucz prywatny w formie zaszyfrowanej w formacie PKCS #12 służy tylko do przenoszenia własnych certyfikatów. Klucz publiczny danego podmiotu jest wykorzystywany przez inne podmioty aby zaszyfrować wiadomość, natomiast klucz prywatny tego podmiotu służy do odszyfrowania tejże wiadomości oraz podpisywania cyfrowego. W tym formacie umieszczamy swój klucz prywatny i certyfikat klucza publicznego, by w przyszłości móc wykonać odszyfrowanie wiadomości lub podpisać cyfrowo wiadomość. \n\n**Odpowiedź 3: \"W celu stworzenia kopii zapasowej certyfikatu\"** - jest **poprawna**. Format PKCS #12 jest idealny do tworzenia kopii zapasowych certyfikatów, ponieważ w jednym pliku możemy przechowywać zarówno certyfikat jak i klucz prywatny. W razie awarii systemu lub konieczności migracji certyfikatu do innego systemu, wystarczy odtworzyć plik PKCS#12 oraz wpisać do niego hasło, aby uzyskać dostęp do certyfikatu i klucza prywatnego.\n\n**Odpowiedź 4: \"zaimportowac w kliencie pocztowym - ze skryptu z labow\"** - jest **poprawna**. Aplikacje pocztowe często używają formatu PKCS #12, aby zaimportować do nich certyfikaty użytkownika. Klient pocztowy w tym przypadku nie tylko importuje certyfikat ale i powiązany z nim klucz prywatny, który jest niezbędny do podpisywania cyfrowego korespondencji i odszyfrowywania wiadomości zaszyfrowanych kluczem publicznym."
    },
    {
        "questionId": 322,
        "title": "Ktory mechanizm pozwala na wirtualizacje jadra systemu: ",
        "answers": [
            {
                "text": "VBS",
                "isCorrect": true
            },
            {
                "text": "ARM TrustZone",
                "isCorrect": true
            },
            {
                "text": "TEE",
                "isCorrect": true
            },
            {
                "text": "SSL",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Wirtualizacja jądra systemu to technika polegająca na stworzeniu odizolowanego środowiska wykonawczego, w którym jądro systemu operacyjnego działa w sposób ograniczony. To umożliwia na przykład wykonywanie niebezpiecznego kodu lub testowanie nowych funkcji systemu bez ryzyka zakłócenia działania całego systemu.\n\n**VBS (Virtualization Based Security)** to technologia bezpieczeństwa firmy Microsoft, która wykorzystuje wirtualizację do ochrony systemu Windows, szczególnie w celu zabezpieczenia jądra systemu przed atakami. W skrócie, VBS tworzy \"wirtualną\" wersję jądra, w której działają wrażliwe procesy bezpieczeństwa. Pozwala to izolować je od głównego jądra i chronić przed złośliwym oprogramowaniem, które próbuje uzyskać nieautoryzowany dostęp. Na przykład, VBS chroni przed atakami wykorzystującymi luki w zabezpieczeniach jądra, w taki sposób iż działający malware nie ma dostępu do zasobów chronionych przez VBS. Ma to na celu ochronę przed atakami wykorzystującymi przepełnienie bufora, kod wstrzykiwany do procesu i wiele innych.\n\n**ARM TrustZone** to technologia wbudowana w procesory ARM, która tworzy oddzielne, bezpieczne środowisko wykonawcze (TEE) na poziomie sprzętowym. Środowisko to umożliwia bezpieczne przetwarzanie poufnych danych i wykonywanie operacji kryptograficznych. Przykładowo, dane biometryczne do odblokowania telefonu są przechowywane w TrustZone. Innym zastosowaniem TrustZone są operacje kryptograficzne przy bezpiecznej transmisji danych oraz przy operacjach bankowych. Dodatkowo dane przechowywane w TEE nie są dostępne dla systemu operacyjnego.\n\n**TEE (Trusted Execution Environment)** to ogólny termin oznaczający bezpieczne środowisko wykonawcze. Technologia ARM TrustZone jest jedną z implementacji koncepcji TEE. TEE jest odizolowanym środowiskiem w którym mogą być wykonywane operacje kryptograficzne oraz przetwarzane wrażliwe dane. TEE chroni przed nieautoryzowanym dostępem, nawet jeśli system operacyjny został już zainfekowany. Podstawowym zadaniem TEE jest tworzenie \"bezpiecznego pasa\" w systemie.\n\n**SSL (Secure Sockets Layer)** to protokół warstwy transportowej służący do zapewnienia bezpieczeństwa transmisji danych w sieci. W szczególności chroni przed podsłuchiwaniem danych, zapewnia również weryfikację tożsamości. SSL nie wirtualizuje jądra systemu operacyjnego. Działa na wyższym poziomie niż jądro, a jego zadaniem jest ochrona komunikacji, a nie bezpośrednia ochrona integralności i bezpieczeństwa jądra systemu. Przykładowo, SSL jest używany w protokole HTTPS do szyfrowania połączeń z przeglądarką internetową i ochroną hasła podczas logowania.\n\nPodsumowując, VBS, ARM TrustZone, oraz TEE to mechanizmy bezpośrednio związane z wirtualizacją i izolacją na poziomie jądra systemu operacyjnego lub na poziomie sprzętowym, natomiast SSL to protokół kryptograficzny służący do zabezpieczania komunikacji, ale nie jest mechanizmem wirtualizacji."
    },
    {
        "questionId": 323,
        "title": "Aby zweryfikowac podpis cyfrowy w systeme PGP wiadomosci od nadawcy A do odbiorcy B potrzeba: ",
        "answers": [
            {
                "text": "klucz prywatny nadawcy A, przeciez B nie posiada klucza prywatnego A, a A podpisuje swoim prywatnym",
                "isCorrect": false
            },
            {
                "text": "klucz publiczny nadawcy A",
                "isCorrect": true
            },
            {
                "text": "klucz prywatny odbiorcy B",
                "isCorrect": false
            },
            {
                "text": "klucz publiczny odbiorcy B",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Weryfikacja podpisu cyfrowego w systemie PGP opiera się na asymetrycznej kryptografii, gdzie każda strona posiada parę kluczy: prywatny i publiczny. Klucz prywatny jest utrzymywany w tajemnicy i służy do podpisywania wiadomości (tworzenia podpisu cyfrowego), a klucz publiczny jest udostępniany i używany do weryfikacji podpisu.\n\n*   **\"klucz prywatny nadawcy A, przeciez B nie posiada klucza prywatnego A, a A podpisuje swoim prywatnym\"**\n    -   Ta odpowiedź jest **niepoprawna**. Klucz prywatny nadawcy A służy do *tworzenia* podpisu cyfrowego, a nie do jego weryfikacji. Klucz prywatny musi być utrzymywany w tajemnicy przez jego posiadacza. Użycie prywatnego klucza do weryfikacji podpisu w systemie PGP byłoby błędem proceduralnym (bezpieczeństwa). Odpowiedź sugeruje, że odbiorca potrzebuje prywatnego klucza nadawcy, aby zweryfikować podpis, co narusza podstawową zasadę bezpieczeństwa asymetrycznej kryptografii.\n\n*   **\"klucz publiczny nadawcy A\"**\n    -   Ta odpowiedź jest **poprawna**. Klucz publiczny nadawcy A służy do weryfikacji podpisu cyfrowego utworzonego za pomocą jego klucza prywatnego. Każdy, kto posiada klucz publiczny nadawcy, może zweryfikować, czy wiadomość została podpisana przez danego nadawcę i czy nie została zmodyfikowana po podpisaniu. Odbiorca B musi posiadać klucz publiczny nadawcy A, aby zweryfikować jego podpis cyfrowy.\n        *   **Przykład:** Załóżmy, że Alicja wysyła wiadomość do Bolka i podpisuje ją cyfrowo swoim kluczem prywatnym. Bolek, aby zweryfikować, czy wiadomość rzeczywiście pochodzi od Alicji i czy nikt jej nie zmienił w trakcie przesyłania, potrzebuje klucza publicznego Alicji. Klucz publiczny umożliwia Bolkowi potwierdzenie, że podpis wiadomości został wygenerowany za pomocą klucza prywatnego Alicji.\n\n*   **\"klucz prywatny odbiorcy B\"**\n    -   Ta odpowiedź jest **niepoprawna**. Klucz prywatny odbiorcy B służy do *odszyfrowania* wiadomości zaszyfrowanej jego kluczem publicznym i nie jest potrzebny do weryfikacji podpisu cyfrowego. Podpis cyfrowy jest wygenerowany na podstawie klucza prywatnego nadawcy i weryfikowany przy pomocy klucza publicznego nadawcy.\n        *   **Przykład:** Prywatny klucz Bolka jest używany tylko do odszyfrowania wiadomości, które zostały zaszyfrowane przy pomocy jego klucza publicznego.\n\n*   **\"klucz publiczny odbiorcy B\"**\n    -   Ta odpowiedź jest **niepoprawna**. Klucz publiczny odbiorcy B służy do *zaszyfrowania* wiadomości, którą do niego wysyłamy. Odbiorca B sam nie używa swojego klucza publicznego do weryfikacji podpisu, ale udostępnia go innym aby mogli wysyłać mu tajne wiadomości.\n         *  **Przykład:** Klucz publiczny Bolka jest używany do zaszyfrowania wiadomości, aby tylko on mógł ją przeczytać, ponieważ jedynie on posiada odpowiadający temu kluczowi klucz prywatny. Nie ma on nic wspólnego z weryfikacją podpisu cyfrowego, który dotyczy tylko autentyczności nadawcy.\n\n**Podsumowując**: Do weryfikacji podpisu cyfrowego, który nadawca A złożył, potrzebny jest wyłącznie klucz publiczny nadawcy A. To pozwala jednoznacznie potwierdzić tożsamość nadawcy i integralność wiadomości."
    },
    {
        "questionId": 324,
        "title": "Kiedy w Windowsie nastepuje zerowanie licznika prob wpisania hasla: ",
        "answers": [
            {
                "text": "Po pomyslnym zalogowaniu",
                "isCorrect": false
            },
            {
                "text": "Po uplywie okreslonego czasu",
                "isCorrect": true
            },
            {
                "text": "Administrator moze recznie wyzerowac",
                "isCorrect": true
            },
            {
                "text": "nie pamietam, ale nie powinno byc zaznaczone",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizmy blokowania kont w systemach Windows mają na celu ochronę przed atakami brute-force, czyli polegającymi na wielokrotnym próbowaniu różnych haseł w celu uzyskania nieautoryzowanego dostępu do konta użytkownika. Po przekroczeniu zdefiniowanej liczby nieudanych prób logowania, konto zostaje zablokowane, uniemożliwiając dalsze próby dostępu przez określony czas. Aby zablokowane konto było ponownie dostępne, musi nastąpić wyzerowanie licznika błędnych prób logowania.\n\n**\"Po pomyślnym zalogowaniu\"** - Jest to **nieprawidłowa** odpowiedź. Pomyślne zalogowanie nie zeruje licznika nieudanych prób logowania. Licznik ten jest niezależny i przechowuje informacje tylko o nieudanych próbach. Pomyślne logowanie oznacza, że mechanizm ochrony zadziałał zgodnie z założeniami, czyli ochrona konta przed wielokrotnym próbowaniem haseł, a nie wyeliminowanie historii prób.\n\n**\"Po uplywie okreslonego czasu\"** - Jest to **poprawna** odpowiedź. Zablokowanie konta w wyniku przekroczenia progu nieudanych prób logowania jest czasowe. Po upływie zdefiniowanego w ustawieniach czasu, licznik nieudanych prób logowania jest automatycznie zerowany, co umożliwia ponowne logowanie do konta, przy czym jest to nowa sesja logowania bez jakiejkolwiek historii poprzednich nieudanych prób logowania. Na przykład, jeśli administrator skonfiguruje system tak, aby blokował konto na 30 minut, a użytkownik po 5 nieudanych próbach zostanie zablokowany, to po 30 minutach licznik błędnych logowań zostanie wyzerowany i użytkownik ponownie będzie miał możliwość logowania się. Ten czas jest ustawiany przez administratora w ustawieniach polityki konta.\n\n**\"Administrator moze recznie wyzerowac\"** - Jest to **poprawna** odpowiedź. Administrator systemu ma możliwość ręcznego wyzerowania licznika błędnych prób logowania. Może to być konieczne, gdy na przykład użytkownik został zablokowany przez przypadek lub zapomniał hasła i potrzebuje natychmiastowego dostępu do systemu. Administrator ma dostęp do konfiguracji polityki kont i może w dowolnym momencie zresetować licznik. W systemie Windows, robi się to na przykład poprzez narzędzie _Lokalne zasady zabezpieczeń_. Administrator po odblokowaniu konta powinien skontaktować się z użytkownikiem, aby ten nie zapomniał ponownie swojego hasła.\n\n**\"nie pamietam, ale nie powinno byc zaznaczone\"** - Jest to **nieprawidłowa** odpowiedź. Jest to odpowiedź rozpraszająca."
    },
    {
        "questionId": 325,
        "title": "Czy iptables umozliwia okreslenie domyslnej polityki w lancuchu?: ",
        "answers": [
            {
                "text": "Tylko w lancuchach tablicy filter",
                "isCorrect": false
            },
            {
                "text": "Tylko w predefiniowanych lancuchach",
                "isCorrect": false
            },
            {
                "text": "Tak, w kazdym lancuchu",
                "isCorrect": true
            },
            {
                "text": "tylko w nowo utworzonych lancuchach",
                "isCorrect": false
            },
            {
                "text": "tak",
                "isCorrect": false
            },
            {
                "text": "tylko w standardowych lancuchach",
                "isCorrect": false
            },
            {
                "text": "Nie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "W systemie `iptables`, który jest zaporą sieciową w systemie Linux, kluczowym elementem są łańcuchy (ang. *chains*). Łańcuch to uporządkowany zbiór reguł, które są stosowane do pakietów przesyłanych przez zaporę. Domyślna polityka (_ang. default policy_) jest akcją (np. `ACCEPT`, `DROP`, `REJECT`) wykonywaną na pakiecie, który nie pasuje do żadnej z reguł w danym łańcuchu. Domyślna polityka jest określana za pomocą opcji `-P`  polecenia `iptables`, np. `iptables -P INPUT DROP` ustawia domyślną politykę łańcucha `INPUT` na odrzucanie wszystkich pakietów, które nie pasują do żadnej wcześniejszej reguły w tym łańcuchu.\n\n**Odpowiedź 1: \"Tylko w łańcuchach tablicy filter\" jest niepoprawna.**\n`iptables` operuje na różnych tablicach (np. `filter`, `nat`, `mangle`), a każda z tablic ma łańcuchy (np. `INPUT`, `OUTPUT`, `FORWARD` w tabeli `filter`; `PREROUTING`, `POSTROUTING` w tabeli `nat`). Chociaż tablica `filter` jest najczęściej używana do filtrowania ruchu, to możliwość ustawienia domyślnej polityki nie jest ograniczona tylko do tej tablicy, można to zrobić we wszystkich tablicach `iptables`. W szczególności tablica `nat` również posiada łańcuchy i również można tam ustawić domyślne polityki. Przykładowo `iptables -t nat -P PREROUTING ACCEPT` ustawia domyślną politykę łańcucha `PREROUTING` w tabeli `nat` na przepuszczanie pakietów.\n\n**Odpowiedź 2: \"Tylko w predefiniowanych łańcuchach\" jest niepoprawna.**\n`iptables` pozwala administratorowi na tworzenie własnych, użytkownika łańcuchów, które można dołączyć do wbudowanych łańcuchów. Domyślna polityka może być ustawiona również dla nowo utworzonych łańcuchów.  Przykładowo `iptables -N MYCHAIN` tworzy nowy łańcuch a `iptables -P MYCHAIN DROP` ustawia domyślną politykę na odrzucanie pakietów. \n\n**Odpowiedź 3: \"Tak, w każdym łańcuchu\" jest poprawna.**\nMożliwość ustawienia domyślnej polityki jest niezależna od typu łańcucha i tablicy do której on należy. Użytkownik ma pełną swobodę ustawienia domyślnych polityk, zarówno w predefiniowanych, jak i w nowo utworzonych łańcuchach. Oznacza to, że można dostosować działanie zapory do konkretnych potrzeb, mając pełną kontrolę nad domyślnym zachowaniem w różnych miejscach przetwarzania pakietów. Jest to bardzo elastyczne rozwiązanie.\n\n**Odpowiedź 4: \"tylko w nowo utworzonych łańcuchach\" jest niepoprawna.**\nJak wspomniano wcześniej, `iptables` umożliwia konfigurację domyślnej polityki dla wszystkich typów łańcuchów a nie tylko dla nowo utworzonych łańcuchów. Ustawienie domyślnej polityki jest bardzo istotne i często jest używane do określenia jak ma zachowywać się zapora w sytuacji, gdy pakiet nie zostanie dopasowany do żadnej z reguł w danym łańcuchu. \n\n**Odpowiedź 5: \"tak\" jest niepoprawna.**\nTa odpowiedź jest nieprecyzyjna, gdyż nie określa w jaki sposób można ustawić tą politykę. Mimo że odpowiedź nie jest fałszywa to jednak jest mniej precyzyjna. Z punktu widzenia zadania, które ma sprawdzić znajomość wszystkich właściwości mechanizmu `iptables` oraz tego jak ten mechanizm działa, odpowiedź ta jest zła.\n\n**Odpowiedź 6: \"tylko w standardowych łańcuchach\" jest niepoprawna.**\nTa odpowiedź jest przeciwieństwem poprawnej odpowiedzi i ma podobny charakter jak odpowiedź numer 2. \n\n**Odpowiedź 7: \"Nie\" jest niepoprawna.**\nTa odpowiedź jest fałszywa, gdyż `iptables` jak najbardziej wspiera ustawianie domyślnej polityki. Jest to bardzo częsta konfiguracja zaporowa, gdy wszystkie pakiety nie spełniające żadnego z kryteriów, są domyślnie odrzucane, a tylko te które pasują do konkretnych reguł są przepuszczane przez zaporę. \n\n**Podsumowanie:**\nZasadniczo, `iptables` umożliwia ustawienie domyślnej polityki we wszystkich łańcuchach, predefiniowanych i tworzonych przez administratora, we wszystkich tabelach `iptables`. Konfiguracja domyślnej polityki łańcucha jest ważnym elementem w budowaniu zapory sieciowej. Decyduje ona o tym, co stanie się z pakietem, który nie spełnia warunków żadnej reguły w danym łańcuchu. Dobrze ustawiona domyślna polityka minimalizuje ryzyko nieuprawnionego dostępu. Należy również pamiętać o tym, że na początku tworzenia reguł filtrujących warto ustawić politykę domyślną na `DROP` a następnie zdefiniować szereg reguł, które będą akceptować ruch dla wybranych usług i hostów."
    },
    {
        "questionId": 326,
        "title": "W metodzie uzgadniania klucza Diffiego-Hellmana system kompromituje (narusza bezpieczenstwo): ",
        "answers": [
            {
                "text": "przechwycenia jednego z wymienianych kluczy",
                "isCorrect": false
            },
            {
                "text": "przechwycenia obu wymienianych kluczy",
                "isCorrect": false
            },
            {
                "text": "podstawienie falszywego klucza w miejsce kazdego z wymienianych",
                "isCorrect": true
            },
            {
                "text": "podstawienie falszywego klucza w miejsce dowolnego z wymienianych",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Metoda uzgadniania klucza Diffiego-Hellmana (DH) to protokół kryptograficzny służący do wymiany tajnego klucza pomiędzy dwiema stronami w publicznie dostępnym kanale, bez konieczności wcześniejszego uzgadniania tego klucza, czy przekazywania go bezpiecznym kanałem. Protokół ten bazuje na matematycznej trudności obliczeniowej problemu logarytmu dyskretnego i nie zapewnia autentyczności stron, które uzgadniają wspólny klucz. Oznacza to, że w trakcie wymiany klucza strony nie są pewne, z kim tak naprawdę wymieniają dane, i na tym polega główna słabość tego algorytmu.\n    \n1.  **\"przechwycenia jednego z wymienianych kluczy\"** - Ta odpowiedź jest **niepoprawna**. W protokole Diffiego-Hellmana, strony wymieniają publiczne wartości, które nie są same w sobie kluczami sesyjnymi, ani kluczami prywatnymi i ich przechwycenie nie ujawnia tajnego klucza, który po cichu każda ze stron oblicza. Przechwycenie jednej z tych wartości bez dalszej manipulacji nie kompromituje systemu.\n\n2.  **\"przechwycenia obu wymienianych kluczy\"** - Ta odpowiedź jest również **niepoprawna**. Podobnie jak w poprzedniej odpowiedzi samo przechwycenie publicznych wartości (kluczy), wymienianych w procesie DH, nie powoduje naruszenia bezpieczeństwa systemu. Atakujący nie jest w stanie, posługując się wyłącznie przechwyconymi wartościami, obliczyć tajnego klucza sesyjnego, ani podszyć się pod żadną ze stron komunikacji. Jest to bardzo ważne, gdyż pokazuje na czym polega bezpieczeństwo algorytmu DH.\n\n3.  **\"podstawienie fałszywego klucza w miejsce każdego z wymienianych\"** - Ta odpowiedź jest **poprawna**. Jest to istota ataku Man-in-the-Middle (MitM) na protokół Diffiego-Hellmana. Ponieważ strony nie autentykują swoich kluczy publicznych, atakujący może na każdym z węzłów komunikacji przechwycić przesyłane wartości, a następnie podstawić za nie swoje wartości. Atakujący tworzy w ten sposób dwie różne sesje z wykorzystaniem mechanizmu DH, oddzielną z każdym z uczestników komunikacji. I tak atakujący jest w stanie podszyć się pod każdą ze stron i prowadzić z nimi szyfrowaną komunikację.\n\n4.  **\"podstawienie fałszywego klucza w miejsce dowolnego z wymienianych\"** - Ta odpowiedź jest również **poprawna**. Jak w poprzednim przypadku wystarczy, że atakujący (man-in-the-middle) przechwyci klucz przesyłany w trakcie wymiany i podstawi fałszywy klucz. Efekt jest taki sam, ponieważ pozwala to atakującemu na obliczenie klucza współdzielonego ze stroną A i innym ze stroną B. Do ataku nie jest konieczne podstawianie fałszywego klucza w miejsce *każdego* z wymienianych, ale w miejsce *dowolnego* klucza, w procesie wymiany DH, umożliwia on podstawienie się pod każdą ze stron, oddzielnie.\n\n    **Przykład praktyczny:** Załóżmy, że Alicja chce bezpiecznie skomunikować się z Bolkiem, wykorzystując mechanizm DH. Atakujący, Edziu, przechwytuje ich komunikację. Podczas wymiany danych Diffiego-Hellmana, Edziu zamiast przekazywać Alicji klucz Bolka, wysyła jej swój fałszywy klucz. Podobnie z kluczem Alicji - do Bolka Edziu przesyła swój klucz, a nie klucz Alicji. W efekcie Alicja uważa, że ustaliła bezpieczny klucz z Bolkiem, Bolek uważa, że ustalił bezpieczny klucz z Alicją, a w rzeczywistości, każda z nich ma klucz tylko z Edziem. Od tej pory Edziu może odszyfrowywać i podmieniać ich komunikację.\n    \n    **Podsumowanie:** Protokół Diffiego-Hellmana, pomimo że umożliwia ustalenie tajnego klucza, to w podstawowej wersji jest podatny na ataki MitM z powodu braku mechanizmów uwierzytelnienia stron. Dlatego w praktyce protokół ten jest łączony z innymi protokołami autentykacji, najczęściej są to protokoły wykorzystujące podpisy cyfrowe, a do wymiany danych szyfrowanych wykorzystywany jest protokół AES."
    },
    {
        "questionId": 327,
        "title": "Klasa B1 wg TCSEC (,,Orange Book\") lub rownowazna jej klasa EAL4 wg Common Criteria wymaga m. in.: ",
        "answers": [
            {
                "text": "ochrony systemowych obszarow pamieci",
                "isCorrect": false
            },
            {
                "text": "uwierzytelniania uzytkownikow",
                "isCorrect": false
            },
            {
                "text": "scislej kontroli dostepu do danych (MAC)",
                "isCorrect": true
            },
            {
                "text": "szyfrowania plikow",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Klasyfikacja bezpieczeństwa systemów komputerowych definiuje wymagania dotyczące mechanizmów zabezpieczeń w zależności od poziomu zaufania. W szczególności, klasa B1 wg TCSEC (\"Orange Book\") oraz równoważna jej klasa EAL4 wg Common Criteria wprowadzają obowiązkową kontrolę dostępu (MAC, _Mandatory Access Control_). MAC to model kontroli dostępu, w którym uprawnienia dostępu do zasobów nie są przyznawane uznaniowo przez właścicieli tych zasobów, lecz są wymuszane automatycznie przez system na podstawie zdefiniowanych reguł.  W systemie MAC każdy zasób i każdy użytkownik posiada etykietę bezpieczeństwa, która określa, jaki poziom zaufania jest związany z danymi i użytkownikiem, i dostęp odbywa się na podstawie porównania etykiet. Na przykład, zasób z etykietą „tajne” może być odczytany jedynie przez użytkownika z etykietą „tajne” lub „ściśle tajne”.  System operacyjny, działając w oparciu o ścisłą politykę bezpieczeństwa, automatycznie wymusza dostęp tylko do zasobów, do których dany użytkownik ma prawa. Jest to przeciwieństwo uznaniowej kontroli dostępu (DAC, _Discretionary Access Control_), w którym to właściciel zasobu może swobodnie przyznawać prawa dostępu innym użytkownikom.\n\n*   **ochrony systemowych obszarow pamieci:** Choć ochrona pamięci jest ważnym aspektem bezpieczeństwa systemów komputerowych, nie jest to cecha charakterystyczna konkretnie dla klasy B1 TCSEC czy EAL4. Ochrona pamięci jest ważna już na niższych poziomach klasyfikacji, np C2. Zatem odpowiedź ta jest nieprawidłowa.\n\n*   **uwierzytelniania uzytkownikow:** Uwierzytelnianie użytkowników to podstawowy element bezpieczeństwa, obecny już w klasach niższych od B1 (np. C1, C2), jak również w standardach EAL1 - EAL3. Zatem odpowiedź ta jest nieprawidłowa.\n\n*   **scislej kontroli dostepu do danych (MAC):**  Ścisła kontrola dostępu (MAC) jest kluczową cechą charakterystyczną dla klasy B1 w TCSEC i EAL4 w Common Criteria. W systemach MAC to system, a nie użytkownik, decyduje o tym, kto ma dostęp do jakich zasobów na podstawie poziomu klasyfikacji. Przykładowo, system z MAC może zarządzać dostępem do plików w zależności od etykiet poufności plików i użytkowników. Dostęp do plików “tajne” nie zostanie przyznany użytkownikowi z uprawnieniami \"poufne\". Odpowiedź ta jest prawidłowa.\n\n*   **szyfrowania plikow:** Szyfrowanie plików jest ważne dla ochrony poufności, ale nie jest specyficzne dla klasy B1 czy EAL4. Szyfrowanie jest mechanizmem zabezpieczającym który może być wykorzystany na różnych poziomach bezpieczeństwa, również niższych.  Zatem odpowiedź ta jest nieprawidłowa.\n\nW praktyce, system operacyjny certyfikowany na poziomie B1/EAL4 implementowałby mechanizmy MAC poprzez wymuszenie etykiet bezpieczeństwa na wszystkich danych i procesach, regulując przepływ informacji i interakcji między tymi elementami. Użytkownik nie może obejść tych ograniczeń, a tylko system może kontrolować przepływ informacji pomiędzy różnymi poziomami bezpieczeństwa."
    },
    {
        "questionId": 328,
        "title": "Czy certyfikaty SSL dla obu stron polaczenia vpn nawiazanego przy pomocy programu OpenVPN musza by podpisane przez ta sam zaufana strone trzecia?: ",
        "answers": [
            {
                "text": "nie, poniewaz nie ma takiej opcji w OpenVPN",
                "isCorrect": false
            },
            {
                "text": "nie, poniewaz nie ma znaczenia czy to jest to samo CA, wazne aby zaufanie strony trzeciej bylo ogolnie znane CA, np. Thawte, VeriSign, Unizeto",
                "isCorrect": false
            },
            {
                "text": "nie trzeba podawac parametru wskazujacego na CA, jest to opcjonalne",
                "isCorrect": false
            },
            {
                "text": "tak",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Certyfikaty SSL wykorzystywane w OpenVPN zapewniają uwierzytelnianie i szyfrowanie komunikacji poprzez mechanizm klucza publicznego. Uwierzytelnianie w protokole SSL polega na weryfikacji certyfikatu, który jest podpisem zaufanej strony trzeciej, nazywanej urzędem certyfikacji (CA). Certyfikat zawiera klucz publiczny danego podmiotu. Każdy podmiot w procesie komunikacji SSL musi zaufać danemu urzędowi certyfikacji, aby móc uznać, że certyfikat jest ważny. W OpenVPN w konfiguracji wykorzystującej certyfikaty, zarówno klient, jak i serwer, muszą być skonfigurowane tak, aby ufały certyfikatowi CA drugiej strony.\n\n**Poprawna odpowiedź:**\n*   **tak** -  Aby połączenie OpenVPN wykorzystujące certyfikaty SSL działało poprawnie, zarówno serwer, jak i klient muszą ufać tej samej stronie trzeciej - temu samemu urzędowi certyfikacji (CA). Oznacza to, że certyfikaty SSL, którymi uwierzytelniają się obie strony połączenia, muszą być podpisane przez ten sam CA (lub CA z tego samego łańcucha zaufania). W innym wypadku weryfikacja certyfikatu nie powiedzie się, ponieważ jedna ze stron nie będzie ufała podpisowi drugiej strony. Bez weryfikacji tożsamości drugiej strony nie dojdzie do bezpiecznego połączenia, a nawet nie dojdzie do połączenia w ogóle. Przykładem może być sytuacja, gdzie serwer VPN został uwierzytelniony certyfikatem podpisanym przez \"CA_firmy_X\" a klient używa certyfikatu podpisanego przez CA \"CA_firmy_Y\". Klient nie będzie ufał serwerowi i połączenie nie będzie mogło być ustanowione.\n\n**Niepoprawne odpowiedzi:**\n*   **nie, ponieważ nie ma takiej opcji w OpenVPN** -  OpenVPN posiada opcję `ca` która wskazuje ścieżkę do certyfikatu urzędu certyfikacji, który jest wykorzystywany do weryfikacji połączenia. Jeżeli nie zostanie podany ten parametr, domyślnie weryfikacja certyfikatów nie zostanie wykonana. Dlatego opcja ta jest obowiązkowa w procesie weryfikacji certyfikatów SSL. Podanie tego parametru nie jest opcjonalne, jeśli chcemy korzystać z certyfikatów do weryfikacji połączenia. Zatem odpowiedź jest niepoprawna.\n\n*   **nie, ponieważ nie ma znaczenia czy to jest to samo CA, ważne aby zaufanie strony trzeciej było ogólnie znane CA, np. Thawte, VeriSign, Unizeto** -  To odpowiedź jest fałszywa, ponieważ certyfikaty muszą być podpisane przez ten sam urząd certyfikacji(lub CA z tego samego łańcucha zaufania) w konfiguracji OpenVPN. W sytuacji w której, certyfikaty będą podpisane przez różne urzędy certyfikacji, należy skonfigurować oba programy OpenVPN tak aby oba zaufały certyfikatom CA drugiej strony. OpenVPN nie potrafi sam odnaleźć łańcucha zaufania między dwoma różnymi CA. Zaufanie do urzędu certyfikacji np. Thawte czy VeriSign nie gwarantuje poprawności działania protokołu OpenVPN, ponieważ każda ze stron połączenia musi jawnie mieć zaufanie do tego samego urzędu certyfikacji. Takie zachowanie wynika z faktu, iż OpenVPN nie wykorzystuje globalnej infrastruktury zaufania jak w przypadku certyfikatów klientów poczty elektronicznej czy certyfikatów serwerów www. W przypadku OpenVPN każda ze stron połączenia musi jawnie określić który certyfikat CA jest dla niej zaufany.\n\n*   **nie trzeba podawać parametru wskazującego na CA, jest to opcjonalne** - Parametr `ca` w konfiguracji OpenVPN nie jest opcjonalny jeśli zależy nam na weryfikacji tożsamości drugiej strony połączenia. Brak tego parametru spowoduje brak weryfikacji i nie zapewni zaufania. Zatem odpowiedź jest niepoprawna."
    },
    {
        "questionId": 329,
        "title": "Ktore funkcje i parametry konfiguracyjne PHP moga byc wykorzystane do ochrony przed atakami typu command injection? ",
        "answers": [
            {
                "text": "magic_quotes_gpc",
                "isCorrect": false
            },
            {
                "text": "addslashes()",
                "isCorrect": true
            },
            {
                "text": "mysql_escape_string()",
                "isCorrect": true
            },
            {
                "text": "strip_tags()",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "`addslashes()` to funkcja w PHP, która dodaje ukośniki odwrotne przed znakami, które mogą mieć specjalne znaczenie w kontekście powłoki systemowej (np. `, $, \", \\, itd.). To zabezpiecza przed interpretacją tych znaków jako poleceń powłoki, zamiast zwykłego tekstu. Na przykład, jeśli użytkownik wprowadzi w formularzu `polecenie; rm -rf /`, `addslashes()` zamieni to na `polecenie\\; rm -rf /`, co uniemożliwi wykonanie groźnej komendy. Jest to ważny krok w ochronie przed wstrzykiwaniem komend.\n`mysql_escape_string()` (w starszych wersjach PHP) lub `mysqli_real_escape_string()` (w nowszych wersjach), są funkcjami służącymi do oczyszczania stringów przed użyciem ich w zapytaniach do bazy danych MySQL, chroniąc przed wstrzykiwaniem SQL (SQL injection). Funkcja ta również dodaje ukośniki odwrotne przed znakami, które mogą mieć specjalne znaczenie, ale tym razem w kontekście SQL, a nie powłoki. Chociaż jej głównym zadaniem jest zabezpieczenie przed SQL injection, pośrednio może chronić przed wstrzykiwaniem komend jeśli dane z bazy danych są później wykorzystywane do stworzenia komendy w systemie operacyjnym. Na przykład, jeśli pobierzemy z bazy danych nieoczyszczony tekst, który zawiera znak specjalny np. `;`, a następnie użyjemy go w systemowej komendzie, możemy otworzyć lukę. `mysql_escape_string()` lub `mysqli_real_escape_string()` ochroni nas przed tą luką, pod warunkiem, że dane z bazy danych są wykorzystywane także w powłoce systemowej, a nie tylko w kontekście SQL.\n`strip_tags()` jest funkcją PHP służącą do usuwania znaczników HTML i PHP z ciągu znaków. Zabezpiecza przed wstrzykiwaniem kodu HTML/PHP. Na przykład, jeśli w formularzu użytkownik wprowadzi `<b>pogrubienie</b>`, `strip_tags()` usunie znaczniki `<b>` i `</b>`, pozostawiając sam tekst `pogrubienie`. Chroni to nas przed potencjalnym atakiem ze strony HTML/PHP. Funkcja ta jednak nie jest bezpośrednią ochrona przed atakami typu command injection, może co prawda pośrednio pomóc jeżeli aplikacja korzysta z parsera html w celu ustalenia polecenia, ale nie jest to jej główne zadanie.\n`magic_quotes_gpc` to **niepoprawna** odpowiedź. Jest to przestarzała funkcja PHP która, automatycznie dodawała ukośniki odwrotne przed niektórymi znakami w danych wejściowych pochodzących z GET, POST i COOKIE. Jej działanie było nieprzewidywalne i nie stanowiło skutecznego zabezpieczenia przed command injection i innymi atakami. Jest to mechanizm przestarzały i usunięty z nowszych wersji PHP. Zamiast magic_quotes_gpc należy stosować funkcję `addslashes()`(lub w nowszych wersjach  `mysqli_real_escape_string()`) we własnym kodzie, tam gdzie jest to niezbędne. W przeciwnym przypadku aplikacja może być podatna na ataki typu command injection.\nPrzykład: Załóżmy że mamy aplikacje, która na podstawie parametru przekazanego w URL (zastosowanie metody GET) wyświetla informacje na temat pliku. Nieprawidłowo napisana aplikacja mogłaby wyglądać tak: `<?php system(\"cat \".$_GET['file']); ?>` . Jeśli użytkownik wpisałby adres: `http://przyklad.pl/plik.php?file=/etc/passwd` aplikacja wyświetliłaby informacje o pliku /etc/passwd. Intruz mógłby wykorzystać ten mechanizm do wyświetlenia dowolnego pliku. Wykorzystanie funkcji `addslashes` :  `<?php system(\"cat \".addslashes($_GET['file'])); ?>` uniemożliwiłoby wykonanie takiej operacji. Intruz może spróbować zaatakować w inny sposób np. `http://przyklad.pl/plik.php?file=/etc/passwd%20|%20id`, `addslashes` zamieniłoby te znaki na `http://przyklad.pl/plik.php?file=/etc/passwd\\%20|\\%20id` co uniemożliwi wykonanie polecenia `id`.\nZatem, `addslashes()`, `mysql_escape_string()`, i `strip_tags()` przyczyniają się do zwiększenia bezpieczeństwa aplikacji, ale `magic_quotes_gpc` jest przestarzałą funkcją, której nie powinno się używać."
    },
    {
        "questionId": 330,
        "title": "Wskaz prawidlowe stwierdzena dotyczace metod uwierzytelniania systemow operacyjnych MS Windows w srodowisku sieciowym: ",
        "answers": [
            {
                "text": "Kerberos jest bezpieczniejszy niz LM i NTLM",
                "isCorrect": true
            },
            {
                "text": "LM jest bezpieczniejszy niz NTLM",
                "isCorrect": false
            },
            {
                "text": "Kerberos jest bezpieczniejszy niz NTLM, ale jest dostepny tylko w srodowisku domenowym",
                "isCorrect": true
            },
            {
                "text": "NTLM jest bezpieczniejszy niz LM",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Protokół uwierzytelniania Kerberos to zaawansowany mechanizm uwierzytelniania, który wykorzystuje bilety, a nie hasła przesyłane bezpośrednio, co czyni go bezpieczniejszym niż LM i NTLM.  LM (LAN Manager) i NTLM (NT LAN Manager) to starsze protokoły uwierzytelniania. LM jest znacznie mniej bezpieczny, gdyż przechowuje hasła w słabo zabezpieczony sposób, a sam protokół wykorzystuje słabe mechanizmy kryptograficzne. NTLM jest ulepszeniem LM, ale nadal jest mniej bezpieczny niż Kerberos.  Kerberos, jako protokół oparty na biletach, redukuje ryzyko przechwycenia haseł. Kerberos domyślnie jest stosowany w środowiskach domenowych MS Windows.\n\n**Odpowiedź 1: \"Kerberos jest bezpieczniejszy niż LM i NTLM\" - JEST POPRAWNA.**\nKerberos jest protokołem uwierzytelniania bazującym na biletach, przez co jest bezpieczniejszy niż protokoły LM i NTLM, które bazują na hasłach. Hasła w protokole LM są bardzo słabo zabezpieczone, a sam protokół wykorzystuje słabe mechanizmy kryptograficzne.  NTLM jest ulepszeniem protokołu LM, ale nadal nie jest tak bezpieczny jak protokół Kerberos.\n\n**Odpowiedź 2: \"LM jest bezpieczniejszy niż NTLM\" - JEST NIEPOPRAWNA.**\nProtokół LM jest zdecydowanie mniej bezpieczny niż NTLM. LM wykorzystuje słabe mechanizmy kryptograficzne i słabą metodę przechowywania haseł.  Zastosowanie protokołu LM naraża system na dużą podatność na atak. \n\n**Odpowiedź 3: \"Kerberos jest bezpieczniejszy niż NTLM, ale jest dostępny tylko w środowisku domenowym\" - JEST POPRAWNA.**\nKerberos jest bezpieczniejszy niż NTLM z uwagi na fakt, iż wykorzystuje bilety, które z założenia są jednorazowego użytku. Oczywiście aby Kerberos mógł działać poprawnie serwer na którym działa ta usługa musi być dostępny i sprawny. W systemie MS Windows Kerberos jest domyślnie wykorzystywany w środowiskach domenowych. W mniejszych środowiskach, w których nie ma potrzeby używania domeny najczęściej używanym protokołem jest NTLM.\n\n**Odpowiedź 4: \"NTLM jest bezpieczniejszy niż LM\" - JEST POPRAWNA.**\nProtokół NTLM stanowi ulepszenie w stosunku do protokołu LM. NTLM wykorzystuje mechanizmy kryptograficzne oraz inaczej przechowuje hasła, co nie wystarcza, by uznać ten protokół za bezpieczny, ale jest bezpieczniejszy od LM. W systemach operacyjnych MS Windows zaleca się rezygnację z przechowywania skrótów haseł w postaci LM."
    },
    {
        "questionId": 331,
        "title": "Czy program inetd to: ",
        "answers": [
            {
                "text": "jest waznym elementem systemu operacyjnego Linux, odpowiedzialny za uruchamianie innych programow",
                "isCorrect": true
            },
            {
                "text": "krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony",
                "isCorrect": false
            },
            {
                "text": "krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony, jest rodzicem dla wszystkich nowo powstalych procesow",
                "isCorrect": false
            },
            {
                "text": "bardzo wazny komponent systemu Linux, bez ktorego system operacyjny nie bedzie dzialal prawidlowo z uwagi na niemoznosc uruchamiania dodatkowych programow",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`inetd` to demon, który działa jako super-serwer lub meta-serwer w systemach operacyjnych Linux i Unix. Jego główną rolą jest nasłuchiwanie na określonych portach sieciowych. Kiedy na takim porcie pojawi się żądanie połączenia, `inetd` uruchamia odpowiedni program, który ma obsłużyć to połączenie. Jest to usługa pośrednicząca między żądaniami sieciowymi a procesami systemowymi. `inetd` sam w sobie nie jest usługą, ale mechanizmem, który zarządza innymi usługami. Zamiast mieć wiele procesów nasłuchujących na różnych portach, system ma jeden główny proces `inetd`, który czeka na przychodzące połączenia i zarządza ich uruchomieniem. Jest to szczególnie przydatne dla usług, które nie są często używane, ale muszą być dostępne, takie jak `finger` lub `telnet`.\n\n**Opcja 1: \"jest waznym elementem systemu operacyjnego Linux, odpowiedzialny za uruchamianie innych programow\"**\n\nTa odpowiedź jest **poprawna**. `inetd` faktycznie jest ważnym elementem, ponieważ ułatwia zarządzanie wieloma usługami sieciowymi. Jego zadaniem jest uruchamianie innych programów, co z kolei upraszcza administrację systemu. Bez `inetd`, każda usługa sieciowa musiałaby mieć swój własny proces nasłuchujący na dedykowanym porcie, co jest nieefektywne w kwestii wykorzystania zasobów i zarządzania.\n\n**Opcja 2: \"krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony\"**\n\nTa odpowiedź jest **niepoprawna**. Chociaż `inetd` pełni ważną rolę, to system operacyjny Linux może funkcjonować bez niego. Nowoczesne systemy Linux często wykorzystują `systemd` lub `xinetd` zamiast `inetd`. Te alternatywne systemy również pełnią rolę super-serwerów, ale oferują dodatkowe funkcje i lepsze zarządzanie zasobami. Zatem `inetd` nie jest krytyczny dla działania samego systemu operacyjnego Linux.\n\n**Opcja 3: \"krytyczny program w systemie operacyjnym Linux, ktory zawsze musi byc uruchomiony, jest rodzicem dla wszystkich nowo powstalych procesow\"**\n\nTa odpowiedź jest **niepoprawna**.  Chociaż `inetd` może uruchamiać inne procesy sieciowe, to nie jest on rodzicem dla *wszystkich* nowo powstałych procesów w systemie.  Rodzicem wszystkich procesów w systemach Linux jest zazwyczaj proces `init` (lub w nowoczesnych systemach `systemd`).  `inetd` odpowiada za zarządzanie specyficznymi procesami, które reagują na przychodzące połączenia sieciowe.\n\n**Opcja 4: \"bardzo wazny komponent systemu Linux, bez ktorego system operacyjny nie bedzie dzialal prawidlowo z uwagi na niemoznosc uruchamiania dodatkowych programow\"**\n\nTa odpowiedź jest **niepoprawna**. System Linux będzie działał prawidłowo bez `inetd`, choć uruchamianie dodatkowych programów sieciowych będzie wymagało innych rozwiązań (np. osobnych procesów dla każdego nasłuchującego portu). Aplikacje sieciowe mogą korzystać z innych demonów lub uruchamiać nasłuchiwanie na porcie bez pomocy `inetd`.  `inetd` jest udogodnieniem, a nie niezbędnym elementem do podstawowego funkcjonowania systemu operacyjnego. \n\nPodsumowując, `inetd` jest ważnym elementem w kontekście konfiguracji usług sieciowych, ale nie jest on krytyczny dla działania systemu. System operacyjny Linux może bez niego działać poprawnie. `inetd` jest mechanizmem, który uruchamia (a nie tworzy) inne programy, ułatwia zarządzanie usługami, ale jego rolę przejęły bardziej nowoczesne rozwiązania."
    },
    {
        "questionId": 332,
        "title": "Wskaz cechy mechanizmu SYN cookies: ",
        "answers": [
            {
                "text": "pozwala przegladarce na bezpieczna aktualizacje ciasteczek",
                "isCorrect": false
            },
            {
                "text": "minimalizuje ilosc informacji potrzebnych przegladarce do uwierzytelniania zdalnego dostepu",
                "isCorrect": false
            },
            {
                "text": "identyfikuje polaczenie wartoscia wpisywana do pola ACK",
                "isCorrect": true
            },
            {
                "text": "minimalizuje wielkosc zasobow przydzielanych przy odbiorze zadania nawiazania polaczenia",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "SYN cookies to mechanizm obronny przed atakami typu SYN flood. Atak SYN flood wykorzystuje protokół TCP, a konkretnie jego trójstopniowy proces nawiązywania połączenia (ang. _three-way handshake_). W normalnej sytuacji klient wysyła do serwera pakiet SYN, serwer odpowiada pakietem SYN+ACK, a klient przesyła pakiet ACK. W ataku SYN flood atakujący wysyła dużą liczbę pakietów SYN, ale nigdy nie wysyła pakietu ACK. Serwer w odpowiedzi na każdy SYN przydziela zasoby oczekując na ostateczne potwierdzenie, ale nigdy go nie otrzyma. W rezultacie, zasoby serwera zostają wyczerpane i serwer staje się niedostępny dla prawidłowo działających klientów. SYN cookies minimalizują obciążenie serwera w tej sytuacji. Serwer nie przydziela zasobów po otrzymaniu pakietu SYN. Zamiast tego, serwer generuje specjalną wartość, nazywaną ciasteczkiem SYN (_SYN cookie_) na podstawie parametrów pakietu SYN oraz tajnego klucza. To ciasteczko jest kodowane i wysyłane klientowi w pakiecie SYN+ACK jako pole `sequence number`. Klient odsyłając ostateczny pakiet ACK, nie przesyła ciasteczka, a jedynie potwierdzenie, czyli sekwencję, z jaką otrzymał pakiet SYN+ACK. Serwer na podstawie potwierdzenia odtwarza tajną wartość i jeśli wszystko jest w porządku przydziela zasoby i ustanawia połączenie.\n\n*   **\"pozwala przegladarce na bezpieczna aktualizacje ciasteczek\"** - *Nieprawidłowa odpowiedź*. Ciasteczka, o których mowa to ciasteczka HTTP (ang. HTTP cookies), używane przez przeglądarki do przechowywania danych sesyjnych. SYN cookies nie mają nic wspólnego z tym rodzajem ciasteczek.  SYN cookies są wykorzystywane do obrony przed atakiem SYN flood.\n\n*  **\"minimalizuje ilosc informacji potrzebnych przegladarce do uwierzytelniania zdalnego dostepu\"** - *Nieprawidłowa odpowiedź*. SYN cookies nie służą do uwierzytelniania. Nie minimalizują również ilości informacji potrzebnych przeglądarce. W rzeczywistości mechanizmy uwierzytelniania i SYN cookies są elementami, które występują na różnych warstwach modelu ISO/OSI, a także pełnią zupełnie inne funkcje. SYN cookies są mechanizmem obronnym na poziomie protokołu TCP w warstwie transportowej. Natomiast uwierzytelnianie w przeglądarce (np. przy wykorzystaniu loginu i hasła) jest mechanizmem, który występuje w wyższych warstwach modelu.\n\n*   **\"identyfikuje polaczenie wartoscia wpisywana do pola ACK\"** - *Prawidłowa odpowiedź*. To jest kluczowe. W protokole TCP pole ACK zawiera numer sekwencyjny oczekiwanego bajtu. W mechanizmie SYN cookies to pole jest wykorzystane do przekazania informacji generowanej przez serwer, na podstawie której serwer jest w stanie ustalić, czy dany klient prawidłowo przeszedł proces trójstopniowego nawiązywania połączenia.  Wartość wpisana do pola ACK nie jest losową wartością a powstaje w wyniku specyficznej procedury kodowania.\n\n*   **\"minimalizuje wielkosc zasobow przydzielanych przy odbiorze zadania nawiazania polaczenia\"** - *Prawidłowa odpowiedź*. Mechanizm SYN cookies z założenia minimalizuje wykorzystanie zasobów po odebraniu pakietu SYN. Zasoby są przydzielane dopiero po prawidłowym nawiązaniu połączenia na podstawie odpowiedzi na pakiet SYN-ACK zawierający SYN cookie, czyli po odebraniu pakietu ACK, gdy serwer zweryfikuje poprawność przesłanego potwierdzenia.  Dzięki temu, serwer nie ma potrzeby rezerwowania dużej ilości pamięci i czasu procesora w reakcji na potencjalnie złośliwe pakietu SYN."
    },
    {
        "questionId": 333,
        "title": "Jesli ls -l plik.txt wyglada nastepujaco -rwxr-xr-x+ 1 user group 1000 2005-01-10 09:00 plik.txt to chmod 715 plik.txt\" spowoduje:  ",
        "answers": [
            {
                "text": "zwiekszenie uprawnien wpisom ACL'owym",
                "isCorrect": false
            },
            {
                "text": "zmiane uprawnien grupie \"group\" dla tego pliku",
                "isCorrect": true
            },
            {
                "text": "zmniejszenie uprawnien wpisom ACL'owym",
                "isCorrect": false
            },
            {
                "text": "rozszerzenie uprawnien dla innych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Polecenie `chmod` w systemach Linux i Unix służy do zmiany uprawnień dostępu do plików i katalogów. Uprawnienia te są reprezentowane symbolicznie, np. `-rwxr-xr-x`, gdzie pierwszy znak oznacza typ pliku ( `-` dla pliku zwykłego, `d` dla katalogu, itp.), kolejne trzy znaki ( `rwx` ) określają uprawnienia właściciela pliku, następne trzy ( `r-x` ) – uprawnienia grupy właściciela, a ostatnie trzy ( `r-x` ) – uprawnienia pozostałych użytkowników. Litery oznaczają: `r` (read - odczyt), `w` (write - zapis) i `x` (execute - wykonanie). Dodatkowo, znak `+` na końcu stringa oznacza, że plik ma ustawione dodatkowe, rozszerzone uprawnienia zdefiniowane za pomocą list kontroli dostępu (ACL).\n\nW tym konkretnym przypadku, plik `plik.txt` ma początkowe uprawnienia `-rwxr-xr-x+`. To oznacza, że:\n*   Właściciel (user) ma pełne uprawnienia: odczyt, zapis i wykonanie (`rwx`).\n*   Grupa (group) ma uprawnienia do odczytu i wykonania (`r-x`).\n*   Pozostali użytkownicy mają uprawnienia do odczytu i wykonania (`r-x`).\n* Plik ma dodatkowo ustawione uprawnienia za pomocą ACL\n\nPolecenie `chmod 715 plik.txt` zmienia te uprawnienia przy użyciu notacji ósemkowej (oktalnej). Każda cyfra w notacji ósemkowej reprezentuje uprawnienia dla właściciela, grupy i innych, w tym samym porządku jak w notacji symbolicznej. Wartości są sumą bitową z:\n*  4 - prawo do odczytu (r)\n*  2 - prawo do zapisu (w)\n*  1 - prawo do wykonania (x)\n\nZatem cyfra `7` (4 + 2 + 1)  oznacza prawa odczytu, zapisu i wykonywania (rwx).  `1` (0 + 0 + 1) – prawo tylko do wykonywania( --x). `5` (4 + 0 + 1) – prawo do odczytu i wykonywania (r-x).\n\nPo wykonaniu polecenia `chmod 715 plik.txt` uprawnienia pliku zostaną zmienione następująco:\n*   Właściciel (user) będzie miał pełne uprawnienia (`rwx`).\n*   Grupa (group) będzie miała uprawnienia tylko do wykonania (`--x`).\n*   Pozostali użytkownicy będą mieli uprawnienia do odczytu i wykonania (`r-x`).\n\n**Odpowiedź pierwsza (niepoprawna): \"zwiekszenie uprawnien wpisom ACL'owym\"**\n`chmod` w żaden sposób nie modyfikuje rozszerzonych uprawnień zdefiniowanych przez ACL. Polecenie zmienia standardowe uprawnienia posixowe, a nie ACL, nawet jeśli plik ma przypisane wpisy ACL. W tym przypadku, uprawnienia zdefiniowane przez ACL mogą być silniejsze od uprawnień zdefiniowanych przez `chmod`.\n\n**Odpowiedź druga (poprawna): \"zmiane uprawnien grupie \"group\" dla tego pliku\"**\nJest to poprawna odpowiedź. `chmod 715 plik.txt` zmieni uprawnienia grupy `group`  z `r-x` na `--x`. Polecenie zmienia standardowe uprawnienia, a nie uprawnienia zdefiniowane za pomocą ACL.\n\n**Odpowiedź trzecia (niepoprawna): \"zmniejszenie uprawnien wpisom ACL'owym\"**\nJak zostało wspomniane w punkcie pierwszym, `chmod` nie zmienia uprawnień ACL. Dlatego jest to niepoprawna odpowiedź.\n\n**Odpowiedź czwarta (niepoprawna): \"rozszerzenie uprawnien dla innych\"**\nZmiana uprawnień dla _innych_ przez `chmod 715` zmieniają uprawnienia do odczytu i wykonania (`r-x`). W pierwotnych uprawnieniach pozostali użytkownicy również posiadali uprawnienia do odczytu i wykonania (`r-x`). Zatem nie są to rozszerzone uprawnienia, a te same.\n\n**Real-world implication:**\nWyobraźmy sobie plik konfiguracyjny `/etc/apache2/apache2.conf`, do którego, domyślnie, dostęp (odczyt i zapis) ma jedynie właściciel (root) oraz grupa (root) lub inna grupa systemowa. Jeśli chcemy, aby proces serwera WWW (na koncie `www-data`) mógł odczytywać ten plik, to nie zmieniamy praw do tego pliku komendą `chmod`, a stosujemy mechanizm ACL za pomocą którego nadajemy uprawnienia do czytania pliku konkretnemu użytkownikowi.  W sytuacji takiej, gdybyśmy użyli polecenia `chmod 777 apache2.conf`, to udostępnilibyśmy plik do zapisu każdemu użytkownikowi w systemie, co w konsekwencji byłoby niepożądane.\n\n**Pedagogical value:**\nPrawidłowa odpowiedź wymaga od studenta wiedzy na temat tego jak działa `chmod` i jak działa ACL. Zastosowanie ACL do uprawnień dostępu do plików nie zmienia uprawnień podstawowych. Podstawowe uprawnienia są tylko alternatywną formą zapisu tego, jakie uprawnienia do pliku posiada właściciel, grupa i pozostali użytkownicy. Listy ACL są dodatkowym, znacznie bardziej zaawansowanym narzędziem do precyzyjnego określenia dostępu do obiektów systemowych i nie są zamiennikiem uprawnień podstawowych."
    },
    {
        "questionId": 334,
        "title": "Zapora sieciowa wbudowana w Ms Win XP sp2: ",
        "answers": [
            {
                "text": "jest typu stateless",
                "isCorrect": false
            },
            {
                "text": "jest jedyna mozliwa do zastosowania zapora sieciowa w systemie",
                "isCorrect": false
            },
            {
                "text": "pozwala powiadamiac uzytkownika droga mailowa o zagrozeniach",
                "isCorrect": false
            },
            {
                "text": "jest zapora typu stateful",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Zapora sieciowa typu stateful (stanowa) śledzi stan połączeń sieciowych. Oznacza to, że zapora analizuje nie tylko pojedyncze pakiety danych, ale również całe sesje połączeń. Zapamiętuje informacje o połączeniach nawiązanych, a następnie wykorzystuje te informacje podczas filtrowania kolejnych pakietów z tych połączeń. Na przykład, gdy komputer w sieci lokalnej nawiązuje połączenie z serwerem w Internecie, zapora typu stateful zapamiętuje parametry tego połączenia (np. adres IP komputera, port, użyty protokół), aby móc później bez problemu przepuścić pakiety z odpowiedzią na ten sam port oraz na ten sam adres IP. Dzięki temu nie ma potrzeby dodawania reguł, które zezwalały by na odbiór pakietów na każdym porcie – wystarczy jedna reguła zezwalająca na nawiązanie połączenia z zewnątrz. Natomiast zapora sieciowa typu stateless (bezstanowa) nie zapamiętuje stanu połączeń i w celu zapewnienia poprawności przepływu danych musi być skonfigurowana bardzo dokładnie i musi posiadać reguły przepuszczające ruch na każdym porcie oraz dla każdego protokołu. Zapory bezstanowe działają znacznie szybciej, gdyż nie muszą przetwarzać tak dużej liczby informacji, jednakże są znacznie mniej bezpieczne od zapór stanowych.\n* **\"jest typu stateless\"** - To jest **nieprawidłowa** odpowiedź. Zapora sieciowa wbudowana w MS Windows XP SP2 jest zaporą stanową.\n* **\"jest jedyna mozliwa do zastosowania zapora sieciowa w systemie\"** - To jest **nieprawidłowa** odpowiedź. Istnieje wiele innych zapór sieciowych, które można zainstalować w systemie Windows XP, takich jak Kerio Personal Firewall, ZoneAlarm, a także inne zapory sprzętowe (np. dedykowane bramy firewall). Wbudowana zapora jest jedną z opcji, a nie jedyną możliwością.\n* **\"pozwala powiadamiac uzytkownika droga mailowa o zagrozeniach\"** - To jest **nieprawidłowa** odpowiedź. Wbudowana zapora w MS Windows XP SP2 nie ma funkcji powiadamiania użytkownika drogą mailową o zagrożeniach. Informacje o niebezpieczeństwach zapisywane są w logach, a ich przeglądanie możliwe jest przez systemowy podgląd zdarzeń.\n* **\"jest zapora typu stateful\"** - To jest **poprawna** odpowiedź.  Zapora systemu Windows XP SP2 jest zaporą typu stateful, tzn., że  śledzi stan połączeń sieciowych. To oznacza, że pamięta połączenia nawiązane przez komputer i dzięki temu może dynamicznie  filtrować pakiety wchodzące,  zezwalając na ruch odpowiedzi w ramach tych połączeń (bez jawnej definiowania reguł dla pakietów odpowiedzi). Ta funkcja pozwala na znacznie większą swobodę działania użytkownika chronionej sieci, oraz ogranicza  liczbę reguł konfiguracji."
    },
    {
        "questionId": 335,
        "title": "W jaki sposob mozna utworzyc wiele polaczen z danego hosta za pomoca programu OpenVPN?: ",
        "answers": [
            {
                "text": "nalezy powtorzyc wpisanie opcji: remote tyle razy ile polaczen VPN mamy utworzyc",
                "isCorrect": true
            },
            {
                "text": "nalezy uruchomic program OpenVPN z przelacznikiem: --force-multi-instance, wymuszajac w ten sposob uruchomienie wielu procesow programu OpenVPN do obslugi wielu",
                "isCorrect": false
            },
            {
                "text": "jednoczesnych polaczen vpn",
                "isCorrect": false
            },
            {
                "text": "nie ma takiej mozliwosci",
                "isCorrect": false
            },
            {
                "text": "nalezy uruchomic program OpenVPN z wieloma plikami konfiguracyjnymi, kazdy plik definiuje jedno polaczenie",
                "isCorrect": false
            },
            {
                "text": "nalezy wykorzystac opcje --mode server ale tylko dla polaczen z zastosowaniem certyfikatow SSL",
                "isCorrect": false
            },
            {
                "text": "nalezy uruchomic kolejne instancje programu OpenVPN wraz z osobnymi plikami konfiguracyjnymi",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Aby utworzyć wiele połączeń VPN z danego hosta za pomocą OpenVPN, konieczne jest uruchomienie wielu instancji programu OpenVPN, każda z osobnym plikiem konfiguracyjnym. OpenVPN nie obsługuje tworzenia wielu połączeń w ramach jednego procesu.\n\n*   **\"nalezy powtorzyc wpisanie opcji: remote tyle razy ile polaczen VPN mamy utworzyc\"** - To odpowiedź **niepoprawna**. Opcja `remote` w pliku konfiguracyjnym OpenVPN służy do określenia zdalnego adresu serwera, z którym klient ma nawiązać połączenie. Wpisanie opcji `remote` wielokrotnie w pojedynczym pliku konfiguracyjnym nie spowoduje utworzenia wielu połączeń, a raczej zostanie wzięta pod uwagę ostatnia definicja. Każde połączenie VPN jest osobnym tunelem (logicznie odseparowanym) i dlatego wymaga odrębnej konfiguracji i odrębnego procesu OpenVPN. To nie jest podejście modularne. Praktycznie wygląda to tak, że OpenVPN połączy się tylko z ostatnim wymienionym `remote`, czyli nie zbudujemy wielu połączeń.\n\n*   **\"nalezy uruchomic program OpenVPN z przelacznikiem: --force-multi-instance, wymuszajac w ten sposob uruchomienie wielu procesow programu OpenVPN do obslugi wielu\"** - To odpowiedź **niepoprawna**. W OpenVPN nie istnieje przełącznik `--force-multi-instance`. Jest to typowe mylne założenie. Użytkownicy często spodziewają się istnienia parametrów dla programów, które pozwolą na ich dostosowanie do nietypowych potrzeb. W tym wypadku nie ma możliwości wymuszenia wieloinstancyjności.\n\n*   **\"jednoczesnych polaczen vpn\"** - To odpowiedź **niepoprawna**, gdyż jest ona kontynuacją poprzedniej odpowiedzi.\n\n*   **\"nie ma takiej mozliwosci\"** - To odpowiedź **niepoprawna**. Istnieje możliwość utworzenia wielu połączeń, jednak wymaga to odpowiedniej konfiguracji i uruchomienia wielu instancji programu.\n\n*    **\"nalezy uruchomic program OpenVPN z wieloma plikami konfiguracyjnymi, kazdy plik definiuje jedno polaczenie\"** - To odpowiedź **niepoprawna**, gdyż brakuje w niej informacji o odrębnych instancjach programu OpenVPN. Samodzielne pliki konfiguracyjne nie pozwolą na utworzenie wielu połączeń. W przypadku tej odpowiedzi brakuje istotnej informacji o odrębnych instancjach programu.\n\n*  **\"nalezy wykorzystac opcje --mode server ale tylko dla polaczen z zastosowaniem certyfikatow SSL\"** - To odpowiedź **niepoprawna**. Opcja `--mode server` w OpenVPN określa, że dany proces działa jako serwer VPN i jest niezbędna, gdy chcesz odbierać połączenia od innych klientów VPN. Ale ustawienie tej opcji nie decyduje o ilości jednoczesnych połączeń ani nie wymusza używania certyfikatów SSL (w OpenVPN można korzystać z współdzielonego klucza).\n\n*   **\"nalezy uruchomic kolejne instancje programu OpenVPN wraz z osobnymi plikami konfiguracyjnymi\"** - To odpowiedź **poprawna**. Każde połączenie VPN w OpenVPN (w standardowej konfiguracji) wymaga osobnej instancji programu OpenVPN oraz osobnego pliku konfiguracyjnego. Oznacza to, że aby utworzyć np. 3 połączenia VPN, należy uruchomić trzy osobne procesy OpenVPN, każdy z innym plikiem konfiguracyjnym. Takie rozwiązanie pozwala na jednoczesne obsługiwanie wielu tuneli VPN. Przykładowo w systemie Linux można to zrobić następującymi poleceniami:\n\n    ```bash\n    openvpn --config config1.ovpn &\n    openvpn --config config2.ovpn &\n    openvpn --config config3.ovpn &\n    ```\n    Każde wywołanie `openvpn` uruchamia osobną instancję z własną konfiguracją (config1.ovpn, config2.ovpn, config3.ovpn). Każda z tych konfiguracji (ovpn) musi mieć definicję połączenia z innym serwerem (inną opcję `remote`) oraz unikalne adresy IP przypisane interfejsom tun/tap."
    },
    {
        "questionId": 336,
        "title": "Ktore polecenie bedzie poprawne, dla ustalenia DNAT (wybierz 2 odpowiedzi)?: ",
        "answers": [
            {
                "text": "iptables -t nat -A FORWARD -d 150.254.17.3 -i eth- -j DNAT --to 192.168.1.1",
                "isCorrect": false
            },
            {
                "text": "iptables -t nat -A PREROUTING -d 150.254.17.3 -i eth0 -j NAT --to 192.168.1.1",
                "isCorrect": false
            },
            {
                "text": "iptables -t nat -A PREROUTING -i eth0 -j SAME --to 150.254.17.2",
                "isCorrect": true
            },
            {
                "text": "iptables -t nat -A PREROUTING -d 150.254.17.3 -i eth0 -j DNAT --to 192.168.1.1",
                "isCorrect": true
            },
            {
                "text": "iptables -t nat -A POSTROUTING -d 150.254.17.3 -i eth0 -j DNAT --to 192.168.1.1",
                "isCorrect": false
            },
            {
                "text": "iptables -t nat -A POSTROUTING -o eth0 -j SAME --to 150.254.17.2",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Translacja adresów docelowych (DNAT, ang. Destination NAT) to proces zmiany adresu docelowego w nagłówku pakietu IP. Jest ona stosowana głównie na routerach i zaporach sieciowych, aby przekierować ruch sieciowy z zewnątrz do wewnętrznych serwerów. W systemie Linux, do konfiguracji DNAT używa się narzędzia `iptables`, operując na tablicy `nat` i łańcuchu `PREROUTING`.\n\n*   **`iptables -t nat -A FORWARD -d 150.254.17.3 -i eth- -j DNAT --to 192.168.1.1`** - **Niepoprawne**.  Ta opcja używa łańcucha `FORWARD`. Łańcuch `FORWARD` jest używany w sytuacji, gdy dany pakiet przechodzi przez router. Natomiast w przypadku, gdy ruter sam ma być celem końcowym takiego pakietu, w którym następuje przekierowanie portu, należy użyć łańcucha `PREROUTING`. Dodatkowo w podanym przykładzie użyto parametr -i eth- , w takim przypadku należy podać konkretny interfejs np eth0 , eth1. W przypadku gdy jest to dowolny interfejs należy pominąć ten parametr. Opcja `--to` wskazuje na adres IP serwera wewnętrznego, do którego będzie przekierowany ruch. Zatem cała reguła jest źle sformułowana.\n*   **`iptables -t nat -A PREROUTING -d 150.254.17.3 -i eth0 -j NAT --to 192.168.1.1`** - **Niepoprawne**. To polecenie używa tablicy `nat` i prawidłowego łańcucha `PREROUTING`, a także określa adres docelowy za pomocą opcji `-d`. Podaje również interfejs wejściowy.  Jednak występuje błąd w opcji akcji: nie istnieje akcja `NAT`, zamiast tego powinna zostać użyta akcja `DNAT`. Opcja `--to` również jest poprawna.\n*   **`iptables -t nat -A PREROUTING -i eth0 -j SAME --to 150.254.17.2`** - **Poprawne**.  To polecenie jest poprawne, ponieważ translacja odbywa się w łańcuchu `PREROUTING`. Opuszczono parametr -d co sprawia, że każdy pakiet który dociera z interfejsu eth0 zostanie przekierowany na port 150.254.17.2 z użyciem celu `SAME`. Parametr SAME sprawia, że źródłowy port i adres również zostają zmienione. Zatem reguła ta wykona translację adresu i portu zarówno docelowego jak i źródłowego w przypadku pakietów przychodzących na interfejs eth0.\n*   **`iptables -t nat -A PREROUTING -d 150.254.17.3 -i eth0 -j DNAT --to 192.168.1.1`** - **Poprawne**. To polecenie używa tablicy `nat` i prawidłowego łańcucha `PREROUTING`. Opcja `-d` podaje adres IP docelowy i na ten adres pakiety mają trafić. Został podany interfejs wejściowy. W nagłówku pakietu adres docelowy o wartości 150.254.17.3 po przejściu przez firewall zostanie zmieniony na wartość 192.168.1.1. Parametr `--to` wskazuje na adres IP serwera wewnętrznego, do którego będzie przekierowany ruch. Polecenie w poprawny sposób definiuje translację adresów docelowych(DNAT).\n*  **`iptables -t nat -A POSTROUTING -d 150.254.17.3 -i eth0 -j DNAT --to 192.168.1.1`** - **Niepoprawne**.  Ta odpowiedź  zawiera większość elementów poprawnej odpowiedzi, jednak jest jeden element, który ja dyskwalifikuje. Jest nim łańcuch **POSTROUTING**, łańcuch ten jest używany do zmiany adresów źródłowych w pakiecie. Do translacji adresu docelowego wymagany jest łańcuch `PREROUTING`.\n*  **`iptables -t nat -A POSTROUTING -o eth0 -j SAME --to 150.254.17.2`** - **Niepoprawne**.  Ta odpowiedź używa tablicy `nat` i łańcucha `POSTROUTING`. Użycie łańcucha `POSTROUTING` jest poprawne, w przypadku chęci zmiany adresu nadawcy w pakiecie, jednak nie o to chodzi w tym zadaniu. Został również wykorzystany interfejs wychodzący oraz cel `SAME` z parametrem `--to`. Parametr `--to`  jest parametrem celu `SNAT` i `DNAT` i nie ma zastosowania do celu `SAME`.\n\nKonkretny przykład:\nZałóżmy, że serwer WWW o adresie IP 192.168.1.1 działa w sieci lokalnej za zaporą ogniową, której publiczny adres to 150.254.17.3. Używając poprawnego polecenia `iptables -t nat -A PREROUTING -d 150.254.17.3 -j DNAT --to 192.168.1.1`, wszystkie pakiety przychodzące na adres 150.254.17.3 (publiczny adres zapory) i kierowane na port 80 (domyślny port usługi WWW) zostaną przekierowane na adres 192.168.1.1. Serwer WWW, który znajduje się w sieci lokalnej z perspektywy sieci publicznej widoczny będzie jako serwer zapory ogniowej."
    },
    {
        "questionId": 337,
        "title": "Ponizsza regula zostala wpisana na komputerze pelniacym role routera: iptables -t filter -A INPUT -m state --state NEW -j DROP ",
        "answers": [
            {
                "text": "odrzuca nowe polaczenia do tego komputera",
                "isCorrect": true
            },
            {
                "text": "odrzuca nowe polaczenia inicjalizowane przez ten komputer",
                "isCorrect": false
            },
            {
                "text": "odrzuca nowe polaczenia przechodzace przez ten komputer",
                "isCorrect": false
            },
            {
                "text": "DROP znaczy nie przeszukuj dalej zapory, przepusc pakiet",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`iptables` to narzędzie w systemach Linux służące do konfiguracji zapory sieciowej. Działa na poziomie jądra systemu operacyjnego i filtruje pakiety sieciowe na podstawie zdefiniowanych reguł. Reguły te są zorganizowane w tablicach i łańcuchach. Tablica `filter` odpowiada za filtrowanie pakietów, a w niej łańcuchy (`INPUT`, `OUTPUT`, `FORWARD`) definiują kierunek ruchu sieciowego, do którego mają być zastosowane. Łańcuch `INPUT` dotyczy pakietów docierających do komputera, na którym jest skonfigurowana zapora, a nie pakietów przez niego przepuszczanych czy z niego wychodzących. Flaga `-A` określa, że reguła jest dodawana na końcu łańcucha. Moduł `-m state` z opcją `--state NEW` jest używany do wyboru pakietów, które inicjują nowe połączenia TCP. W kontekście połączenia TCP, pakiet inicjujący, czyli pakiet SYN (synchronization), ma ustawioną flagę SYN i nie ma flagi ACK (acknowledgment). Natomiast akcja `-j DROP` powoduje odrzucenie pakietu.\n\n**Odpowiedź 1: \"odrzuca nowe polaczenia do tego komputera\" - Poprawna.**\nTa odpowiedź jest poprawna, ponieważ reguła działa w łańcuchu `INPUT`, który dotyczy pakietów, które mają dotrzeć do danego komputera, a nie do pakietów z niego wychodzących ani przesyłanych dalej. Dodatkowo reguła za pomocą modułu `state` i stanu `NEW` wyłapuje pakiety, które rozpoczynają nowe połączenia TCP, i to do danego komputera a nie z niego. Akcja `DROP` powoduje, że komputer nie odpowie na ten pakiet SYN, a klient który go wysłał nie otrzyma żadnej zwrotnej informacji (ani akceptu, ani też komunikatu o odrzuceniu połączenia). W praktyce oznacza to, że komputer będzie blokował próby nawiązania z nim nowych połączeń. \nPrzykładowo jeśli komputer pełniący role routera ma adres IP 192.168.1.1 to ta reguła nie dopuści do nawiązania nowego połączenia z tym komputerem.\n\n**Odpowiedź 2: \"odrzuca nowe polaczenia inicjalizowane przez ten komputer\" - Niepoprawna.**\nTa odpowiedź jest niepoprawna, ponieważ reguła działa w łańcuchu `INPUT`, który filtruje tylko pakiety docierające do komputera, a nie pakiety wysyłane z komputera (te filtruje łańcuch `OUTPUT`). A zatem nie dotyczy ona nowych połączeń inicjowanych przez ten komputer. W praktyce reguła ta nie wpływa na ruch generowany przez ten komputer, a jedynie na ruch jaki chce do niego trafić.\n\n**Odpowiedź 3: \"odrzuca nowe polaczenia przechodzace przez ten komputer\" - Niepoprawna.**\nTa odpowiedź jest niepoprawna, ponieważ łańcuch `INPUT` filtruje tylko pakiety docierające do komputera, a nie pakiety, które przez niego przepływają (te filtruje łańcuch `FORWARD`). Ta reguła nie ma wpływu na to, czy pakiety przechodzące przez router będą odrzucane.\n\n**Odpowiedź 4: \"DROP znaczy nie przeszukuj dalej zapory, przepusc pakiet\" - Niepoprawna.**\nTa odpowiedź jest niepoprawna, ponieważ akcja `DROP` w `iptables` oznacza, że pakiet pasujący do reguły jest odrzucany, a nie przepuszczany. Dodatkowo akcja DROP powoduje, że nie jest sprawdzana dalsza część reguł na danym łańcuchu. Pakiety te są tracone bez powiadomienia nadawcy. A zatem po napotkaniu reguły z akcją DROP zapora nie szuka dalej w kolejnych regułach tylko odrzuca dany pakiet."
    },
    {
        "questionId": 338,
        "title": "Narzedzie OpenVPN: ",
        "answers": [
            {
                "text": "dziala tylko na protokole TCP",
                "isCorrect": false
            },
            {
                "text": "wykorzystuje mechanizm pre-shared key do losowego generowania kluczy",
                "isCorrect": false
            },
            {
                "text": "nie ma wyroznionego programu serwerowego i klienckiego",
                "isCorrect": false
            },
            {
                "text": "jest przykladem SSL-VPN",
                "isCorrect": true
            },
            {
                "text": "wykorzystuje certyfikaty MD5 i funkcje skrotu SHA-1 do uwierzytelniania stron i szyfrowania ruchu sieciowego",
                "isCorrect": false
            },
            {
                "text": "wykorzystuje mechanizm SSL-VPN do laczenia sie z serwerami wspierajacymi protokol https np. Apache",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "OpenVPN jest przykładem implementacji technologii SSL-VPN, która umożliwia tworzenie bezpiecznych połączeń typu tunel. SSL-VPN, w przeciwieństwie do IPsec VPN, wykorzystuje protokół SSL/TLS do szyfrowania danych przesyłanych w tunelu. OpenVPN może działać zarówno w trybie klienta, jak i serwera, a do tworzenia tunelu używa wirtualnych interfejsów sieciowych (TUN/TAP). Jest to bardzo elastyczne narzędzie pozwalające na zbudowanie połączeń VPN o różnym poziomie bezpieczeństwa.\n\n**Opcja 1: \"działa tylko na protokole TCP\" - Niepoprawna.**\nOpenVPN może działać zarówno na protokole TCP, jak i UDP. TCP zapewnia bardziej niezawodne połączenie, natomiast UDP jest szybsze i bardziej odpowiednie dla strumieniowania danych w czasie rzeczywistym. Użytkownik ma możliwość konfiguracji używanego protokołu podczas konfiguracji połączenia. Przykładowo w pliku konfiguracyjnym może zostać zdefiniowana opcja „proto tcp-server” lub opcja „proto udp-server” dla trybu serwera lub odpowiednio opcje „proto tcp-client” i „proto udp-client” dla trybu klienta.\n\n**Opcja 2: \"wykorzystuje mechanizm pre-shared key do losowego generowania kluczy\" - Niepoprawna.**\nOpenVPN faktycznie może używać mechanizmu pre-shared key, który działa na zasadzie współdzielonego tajnego klucza między stronami połączenia, jednak nie jest wykorzystywany do losowego generowania kluczy. Pre-shared key to tajny ciąg znaków, który jest ustalany z góry przez administratorów systemu i jest wykorzystywany do uwierzytelniania stron oraz do szyfrowania komunikacji między nimi. OpenVPN domyślnie wykorzystuje mechanizm algorytmu Blowfish z kluczem 128 bitów do szyfrowania komunikacji. OpenVPN w tym przypadku nie dokonuje losowego generowania kluczy, gdyż są one z góry zdefiniowane. OpenVPN może losowo generować tylko klucze sesji za pomocą wynegocjowanego tajnego klucza współdzielonego ale domyślnie ten mechanizm nie jest używany. Bezpieczniejszą alternatywą jest użycie certyfikatów X.509, gdzie tajny klucz jest kluczem prywatnym użytkownika i nie jest potrzebny mechanizm pre-shared key.\n\n**Opcja 3: \"nie ma wyroznionego programu serwerowego i klienckiego\" - Niepoprawna.**\nOpenVPN nie posiada osobnych programów dla klienta i serwera. Ten sam program wykonywalny `openvpn` jest używany po obu stronach tunelu. Różnica polega jedynie na pliku konfiguracyjnym, który definiuje sposób działania. Jeden z komputerów jest konfigurowany jako serwer nasłuchujący połączeń a drugi jako klient nawiązujący połączenie.\n\n**Opcja 4: \"jest przykładem SSL-VPN\" - Poprawna.**\nJest to podstawowa cecha OpenVPN, który działa jak SSL-VPN, wykorzystując protokół SSL/TLS (Transport Layer Security, który jest następca SSL) do tworzenia bezpiecznych połączeń VPN. Oznacza to, że OpenVPN wykorzystuje bibliotekę OpenSSL, aby zrealizować szyfrowanie przesyłanych danych i uwierzytelnienie stron. Wykorzystuje certyfikaty X.509 lub współdzielone klucze w połączeniu z kryptografią asymetryczną (np. algorytm Diffiego-Hellmana). To odróżnia go od VPN-ów opartych o protokół IPsec, który działa bezpośrednio na poziomie warstwy IP i często wykorzystuje inne algorytmy.  Przykładowo popularne serwery OpenVPN stosują algorytm blowfish lub AES z kluczem 128, 192 lub 256 bitów oraz funkcje skrótu MD5 lub SHA-1.\n\n**Opcja 5: \"wykorzystuje certyfikaty MD5 i funkcje skrotu SHA-1 do uwierzytelniania stron i szyfrowania ruchu sieciowego\" - Niepoprawna.**\nOpenVPN może korzystać z algorytmów MD5 lub SHA1 w połączeniu z algorytmem HMAC w celu weryfikacji integralności danych w mechanizmach opartych o współdzielony klucz. Do weryfikacji autentyczności i tworzenia kluczy sesji protokół TLS (w którym opiera się OpenVPN) wykorzystuje algorytmy szyfrowania asymetrycznego a certyfikaty X.509 służą do rozdzielania kluczy publicznych. OpenVPN używa algorytmów symetrycznych do szyfrowania samego ruchu sieciowego po uprzednim uzgodnieniu tajnego klucza symetrycznego algorytmem klucza publicznego, najczęściej są to algorytmy AES, Blowfish, 3DES, CAST. Zastosowanie MD5 lub SHA1 występuje jedynie w algorytmie HMAC (funkcja skrótu z kluczem), który służy do weryfikacji integralności klucza. W celu weryfikacji integralności wiadomości i tworzenia podpisu cyfrowego stosowane są certyfikaty X.509 oraz algorytmy szyfrowania asymetrycznego RSA lub ElGamal.\n\n**Opcja 6: \"wykorzystuje mechanizm SSL-VPN do laczenia sie z serwerami wspierajacymi protokol https np. Apache\" - Niepoprawna.**\nOpenVPN nie służy do łączenia z serwerami HTTPS (które również wykorzystują SSL/TLS).  OpenVPN tworzy tunel warstwy IP, a nie na poziomie protokołu aplikacji. OpenVPN używa własnego protokołu opartym o bibliotekę OpenSSL, który jest bardziej elastyczny od protokołu HTTPS. Użycie HTTPS do tworzenia tuneli wirtualnych jest możliwe, jednak jest rzadko stosowane gdyż OpenVPN, czy inne dedykowane mechanizmy tworzenia VPN oferują więcej możliwości."
    },
    {
        "questionId": 339,
        "title": "Narzedzie Vtun to: ",
        "answers": [
            {
                "text": "samodzielny pakiet niskopoziomowego(dzialajacego na poziomie jadra ) oprogramowania do tworzenia podsieci VPN",
                "isCorrect": false
            },
            {
                "text": "proste narzedzie do tworzenia polaczen VPN korzystajace tylko z jednego pliku konfiguracyjnego i zestawu narzedzi obecnych w systemie",
                "isCorrect": true
            },
            {
                "text": "narzedzie dzialajace na poziomie warstwy uzytkownika ( tzw. userland ) pozwalajace tworzyc tylko pojedyncze polaczenia VPN przy uzyciu prostego pliku",
                "isCorrect": false
            },
            {
                "text": "konfiguracyjnego vtund.",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`Vtun` to narzędzie do tworzenia tuneli VPN (Virtual Private Network) działające w przestrzeni użytkownika (_userland_), co oznacza, że nie wchodzi bezpośrednio w interakcję z jądrem systemu operacyjnego, ale wykorzystuje do tego API dostarczane przez jądro. Pozwala ono tworzyć tunele VPN głównie w systemach operacyjnych z rodziny Linux/Unix. W odróżnieniu od rozwiązań zintegrowanych na poziomie jądra systemu operacyjnego (np. IPsec), `vtun` jest bardziej prostym i szybkim rozwiązaniem, które nie wymaga skomplikowanej konfiguracji.\n    \n    *   **\"samodzielny pakiet niskopoziomowego(dzialajacego na poziomie jadra ) oprogramowania do tworzenia podsieci VPN\"** -  _Niepoprawna_. Opis ten odnosi się bardziej do narzędzi takich jak OpenSWAN, które implementują IPsec bezpośrednio w jądrze systemu. `Vtun` działa na wyższym poziomie, w przestrzeni użytkownika. Określenie pakiet niskopoziomowy, opisuje mechanizmy które wchodzą w interakcję bezpośrednio z jądrem systemu operacyjnego. Takie pakiety posiadają dostęp do zasobów na niskim poziomie abstrakcji. Pakiety działające w przestrzeni użytkownika wykorzystują API udostępniane przez jądro. Użycie pakietu działającego w jądrze wiąże się z wymuszeniem załadowania modułu jądra co dodatkowo nie jest pożądane przy tworzeniu bezpiecznego połączenia.\n\n    *   **\"proste narzedzie do tworzenia polaczen VPN korzystajace tylko z jednego pliku konfiguracyjnego i zestawu narzedzi obecnych w systemie\"** - _Poprawna_. `Vtun` jest znane z łatwości konfiguracji, która najczęściej sprowadza się do edycji pojedynczego pliku konfiguracyjnego. Dodatkowo, `vtun` korzysta z standardowych narzędzi systemowych, nie wymagając instalacji dodatkowych komponentów. Z uwagi na swoją prostotę `vtun` jest powszechnie stosowane w środowisku hobbystycznym oraz w celu szybkiego zestawiania połączeń VPN. Przykładowo jeśli mamy dwa komputery z systemem Linux to do zestawienia połączenia VPN z użyciem `vtun` wystarczy skopiowanie wygenerowanego pliku konfiguracyjnego oraz pliku z kluczem.\n\n    *  **\"narzedzie dzialajace na poziomie warstwy uzytkownika ( tzw. userland ) pozwalajace tworzyc tylko pojedyncze polaczenia VPN przy uzyciu prostego pliku\"** -  _Niepoprawna_. Chociaż `vtun` działa w przestrzeni użytkownika (_userland_), nie jest ono ograniczone tylko do tworzenia pojedynczych połączeń VPN. Potrafi tworzyć wiele tuneli jednocześnie.  Mechanizmy działające w przestrzeni użytkownika są z założenia bezpieczniejsze, gdyż nie ingerują bezpośrednio w jądro. Jednakże są bardziej ograniczone i posiadają ograniczony dostęp do systemowych funkcji.\n\n    *   **\"konfiguracyjnego vtund.\"** - _Niepoprawna_. Ta odpowiedź jest niekompletna i wprowadza błąd, ponieważ sugeruje istnienie pliku konfiguracyjnego o nazwie `vtund.`, który jest nieprawdziwy. `Vtun` co prawda korzysta z pliku konfiguracyjnego, ale jego nazwa zależy od decyzji użytkownika. Nazwa `vtund` to nazwa demona, czyli procesu, który nasłuchuje na przychodzące połączenia."
    },
    {
        "questionId": 340,
        "title": "Program Vtun dziala w architekturze: ",
        "answers": [
            {
                "text": "punkt - punkt",
                "isCorrect": true
            },
            {
                "text": "klient - serwer",
                "isCorrect": false
            },
            {
                "text": "polaczenia peer-to-peer dla kazdego polaczenia",
                "isCorrect": false
            },
            {
                "text": "w zadnej z powyzszych poniewaz Vtun jest bardzo prosty i nie zawiera w sobie zadnej skomplikowanej architektury",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Vtun tworzy tunele wirtualne w architekturze punkt-punkt. Oznacza to, że Vtun ustanawia bezpośrednie, szyfrowane połączenie pomiędzy dwoma konkretnymi węzłami sieci.  Dwa końce tunelu tworzonego przez Vtun to zazwyczaj pojedyncze komputery, routery lub inne urządzenia sieciowe. Tunele te zapewniają bezpieczne połączenie przez publiczną sieć, taką jak Internet, gdzie przesyłane dane są chronione przed podsłuchem lub modyfikacją.\n\n*   **\"punkt - punkt\"**\n    *   **Poprawna odpowiedź.**  Architektura punkt-punkt oznacza, że połączenie jest ustanawiane bezpośrednio między dwoma zdefiniowanymi punktami. W przypadku Vtun, jeden koniec tunelu nasłuchuje na połączenia (serwer), a drugi koniec łączy się z pierwszym, tworząc bezpośredni, szyfrowany tunel. Jest to najprostsza forma sieci VPN, która nie wykorzystuje centralnego serwera do zarządzania połączeniami. \n    *   **Praktyczne implikacje:** Ustawienie połączenia VPN za pomocą Vtun między dwoma oddziałami firmy pozwala na utworzenie bezpiecznego kanału do wymiany danych.\n*   **\"klient - serwer\"**\n    *   **Niepoprawna odpowiedź.** Architektura klient-serwer oznacza, że wiele komputerów-klientów łączy się z jednym centralnym komputerem-serwerem. Vtun nie działa w ten sposób. Vtun tworzy bezpośrednie połączenia \"punkt-punkt\", gdzie jeden host pełni rolę serwera, a drugi rolę klienta (tylko w kontekście zestawiania połączenia). Po ustanowieniu połączenia, dwa węzły wymieniają dane między sobą w sposób bezpośredni.\n    *   **Praktyczne implikacje:** Typowe systemy VPN oparte o architekturę klient-serwer to np. OpenVPN w konfiguracji z centralnym serwerem VPN i wieloma klientami. Vtun nie tworzy takiej scentralizowanej architektury.\n*   **\"polaczenia peer-to-peer dla kazdego polaczenia\"**\n    *   **Niepoprawna odpowiedź.** Architektura peer-to-peer (_P2P_) oznacza, że wszystkie węzły sieci działają na tym samym poziomie, każdy węzeł może działać jako klient i serwer jednocześnie. W przypadku Vtun, tunel jest tworzony bezpośrednio między dwoma zdefiniowanymi węzłami, a nie w zdecentralizowany sposób.\n    *   **Praktyczne implikacje:** Sieci P2P cechuje duża elastyczność i brak centralnego punktu zarządzania siecią, natomiast Vtun jest wykorzystywany do tworzenia połączeń VPN o zdefiniowanych na stałe węzłach.\n*    **\"w zadnej z powyzszych poniewaz Vtun jest bardzo prosty i nie zawiera w sobie zadnej skomplikowanej architektury\"**\n    *    **Niepoprawna odpowiedź.** Mimo, że konfiguracja Vtun może wydawać się prosta, to nie znaczy, że nie ma on zdefiniowanej architektury. Vtun realizuje połączenie w oparciu o topologię punkt-punkt, która jest prostą lecz podstawową architekturą sieciową. Odpowiedź ta ignoruje pojęcie architektury w kontekście rozwiązań sieciowych.\n    *   **Praktyczne implikacje:** Chociaż Vtun jest prosty w konfiguracji, to opiera się na konkretnym modelu połączeń."
    },
    {
        "questionId": 341,
        "title": "Program Vtun dziala: ",
        "answers": [
            {
                "text": "na porcie domyslnym 1045 ale mozna to zmienic",
                "isCorrect": false
            },
            {
                "text": "na porcie domyslnym 5000 i mozna to zmienic ale trzeba przekompilowac kod programu",
                "isCorrect": false
            },
            {
                "text": "na domyslnym porcie 5000",
                "isCorrect": true
            },
            {
                "text": "na porcie domyslnym 1001 mozna to zmienic w pliku konfiguracyjnym vtund.conf",
                "isCorrect": false
            },
            {
                "text": "na porcie domyslnym 1045 ale mozna to bez problemu zmienic w pliku konfiguracyjnym vtund.conf",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół Vtun, służący do tworzenia tuneli VPN (Virtual Private Network), domyślnie nasłuchuje na porcie UDP o numerze 5000. Jest to standardowy port, który został przypisany do tego protokołu i pozwala na identyfikację tego protokołu w ruchu sieciowym. Oznacza to, że jeśli serwer Vtun nie zostanie inaczej skonfigurowany, klient będzie domyślnie próbował nawiązać z nim połączenie na tym właśnie porcie.\n\n**Odpowiedź 1: \"na porcie domyslnym 1045 ale mozna to zmienic\"**\nTa odpowiedź jest niepoprawna. Chociaż protokoły i aplikacje często umożliwiają zmianę portu na którym nasłuchują, port domyślny dla protokołu Vtun to 5000 a nie 1045. Ponadto, nie zawsze zmiana ta jest banalna i wymaga jedynie edycji pliku konfiguracyjnego, często port jest zaprogramowany na sztywno i trzeba zmienić kod źródłowy programu.\n\n**Odpowiedź 2: \"na porcie domyslnym 5000 i mozna to zmienic ale trzeba przekompilowac kod programu\"**\nTa odpowiedź jest niepoprawna. Pomimo, że poprawnie wskazuje port domyślny (5000), niepoprawnie wskazuje sposób jego zmiany, sugerując konieczność rekompilacji programu. Choć rzeczywiście niektóre aplikacje mogą wymagać rekompilacji, zmiana portu w aplikacji Vtun jest możliwa do wykonania poprzez zmianę parametrów w odpowiednim pliku konfiguracyjnym a nie przez zmianę kodu źródłowego.\n\n**Odpowiedź 3: \"na domyslnym porcie 5000\"**\nTa odpowiedź jest poprawna. Protokół Vtun domyślnie wykorzystuje port UDP o numerze 5000. Jest to port znany i udokumentowany jako port powszechnie wykorzystywany przez ten protokół.\n\n**Odpowiedź 4: \"na porcie domyslnym 1001 mozna to zmienic w pliku konfiguracyjnym vtund.conf\"**\nTa odpowiedź jest niepoprawna. Program Vtun nie używa portu 1001 jako domyślnego, a plik konfiguracyjny który ten protokół wykorzystuje nie nazywa się vtund.conf tylko jest wskazany przez opcję -config np. plik static.conf dla trybu tun.\n\n**Odpowiedź 5: \"na porcie domyslnym 1045 ale mozna to bez problemu zmienic w pliku konfiguracyjnym vtund.conf\"**\nTa odpowiedź jest niepoprawna. Niepoprawnie wskazuje domyślny port (1045) oraz plik konfiguracyjny (vtund.conf), który nie istnieje. Natomiast poprawnie wskazuje, że port może być zmieniony przez konfigurację pliku.\n\n**Real-world application:**\nZnajomość domyślnych portów jest bardzo ważna przy konfigurowaniu zapór ogniowych. Administrator sieci musi wiedzieć, które porty powinny być otwarte dla konkretnych usług i aplikacji. Ustawianie reguł blokujących zbędny ruch jest jedną z podstawowych zasad bezpieczeństwa sieciowego. Na przykład jeśli administrator w firmie nie wykorzystuje połączeń VPN opartych o Vtun to port 5000 powinien zostać zablokowany na zapory. Analogicznie, jeśli administrator wykorzystuje protokół SSH to powinien zezwolić na ruch przychodzący na port TCP o numerze 22. W celu zminimalizowania zagrożeń spowodowanych wystawieniem usług na publiczne porty konieczne jest zmienianie portów domyślnych, w celu utrudnienia potencjalnych ataków automatycznych. Konkretny przykład, serwer SSH domyślnie nasłuchuje na porcie 22 jednak nic nie stoi na przeszkodzie, aby zmienić ten numer na inny. Ustawienie portu na innym numerze niż standardowy nie zabezpieczy serwera w 100%, ale skutecznie wyeliminuje większość niepożądanych działań botów."
    },
    {
        "questionId": 342,
        "title": "Polaczenie w Vtun przebiega nastepujaco: ",
        "answers": [
            {
                "text": "w momencie tworzenia polaczenia wykonywane sa odpowiednie podsekcje up w definicji danego polaczenia ktore ma zostac utworzone, w momencie zakonczenia polaczenia wykonywana jest podsekcja down w definicji polaczenia",
                "isCorrect": false
            },
            {
                "text": "po nawiazaniu polaczenia obie strony uzgadniaja parametry polaczenia takie jak np. haslo i rodzaj transmisji danych, w momencie zakonczenia polaczenia nastepuje specjalna procedura rozpoczynana przez strone, ktora chce zakonczyc polaczenie",
                "isCorrect": false
            },
            {
                "text": "w zaden z wymienionych, na poczatku sposobow, obie strony musza wymienic sie ustalonym haslem, potwierdzic jego prawdziwosc, wynegocjowac parametry transmisji i dopiero tworzone jest polaczenie do przesylania danych, zakonczenie rozpoczynane jest przez dowolna strone",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Proces tworzenia bezpiecznego połączenia VPN (Virtual Private Network), w tym przypadku z użyciem narzędzia Vtun, obejmuje uzgodnienie parametrów sesji oraz bezpieczne przekazanie kluczy kryptograficznych. W przypadku Vtun, wymiana danych służących do ustalenia parametrów połączenia następuje przed utworzeniem tunelu, co zapewnia poufność oraz integralność połączenia VPN. Do tego służy początkowa procedura uzgadniania.\n\n**Odpowiedź 1: \"w momencie tworzenia polaczenia wykonywane sa odpowiednie podsekcje up w definicji danego polaczenia ktore ma zostac utworzone, w momencie zakonczenia polaczenia wykonywana jest podsekcja down w definicji polaczenia\"**\n   - Ta odpowiedź jest niepoprawna. Chociaż Vtun, podobnie jak wiele innych narzędzi, może wykorzystywać sekcje \"up\" i \"down\" w konfiguracji do wykonywania skryptów przed i po nawiązaniu połączenia, to nie opisuje to samej procedury nawiązania połączenia. Te sekcje, w istocie, konfigurują lokalne środowisko po nawiązaniu tunelu, ale nie mają bezpośredniego wpływu na proces uzgadniania parametrów sesji. Praktycznie: Skrypty \"up\" i \"down\" zazwyczaj ustawiają trasę w lokalnym systemie, modyfikują interfejs sieciowy, jednak nie mają wpływu na sam proces uzgadniania parametrów bezpiecznego kanału.\n  \n**Odpowiedź 2: \"po nawiazaniu polaczenia obie strony uzgadniaja parametry polaczenia takie jak np. haslo i rodzaj transmisji danych, w momencie zakonczenia polaczenia nastepuje specjalna procedura rozpoczynana przez strone, ktora chce zakonczyc polaczenie\"**\n   - Ta odpowiedź jest niepoprawna. Proces uzgadniania parametrów połączenia, w tym kluczy szyfrowania, musi nastąpić _przed_ transmisją danych przez tunel, aby dane te mogły być chronione. Wyobraźmy sobie sytuację, że najpierw przesyłamy dane a dopiero potem ustalamy hasło i szyfrowanie. Takie podejście jest nielogiczne. Ponadto zakończenie połączenia może być nagłe i nie zawsze musi zawierać specjalną procedurę. W typowej sytuacji zerwanie łącza po prostu przerywa połączenie. Praktycznie: Zanim zaczniemy przesyłać dane musimy chronić je odpowiednim szyfrem.\n \n**Odpowiedź 3: \"w zaden z wymienionych, na poczatku sposobow, obie strony musza wymienic sie ustalonym haslem, potwierdzic jego prawdziwosc, wynegocjowac parametry transmisji i dopiero tworzone jest polaczenie do przesylania danych, zakonczenie rozpoczynane jest przez dowolna strone\"**\n   - Ta odpowiedź jest poprawna. Poprawny proces nawiązywania połączenia Vtun wymaga początkowej bezpiecznej wymiany danych w celu wynegocjowania parametrów szyfrowania. Następnie weryfikacja odbywa się poprzez potwierdzenie poprawności hasła lub użycie kluczy kryptograficznych. Utworzenie tunelu do przesyłania danych następuje dopiero po zakończeniu procedury weryfikacji i negocjacji. Dodatkowo warto podkreślić, że zakończenie połączenia może być zainicjowane przez dowolną ze stron. Praktycznie: Tak działa każde bezpieczne połączenie VPN - bez początkowej weryfikacji nie możemy uważać połączenia za bezpieczne."
    },
    {
        "questionId": 343,
        "title": "Czy polecenie jest poprawne? iptables -t mangle -A PREROUTING -s localnet -d ! localnet -m ipp2p --dc -m comment --comment \"zla regulka\" -j TTL --ttl-set 1: ",
        "answers": [
            {
                "text": "tak, ale system bedzie usuwal te pakiety",
                "isCorrect": true
            },
            {
                "text": "tak, lecz taka regula niczego nie zmieni, gdyz nie ma celu ACCEPT lub DROP",
                "isCorrect": false
            },
            {
                "text": "nie, gdyz nie mozna uzywac wielu argumentow \"-m\"",
                "isCorrect": false
            },
            {
                "text": "nie, gdyz cel TTL moze byc uzywany tylko w lancuchu POSTROUTING",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`iptables` to narzędzie w systemie Linux, działające w przestrzeni użytkownika, które pozwala na konfigurację zapory sieciowej Netfilter wbudowanej w jądro systemu operacyjnego. Pozwala ono definiować reguły filtrowania pakietów i sterować ruchem sieciowym. `iptables` działa na różnych tablicach, z których każda ma określone zadanie i różny zbiór dozwolonych akcji. W tym pytaniu, szczególnie istotna jest tablica `mangle`, która służy do modyfikacji nagłówków pakietów. Tablica ta oferuje wiele celów, które operują na nagłówkach pakietów.\n\n**Poprawna odpowiedź:**\n> tak, ale system będzie usuwał te pakiety\n\nTablica `mangle` jest miejscem, gdzie dokonujemy modyfikacji nagłówków pakietów. Opcja `-j TTL` z argumentem `--ttl-set 1` ustawia wartość pola TTL w nagłówku IP na 1. Pole TTL (_Time To Live_) określa liczbę przeskoków przez routery, jaką dany pakiet może pokonać zanim zostanie usunięty, aby nie powodować pętli w sieci. Celem `TTL` można operować na nagłówkach w pakietach bez konieczności akceptowania pakietu (`-j ACCEPT`) lub usunięcia pakietu (`-j DROP`). Pakiet po wykonaniu akcji w obrębie tablicy `mangle` jest przekazywany do dalszej analizy w łańcuchach, w tablicach _nat_ i/lub _filter_, które określają czy pakiet ma być usunięty, lub przekazany dalej. Ustawienie `--ttl-set 1` spowoduje, że pakiety opuszczające system z takim TTL po przejściu przez router zostaną usunięte, gdyż po przesunięciu się przez router pole TTL zostanie zmniejszone do 0. Reguła jest poprawna składniowo, mimo że nie stosuje domyślnych akcji (-j ACCEPT/DROP). Reguła ta działa i ma pewien sens. Dodatkowo z uwagi, że nie ma żadnej reguły po niej, która zezwalałaby na przepuszczanie ruchu, wszystkie pakiety, które zostaną dopasowane do danej reguły zostaną po wykonaniu akcji w tablicy `mangle` usunięte.\n\n**Niepoprawne odpowiedzi:**\n\n> tak, lecz taka regula niczego nie zmieni, gdyż nie ma celu ACCEPT lub DROP\n\nJest to niepoprawna odpowiedź. W tablicy `mangle` nie musi być docelowo zdefiniowanej akcji `ACCEPT` lub `DROP`. Celem tej tablicy nie jest odrzucanie bądź przepuszczanie pakietów tylko modyfikacja nagłówków. Zatem reguła jest poprawna pod względem składni i prawidłowego użycia tablicy `mangle`. Natomiast w kontekście, iż nie ma kolejnej reguły to w rzeczywistości pakiet po wykonaniu akcji na nagłówku zostanie wyeliminowany przez domyślne akcje w łańcuchu, co czyni tą odpowiedź błędną.\n\n> nie, gdyż nie mozna uzywac wielu argumentow \"-m\"\n\nJest to niepoprawna odpowiedź, gdyż w iptables można stosować wiele modułów rozszerzających (opcja -m) w jednej regule. Każdy moduł dodaje funkcjonalność do reguły, którą budujemy i chcemy aby pakiet był sprawdzany. W podanym w pytaniu przykładzie moduł ipp2p odpowiada za określenie czy pakiet jest P2P a moduł comment dopisuje komentarz.\n\n> nie, gdyż cel TTL moze byc uzywany tylko w lancuchu POSTROUTING\n\nJest to niepoprawna odpowiedź, gdyż cel TTL jest stosowany tylko w obrębie tablicy `mangle`, a to że można go stosować w konkretnym łańcuchu tablicy to już jest kwestia samej tablicy `mangle`, a nie celu TTL. Co więcej, `PREROUTING` jest dozwolonym łańcuchem w tablicy `mangle`."
    },
    {
        "questionId": 344,
        "title": "Idea polaczen typu VPN jest: ",
        "answers": [
            {
                "text": "zmiana routingu pakietow, aby z jednej sieci pakiety trafialy bezposrednio do sieci docelowej",
                "isCorrect": false
            },
            {
                "text": "wsparcie polaczen p2p, aby hosty mogly bezposrednio komunikowal sie",
                "isCorrect": false
            },
            {
                "text": "obejscie problemow z polaczeniami z sieciami zlokalizowanymi za NAT",
                "isCorrect": false
            },
            {
                "text": "mozliwosc zapewnienia bardziej niezawodnych, w sensie polaczeniowym, niz TCP polaczen miedzy hostami",
                "isCorrect": false
            },
            {
                "text": "utworzenie sieci laczacej odseparowane, odlegle sieci lokalne",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Wirtualna sieć prywatna (VPN) to technologia, która tworzy bezpieczne, szyfrowane połączenie tunelowe pomiędzy dwoma punktami w sieci komputerowej. VPN ma na celu stworzenie iluzji jednej spójnej sieci prywatnej, nawet jeśli fizycznie jej elementy znajdują się w różnych lokalizacjach i korzystają z publicznej infrastruktury sieciowej, takiej jak Internet.\n\n*   **\"zmiana routingu pakietow, aby z jednej sieci pakiety trafialy bezposrednio do sieci docelowej\"**  \n    To stwierdzenie jest niepoprawne. Chociaż VPN może wpływać na trasy pakietów, *nie jest to jej głównym zadaniem*. Routing jest mechanizmem kierowania pakietów w oparciu o tablice routingu, aby pakiety były dostarczane do odpowiedniej sieci, jednak VPN nie modyfikuje routingu poza tunelem VPN. Głównym celem VPN jest połączenie dwóch odrębnych sieci w spójną sieć, nie zmiana routingu poza tunelem VPN.  \n    \n*   **\"wsparcie polaczen p2p, aby hosty mogly bezposrednio komunikowal sie\"**\n    To stwierdzenie jest niepoprawne. VPN nie jest technologią zaprojektowaną do tworzenia sieci peer-to-peer (p2p). P2P to zdecentralizowana architektura, w której urządzenia komunikują się bezpośrednio bez pośredników. VPN  łączy różne sieci. Chociaż w teorii VPN może być wykorzystane w p2p to nie jest to jego główne zadanie.\n    \n*   **\"obejscie problemow z polaczeniami z sieciami zlokalizowanymi za NAT\"**  \n    To stwierdzenie jest niepoprawne. VPN może pomóc w obejściu ograniczeń NAT (ang. _Network Address Translation_), ale nie jest to jej głównym celem. NAT to technologia, która pozwala na przesyłanie danych z wykorzystaniem adresów prywatnych do sieci internet i z powrotem do prywatnej sieci. VPN może być stosowany jako mechanizm do bezpiecznej wymiany danych i obejścia ograniczeń NAT ale nie jest to jego podstawowa funkcjonalność. \n\n*   **\"mozliwosc zapewnienia bardziej niezawodnych, w sensie polaczeniowym, niz TCP polaczen miedzy hostami\"**\n    To stwierdzenie jest niepoprawne. VPN jest technologią działającą powyżej protokołu TCP i protokołu IP, i nie wpływa na poprawę niezawodności samego protokołu TCP. Mechanizmy protokołu TCP zapewniają niezawodną transmisje pakietów. VPN dostarcza  bezpieczny kanał komunikacji, a nie niezawodne połączenie, gdyż VPN w swoich założeniach korzysta z TCP a nie stara się go zastąpić. \n    \n*  **\"utworzenie sieci laczacej odseparowane, odlegle sieci lokalne\"** \n   To stwierdzenie jest poprawne. Podstawowym celem technologii VPN jest stworzenie bezpiecznego połączenia między odseparowanymi sieciami LAN tak, aby utworzyć logicznie jedną wspólną sieć, pomimo że odległe od siebie sieci fizycznie są rozdzielone i wykorzystują publiczne, niezaufane medium. Na przykład firma posiadająca kilka oddziałów w różnych lokalizacjach może wykorzystać VPN do utworzenia jednej spójnej sieci dla wszystkich oddziałów pomimo, że są one rozdzielone, np. Internetem."
    },
    {
        "questionId": 345,
        "title": "Opcja PARANOID w pliku hosts.deny: ",
        "answers": [
            {
                "text": "blokuje zdalne zarzadzanie mechanizmem TCP wrappers, pozostawiajac dostep tylko z lokalnego hosta",
                "isCorrect": false
            },
            {
                "text": "wymusza sprawdzanie segmentow TCP czy sa poprawne w stosunku do norm RFC",
                "isCorrect": false
            },
            {
                "text": "pozwala ograniczyc ilosc pakietow/s przychodzacych do danej uslugi",
                "isCorrect": false
            },
            {
                "text": "blokuje pakiety pochodzace od hosta, ktorego ip nie posiada nazwy domenowej",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Plik `/etc/hosts.deny` jest częścią mechanizmu TCP Wrappers, który służy do kontrolowania dostępu do usług sieciowych na systemach Linux i Unix. Każda linijka w tym pliku definiuje regułę, która określa, czy dany host ma mieć zablokowany dostęp do konkretnej usługi. Reguła ta składa się z dwóch pól oddzielonych dwukropkiem: pole usługi oraz pole, które opisuje hosta. Pole z hostem może być adresem IP lub nazwą domenową, przy czym może również stosować znaki specjalne np. ALL, co oznacza wszystkie. Mechanizm TCP Wrappers działa w ten sposób, że jeżeli klient łączy się z usługą siecową, to następuje sprawdzenie czy adres IP klienta pasuje do jakiejś reguły w `/etc/hosts.allow`, jeśli tak to dostęp jest przyznawany, w przeciwnym wypadku następuje sprawdzenie pliku `/etc/hosts.deny` jeżeli adres IP klienta pasuje do jakiejś reguły w tym pliku to dostęp jest odrzucany, a jeśli nie to dostęp zostaje przyznany. Słowo `PARANOID` jest specjalnym parametrem, który może zostać użyty w polu hosta w pliku `/etc/hosts.deny`. \n\n**Odpowiedź A jest niepoprawna.** Parametr `PARANOID` nie blokuje zdalnego zarządzania mechanizmem TCP Wrappers. `PARANOID` wpływa na sposób weryfikacji adresu IP hosta, który próbuje połączyć się z usługa, a nie na mechanizm zdalnego zarządzania. Ustawienia zarządzania mechanizmem TCP Wrappers znajdują się poza plikiem `/etc/hosts.deny`, i nie dotyczą opcji `PARANOID`.\n\n**Odpowiedź B jest niepoprawna.** Opcja `PARANOID` nie wymusza sprawdzania poprawności segmentów TCP w odniesieniu do norm RFC. Opcje związane ze szczegółowym sprawdzaniem segmentów TCP znajdują się w definicjach reguł firewall-a `iptables`, a nie w plikach konfiguracyjnych TCP Wrappers. Dodatkowo mechanizm TCP Wrappers nie analizuje treści pakietów, sprawdza jedynie adresy IP.\n\n**Odpowiedź C jest niepoprawna.** Opcja `PARANOID` nie ma nic wspólnego z ograniczeniem ilości pakietów na sekundę, jakie trafiają do danej usługi. Ograniczanie szybkości przesyłania pakietów można realizować przy pomocy mechanizmu _traffic shaping_ w zaporach sieciowych (firewall) oraz routerach. Nie jest to cecha charakterystyczna dla mechanizmu TCP Wrappers.\n\n**Odpowiedź D jest poprawna.** Opcja `PARANOID` w pliku `/etc/hosts.deny` blokuje dostęp do usług od wszystkich hostów, których adres IP nie ma przypisanej nazwy domenowej w systemie DNS. TCP Wrappers przed podjęciem decyzji o blokowaniu lub akceptacji połączenia wykonuje tzw. odwrotne zapytanie DNS (reverse DNS lookup). Odwrotne zapytanie DNS to próba odnalezienia nazwy domenowej na podstawie adresu IP, jeśli DNS dla danego adresu IP nie posiada rekordu PTR (odwrotnego A), to nazwa domenowa dla tego adresu nie zostanie odnaleziona, i w takiej sytuacji parametr `PARANOID` zadziała i zablokuje dostęp. Z praktycznego punktu widzenia użycie opcji `PARANOID` uniemożliwia łączenie się z usługami z użyciem dynamicznych adresów IP. Przykładem może być dostawca Internetu który przydziela użytkownikowi dynamiczny adres IP a nie przypisuje temu adresowi nazwy domenowej. Próba połączenia się z chroniona usługą z takim adresem zakończy się niepowodzeniem."
    },
    {
        "questionId": 346,
        "title": "getfacl --omit-header acl-test5 user::r-x user:inf44444:r-- group::rw- group:student:r-x mask::rwx other::--x Oznacza: ",
        "answers": [
            {
                "text": "uzytkownik \"inf44444\" nie moze czytac pliku acl-test5",
                "isCorrect": false
            },
            {
                "text": "wlasciciel ma prawo zmodyfikowac zawartosc katalogu acl-test5",
                "isCorrect": false
            },
            {
                "text": "uzytkownik \"inf44444\" moze czytac plik acl-test5",
                "isCorrect": true
            },
            {
                "text": "maska blokuje wszystkie uprawnienia do pliku acl-test5",
                "isCorrect": false
            },
            {
                "text": "grupa wlasciciela moze zmodyfikowac plik acl-test5",
                "isCorrect": true
            },
            {
                "text": "grupa \"student\" moze zmodyfikowac plik acl-test5",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "`getfacl` to narzędzie w systemach Linux/Unix, które wyświetla listy kontroli dostępu (ACL) dla plików i katalogów.  `--omit-header` powoduje pominięcie wierszy nagłówkowych w wyjściu polecenia.  Wyjście `getfacl` zawiera informacje o prawach dostępu dla różnych kategorii użytkowników oraz dodatkowo maskę, która modyfikuje te prawa. Struktura wynikowa jest następująca:  `user::r-x`, `user:inf44444:r--`, `group::rw-`, `group:student:r-x`, `mask::rwx`, `other::--x`.  \n  * `user::r-x` oznacza, że właściciel pliku ma prawa odczytu (r) i wykonywania (x), ale nie ma prawa zapisu.\n  * `user:inf44444:r--` oznacza, że użytkownik o identyfikatorze `inf44444` ma prawa tylko do odczytu (r) pliku.\n  * `group::rw-` oznacza, że grupa, do której należy plik ma prawo odczytu (r) i zapisu (w), ale nie ma prawa wykonywania (x).\n  * `group:student:r-x` oznacza, że grupa `student` ma prawa odczytu (r) i wykonywania (x), ale nie ma prawa zapisu.\n  * `mask::rwx` to maska, która ogranicza maksymalne prawa jakie mogą mieć użytkownicy lub grupy (poza właścicielem) w odniesieniu do tego pliku. W tym przypadku maska dopuszcza odczyt, zapis i wykonywanie. Zatem, mimo że dla grupy student jest przypisane prawo wykonywania, a dla grupy pliku prawo zapisu, ostateczne, faktycznie wykorzystane uprawnienia są ograniczone przez maskę.\n  * `other::--x` oznacza, że pozostali użytkownicy mają tylko prawo wykonywania (x).\n\n**Analiza odpowiedzi:**\n\n*   **\"uzytkownik \"inf44444\" nie moze czytac pliku acl-test5\"** - **Niepoprawna.** Wpis `user:inf44444:r--` bezpośrednio wskazuje, że ten użytkownik *może* czytać plik (prawo `r`). Maska nie ogranicza tego prawa, gdyż `r` jest zawarte w masce `rwx`.\n\n*   **\"wlasciciel ma prawo zmodyfikowac zawartosc katalogu acl-test5\"** - **Niepoprawna.**  Wyjście `getfacl` dotyczy pliku, a nie katalogu. Właściciel ma prawo odczytu i wykonywania, ale nie zapisu. Słowo zmodyfikować odnosi się do prawa zapisu.\n\n*   **\"uzytkownik \"inf44444\" moze czytac plik acl-test5\"** - **Poprawna.** Jak wyjaśniono w punkcie pierwszym, wpis `user:inf44444:r--` oznacza dostęp do odczytu dla tego użytkownika.\n\n*   **\"maska blokuje wszystkie uprawnienia do pliku acl-test5\"** - **Niepoprawna.** Maska `rwx` nie blokuje *wszystkich* uprawnień, a tylko *ogranicza maksymalne* uprawnienia. Maska w tym przypadku pozwala użytkownikom i grupom, na odczyt, zapis i wykonywanie.\n\n*    **\"grupa wlasciciela moze zmodyfikowac plik acl-test5\"** - **Poprawna.** Linia `group::rw-` wskazuje, że grupa będąca właścicielem pliku ma uprawnienia odczytu (r) i zapisu (w). Maska nie ogranicza tych praw, ponieważ maska dopuszcza prawo zapisu.\n\n*   **\"grupa \"student\" moze zmodyfikowac plik acl-test5\"** - **Niepoprawna.** Linia `group:student:r-x` wskazuje, że grupa student ma prawa odczytu (r) i wykonywania (x). Maska dopuszcza wszystkie uprawnienia `rwx` ale w definicji grupy nie występuje uprawnienie zapisu.\n\n**Przykład:**\n\nWyobraźmy sobie plik o nazwie `dane.txt`, do którego dostęp jest kontrolowany ACL. Właściciel pliku to użytkownik `wlasciciel`, a plik należy do grupy `wlasciciel-grupa`. Chcemy udostępnić ten plik do odczytu użytkownikowi `inf44444` oraz do zapisu użytkownikowi `anowak`. Zastosowanie mechanizmu ACL jest następujące:\n*  `setfacl -m u:inf44444:r-- dane.txt`\n*  `setfacl -m u:anowak:rw- dane.txt`\nPo zastosowaniu powyższych operacji plik `dane.txt` jest dostępny dla każdego z użytkowników według ich uprawnień, tak, jak zostało to zamierzone przez administratora. Użytkownik `inf44444` ma dostęp jedynie do odczytu a użytkownik `anowak` ma uprawnienia do odczytu i zapisu."
    },
    {
        "questionId": 347,
        "title": "Zaleta single-sign-on jest: ",
        "answers": [
            {
                "text": "jednokrotne uwierzytelnianie",
                "isCorrect": true
            },
            {
                "text": "stosowanie funkcji skrotu w celu uwierzytelniania",
                "isCorrect": false
            },
            {
                "text": "jednokrotne szyfrowanie",
                "isCorrect": false
            },
            {
                "text": "jednokrotna autoryzacja",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Single Sign-On (SSO), w tłumaczeniu jednokrotne logowanie, to mechanizm uwierzytelniania, który pozwala użytkownikowi na dostęp do wielu systemów lub aplikacji za pomocą pojedynczego zestawu danych uwierzytelniających, najczęściej loginu i hasła. Kluczowym aspektem SSO jest to, że użytkownik loguje się tylko raz, a następnie system automatycznie umożliwia dostęp do innych, powiązanych systemów. Zapewnia to wygodę i eliminuje potrzebę wielokrotnego logowania.\n\n*   **\"jednokrotne uwierzytelnianie\"** Jest to **poprawna** odpowiedź. SSO, jak sama nazwa wskazuje, opiera się na koncepcji jednokrotnego uwierzytelniania. Po pomyślnym zalogowaniu użytkownik uzyskuje dostęp do wielu zasobów bez potrzeby ponownego podawania danych uwierzytelniających. Przykładowo, pracownik loguje się raz do firmowej sieci, a potem ma dostęp do poczty, aplikacji CRM i innych systemów, bez potrzeby wpisywania hasła do każdego z nich. W ten sposób SSO upraszcza dostęp do zasobów, minimalizując jednocześnie zagrożenia związane z przechowywaniem haseł do wielu systemów.\n\n*   **\"stosowanie funkcji skrotu w celu uwierzytelniania\"** Jest to **niepoprawna** odpowiedź. Funkcje skrótu (hash functions) są używane w procesie uwierzytelniania do bezpiecznego przechowywania haseł. Hasła nie są przechowywane w postaci jawnej, ale jako skrót, którego nie można łatwo odwrócić. W przypadku ataku, nawet jeśli baza danych haseł zostanie wykradziona, trudne jest odtworzenie z niej oryginalnych haseł. SSO *może* korzystać z funkcji skrótu w procesie uwierzytelniania, ale nie jest to jego kluczowa cecha. Istotą SSO jest redukcja ilości uwierzytelnień potrzebnych użytkownikowi.\n\n*  **\"jednokrotne szyfrowanie\"** Jest to **niepoprawna** odpowiedź. Szyfrowanie, to proces przekształcania danych do postaci nieczytelnej dla osób nieuprawnionych. Zapewnia poufność przesyłanych informacji. SSO, w przeciwieństwie do szyfrowania, skupia się na sposobie weryfikacji tożsamości użytkownika, a nie ochronie danych. SSO może wymagać, lub korzystać z szyfrowania np. podczas przesyłania tokenu uwierzytelniającego, ale samo nie jest szyfrowaniem. Przykładowo token uwierzytelniający po jednokrotnym uwierzytelnieniu może być zaszyfrowany podczas przesyłania go do innych usług w celu zachowania poufności.\n\n*   **\"jednokrotna autoryzacja\"** Jest to **niepoprawna** odpowiedź. Autoryzacja to proces przypisywania uprawnień, czyli ustalania, do jakich zasobów użytkownik ma dostęp po uwierzytelnieniu. SSO odnosi się do procesu jednokrotnego udowodnienia tożsamości użytkownika, natomiast autoryzacja, która jest często procesem wtórnym wobec SSO określa do jakich zasobów dany, już uwierzytelniony użytkownik, ma mieć dostęp. Aplikacje i zasoby do których użytkownik ma dostęp mogą być różne. Na przykład administrator ma autoryzacje dostępu do konfiguracji, a zwykły użytkownik do korzystania z aplikacji. Zatem SSO ułatwia wielokrotną autoryzację poprzez weryfikacje tożsamości użytkownika."
    },
    {
        "questionId": 348,
        "title": "$ssh host Enter passphrase for key '/home/junior/.ssh/id_dsa': Wpis passphrase to: ",
        "answers": [
            {
                "text": "Haslo, ktorym jest zaszyfrowany klucz publiczny",
                "isCorrect": false
            },
            {
                "text": "haslo, ktorym jest zaszyfrowany klucz prywatny",
                "isCorrect": true
            },
            {
                "text": "klucz, ktorym bedzie szyfrowana transmisja",
                "isCorrect": false
            },
            {
                "text": "haslo wymagane przez zdalny host, aby zostac zalogowanym",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Klucz prywatny w SSH (Secure Shell) jest często szyfrowany za pomocą hasła, czyli frazy, którą ustala użytkownik. Ten mechanizm bezpieczeństwa ma na celu zabezpieczenie klucza prywatnego, który jest kluczowy dla uwierzytelniania użytkownika bez konieczności podawania hasła przy każdym połączeniu. Hasło, które jest wymagane w przedstawionym komunikacie: \"$ssh host Enter passphrase for key '/home/junior/.ssh/id_dsa':\", jest hasłem, którym zaszyfrowany jest właśnie ten klucz prywatny.\n- **\"Haslo, ktorym jest zaszyfrowany klucz publiczny\"** - To jest nieprawidłowa odpowiedź. Klucz publiczny w systemie kryptografii asymetrycznej, takiej jak RSA czy DSA używanej w SSH, nie jest szyfrowany. Klucz publiczny jest przeznaczony do swobodnego rozpowszechniania. Klucz prywatny jest zawsze szyfrowany gdy jest zapisywany do pliku na dysku w celu ochrony przed dostępem nieuprawnionych osób.\n- **\"haslo, ktorym jest zaszyfrowany klucz prywatny\"** - To jest **poprawna** odpowiedź. Klucz prywatny w SSH jest bardzo wrażliwym elementem. Jego posiadanie, bez ochrony hasłem, umożliwia nieautoryzowany dostęp do systemu. Dlatego klucz prywatny jest zazwyczaj szyfrowany za pomocą hasła, które jest sprawdzane za każdym razem, kiedy używa się klucza.\n- **\"klucz, ktorym bedzie szyfrowana transmisja\"** - To jest niepoprawna odpowiedź. Hasło, które jest wymagane to nie klucz sesyjny. Protokół SSH po poprawnym uwierzytelnieniu użytkownika i uzgodnieniu algorytmów, wykorzystuje symetryczne klucze sesyjne do szyfrowania transmisji danych, a nie hasło. Klucze sesyjne są ustalane automatycznie za pomocą mechanizmu wymiany kluczy, np. algorytmu Diffie-Hellmana. Hasło jest wykorzystywane do odszyfrowania klucza prywatnego.\n- **\"haslo wymagane przez zdalny host, aby zostac zalogowanym\"** - To jest niepoprawna odpowiedź. Jest to bardzo częste źródło pomyłki. W systemach Linux/Unix użytkownik może zalogować się zdalnie (bez hasła systemu zdalnego), po poprawnym uwierzytelnieniu za pomocą klucza prywatnego, który w systemie zdalnym został skojarzony z nazwą użytkownika. Hasło, które jest wymagane to nie hasło użytkownika w zdalnym systemie operacyjnym. To hasło chroni twój klucz prywatny. Zatem poprawne jest tylko hasło do prywatnego klucza.\n\n**Przykład:**\nWyobraźmy sobie scenariusz, w którym administrator systemu \"admin\" chce zalogować się zdalnie na maszynę \"serwer\" z wykorzystaniem SSH. Administrator generuje parę kluczy: prywatny (id_rsa) i publiczny (id_rsa.pub). Klucz prywatny administrator zabezpiecza hasłem i umieszcza na swoim lokalnym komputerze. Klucz publiczny (id_rsa.pub) umieszcza w autoryzowanych kluczach na maszynie \"serwer\". Uwierzytelnienie, czyli dopuszczenie do systemu, następuje po odszyfrowaniu klucza prywatnego i potwierdzeniu przez serwer, że klucz publiczny użytkownika jest na liście uprawnionych. System \"serwer\" nie zna ani nie pyta o hasło zabezpieczające klucz prywatny, chce tylko sprawdzić, czy jesteś w posiadaniu klucza, który jest znany serwerowi. W praktyce jest to równoznaczne z zalogowaniem w systemie zdalnym bez konieczności podawania hasła.\n\nPodsumowując, fraza wymagana podczas połączenia ssh chroni Twój prywatny klucz. Bez jej znajomości nie będziesz mógł korzystać z klucza prywatnego i zalogować się. Zatem ważne jest, aby zapamiętać hasło oraz chronić plik z kluczem prywatnym."
    },
    {
        "questionId": 349,
        "title": "getfacl --omit-header acl-test1 user::rw- user:junior:rwx group::r-- group:student:r-x mask::r-- other::--- Oznacza, ze: ",
        "answers": [
            {
                "text": "wlasciciel moze wykonac plik",
                "isCorrect": false
            },
            {
                "text": "grupa domyslna/wlasciciela moze odczytac plik",
                "isCorrect": true
            },
            {
                "text": "uzytkownik \"junior\" moze wykonac plik",
                "isCorrect": false
            },
            {
                "text": "wlasciciel moze modyfikowac plik",
                "isCorrect": true
            },
            {
                "text": "grupa \"student\" moze wykonac plik",
                "isCorrect": false
            },
            {
                "text": "inni moga zmodyfikowac plik",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "`getfacl` to polecenie systemu Linux, służące do wyświetlania rozszerzonych atrybutów kontroli dostępu, czyli ACL (ang. Access Control Lists), dla plików i katalogów. Wyświetlone atrybuty kontrolują kto i w jaki sposób może uzyskać dostęp do danego pliku, katalogu. Wyświetlony wynik zawiera następujące informacje:\n  * `user::rw-`:  oznacza, że właściciel pliku ma prawa odczytu (`r`) i zapisu (`w`), ale nie ma prawa wykonywania (`-`). Własność jest identyfikowana poprzez dwa dwukropki (`::`) po słowie `user`.\n  * `user:junior:rwx`: oznacza, że użytkownik o nazwie `junior` ma prawa odczytu (`r`), zapisu (`w`) i wykonywania (`x`). Jest to wpis ACL dla konkretnego użytkownika, identyfikowanego przez pojedynczy dwukropek (`:`) po słowie `user`.\n   * `group::r--`:  oznacza, że domyślna grupa właściciela pliku ma prawo odczytu (`r`), ale nie ma prawa zapisu ani wykonywania (`-`). Wpis dla grupy domyślnej, identyfikowany poprzez dwa dwukropki (`::`) po słowie `group`.\n   * `group:student:r-x`: oznacza, że grupa o nazwie `student` ma prawo odczytu (`r`) i wykonywania (`x`), ale nie ma prawa zapisu (`-`). Jest to wpis ACL dla konkretnej grupy, identyfikowanej przez pojedynczy dwukropek (`:`) po słowie `group`.\n   * `mask::r--`: oznacza, że maska dla ACL ma prawa odczytu. Maska, podobnie jak i domyślny właściciel oraz domyślna grupa, ma identyfikator w postaci dwóch dwukropków po słowie `mask`, dodatkowo maska kontroluje efektywne prawa dla imiennych użytkowników (`user:junior:rwx`) oraz grup (`group:student:r-x`).  Maska ogranicza maksymalne prawa, które mogą być przyznane tym użytkownikom/grupom. W tym przypadku, pomimo że użytkownik `junior` ma jawnie ustawione `rwx`, to ostatecznie ma tylko prawa `r-x` (odczyt i wykonanie), ponieważ przecina się to z maską `r--`, która redukuje prawa do `r-x`.\n   * `other::---`: oznacza, że pozostali użytkownicy nie mają żadnych praw dostępu (`-`).\n\n**Analiza odpowiedzi:**\n\n*   **\"wlasciciel moze wykonac plik\"** -  **Niepoprawna**. Wpis `user::rw-` wskazuje, że właściciel ma prawo odczytu i zapisu, ale nie wykonania.\n*   **\"grupa domyslna/wlasciciela moze odczytac plik\"** - **Poprawna**. Wpis `group::r--`  oznacza, że domyślna grupa ma prawo odczytu.\n*   **\"uzytkownik \"junior\" moze wykonac plik\"** - **Niepoprawna**. Wpis `user:junior:rwx` wskazuje, że użytkownik *junior* ma wpisane prawa do odczytu, zapisu i wykonywania, ale ponieważ maska w danym ACL  (`mask::r--`) ogranicza jego uprawnienia do `r-x` to ostatecznie ma on tylko prawa odczytu i wykonywania.\n*   **\"wlasciciel moze modyfikowac plik\"** - **Poprawna**. Wpis `user::rw-`  wskazuje, że właściciel ma prawo zapisu, czyli może modyfikować plik.\n*   **\"grupa \"student\" moze wykonac plik\"** - **Niepoprawna**.  Wpis `group:student:r-x` wskazuje, że grupa *student* ma prawo odczytu i wykonania, ale ponieważ maska (`mask::r--`) obcina uprawnienia do praw `r--`, grupa *student* w praktyce ma jedynie uprawnienia do odczytu tego pliku.\n*   **\"inni moga zmodyfikowac plik\"** - **Niepoprawna**. Wpis `other::---` oznacza, że inni użytkownicy nie mają żadnych praw do pliku.\n\n**Przykład praktyczny:**\n\nZałóżmy, że mamy plik `dane.txt` z ustawieniami pokazanymi w pytaniu. Użytkownik `wlasciciel` może odczytywać i modyfikować (zapisywać) plik. Użytkownik `junior`, mimo że ma jawnie ustawione uprawnienia `rwx`, to w efekcie ma tylko `r-x` , czyli tylko odczyt i wykonanie (jeśli byłby to plik wykonywalny), ponieważ maska (`mask::r--`)  ogranicza jego uprawnienia do odczytu. Grupa domyślna (właściciela) może tylko odczytywać plik, a grupa `student` również tylko odczytywać plik. Pozostali użytkownicy nie mogą w ogóle odczytywać ani zmieniać tego pliku. To pokazuje, jak ważne jest zrozumienie interakcji między poszczególnymi elementami ACL."
    },
    {
        "questionId": 350,
        "title": "[niezeryfikowane]Jak zachowa sie system kontroli ACL standardu POSIX w przypadku uzytkownika U nalezacego do grupy G i wpisanego na liscie ACL obiektu p, jesli ani U ani G nie maja jawnie przydzielonego prawa r, ale kategoria ,,wszyscy uzytkownicy\" (others) takie uprawnienie do obiektu posiada: ",
        "answers": [
            {
                "text": "prawo r do obiektu p zostanie efektywnie przyznane, o ile U jest wlascicielem p",
                "isCorrect": false
            },
            {
                "text": "prawo r do obiektu p zostanie efektywnie przyznane bezwarunkowo",
                "isCorrect": false
            },
            {
                "text": "prawo r do obiektu p nie zostanie efektywnie przyznane",
                "isCorrect": true
            },
            {
                "text": "prawo r do obiektu p nie zostanie efektywnie przyznane, ale U odziedziczy je w glab, jesli p jest katalogiem",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm list kontroli dostępu (ACL) standardu POSIX definiuje uprawnienia do zasobów (np. plików, katalogów) dla trzech kategorii podmiotów: właściciela (user), grupy (group) oraz pozostałych (others). Uprawnienia obejmują zazwyczaj odczyt (r), zapis (w) i wykonanie (x). Standard POSIX określa hierarchię, w jakiej system operacyjny analizuje uprawnienia przy próbie dostępu do zasobu. Kolejność sprawdzania jest następująca: najpierw uprawnienia konkretnego użytkownika, potem uprawnienia grupy, do której należy użytkownik, a na końcu, jeśli żadna z powyższych kategorii nie pasuje - uprawnienia 'others'.  Jeśli konkretny użytkownik lub grupa ma w liście ACL konkretne prawa do zasobu, to są one stosowane zamiast praw others. Ważne jest, że 'others' jest kategorią ostatnią i tylko gdy żadna z pozostałych nie jest stosowana.\n\n**Odpowiedź 1: \"prawo r do obiektu p zostanie efektywnie przyznane, o ile U jest wlascicielem p\"**\n\nJest to **nieprawidłowa** odpowiedź.  Mimo iż właściciel pliku ma pewne uprawnienia, to konkretne ustawienia ACL, w pytaniu to zostało wyraźnie zaznaczone iż użytkownik U \"nie ma jawnie przydzielonego prawa r\". Ustawienia na poziomie owners (właściciela pliku) nie zmieniają tego faktu. Uprawnienia dla owners są sprawdzane w pierwszej kolejności, ale pytanie definiuje że ich brak. Zatem, nawet jeżeli użytkownik U byłby właścicielem,  nie otrzymałby prawa dostępu do obiektu *p*  z tej kategorii.\n \n**Odpowiedź 2: \"prawo r do obiektu p zostanie efektywnie przyznane bezwarunkowo\"**\n\nJest to **nieprawidłowa** odpowiedź.  System operacyjny nie przyznałby bezwarunkowo prawa dostępu. Mechanizm ACL działa w hierarchii, sprawdzając kolejno kategorie uprawnionych (użytkownik, grupa, inni). Ponieważ użytkownik U nie ma jawnie przypisanego uprawnienia 'r' i nie pasuje do kategorii 'group' (która też nie ma 'r') i dopiero na końcu, jeśli żadna z wcześniejszych kategorii nie ma zastosowania, stosowane są uprawnienia \"others\".  Użytkownik U nie uzyskałby zatem prawa r bezwarunkowo. \n\n**Odpowiedź 3: \"prawo r do obiektu p nie zostanie efektywnie przyznane\"**\n\nJest to **prawidłowa** odpowiedź. Ponieważ użytkownik U należy do grupy G, a żadna z kategorii 'user' i 'group' nie nadaje mu prawa 'r',  przechodzi się dopiero do ostatniej kategorii – 'others'. Zatem, jeśli użytkownik U nie jest właścicielem i grupa G nie ma przyznanych praw, to uprawnienia do odczytu zostaną przyznane tylko dlatego, że są nadane dla kategorii \"others\", ale nie dla tego konkretnego użytkownika. Sam użytkownik U nie dostanie efektywnie prawa dostępu ponieważ,  system sprawdza uprawnienia w określonej kolejności.  System najpierw patrzy na uprawnienia użytkownika, następnie grupy, na końcu innych.  Użytkownik U nie ma jawnie nadanego uprawnienia do odczytu, a do grupy G też nie ma przypisanego uprawnienia do odczytu.  Dopiero na samym końcu system operacyjny rozważałby możliwość przypisania uprawnień z grupy \"others\" ale tak naprawdę użytkownik U nie ma tych uprawnień, tylko wszystkie inne osoby z którymi nie jest związany, a do tej kategorii kwalifikuje się z powodu braku odpowiednich uprawnień w poprzednich kategoriach, ma prawo odczytu. Jest to bardzo subtelne rozróżnienie, z którego wiele użytkowników nie zdaje sobie sprawy, co często może skutkować niezrozumiałym działaniem systemu operacyjnego. \n\n**Odpowiedź 4: \"prawo r do obiektu p nie zostanie efektywnie przyznane, ale U odziedziczy je w glab, jesli p jest katalogiem\"**\n\nJest to **nieprawidłowa** odpowiedź. Użytkownik U nie ma nadanego prawa do odczytu i  nie odziedziczy takiego uprawnienia w głąb ponieważ to dziedziczenie tyczy się nowo tworzonych plików. Standardowe ACL POSIX-owe nie nadają uprawnień wstecz czyli nie zmieniają atrybutów już istniejących plików.  \nPonadto, nawet jeśli obiekt p byłby katalogiem, dziedziczenie dotyczyłoby tylko nowo tworzonych zasobów w tym katalogu, a nie samego katalogu. Zatem użytkownik nie uzyskuje prawa odczytu, ani nie dziedziczy w ten sposób tego prawa dostępu."
    },
    {
        "questionId": 351,
        "title": "Szyfr, w ktorym poddawana szyfrowaniu zostaje tej samej wielkosci jednobajtowa porcja nieregularnie pojawiajacych sie danych, nazywamy: ",
        "answers": [
            {
                "text": "strumieniowym",
                "isCorrect": true
            },
            {
                "text": "symetrycznym",
                "isCorrect": false
            },
            {
                "text": "blokowym",
                "isCorrect": false
            },
            {
                "text": "niesymetrycznym",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Szyfr strumieniowy (ang. stream cipher) szyfruje dane w sposób ciągły, przetwarzając je bit po bicie lub bajt po bajcie. Oznacza to, że każdy bit lub bajt danych wejściowych jest szyfrowany niezależnie od pozostałych bitów/bajtów, najczęściej poprzez operację XOR ze strumieniem klucza, generowanym w oparciu o klucz tajny. Szyfrowanie strumieniowe jest stosowane np. w przypadku transmisji strumieniowej danych audio-wideo, gdzie dane pojawiają się nieregularnie (nie w ustalonych blokach), oraz w wielu protokołach sieciowych do szyfrowania przesyłanych pakietów.\n\n*   **strumieniowym** - Jest to poprawna odpowiedź, ponieważ szyfr strumieniowy działa na małych porcjach danych, w tym przypadku jednobajtowych, które mogą pojawiać się w nieregularnych odstępach czasu. Typowym przykładem jest szyfrowanie transmisji danych audio w czasie rzeczywistym. Każdy bajt danych jest szyfrowany na bieżąco, gdy się pojawia.\n\n*   **symetrycznym** - Szyfr symetryczny (ang. symmetric cipher) to taki, w którym ten sam klucz służy do szyfrowania i deszyfrowania.  Szyfry symetryczne mogą być strumieniowe lub blokowe. Odpowiedź ta nie opisuje sposobu przetwarzania danych, tylko sposób użycia klucza. Na przykład szyfry AES (Advanced Encryption Standard) i 3DES (Triple DES) to szyfry symetryczne, ale blokowe.\n\n*   **blokowym** - Szyfr blokowy (ang. block cipher) szyfruje dane w ustalonych blokach. Dane wejściowe są dzielone na bloki o określonej wielkości, np. 64 lub 128 bitów, i każdy blok jest szyfrowany oddzielnie. W przypadku szyfru blokowego, nawet jeśli dane wejściowe pojawiają się nieregularnie, są one buforowane, a następnie szyfrowane blokami. Przykładem szyfru blokowego jest AES.\n*   **niesymetrycznym** - Szyfr niesymetryczny (ang. asymmetric cipher) , nazywany również szyfrem klucza publicznego, to taki w którym używane są dwa różne klucze - publiczny(służący do szyfrowania) i prywatny (służący do deszyfrowania). Szyfry niesymetryczne (takie jak RSA czy ElGamal) nie są projektowane do szyfrowania ciągłego strumienia danych. Nie mają też powiązania z przetwarzaniem danych o wielkości jednego bajtu. Służą one do wymiany kluczy sesyjnych używanych w szyfrach symetrycznych lub do podpisywania danych."
    },
    {
        "questionId": 352,
        "title": "SUID to: ",
        "answers": [
            {
                "text": "uproszczona wersji limitow",
                "isCorrect": false
            },
            {
                "text": "bit uprawnien",
                "isCorrect": true
            },
            {
                "text": "odpowiednik SGID dla katalogow",
                "isCorrect": false
            },
            {
                "text": "rozszerzenie mechanizmu SUDO",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "SUID (Set User ID) to bit uprawnień w systemach operacyjnych Unix i Linux. Kiedy bit SUID jest ustawiony na pliku wykonywalnym, program ten nie uruchamia się z uprawnieniami użytkownika, który go uruchomił, ale z uprawnieniami właściciela tego pliku. Na przykład, jeśli plik `program` jest własnością użytkownika `root` i ma ustawiony bit SUID, to każdy użytkownik uruchamiający `program` w rzeczywistości będzie uruchamiał go z uprawnieniami użytkownika `root`. Jest to ważne, gdyż umożliwia zwykłemu użytkownikowi wykonanie akcji, które normalnie wymagałyby uprawnień administratora (root). Ustawienie bitu SUID reprezentowane jest w symbolicznej notacji jako \"s\" w miejscu prawa do wykonywania (x) na poziomie użytkownika (user).\n\n**Odpowiedzi:**\n*   **\"uproszczona wersji limitow\"** - To jest **niepoprawna** odpowiedź. Limity w systemach Linux (i Unix) są mechanizmami, które ograniczają ilość zasobów systemowych (procesów, pamięci, otwartych plików), które użytkownik lub proces może wykorzystać. Natomiast SUID służy do tymczasowej zmiany uprawnień procesu. Te mechanizmy mają inny cel i zakres. Praktycznie, limity pozwalają na ochronę systemu przed niekontrolowanym użyciem zasobów przez danego użytkownika lub proces. Z kolei SUID umożliwia wykonanie programu z innymi uprawnieniami co ma na celu uprzywilejowanie danego procesu.\n*   **\"bit uprawnien\"** - To jest **poprawna** odpowiedź. SUID jest właśnie bitem uprawnień, który ustawiany jest na pliku wykonywalnym, umożliwiając zmianę efektywnego identyfikatora użytkownika procesu na identyfikator właściciela pliku. Praktycznie, pozwala to programom wykonywanym przez zwykłych użytkowników na wykonywanie akcji wymagających uprawnień administratora(root). Ustawienie bitu SUID za pomocą polecenia `chmod u+s plik` powoduje, że program ten jest uruchamiany z uprawnieniami właściciela pliku, a nie użytkownika który go uruchomił.\n*  **\"odpowiednik SGID dla katalogow\"** - To jest **niepoprawna** odpowiedź. SGID (Set Group ID) jest innym bitem uprawnień w systemach Unix i Linux. Bit SGID, ustawiony na pliku wykonywalnym, powoduje, że proces uruchamia się z uprawnieniami grupy będącej właścicielem pliku, a nie z uprawnieniami grupy, do której należy użytkownik. Bit SGID na katalogu ma inne działanie - ustawia domyślną grupę dla plików i podkatalogów tworzonych w takim katalogu. W ten sposób wymusza należność wszystkich plików i katalogów do danej grupy. SUID i SGID są powiązane w strukturze systemów Unix i Linux, ale mają różne zastosowania i znaczenie. \n*   **\"rozszerzenie mechanizmu SUDO\"** - To jest **niepoprawna** odpowiedź. SUDO jest zewnętrznym mechanizmem, który pozwala na uruchamianie wybranych komend przez wybranych użytkowników z uprawnieniami innego użytkownika (zwykle root). SUID jest bit uprawnień i działa na innym poziomie bezpieczeństwa system operacyjnego.  SUDO to program, który umożliwia kontrolowane przejęcie uprawnień administratora, natomiast SUID to atrybut plików.  SUDO może być stosowane na plikach które nie posiadają bitu SUID. SUID nie jest rozszerzeniem SUDO, oba mechanizmy realizują inne zadania.\n\n**Przykład:**\nZałóżmy, że mamy program `/usr/bin/mójprogram`, który jest własnością użytkownika `root` i posiada ustawiony bit SUID (ustawienie bitu: `chmod u+s /usr/bin/mójprogram`).  Jeśli użytkownik `piotr` uruchomi ten program (`/usr/bin/mójprogram`), to program ten będzie wykonywany tak, jakby uruchomił go użytkownik `root`, czyli będzie miał dostęp do zasobów, do których użytkownik `piotr` normalnie nie ma uprawnień. Jest to przykład, który pokazuje potencjalne zagrożenia wynikające z nadużywania bitu SUID."
    },
    {
        "questionId": 353,
        "title": "W jaki sposob administrator moze narzucic ograniczenia uzytkownikom (limity)? ",
        "answers": [
            {
                "text": "korzystajac z mechanizmu PAM",
                "isCorrect": true
            },
            {
                "text": "korzystajac z mechanizmu Kerberos",
                "isCorrect": false
            },
            {
                "text": "wykorzystujac skrypt \"hosts.equiv\"",
                "isCorrect": false
            },
            {
                "text": "wykorzystujac skrypty startowe systemu",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Pluggable Authentication Modules (PAM) to modułowy system uwierzytelniania w systemach Linux/Unix, który pozwala na podłączanie różnych modułów do różnych aplikacji. Moduły PAM mogą implementować różne mechanizmy uwierzytelniania(np. tradycyjne hasło, token, biometria, itp), mogą również służyć do ograniczania zasobów i uprawnień poszczególnych użytkowników lub grup. PAM jest mechanizmem działającym na poziomie systemu operacyjnego i jest wykorzystywany przez wszystkie aplikacje wykorzystujące ten mechanizm do uwierzytelniania oraz definiowania limitów dla danych użytkowników, a nie bezpośrednio przez programy aplikacyjne, które nie wiedzą nawet o istnieniu tego mechanizmu, działanie aplikacji jest zdeterminowane przez moduł PAM.\n\n**korzystajac z mechanizmu PAM:**\nTa odpowiedź jest prawidłowa. PAM (Pluggable Authentication Modules) to framework umożliwiający w systemach Linux/Unix konfigurację mechanizmów uwierzytelniania i autoryzacji, a także kontrolę dostępu i limitów zasobów. Administrator, konfigurując odpowiednie moduły PAM (np. `pam_limits`), może narzucić ograniczenia użytkownikom, takie jak maksymalna liczba procesów, wykorzystanie pamięci czy limity otwartych plików.\nPrzykładowo, można ograniczyć pamięć dla użytkownika 'student' w pliku `/etc/security/limits.conf` dodając wpis: `student hard as 102400`. W ten sposób procesy użytkownika `student` będą miały ograniczenie do 100MB pamięci. Aplikacje wywołujące bibliotekę PAM oraz ten konkretny moduł będą mogły wymusić to ograniczenie, jednak dla wszystkich aplikacji w systemie Linux.\n\n**korzystajac z mechanizmu Kerberos:**\nTa odpowiedź jest nieprawidłowa. Kerberos to system uwierzytelniania oparty na biletach (ang. _ticket_). Jego celem jest bezpieczne uwierzytelnianie i autoryzacja w środowisku rozproszonym, a nie ograniczanie wykorzystania zasobów. Mechanizm Kerberos umożliwia stworzenie domeny zaufania w której serwery usługowe zaufają klientom sieciowym którzy uzyskali bilet od serwera Kerberos. Nie jest mechanizmem do ustawienia limitów dla użytkowników. W systemach Linux można go użyć do zabezpieczenia usługi SSH lub innych usług, jednak nie służy on do ustawiania limitów.\n\n**wykorzystujac skrypt \"hosts.equiv\":**\nTa odpowiedź jest nieprawidłowa. Plik `hosts.equiv` służy do konfiguracji zaufanych hostów, na których użytkownicy mogą logować się bez hasła. Nie jest to mechanizm ograniczania zasobów, a raczej mechanizm zaufania i upraszczania dostępu do systemu operacyjnego. Plik ten i jego wykorzystanie pozwala użytkownikom logować się bez podawania hasła na wskazanych w tym pliku komputerach.\n\n**wykorzystujac skrypty startowe systemu:**\nTa odpowiedź jest nieprawidłowa. Skrypty startowe (np. te umieszczone w katalogu `/etc/init.d` w systemach Linux/Unix) służą do uruchamiania usług podczas startu systemu. Teoretycznie można w takich skryptach narzucać limity, jednak jest to bardzo prymitywny sposób i nie powinno się go wykorzystywać, gdyż nie jest to zadaniem takich skryptów. Mechanizm PAM oferuje lepsze, bardziej elastyczne i dedykowane metody ograniczania zasobów."
    },
    {
        "questionId": 354,
        "title": "Problem przepelnienia bufora dotyczy potencjalnie aplikacji: ",
        "answers": [
            {
                "text": "napisanych w jezyku C",
                "isCorrect": true
            },
            {
                "text": "napisanych w jezyku Java",
                "isCorrect": false
            },
            {
                "text": "uruchamianych w systemie z rodziny Windows",
                "isCorrect": true
            },
            {
                "text": "uruchamianych w systemie z rodziny Unix/Linux",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Przepełnienie bufora to błąd bezpieczeństwa, który występuje, gdy program próbuje zapisać więcej danych do bufora (obszaru pamięci o ustalonej wielkości) niż jest on w stanie pomieścić. Powoduje to nadpisanie sąsiadujących obszarów pamięci, co może prowadzić do niestabilności systemu, jego awarii, a nawet do przejęcia kontroli nad systemem przez atakującego. Przepełnienie bufora jest jedną z klasycznych luk bezpieczeństwa i nadal stanowi poważne zagrożenie we współczesnych systemach komputerowych. Jest to błąd programistyczny, który wynika z niepoprawnej obsługi pamięci.\n\n**Odpowiedź 1: \"napisanych w języku C\" - POPRAWNA.**\nJęzyk C pozwala na bezpośredni dostęp do pamięci oraz na ręczne zarządzanie nią. W C programista sam decyduje o alokacji i zwalnianiu pamięci. Ta swoboda powoduje, że bardzo łatwo o błędy, które skutkują przepełnieniem bufora. Przykładowo, funkcja `strcpy()` nie sprawdza, czy tekst źródłowy zmieści się w buforze docelowym, więc w rezultacie łatwo o zapis poza bufor. Język C, pomimo swojego wieku, jest nadal szeroko stosowany w systemach operacyjnych, sterownikach, programach sieciowych i innych aplikacjach. Właśnie dlatego, jest on podatny na przepełnienie bufora, jeśli nie zostaną zastosowane odpowiednie techniki zabezpieczające w trakcie pisania kodu. \n\n**Odpowiedź 2: \"napisanych w języku Java\" - NIEPOPRAWNA.**\nJava jest językiem, który posiada wbudowane mechanizmy zarządzania pamięcią. Pamięć jest alokowana i zwalniana automatycznie przez mechanizm zwany \"garbage collector\". Dodatkowo Java ma mechanizmy kontroli dostępu do pamięci, uniemożliwiając nadpisanie sąsiadujących obszarów pamięci. Kod bajtowy Javy wykonywany jest przez maszynę wirtualną JVM (Java Virtual Machine), która również chroni przed tego typu atakami. Z tych powodów aplikacje napisane w Javie są z reguły odporne na przepełnienie bufora. Należy również dodać, że nawet w Javie, programista ma dostęp do pamięci niskiego poziomu poprzez JNI, a w nieumiejętnych rękach może to skutkować tym błędem. Z tego powodu nie można przyjąć sztywnej reguły, że dany język sam w sobie jest bezpieczny.\n\n**Odpowiedź 3: \"uruchamianych w systemie z rodziny Windows\" - POPRAWNA.**\nSystemy z rodziny Windows, pomimo że używają nowoczesnych technik ochrony pamięci (np. DEP - Data Execution Prevention, ASLR - Address Space Layout Randomization), nadal pozostają podatne na ataki przepełnienia bufora, gdyż są na nich wykonywane aplikacje napisane w języku C, C++, które tego typu błędy mogą posiadać. Błędy te mogą występować w kodzie aplikacji, ale też w samym systemie operacyjnym. Ze względu na swoją złożoność i rozmiary system Windows nadal posiada błędy programistyczne związane z niepoprawnym zarządzaniem pamięcią, i te błędy mogą potencjalnie być wykorzystane w ataku z przepełnieniem bufora. Przykładem ataku na przepełnienie bufora może być błąd z 2003 roku w usłudze Windows Messenger, który umożliwiał zdalne przejęcie kontroli nad komputerem poprzez przesłanie niepoprawnej wiadomości.\n\n**Odpowiedź 4: \"uruchamianych w systemie z rodziny Unix/Linux\" - POPRAWNA.**\nSystemy z rodziny Unix/Linux, podobnie jak Windows, są podatne na przepełnienie bufora z tych samych powodów. Aplikacje napisane w języku C są na nich wykonywane, system operacyjny sam w sobie (kernel) również nie jest wolny od błędów programistycznych związanych z niepoprawną obsługą pamięci. Używając odpowiednich technik ataku można spróbować przejąć kontrolę nad komputerem poprzez wykorzystanie podatności na przepełnienie bufora. Wiele serwerów usług sieciowych i programów narzędziowych używanych w systemach Linux/Unix jest właśnie napisanych w języku C, co stwarza potencjalne zagrożenie."
    },
    {
        "questionId": 355,
        "title": "Czy istnieje mozliwosc zmiany portu docelowego i adresu docelowego na adres localhost i dowolny inny port?: ",
        "answers": [
            {
                "text": "tak",
                "isCorrect": true
            },
            {
                "text": "tylko, jesli okreslimy protokol oraz oryginalny port docelowy",
                "isCorrect": true
            },
            {
                "text": "tylko poprzez dodatkowy modul",
                "isCorrect": false
            },
            {
                "text": "nie",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Translacja adresów sieciowych (NAT), a konkretnie translacja adresów docelowych (DNAT), jest techniką, która umożliwia modyfikację docelowego adresu IP i portu w nagłówku pakietu. Dzięki temu mechanizmowi można przekierować ruch sieciowy z jednego miejsca na drugie. W systemie Linux, narzędziem wykorzystywanym do tego celu jest `iptables`.\n\n**Opcja 1: \"tak\" - CORRECT**\n\nTa odpowiedź jest poprawna. `iptables` domyślnie wspiera translację DNAT, umożliwiając zmianę adresu docelowego na `localhost` (127.0.0.1) oraz na dowolny inny port. Jest to podstawowa funkcjonalność `iptables` i nie wymaga instalowania dodatkowych modułów.\nPrzykład: Przekierowanie całego ruchu przychodzącego z portu 80 na port 8080 localhost: `iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 127.0.0.1:8080`. Powyższa reguła przekieruje ruch, gdziekolwiek jest jego docelowy adres IP, ale tylko na port 80 (np. z Internetu), na port 8080 na serwerze na którym działa ta reguła.\n\n**Opcja 2: \"tylko, jesli okreslimy protokol oraz oryginalny port docelowy\" - CORRECT**\n\nTa odpowiedź również jest poprawna. Mechanizm DNAT w `iptables` musi wiedzieć, jaki protokół (np. TCP, UDP) i port docelowy ma zostać poddany translacji. Bez określenia protokołu i oryginalnego portu docelowego, translacja nie będzie możliwa.\nPrzykład: Przekierowanie tylko ruchu TCP przychodzącego na port 80: `iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 127.0.0.1:8080`. Gdyby nie było określone w opcji -p tcp to reguła byłaby zastosowana również dla protokołu UDP.\n\n**Opcja 3: \"tylko poprzez dodatkowy modul\" - INCORRECT**\n\nTo jest niepoprawna odpowiedź. DNAT jest integralną częścią iptables i nie wymaga żadnego dodatkowego modułu. `iptables` posiada wbudowane tablice (_ang. tables_), w których definiowane są łańcuchy reguł, a te z kolei mogą definiować operacje DNAT bez konieczności wczytywania dodatkowych modułów.\n\n**Opcja 4: \"nie\" - INCORRECT**\n\nTa odpowiedź jest niepoprawna. Jak wyjaśniono w opcji 1, `iptables` pozwala na przekierowanie ruchu do localhost oraz na zmianę docelowego portu. Jest to podstawowa funkcja NAT i nie wymaga dodatkowych wtyczek."
    },
    {
        "questionId": 356,
        "title": "W jaki sposob program OpenVPN bedzie wiedzial, gdzie znajduje sie drugi koniec tunelu VPN: ",
        "answers": [
            {
                "text": "OpenVPN w sposob interaktywny poprosi uzytkownika o podanie adresu IP i numeru portu",
                "isCorrect": false
            },
            {
                "text": "nalezy wpisac odpowiednia opcje w pliku konfiguracyjnym",
                "isCorrect": true
            },
            {
                "text": "OpenVPN wysle zapytanie do najblizszego serwera VPN",
                "isCorrect": false
            },
            {
                "text": "OpenVPN odczytuje zawartosc zdalnej tablicy routingu i pobiera ta informacje",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół OpenVPN, będący rozwiązaniem typu open source do tworzenia tuneli VPN, wymaga określenia adresu IP oraz portu serwera, z którym ma być nawiązane połączenie. Adres IP (Internet Protocol address) to numeryczny identyfikator urządzenia w sieci, natomiast port to numer, za pomocą którego aplikacje komunikują się w ramach protokołu TCP lub UDP. Te informacje są kluczowe dla zainicjowania i utrzymania połączenia VPN. Klient OpenVPN nie potrafi automatycznie odszukać serwera, z którym ma się połączyć, a informacje o serwerze nie mogą być ustalane podczas działania programu, tylko w statycznym pliku konfiguracyjnym.\n  \n  * **\"OpenVPN w sposob interaktywny poprosi uzytkownika o podanie adresu IP i numeru portu\"**\n    Ta odpowiedź jest **niepoprawna**. OpenVPN nie ma wbudowanego mechanizmu interaktywnego uzyskiwania adresu IP i portu serwera. W praktyce podczas każdego nawiązania połączenia VPN użytkownik nie powinien być pytany o adres serwera. OpenVPN bazuje na statycznej konfiguracji zawartej w pliku. Interaktywne podejście nie nadaje się do automatyzacji procesów np. nawiązywania tunelu VPN podczas startu systemu.\n \n  *   **\"nalezy wpisac odpowiednia opcje w pliku konfiguracyjnym\"**\n    Ta odpowiedź jest **poprawna**. OpenVPN, jak większość klientów VPN, do określenia adresu serwera VPN, z którym ma być nawiązane połączenie, wykorzystuje plik konfiguracyjny. Plik ten ma rozszerzenie .conf lub .ovpn, i zawiera parametry połączenia, w tym m.in. dyrektywę `remote`. Ta dyrektywa `remote` wskazuje adres IP lub nazwę domenową serwera oraz numer portu, na którym nasłuchuje serwer OpenVPN. Przykładowa dyrektywa `remote` mogłaby wyglądać tak: `remote 192.168.1.100 1194`, gdzie `192.168.1.100` to adres IP serwera, a `1194` to numer portu. Bez poprawnej dyrektywy remote nawiązanie połączenia VPN jest niemożliwe.\n \n  * **\"OpenVPN wysle zapytanie do najblizszego serwera VPN\"**\n   Ta odpowiedź jest **niepoprawna**. OpenVPN, nie ma wbudowanej funkcjonalności automatycznego wyszukiwania najbliższego serwera. Musi zostać mu jawnie podany adres docelowy z którym ma się połączyć. W praktyce oznacza to, że klient musi wcześniej wiedzieć gdzie znajduje się dany serwer VPN, a do tej wiedzy powinien mieć dostęp administrator systemu, który wie, z jakim serwerem VPN ma się łączyć i nie wykorzystuje do tego automatycznego wyszukiwania.\n \n  * **\"OpenVPN odczytuje zawartosc zdalnej tablicy routingu i pobiera ta informacje\"**\n  Ta odpowiedź jest **niepoprawna**. Chociaż tablica routingu zawiera informacje o trasach, którymi pakiety powinny być przekazywane, to jednak OpenVPN nie odczytuje tablicy routingu innego hosta. Tablica routingu danego hosta jest informacją chronioną i nie powinna być wysyłana. Tablice routingu nie zawierają również informacji o adresie IP oraz numerze portu zdalnego serwera. Nawet gdyby serwer chciał się dzielić swoją tablicą routingu, to i tak nie zawierałaby ona parametrów połączenia VPN.\n  \nW praktycznym scenariuszu, administrator sieci musi przygotować plik konfiguracyjny dla OpenVPN z odpowiednią dyrektywą `remote`. Taki plik jest dystrybuowany do klientów, którzy mają uzyskać dostęp do sieci VPN. Nie ma w OpenVPN żadnych mechanizmów automatycznego wyszukiwania serwera czy pozyskiwania informacji o jego adresie, wszystko sprowadza się do poprawnej definicji pliku konfiguracyjnego, w którym należy jawnie wpisać adres i port serwera OpenVPN."
    },
    {
        "questionId": 357,
        "title": "Dyrektywa \"mask\" w ACL okresla: ",
        "answers": [
            {
                "text": "mozna ja modyfikowac jedynie raz",
                "isCorrect": false
            },
            {
                "text": "jest utozsamiana z uprawnieniami grupy",
                "isCorrect": true
            },
            {
                "text": "ukrywanie nadanych uprawnien dodatkowych uzytkownikow",
                "isCorrect": true
            },
            {
                "text": "nie ma zadnego znaczenia",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "W kontekście list kontroli dostępu (ACL), dyrektywa \"mask\" odgrywa kluczową rolę w zarządzaniu uprawnieniami. ACL rozszerzają standardowy system uprawnień plików (właściciel, grupa, inni) poprzez dodanie możliwości nadawania uprawnień konkretnym użytkownikom lub grupom. „Mask\" w ACL działa jak filtr ograniczający efektywne uprawnienia, które są przyznawane użytkownikom lub grupom. Definiuje ona maksymalny zestaw uprawnień, które są brane pod uwagę, kiedy aplikowane są uprawnienia dla dodatkowych użytkowników lub grup.\n\nOpcja \"mozna ja modyfikowac jedynie raz\" jest **niepoprawna**. Dyrektywę \"mask\" w ACL można modyfikować wielokrotnie, dopasowując uprawnienia w zależności od potrzeb. Zmiana maski w ACL wpływa natychmiastowo na efektywne uprawnienia wszystkich użytkowników i grup, których uprawnienia są limitowane przez tę maskę.\n\nOpcja \"jest utozsamiana z uprawnieniami grupy\" jest **poprawna**. Maska działa jako limit dla uprawnień nadanych grupie w ACL. Na przykład, jeśli grupa ma ustawione uprawnienia `rwx`, a maska ma uprawnienia `r-x`, efektywne uprawnienia grupy będą `r-x`. Maska jest efektywnie traktowana jako górny limit uprawnień dla grupy.\n\nOpcja \"ukrywanie nadanych uprawnien dodatkowych uzytkownikow\" jest **poprawna**. Maska w ACL nie ukrywa przypisanych uprawnień, ale ogranicza *efektywne* uprawnienia które mogą korzystać z danego zasobu. Oznacza to, że chociaż użytkownik może mieć wyraźnie przyznane uprawnienie do zapisu, maska może to uprawnienie wyłączyć ograniczając go do uprawnienia odczytu. Uprawnienia same w sobie nie są ukryte, ale efektywnie niedostępne, czyli maska jest ograniczeniem, a nie ukryciem uprawnień nadanych dodatkowym użytkownikom.\n\nOpcja \"nie ma zadnego znaczenia\" jest **niepoprawna**. Maska ma kluczowe znaczenie w mechanizmie ACL, definiując maksymalny zestaw uprawnień dla grupy i dodatkowych użytkowników. Bez maski, administrator nie miałby możliwości ograniczania efektywnych uprawnień, a uprawnienia dodatkowych użytkowników lub grup nadane w ACL byłyby zawsze brane pod uwagę w pełnym zakresie.\n\nNa przykład, wyobraźmy sobie sytuację, gdzie do pliku \"tajne_dane.txt\" przypisane są następujące ACL:\n\n*   właściciel: `user1` (pełne uprawnienia `rwx`)\n*   grupa: `admins` (uprawnienia `rwx`)\n*   mask: `r--`\n*   użytkownik: `user2` (uprawnienia `rw-`)\n\nW tym przypadku, użytkownik `user1` ma pełne uprawnienia `rwx`, użytkownik `user2` ma uprawnienia tylko do odczytu `r--` mimo jawnego nadania uprawnień `rw-`, grupa `admins` ma uprawnienia ograniczone przez maskę, czyli tylko do odczytu `r--`, pomimo jawnego przyznania `rwx`. Zatem maska ogranicza możliwości dostępu do odczytu dla wszystkich oprócz właściciela."
    },
    {
        "questionId": 358,
        "title": "Opcja spawn w pliku hosts.deny: ",
        "answers": [
            {
                "text": "pozwala tworzyc kolejne procesy TCP wrapper",
                "isCorrect": true
            },
            {
                "text": "jest wykorzystywana tylko w pliku hosts.allow",
                "isCorrect": false
            },
            {
                "text": "nie jest wykorzystywana",
                "isCorrect": false
            },
            {
                "text": "pozwala odeslac do nadawcy specjalnie spreparowana wiadomosc w odpowiedzi na zadanie",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Opcja `spawn` w plikach konfiguracyjnych `hosts.allow` i `hosts.deny` narzędzia TCP Wrappers, to mechanizm, który pozwala na wykonanie zewnętrznego polecenia systemu operacyjnego w momencie, gdy pakiet zostanie dopasowany do danej reguły. TCP Wrappers to narzędzie do kontroli dostępu do usług sieciowych w systemach Linux/Unix.\n\n**Opcja `spawn` nie jest ograniczona tylko do pliku `hosts.allow` lub `hosts.deny`.** Może być wykorzystana w obu plikach, jednak jej interpretacja jest diametralnie różna w zależności od pliku. W pliku `hosts.allow`, użycie `spawn` oznacza wykonanie polecenia po _udanej_ autoryzacji, natomiast w pliku `hosts.deny` oznacza wykonanie polecenia po _nieudanej_ autoryzacji.\n\n1.  **\"pozwala tworzyc kolejne procesy TCP wrapper\"** - **PRAWDA**.\n    Opcja `spawn` w plikach konfiguracyjnych TCP Wrappers, uruchamia zewnętrzne polecenie jako nowy proces. Jest to ważna cecha gdyż, gdyby każde połączenie wymagało powołania do życia samego programu `tcpd` to mogło by spowodować obciążenie systemu. Dzięki `spawn` program `tcpd` jest odpowiedzialny tylko za przekazanie reguły do sprawdzania, samo sprawdzanie reguły jest zrealizowane przez inny proces. W tym kontekście TCP Wrapper nie tworzy nowych procesów TCP Wrapper, a pozwala na wykonywanie zewnętrznych procesów, które mogą być logowaniem, wykonywaniem polecenia blokującego lub innym programem napisanym przez administratora.\n\n    *   **Praktyczna Implikacja:** Używając `spawn` administrator może automatycznie logować lub uruchamiać skrypt reagujący na próby połączenia, zarówno udane, jak i nieudane. Na przykład: `in.tftpd : ALL : spawn (logger -t \"TFTP access from %h\")` spowoduje zalogowanie nazwy hosta, który próbował skorzystać z usługi tftp, na podstawie wszystkich reguł wpisanych w pliku.\n\n2.  **\"jest wykorzystywana tylko w pliku hosts.allow\"** - **FAŁSZ**.\n    Opcja `spawn` jest wykorzystywana zarówno w `hosts.allow` jak i `hosts.deny`. W `hosts.allow` wykonuje się ją po pozytywnej autoryzacji, np. logowanie sesji. W `hosts.deny` wykonuje się po nieudanej próbie połączenia, np. zablokowanie połączenia wraz z notyfikacją.\n\n    *   **Praktyczna Implikacja:** Możemy logować próby nieudanych połączeń przez  `hosts.deny`, a w przypadku udanych wysyłać powiadomienia administratorowi.\n\n3.  **\"nie jest wykorzystywana\"** - **FAŁSZ**.\n      `spawn` jest kluczową opcją TCP Wrappers umożliwiającą wykonanie komendy systemowej. Bez jej użycia TCP Wrappers pozwala tylko na przyznanie lub odebranie dostępu. A dzięki niej można rozszerzyć funkcjonalność TCP Wrapper.\n     * **Praktyczna Implikacja:** Bez `spawn` nie ma możliwości notyfikowania administratorów o próbach połączenia, nie ma również możliwości automatycznego blokowania adresów IP, które próbują naruszyć politykę bezpieczeństwa.\n\n4.  **\"pozwala odeslac do nadawcy specjalnie spreparowana wiadomosc w odpowiedzi na zadanie\"** - **PRAWDA**\n      Opcja `spawn` pozwala na wykonanie programu lub skryptu w momencie gdy dany pakiet pasuje do reguły w pliku `hosts.allow` lub `hosts.deny`.  Nic nie stoi na przeszkodzie aby napisać skrypt, który w danej sytuacji odeśle na adres nadawcy spreparowaną wiadomość.\n\n     *   **Praktyczna Implikacja:** W odpowiedzi na próbę połączenia do serwera WWW możemy odesłać HTML'owy kod strony informującej o tym iż administrator nie życzy sobie połączeń z tego adresu IP. To może sugerować użytkownikom podejrzane zachowanie i dać im informację co dzieje się z ich adresem IP. Należy zwrócić uwagę, że ta sytuacja nie będzie powodować wysłania odpowiedzi przez protokół WWW. Odpowiedź będzie spowodowana przez wykonanie naszego skryptu."
    },
    {
        "questionId": 359,
        "title": "Ktore polecenie bedzie poprawne, dla ustalenia SNAT ",
        "answers": [
            {
                "text": "iptables -t nat -A FORWARD -o eth0 -j SNAT --to 150.254.17.2",
                "isCorrect": false
            },
            {
                "text": "iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to 150.254.17.2",
                "isCorrect": true
            },
            {
                "text": "iptables -t nat -A PREROUTING -o eth0 -j SAME --to 150.254.17.2",
                "isCorrect": false
            },
            {
                "text": "iptables -t nat -A POSTROUTING -o eth0 -j NAT --to 150.254.17.2",
                "isCorrect": false
            },
            {
                "text": "iptables -t fnat -A PREROUTING -o eth0 -j SNAT --to 150.254.17.2",
                "isCorrect": false
            },
            {
                "text": "iptables -t nat -A POSTROUTING -o eth0 -j SAME --to 150.254.17.2",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "SNAT (Source Network Address Translation) to technika translacji adresów sieciowych, która polega na zmianie źródłowego adresu IP w pakietach wychodzących z sieci prywatnej do publicznej. Jest to niezbędne, aby urządzenia w sieci lokalnej, korzystające z prywatnych adresów IP (zdefiniowanych w RFC1918), mogły komunikować się z Internetem, ponieważ adresy prywatne nie są routowalne w sieci publicznej. SNAT jest wykonywany na routerze lub zaporze sieciowej, która działa jako brama między siecią prywatną a publiczną. Kluczowe jest umiejscowienie operacji SNAT w prawidłowym łańcuchu tablicy NAT.\n\nPoprawna konfiguracja SNAT w `iptables` wykorzystuje tablicę `nat` i łańcuch `POSTROUTING`. Łańcuch `POSTROUTING` jest używany, gdy pakiet opuszcza już system i jest kierowany na interfejs wyjściowy (np. `eth0`). W tym łańcuchu modyfikujemy adres źródłowy pakietu. Dostępne są dwie komendy do tego celu `SNAT` i `SAME`. `SNAT` jest bardziej uniwersalną z nich.\n\n*   **`iptables -t nat -A FORWARD -o eth0 -j SNAT --to 150.254.17.2`** - **Niepoprawna**.\n    *   Łańcuch `FORWARD` jest stosowany w iptables dla pakietów, które są przekazywane dalej przez zaporę, a nie są generowane lokalnie przez zaporę. SNAT musi być stosowany w łańcuchu `POSTROUTING` ponieważ w tym łańcuchu jest on stosowany do pakietów, które są wysyłane, a nie przekazywane. Opcja `-o eth0`  oznacza, że translacja nastąpi tylko dla pakietów wysyłanych interfejsem eth0. `SNAT --to 150.254.17.2` modyfikuje adres IP źródłowy na 150.254.17.2, czyli statyczny adres zewnętrznego interfejsu. Zatem, ta reguła jest błędna z powodu użycia złego łańcucha: `FORWARD`.\n    *   *Praktyczna implikacja:* Ta reguła mogłaby działać w sytuacjach gdy zapora pełni rolę routingu i przekazuje ruch dalej do innej podsieci. Jednak nie nadaje się do sytuacji gdy ma za zadanie chronić sieć lokalną i wykonywać translacje adresów.\n\n*   **`iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to 150.254.17.2`** - **Poprawna**.\n    *   Używa poprawnego łańcucha `POSTROUTING`, który jest wykonywany po podjęciu decyzji o przekazaniu pakietu przez interfejs `eth0`, przed opuszczeniem pakietu z systemu. Nakazuje użycie funkcji `SNAT` i ustawienie jako adres źródłowy wartość 150.254.17.2. Jest to poprawna składnia polecenia definiującego SNAT.\n    *   *Praktyczna implikacja:* Powoduje że wszystkie pakiety opuszczające interfejs `eth0` będą miały jako adres źródłowy ustawiony adres 150.254.17.2.\n\n*   **`iptables -t nat -A PREROUTING -o eth0 -j SAME --to 150.254.17.2`** - **Niepoprawna.**\n    *   Łańcuch `PREROUTING` jest używany, gdy pakiet dopiero wchodzi do systemu, zanim zostanie podjęta decyzja dokąd ma być przekazany, nie można w tym łańcuchu wykonywać translacji SNAT. Natomiast opcja `-o eth0`  oznacza, że translacja nastąpi tylko dla pakietów wysyłanych interfejsem eth0. Ta opcja również jest nieprawidłowa z uwagi na to, że w łańcuchu PREROUTING nie może być użyta opcja -o. Opcja `SAME` również nie pasuje do łańcucha `PREROUTING`, gdyż jej działanie można obserwować na pakietach, które są już kierowane do wyjściowego interfejsu. Ta reguła jest błędna.\n    *   *Praktyczna implikacja:* Reguła ta nie będzie prawidłowo wykonywała funkcji SNAT.\n\n*    **`iptables -t nat -A POSTROUTING -o eth0 -j NAT --to 150.254.17.2`** - **Niepoprawna.**\n    *  Pomimo, że `POSTROUTING` jest poprawnym łańcuchem, to `NAT` nie jest poprawnym celem dla translacji adresów. W `iptables`, do translacji adresów źródłowych i docelowych, używa się celów `SNAT` (dla źródła) oraz `DNAT`(dla celu). Aplikacja celu `NAT` nie istnieje.\n    *   *Praktyczna implikacja:* Powoduje błąd składni polecenia i nie wykona zadania translacji.\n\n*   **`iptables -t fnat -A PREROUTING -o eth0 -j SNAT --to 150.254.17.2`** - **Niepoprawna.**\n    *   `fnat` nie jest poprawną tablicą w iptables. Tablica nat powinna być nazywana `nat`. Opcja `-o eth0` w łańcuchu PREROUTING jest również niepoprawna, ponieważ nie jest stosowana w tym łańcuchu.\n    *   *Praktyczna implikacja:* Ta reguła z powodu błędnej tablicy `fnat` nie będzie działać.\n\n*   **`iptables -t nat -A POSTROUTING -o eth0 -j SAME --to 150.254.17.2`** - **Poprawna.**\n    *   Używa poprawnego łańcucha `POSTROUTING`, który jest wykonywany po podjęciu decyzji o przekazaniu pakietu przez interfejs `eth0`, przed opuszczeniem pakietu z systemu. Nakazuje użycie funkcji `SAME` i ustawienie jako adres źródłowy wartość 150.254.17.2. Opcja `SAME` jest bardzo podobna do opcji `SNAT`, z tym, że `SAME` ma mniejsze możliwości konfiguracji, jednak w tym konkretnym przypadku `SAME` i `SNAT` osiągną ten sam efekt. Jest to poprawna składnia polecenia definiującego SNAT.\n    *  *Praktyczna implikacja:*  Powoduje że wszystkie pakiety opuszczające interfejs `eth0` będą miały jako adres źródłowy ustawiony adres 150.254.17.2."
    },
    {
        "questionId": 360,
        "title": "Czy iptables umozliwia ograniczenie dostepu do uslugi w jednym poleceniu?:",
        "answers": [
            {
                "text": "jesli okreslamy protokol",
                "isCorrect": true
            },
            {
                "text": "jesli nie okreslimy protokolu",
                "isCorrect": false
            },
            {
                "text": "nie",
                "isCorrect": false
            },
            {
                "text": "tak",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "`iptables` to narzędzie w systemach Linux służące do zarządzania zaporą sieciową, które operuje na zasadzie reguł filtrujących pakiety sieciowe. Reguły te, definiowane za pomocą polecenia `iptables`, określają, które pakiety powinny być przepuszczone, a które odrzucone. Ograniczenie dostępu do usługi za pomocą `iptables` polega na zdefiniowaniu reguły, która będzie pasować do pakietów związanych z tą usługą i odpowiednio je potraktuje. Do ograniczenia dostępu można wykorzystać parametr -p który określa protokół, lub można nie podawać tego parametru.\n*   **\"jesli okreslamy protokol\"** - Ta odpowiedź jest **poprawna**. `iptables` umożliwia ograniczenie dostępu do usługi przy pomocy pojedynczego polecenia, jeśli w tym poleceniu wskażemy protokół, z którego dana usługa korzysta (np. tcp lub udp). Określając protokół, reguła będzie dopasowywać pakiety, które pasują do określonego protokołu, np. `iptables -A INPUT -p tcp --dport 80 -j ACCEPT`, ta reguła pozwala na ruch do portu 80 tcp, czyli typowo port www. Brak podanego protokołu nie blokuje możliwości blokowania i zwalniania dostępu, jednak taka reguła będzie bardziej ogólna niż poprzednia.\n*   **\"jesli nie okreslimy protokolu\"** - Ta odpowiedź jest **niepoprawna**. Brak określenia protokołu powoduje, że reguła będzie dopasowywać pakiety niezależnie od protokołu. W ten sposób również można blokować i zwalniać dostęp do usługi. Jeżeli chcemy aby dana reguła dotyczyła wszystkich protokołów, to należy wydać polecenie `iptables -A INPUT -dport 80 -j ACCEPT`.\n*   **\"nie\"** - Ta odpowiedź jest **niepoprawna**. `iptables` pozwala na ograniczenie dostępu do usługi za pomocą pojedynczego polecenia. Należy pamiętać iż ograniczenie może polegać na zablokowaniu lub dopuszczeniu do usługi. \n*   **\"tak\"** - Ta odpowiedź jest **poprawna**. `iptables` jak najbardziej pozwala ograniczyć dostęp do usługi w jednym poleceniu. Należy pamiętać iż ograniczenie może polegać na zablokowaniu lub dopuszczeniu do usługi.\n\n**Przykład praktyczny:**\nZałóżmy, że chcemy zablokować dostęp do serwera SSH (port 22/tcp) ze wszystkich adresów IP, z wyjątkiem adresu 192.168.1.100. Możemy to zrobić w jednym poleceniu, wskazując protokół `tcp`:\n```\niptables -A INPUT -p tcp --dport 22 -s 192.168.1.100 -j ACCEPT\niptables -A INPUT -p tcp --dport 22 -j DROP\n```\nW powyższym przykładzie można rozdzielić reguły na dwa polecenia, jedno zezwala na dostęp, drugie blokuje dostęp z wszystkich pozostałych adresów, ale w jednym z tych poleceń należy określić protokół. \nJeżeli chcemy zablokować dostęp do portu 22 niezależnie od protokołu, to możemy zrobić to w jednym poleceniu: \n```\niptables -A INPUT --dport 22 -j DROP\n```\nWidzimy, że niezależnie czy określimy protokół czy nie, możemy ograniczyć dostęp do usługi."
    },
    {
        "questionId": 361,
        "title": "Oprogramowanie OpenVPN wykorzystuje tablice routingu w Linuxie:",
        "answers": [
            {
                "text": "do sprawdzenia kosztu trasy prowadzacej do sieci po drugiej stronie polaczenia VPN",
                "isCorrect": false
            },
            {
                "text": "aby dowiedziec sie jak nawiazac polaczenie z siecia po drugiej stronie tunelu VPN",
                "isCorrect": false
            },
            {
                "text": "do przechowywania trasy do sieci dostepnej po drugiej stronie polaczenia VPN",
                "isCorrect": true
            },
            {
                "text": "jako bufor przechowujacy nadchodzace informacje o zmianie trasy do odleglej sieci po drugiej stronie polaczenia VPN",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Tablica routingu to struktura danych w systemie operacyjnym, która przechowuje informacje o tym, jak kierować pakiety danych w sieci. Zawiera wpisy, które określają, do jakiej sieci docelowej, przez który interfejs sieciowy oraz za pośrednictwem jakiego routera (jeśli jest wymagany) należy przekazać pakiet. Innymi słowy, tablica routingu to mapa, która pomaga pakietom danych dotrzeć do właściwego miejsca. W przypadku oprogramowania OpenVPN, tablica routingu jest używana do określenia, jak kierować ruch, który ma być przekazywany przez wirtualny tunel VPN.\n\n**Odpowiedź 1: \"do sprawdzenia kosztu trasy prowadzacej do sieci po drugiej stronie polaczenia VPN\"**\nTo jest niepoprawna odpowiedź. Tablica routingu nie służy do obliczania \"kosztu\" trasy, a do przechowywania informacji o tym, gdzie kierować pakiety. Protokół OpenVPN nie używa tablicy routingu do analizy kosztu trasy. Koszt trasy jest bardziej związany z protokołami routingu dynamicznego (np. OSPF, BGP).\n\n**Odpowiedź 2: \"aby dowiedziec sie jak nawiazac polaczenie z siecia po drugiej stronie tunelu VPN\"**\nTo jest również niepoprawna odpowiedź. Tablica routingu nie jest wykorzystywana do ustalania, jak nawiązać połączenie z siecią, ale gdzie kierować pakiety po nawiązaniu tunelu VPN. Proces nawiązywania połączenia VPN (np. negocjacja kluczy szyfrowania) odbywa się na innym poziomie i jest obsługiwany przez protokoły takie jak TLS lub IPsec.\n\n**Odpowiedź 3: \"do przechowywania trasy do sieci dostepnej po drugiej stronie polaczenia VPN\"**\nTo jest poprawna odpowiedź. Tablica routingu w systemie operacyjnym jest używana przez OpenVPN do przechowywania informacji o tym, jak kierować pakiety, które mają być przesyłane przez tunel VPN. OpenVPN, podczas ustanawiania tunelu, dodaje do tablicy routingu wpisy, które wskazują, że ruch do sieci po drugiej stronie tunelu ma być kierowany przez interfejs wirtualny tunelu OpenVPN. Przykładowo, jeśli sieć po drugiej stronie tunelu ma adres 192.168.2.0/24, OpenVPN doda wpis, który mówi, że pakiety do tej sieci powinny być kierowane przez wirtualny interfejs (np. tun0). W ten sposób aplikacje po stronie klienta/serwera VPN mogą swobodnie komunikować się z siecią zdalną.\n\n**Odpowiedź 4: \"jako bufor przechowujacy nadchodzace informacje o zmianie trasy do odleglej sieci po drugiej stronie polaczenia VPN\"**\nTo jest niepoprawna odpowiedź. Tablica routingu nie jest buforem przechowującym informacje o zmianach tras. Mechanizmy dynamicznego routingu (np. OSPF, BGP) aktualizują tablicę routingu poprzez protokoły, które przekazują informacje o zmianach w topologii sieci, ale nie przez używanie jej jako bufora."
    },
    {
        "questionId": 362,
        "title": "Nazwa konta \"administrator\" w systemie Ms Windows XP:",
        "answers": [
            {
                "text": "mozna ja zmienic w kazdej chwili",
                "isCorrect": true
            },
            {
                "text": "jest definiowana przy instalacji systemu",
                "isCorrect": true
            },
            {
                "text": "mozna ja zmienic tylko przy wykorzystaniu dodatkowego oprogramowania",
                "isCorrect": false
            },
            {
                "text": "jest stala i nie moze byc zmieniona",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Konto \"administrator\" w systemie Windows XP jest specjalnym kontem użytkownika o uprawnieniach nieograniczonego dostępu do całego systemu. Posiada ono możliwość konfiguracji dowolnego aspektu działania systemu operacyjnego. Jego głównym celem jest administrowanie systemem przez uprzywilejowanego użytkownika, który w pełni panuje nad systemem. Początkowa nazwa konta \"administrator\" jest często wykorzystywana podczas ataków i prób włamań do systemów operacyjnych, dlatego jej modyfikacja zwiększa poziom bezpieczeństwa systemu. Należy pamiętać, że zmiana nazwy konta nie uniemożliwia zalogowanie na konto administratora. Atakujący mimo zmienionej nazwy ma możliwość logowania na konto, gdyż obok nazwy konta istnieje identyfikator numeryczny (SID), który również określa konto administratora i nie ulega zmianie. Atakujący wiedząc o tym SID może nadal próbować uzyskać dostęp na konto administratora nawet z niepoprawną nazwą użytkownika. \n\n**Odpowiedź 1: \"mozna ja zmienic w kazdej chwili\"** jest **poprawna.** Nazwa tego konta nie jest na stałe przypisana do systemu operacyjnego, można ja zmienić wykorzystując konsolę zarządzania komputerem i za pomocą sekcji użytkownicy i grupy lokalni (ang. Computer Management -> Local Users and Groups), bądź przez aplikacje _net user administrator /rename:nazwa_. Zmiana nazwy konta administratora ma na celu utrudnienie ataków polegających na wypróbowywaniu haseł domyślnych (dla standardowej nazwy konta). Po zmianie nazwy konta, intruz chcący uzyskać nieautoryzowany dostęp do systemu, musi najpierw odkryć nową nazwę konta o uprawnieniach administracyjnych, a to z pewnością wydłuża czas jaki potrzebuje atakujący na uzyskanie uprawnień administracyjnych. \n\n**Odpowiedź 2: \"jest definiowana przy instalacji systemu\"** jest **poprawna.** Nazwa konta \"administrator\" jest domyślna i domyślnie tworzona w procesie instalacji systemu MS Windows XP. Zostaje ona domyślnie nadana przez system operacyjny, w trakcie instalacji systemu operacyjnego można taką nazwę zmienić, jednak nie wszyscy użytkownicy o tym wiedzą. Po skończonej instalacji nazwę tą można zmienić. \n\n**Odpowiedź 3: \"mozna ja zmienic tylko przy wykorzystaniu dodatkowego oprogramowania\"** jest **niepoprawna.** Nazwa konta Administrator może być zmieniona przy użyciu wbudowanych narzędzi systemu Windows XP, bez konieczności korzystania z dodatkowego oprogramowania. Narzędzia takie jak konsola zarządzania komputerem (Computer Management) lub polecenie net user administrator /rename:nowa_nazwa umożliwiają łatwą i szybką zmianę nazwy konta administratora. Dodatkowe oprogramowanie, do zmiany nazwy konta może niekiedy przydać się przy masowej zmianie nazwy w wielu komputerach, a w pojedynczym przypadku jest ono zbędne.  \n\n**Odpowiedź 4: \"jest stala i nie moze byc zmieniona\"** jest **niepoprawna.** Nazwa konta \"administrator\" w systemie Windows XP nie jest stała i w każdej chwili może być zmieniona przy użyciu standardowych narzędzi systemu. Twierdzenie, że nazwa jest stała, sugeruje nieznajomość podstawowych zasad zarządzania kontami w systemie Windows."
    },
    {
        "questionId": 363,
        "title": "Jaki uzytkownik zostanie wybrany w momencie logowania sie na zdalna maszyne przez rsh, gdy w poleceniu rsh nie podano nazwy uzytkownika?:",
        "answers": [
            {
                "text": "wystapi blad podczas uwierzytelniania poniewaz nie podano nazwy uzytkownika",
                "isCorrect": false
            },
            {
                "text": "lokalny uzytkownik nobody",
                "isCorrect": false
            },
            {
                "text": "zawsze root z uwagi na mozliwosc wykonania niektorych komend systemowych",
                "isCorrect": false
            },
            {
                "text": "lokalny uzytkownik rshd",
                "isCorrect": false
            },
            {
                "text": "zdalny uzytkownik rshd",
                "isCorrect": false
            },
            {
                "text": "lokalny uzytkownik operator",
                "isCorrect": false
            },
            {
                "text": "lokalny biezacy uzytkownik",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Domyślnie, gdy polecenie `rsh` jest użyte do połączenia ze zdalnym systemem i nie zostanie podana nazwa zdalnego użytkownika, `rsh` próbuje zalogować się na zdalną maszynę, używając **nazwy użytkownika, która jest aktualnie używana lokalnie**.\n\n**Opcja \"wystąpi błąd podczas uwierzytelniania ponieważ nie podano nazwy użytkownika\" jest niepoprawna**. `rsh` nie wymaga podania nazwy użytkownika do działania, ponieważ domyślnie użyje nazwy lokalnego użytkownika.  Chociaż w dzisiejszych czasach systemy rzadko korzystają z rsh, mechanizm ten jest istotny ze względu na historyczny sposób działania usług. Praktycznie, w poprawnie skonfigurowanym systemie `rsh` odmówi dostępu, ponieważ wymaga dodatkowej konfiguracji w systemie zdalnym - albo po przez listę zaufanych hostów - albo po przez specjalną listę użytkowników powiązanych z danym hostem, jednak nigdy nie wygeneruje błędu.\n\n**Opcja \"lokalny użytkownik nobody\" jest niepoprawna**. Użytkownik `nobody` jest specjalnym kontem w systemach Unix/Linux. Jest ono używane do uruchamiania nieuprzywilejowanych procesów, których nie chcemy by były powiązane z żadnym użytkownikiem. `rsh` w tej konkretnej sytuacji nie skorzysta z tego użytkownika.\n\n**Opcja \"zawsze root z uwagi na możliwość wykonania niektórych komend systemowych\" jest niepoprawna**. Użycie `rsh` nie implikuje automatycznie logowania jako użytkownik `root`. Jest to potencjalnie niebezpieczna opcja, więc twórcy tej usługi nie zdecydowali się na taką implementację.  Chociaż niektóre komendy systemowe wymagają uprawnień `root` to mechanizm `rsh` sam nie nadaje takich uprawnień. Z punktu widzenia bezpieczeństwa, takie działanie byłoby bardzo ryzykowne.\n\n**Opcja \"lokalny użytkownik rshd\" jest niepoprawna**. `rshd` to nazwa demona po stronie serwera, który obsługuje połączenia `rsh`. Nazwa demona nie jest powiązana z nazwą lokalnego użytkownika. Zatem mechanizm `rsh` nie korzysta z konta `rshd` do logowania.\n\n**Opcja \"zdalny użytkownik rshd\" jest niepoprawna**. Podobnie jak w powyższej opcji, usługa `rshd` po stronie zdalnej nie jest związana z nazwą użytkownika. Jest to demon nasłuchujący na połączenia z zewnątrz. Nie jest to nazwa użytkownika, na które nastąpi próba zalogowania. \n\n**Opcja \"lokalny użytkownik operator\" jest niepoprawna**. `operator` to konto systemowe o specyficznym przeznaczeniu, ale `rsh` nie skorzysta z niego w przypadku braku nazwy użytkownika.\n\n**Opcja \"lokalny bieżący użytkownik\" jest poprawna**. Jest to poprawne zachowanie. Jeśli użytkownik `adam` na lokalnym komputerze wyda polecenie `rsh zdalny_komputer`, `rsh` na zdalnym komputerze spróbuje zalogować użytkownika `adam`. Jest to domyślne zachowanie tego polecenia, które wykorzystuje nazwę lokalnego użytkownika do logowania na zdalnym systemie. Na przykład: jeśli na stacji roboczej  jesteś zalogowany jako użytkownik `student` i wykonasz polecenie `rsh server.example.com`, to program `rsh` spróbuje zalogować się na maszynie `server.example.com` jako użytkownik `student`. Praktycznie ten mechanizm ma poważne luki bezpieczeństwa i nie jest zalecany do użycia. W dzisiejszych czasach najczęściej spotykamy alternatywę dla tej usługi, czyli ssh (Secure Shell), które opiera się na bezpieczniejszym mechanizmie uwierzytelniania.\n\nPrawidłowa odpowiedź \"lokalny bieżący użytkownik\" demonstruje, jak ważne jest zrozumienie domyślnego zachowania systemów i ich wpływ na bezpieczeństwo. W praktyce używanie `rsh` bez dokładnej konfiguracji jest potencjalnie niebezpieczne, ponieważ często pomijane jest sprawdzanie poprawności nazwy użytkownika z listy dozwolonych kont i wystarczy podanie poprawnej nazwy, aby uzyskać dostęp."
    },
    {
        "questionId": 364,
        "title": "Do czego sluzy komenda rsh?:",
        "answers": [
            {
                "text": "pozwala wykonac zdalne polecenie na lokalnym hoscie",
                "isCorrect": false
            },
            {
                "text": "pozwala wykonac polecenie na zdalnym hoscie",
                "isCorrect": true
            },
            {
                "text": "pozwala nawiazac szyfrowane polaczenie ze zdalnym hostem",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Komenda `rsh` (remote shell) służy do wykonywania poleceń na zdalnym hoście. Działa ona poprzez nawiązanie połączenia z usługą `rshd` (remote shell daemon) działającą na zdalnym komputerze. Po uwierzytelnieniu użytkownika, komenda `rsh` przesyła polecenie do zdalnego hosta i wyświetla jego wynik na komputerze lokalnym użytkownika. Protokół `rsh` nie zapewnia szyfrowania przesyłanych danych, w tym hasła użytkownika, co stanowi istotne zagrożenie bezpieczeństwa.\n\nOpcja \"pozwala wykonać zdalne polecenie na lokalnym hoście\" jest nieprawidłowa, ponieważ `rsh` działa w przeciwnym kierunku – wykonuje polecenia na zdalnym komputerze a nie lokalnym. Użycie `rsh` do wykonania polecenia na hoście lokalnym nie ma sensu, ponieważ do tego służą komendy wywoływane bezpośrednio w powłoce.\n\nPrawidłową odpowiedzią jest \"pozwala wykonać polecenie na zdalnym hoście\". W ten sposób komenda `rsh` realizuje swoje przeznaczenie – zdalne wykonanie polecenia. Przykładowo, aby wyświetlić zawartość katalogu na hoście o nazwie `remotehost`, można użyć polecenia `rsh remotehost ls`. Spowoduje to wykonanie polecenia `ls` na zdalnym komputerze `remotehost` i wyświetlenie wyniku na komputerze lokalnym użytkownika.\n\nOpcja \"pozwala nawiązać szyfrowane połączenie ze zdalnym hostem\" jest niepoprawna, ponieważ `rsh` nie zapewnia żadnego szyfrowania przesyłanych danych. Do tego celu używa się protokołu `ssh` (secure shell), który dodatkowo oprócz szyfrowania umożliwia również bezpieczne przesyłanie hasła podczas logowania użytkownika. `rsh` przesyła hasło tekstem jawnym, co jest bardzo niebezpieczne w publicznych sieciach, ponieważ każdy, kto ma możliwość przechwytywania danych w sieci, może potencjalnie przechwycić hasło użytkownika i uzyskać dostęp do konta na zdalnym systemie. W praktyce komenda rsh nie powinna być stosowana, gdyż jej wykorzystanie wiąże się z dużym ryzykiem naruszenia bezpieczeństwa."
    },
    {
        "questionId": 365,
        "title": "user::rw- user:inf44444:r-x group::rwx group:student:rwx mask::rwx other::--- Oznacza:",
        "answers": [
            {
                "text": "grupa \"student\" nie moze skasowac pliku",
                "isCorrect": false
            },
            {
                "text": "uzytkownik \"inf44444\" moze wykonac plik",
                "isCorrect": true
            },
            {
                "text": "grupa \"student\" moze skasowac katalog",
                "isCorrect": true
            },
            {
                "text": "wlasciciel moze wykonac plik",
                "isCorrect": false
            },
            {
                "text": "maska blokuje wszystkie uprawnienia",
                "isCorrect": false
            },
            {
                "text": "grupa domyslna (wlasciciela) nie moze zmodyfikowac pliku",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Systemy plików w systemach Linux/Unix wykorzystują listy kontroli dostępu (ACL) do precyzyjnego definiowania uprawnień do plików i katalogów. ACL pozwalają na nadawanie uprawnień użytkownikom, grupom i wszystkim innym użytkownikom. Dodatkowo listy kontroli dostępu pozwalają na ustawienie maski uprawnień. Maska wpływa na to jakie uprawnienia są stosowane w momencie analizy uprawnień dla użytkownika lub grupy. Lista kontroli dostępu ACL zawiera wiele elementów, które na pierwszy rzut oka mogą być trudne do zrozumienia. W niniejszym pytaniu przedstawiono listę kontroli dostępu, która obejmuje kilka podstawowych elementów w następującej kolejności: `user::rw- user:inf44444:r-x group::rwx group:student:rwx mask::rwx other::---`\n\n*  `user::rw-`: Określa uprawnienia dla właściciela pliku lub katalogu, w tym przypadku właściciel posiada uprawnienie do odczytu (`r`) oraz zapisu (`w`). Brak uprawnienia do wykonywania (`x`).\n* `user:inf44444:r-x`: Określa uprawnienia dla użytkownika o nazwie `inf44444`, w tym przypadku użytkownik ten posiada uprawnienia odczytu (`r`) oraz wykonywania (`x`). Brak jest uprawnienia zapisu (`w`).\n* `group::rwx`: Określa uprawnienia dla grupy głównej właściciela pliku/katalogu, w tym przypadku wszyscy użytkownicy należący do tej grupy mają uprawnienia do odczytu (`r`), zapisu (`w`) oraz wykonywania/przeszukiwania (`x`).\n* `group:student:rwx`: Określa uprawnienia dla grupy o nazwie `student`. Użytkownicy z tej grupy posiadają uprawnienia do odczytu (`r`), zapisu (`w`) oraz wykonywania/przeszukiwania (`x`).\n*  `mask::rwx`:  Określa maskę uprawnień. Maska określa, do jakich uprawnień będą miały dostęp wyżej wymienione grupy i użytkownicy. W tym przypadku maska pozwala na odczyt, zapis i wykonywanie.\n* `other::---`: Określa uprawnienia dla wszystkich pozostałych użytkowników którzy nie należą do właściciela, grup określonych powyżej i użytkownika o nazwie inf44444. Wszyscy pozostali użytkownicy nie posiadają żadnych uprawnień do danego pliku/katalogu.\n\n**Poprawna odpowiedź:**\n\n*   **\"uzytkownik \"inf44444\" moze wykonac plik\"** - Jest to poprawna odpowiedź, ponieważ w pozycji `user:inf44444:r-x`, uprawnienie do wykonywania reprezentowane jest przez `x`, a zatem użytkownik `inf44444` ma prawo wykonywać ten plik. Należy zwrócić uwagę, że jeśli obiekt jest katalogiem, `x` oznacza również prawo przeszukiwania. Ustawiona maska `mask::rwx` nie ogranicza uprawnienia wykonywania.\n*   **\"grupa \"student\" moze skasowac katalog\"** - Jest to poprawna odpowiedź, ponieważ w pozycji `group:student:rwx` grupa `student` ma uprawnienie do zapisu (`w`), co w przypadku katalogu umożliwia jego kasowanie. Maska `mask::rwx` nie ogranicza w tym przypadku uprawnień `rwx`.\n\n**Niepoprawne odpowiedzi:**\n\n*   **\"grupa \"student\" nie moze skasowac pliku\"** - Jest to niepoprawna odpowiedź ponieważ w pozycji `group:student:rwx` grupa `student` ma uprawnienie do zapisu (`w`). W przypadku pliku prawo zapisu oznacza prawo jego modyfikacji i kasowania. Maska `mask::rwx` nie ogranicza w tym przypadku uprawnień `rwx`.\n*  **\"wlasciciel moze wykonac plik\"** - Jest to niepoprawna odpowiedź. Właściciel posiada prawa `rw-`, czyli odczytu i zapisu, ale nie ma prawa wykonywania. Maska `mask::rwx` nie nadaje uprawnienia do wykonywania jeżeli użytkownik nie posiada go w podstawowej konfiguracji uprawnień.\n*   **\"maska blokuje wszystkie uprawnienia\"** - Jest to niepoprawna odpowiedź ponieważ maska blokuje prawa tylko dla wyszczególnionych użytkowników i grup na liście kontroli dostępu. Maska ma wartość `rwx` zatem nie blokuje żadnych uprawnień.\n*   **\"grupa domyslna (wlasciciela) nie moze zmodyfikowac pliku\"** - Jest to niepoprawna odpowiedź, ponieważ grupa domyślna (właściciela) ma ustawione uprawnienia `rwx` co obejmuje modyfikację pliku/katalogu. Maska `mask::rwx` nie blokuje prawa zapisu.\n\nPodsumowując, ważne jest zrozumienie, że ACL pozwalają precyzyjnie definiować prawa dostępu, a maska uprawnień ogranicza widoczne uprawnienia dla użytkowników i grup. W systemach Linux, atrybuty takie jak `setfacl` i `getfacl` są używane do modyfikacji tych praw."
    },
    {
        "questionId": 366,
        "title": "Czy system MS Windows korzysta z serwera Kerberos?: ",
        "answers": [
            {
                "text": "nigdy",
                "isCorrect": false
            },
            {
                "text": "tylko w starszych systemach (95, 98)",
                "isCorrect": false
            },
            {
                "text": "zawsze",
                "isCorrect": true
            },
            {
                "text": "jesli zostanie odpowiednio skonfigurowany",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół Kerberos to system uwierzytelniania sieciowego, który używa biletów do weryfikacji tożsamości użytkowników i usług w sieci. Zamiast przesyłać hasła przez sieć, Kerberos opiera się na wymianie zaszyfrowanych biletów pomiędzy klientem, serwerem i centrum dystrybucji kluczy (KDC, _Key Distribution Center_). W systemach MS Windows, Kerberos jest domyślnym protokołem uwierzytelniania, szczególnie w środowiskach domenowych, gdzie kontroler domeny (Domain Controller) pełni rolę centrum dystrybucji kluczy.\n\n**Odpowiedź \"nigdy\" jest niepoprawna.** Systemy MS Windows *zawsze* korzystają z protokołu Kerberos w środowiskach domenowych. Jest to podstawowy protokół uwierzytelniania, bez którego działanie domeny nie byłoby możliwe.\n\n**Odpowiedź \"tylko w starszych systemach (95, 98)\" jest niepoprawna.** W rzeczywistości, to starsze systemy MS Windows (95, 98) *nie* używały Kerberosa. Te systemy zazwyczaj korzystały z protokołu NTLM lub podobnych, mniej bezpiecznych metod uwierzytelniania. Kerberos został wprowadzony jako protokół uwierzytelniania w systemach z rodziny Windows NT, a jego rola wzrosła wraz z pojawieniem się Windows 2000 i Active Directory.\n\n**Odpowiedź \"zawsze\" jest poprawna.** Systemy MS Windows od wersji 2000 (w szczególności te pracujące w strukturze domeny Active Directory) *zawsze* korzystają z protokołu Kerberos, gdy tylko jest to możliwe. Uwierzytelnianie z wykorzystaniem Kerberos jest preferowanym sposobem komunikacji w środowiskach domenowych Windows. Jest to integralna część architektury bezpieczeństwa tych systemów i jest wykorzystywana automatycznie do uwierzytelniania użytkowników i usług.\n\n**Odpowiedź \"jeśli zostanie odpowiednio skonfigurowany\" jest niepoprawna.** Chociaż konfiguracja Kerberosa jest możliwa, np. poprzez zmianę parametrów zasad uwierzytelniania, *nie jest opcjonalne* użycie tego protokołu w środowisku domenowym. Ustawienia Kerberosa wpływają na sposób weryfikacji biletów oraz dozwolone czasy ważności biletów. Natomiast użycie Kerberosa jako takiego jest wymuszone w środowiskach domenowych i nie da się go wyłączyć czy zastąpić innym protokołem, gdy system działa w domenie.\n\\\nW praktyce, gdy komputer z systemem Windows jest dołączony do domeny Active Directory, automatycznie staje się klientem Kerberosa. Po zalogowaniu się do domeny, komputer i użytkownik uzyskują bilety Kerberos, które wykorzystywane są do uzyskiwania dostępu do innych usług i zasobów sieciowych. W tym procesie bilety są automatycznie generowane i weryfikowane w tle, bez udziału użytkownika, pod warunkiem, że polityki bezpieczeństwa (głównie dotyczące hasła) są spełnione.\n\nBrak znajomości działania protokołu Kerberos i jego roli w systemie Windows może prowadzić do błędnych konfiguracji sieciowych, a w konsekwencji do naruszeń bezpieczeństwa. Dlatego tak istotne jest, aby każdy administrator sieci i systemu Windows rozumiał działanie tego protokołu."
    },
    {
        "questionId": 367,
        "title": "Algorytmy SHA-256 i SHA-512 roznia sie wzajemnie:",
        "answers": [
            {
                "text": "ograniczeniami eksportowymi",
                "isCorrect": false
            },
            {
                "text": "dlugoscia kluczy",
                "isCorrect": true
            },
            {
                "text": "wielkoscia wynikowego skrotu",
                "isCorrect": true
            },
            {
                "text": "zadne z powyzszych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Algorytmy SHA-256 i SHA-512 to funkcje skrótu kryptograficznego należące do rodziny SHA-2. Funkcja skrótu, zwana też funkcją mieszającą, to algorytm, który przekształca dowolnej długości dane wejściowe w dane wyjściowe o stałej, z góry określonej długości, zwane skrótem lub _digest_. Funkcje skrótu są algorytmami jednokierunkowymi – łatwo obliczyć skrót dla danej wiadomości, ale bardzo trudno, w praktyce niemożliwe, jest odtworzenie oryginalnej wiadomości na podstawie samego skrótu. SHA-256 i SHA-512 różnią się głównie długością wynikowego skrótu i wewnętrzną budową, co wynika z różnej długości użytych kluczy.\n\n*   **\"ograniczeniami eksportowymi\"** - Jest to **niepoprawna** odpowiedź. Ograniczenia eksportowe miały istotny wpływ na rozwój kryptografii, ale dotyczyły głównie algorytmów szyfrowania, takich jak DES czy AES. W przeszłości, ze względu na bezpieczeństwo narodowe, rządy różnych państw ograniczały eksport oprogramowania wykorzystującego zaawansowane algorytmy. Algorytmy z rodziny SHA-2 generalnie nie podlegały takim ograniczeniom, stąd odpowiedź ta nie rozróżnia tych dwóch algorytmów z rodziny SHA-2. Chociaż oba algorytmy SHA-256 i SHA-512 należą do rodziny SHA-2, to *same w sobie* nie różnią się ograniczeniami eksportowymi. Oba algorytmy mają podobny status prawny.\n\n*   **\"dlugoscia kluczy\"** - Jest to **poprawna** odpowiedź. Algorytmy SHA-256 i SHA-512 różnią się wewnętrzną konstrukcją, która używa różnej wielkości kluczy. W kontekście funkcji skrótu, termin „klucz” nie odnosi się do klucza szyfrowania, a raczej do parametrów wewnętrznych algorytmu, które wpływają na jego bezpieczeństwo. Dłuższy klucz wewnętrzny w SHA-512 implikuje większą złożoność obliczeniową i w efekcie dłuższy czas obliczenia skrótu, w porównaniu do SHA-256. Zastosowanie dłuższego klucza wewnętrznego algorytmu SHA-512 pozwala uzyskać większą odporność na kolizje, tj. znalezienie dwóch różnych wiadomości dających ten sam skrót. Klucz jest parametrem wewnętrznym algorytmu - nie jest on elementem wejściowym funkcji skrótu.\n    _Przykład:_ Implementacja SHA-512 używa 64-bitowych słów wewnątrz algorytmu, podczas gdy SHA-256 używa 32-bitowych słów. Ta różnica w konstrukcji (wyrażona w długości „klucza wewnętrznego”) wpływa na odporność i charakterystykę tych funkcji.\n\n*   **\"wielkoscia wynikowego skrotu\"** - Jest to **poprawna** odpowiedź. SHA-256 produkuje skróty o długości 256 bitów, natomiast SHA-512 - skróty o długości 512 bitów. Długość skrótu bezpośrednio wpływa na poziom bezpieczeństwa, jaki zapewnia algorytm.  Im dłuższy skrót, tym bardziej zmniejsza się prawdopodobieństwo znalezienia kolizji. Jest to podstawowa różnica pomiędzy algorytmami SHA-256 i SHA-512.\n    _Przykład:_ SHA-256 jest powszechnie używany do weryfikacji integralności plików, natomiast SHA-512 jest używany, gdy priorytetem jest wyższy poziom bezpieczeństwa, na przykład w przypadku hashowania haseł lub tworzenia podpisów cyfrowych.\n\n*   **\"zadne z powyzszych\"** - Jest to **niepoprawna** odpowiedź, ponieważ co najmniej dwie poprzednie odpowiedzi są prawidłowe."
    },
    {
        "questionId": 368,
        "title": "Ktorym z ponizszych terminow okresla sie ograniczone srodowisko wykonawcze aplikacji lub jej komponentu:",
        "answers": [
            {
                "text": "komnata (room)",
                "isCorrect": false
            },
            {
                "text": "komora (chamber)",
                "isCorrect": false
            },
            {
                "text": "karcer (jailbox)",
                "isCorrect": false
            },
            {
                "text": "piaskownica (sandbox)",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Piaskownica (ang. sandbox) to w informatyce i bezpieczeństwie systemów komputerowych termin opisujący odizolowane środowisko wykonawcze dla aplikacji lub jej komponentu. Celem piaskownicy jest uniemożliwienie uruchamianemu kodowi dostępu do zasobów systemu operacyjnego lub innych aplikacji, które nie są mu jawnie udostępnione. Piaskownica jest wykorzystywana przede wszystkim do uruchamiania kodu o nieznanym lub niskim poziomie zaufania. Przykładowo, przeglądarki internetowe uruchamiają aplety Java i kod JavaScript w piaskownicy, aby złośliwy kod nie mógł wyrządzić szkody systemowi operacyjnemu czy innym aplikacjom.\n\n*   **komnata (room)** - Ten termin nie jest w żaden sposób powiązany z odizolowanym środowiskiem wykonawczym w kontekście systemów komputerowych. \"Komnata\" jest terminem ogólnym oznaczającym pomieszczenie, a nie środowisko wirtualne.\n\n*   **komora (chamber)** - Podobnie jak \"komnata\", termin \"komora\" nie jest używany do opisu odizolowanego środowiska wirtualnego w informatyce. \"Komora\" odnosi się do fizycznej przestrzeni, a nie do środowiska wykonawczego kodu.\n\n*   **karcer (jailbox)** - Termin \"karcer\" jest bliski z tematyki ale nie jest poprawny. Jest on czasami stosowany dla określenia mechanizmu _jail_ z systemów Unix/Linux jednak znacznie bardziej odpowiednim określeniem jest _piaskownica_. Aplikacje osadzona w karcerze nie może modyfikować plików poza wyznaczonym zakresem, jednak nadal ma dostęp do większości mechanizmów jądra systemu operacyjnego. \n\n*   **piaskownica (sandbox)** - Jest to poprawne określenie odizolowanego środowiska wykonawczego dla aplikacji lub jej komponentu. Aplikacja zamknięta w piaskownicy nie ma dostępu do większości funkcji oferowanych przez system operacyjny a do swoich zadań ma wydzielone miejsce na dysku. Dobrym przykładem jest wspomniana wcześniej implementacja piaskownicy w przeglądarkach internetowych. Przykładowo, gdy pobieramy nieznany plik i zechcemy go uruchomić w takim środowisku, to system operacyjny zadba aby taki program nie mógł modyfikować ważnych danych systemu, w tym w szczególności rejestru systemowego czy innych aplikacji."
    },
    {
        "questionId": 369,
        "title": "Kontrola dostepu do zasobow jest zwiazana z zachowaniem wlasnosci:",
        "answers": [
            {
                "text": "poufnosci i integralnosci",
                "isCorrect": true
            },
            {
                "text": "tylko poufnosci",
                "isCorrect": false
            },
            {
                "text": "tylko integralnosci",
                "isCorrect": false
            },
            {
                "text": "zadnej z powyzszych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Kontrola dostępu, czyli mechanizmy decydujące o tym, kto i w jaki sposób może korzystać z zasobów systemu komputerowego, jest bezpośrednio związana z dwoma kluczowymi własnościami bezpieczeństwa: poufnością i integralnością. Poufność (ang. *confidentiality*) oznacza ochronę danych przed nieautoryzowanym ujawnieniem, czyli dostępem do odczytu. Integralność (ang. *integrity*) natomiast zapewnia, że dane są chronione przed nieautoryzowaną modyfikacją lub zniszczeniem, czyli dostępem do zapisu. Mechanizmy kontroli dostępu, takie jak listy kontroli dostępu (ACL) czy mechanizmy oparte na rolach, decydują o tym, kto może czytać dane (własność poufności) i kto może je zmieniać lub kasować (własność integralności). \n\n*   **\"poufnosci i integralnosci\"** - Jest to poprawna odpowiedź. Kontrola dostępu ma na celu zabezpieczenie zasobów przed nieuprawnionym odczytem (poufność) i modyfikacją (integralność). Na przykład, system kontroli dostępu w banku zapewnia, że tylko uprawnieni pracownicy mogą przeglądać dane osobowe klientów (poufność) oraz dokonywać zmian w ich kontach (integralność).\n\n*   **\"tylko poufnosci\"** - Ta odpowiedź jest niepoprawna. Chociaż kontrola dostępu ma kluczowe znaczenie dla zapewnienia poufności danych, to równie ważna jest jej rola w zachowaniu integralności. System kontroli dostępu zabezpiecza przed nieuprawnionym ujawnieniem, ale także chroni przed nieuprawnioną modyfikacją, która mogłaby zafałszować dane. \n\n*   **\"tylko integralnosci\"** - Ta odpowiedź jest również niepoprawna. Kontrola dostępu ma kluczowe znaczenie dla integralności, ale nie można pominąć jej roli w zachowaniu poufności. Sam mechanizm integralności nie chroni przed ujawnieniem danych, a jedynie przed ich modyfikacją.\n\n*   **\"zadnej z powyzszych\"** - Jest to niepoprawna odpowiedź. Kontrola dostępu jest podstawowym mechanizmem służącym do zachowania zarówno poufności, jak i integralności danych. System operacyjny, system bazodanowy czy aplikacja, aby były bezpieczne muszą opierać się o mechanizmy kontroli dostępu."
    },
    {
        "questionId": 370,
        "title": "Czy RSBAC to:",
        "answers": [
            {
                "text": "poprawnie skonfigurowana polityka bezpieczenstwa",
                "isCorrect": false
            },
            {
                "text": "domyslne uprawnienia systemowe",
                "isCorrect": false
            },
            {
                "text": "zestaw rozszerzajacy kontrole uprawnien",
                "isCorrect": true
            },
            {
                "text": "zestaw lat na jadro systemu Linux",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "RSBAC, czyli Rule-Set Based Access Control, to system kontroli dostępu, który wprowadza zmiany w jądrze systemu operacyjnego Linux. Nie jest to tylko zestaw reguł, które można łatwo zmienić, ale zestaw łat (ang. *patches*) modyfikujących zachowanie jądra systemu. Zwykły system Linux używa mechanizmu kontroli dostępu DAC (ang. *Discretionary Access Control*), gdzie użytkownik ma możliwość nadawania i zmieniania uprawnień dostępu do posiadanych plików. System RSBAC to mechanizm MAC (ang. *Mandatory Access Control*), gdzie polityka bezpieczeństwa jest centralnie zarządzana i narzucana przez administratora systemu. Oznacza to, że nawet jeśli atakujący zdobędzie uprawnienia użytkownika, nie będzie mógł w łatwy sposób ominąć ograniczeń nałożonych przez system RSBAC.\n\n*   **„poprawnie skonfigurowana polityka bezpieczenstwa”** - Ta odpowiedź jest niepoprawna. RSBAC to *narzędzie*, które pomaga *wdrożyć* politykę bezpieczeństwa, a nie sama polityka. Polityka bezpieczeństwa jest abstrakcyjnym opisem zasad i reguł, które określają jak dane i zasoby mają być chronione. RSBAC jest mechanizmem, który umożliwia realizację tej polityki w systemie. Przykładowo, polityka bezpieczeństwa może zakładać, że serwer WWW nie powinien mieć prawa odczytu kluczy kryptograficznych systemowych, a RSBAC to zestaw narzędzi które pozwalają to ustawić.\n\n*   **„domyslne uprawnienia systemowe”** - Ta odpowiedź jest niepoprawna. Domyślne uprawnienia systemowe to te, które są ustawiane przy standardowej instalacji Linuxa i korzystają z DAC, a nie z rozszerzeń oferowanych przez system RSBAC. Te standardowe uprawnienia mogą być zmieniane przez właściciela zasobu i nie są w żaden sposób chronione, tak jak to jest w systemie RSBAC (MAC), gdzie system centralnie zarządza uprawnieniami.\n\n*   **„zestaw rozszerzajacy kontrole uprawnien”** - Ta odpowiedź jest poprawna. RSBAC jest właśnie takim zestawem rozszerzającym możliwości kontroli dostępu oferowanym przez standardowy system Linux. RSBAC pozwala na definiowanie bardziej skomplikowanych reguł kontroli dostępu, wykraczających poza standardowe prawa dostępu użytkownika i grupy (odczyt, zapis, wykonywanie).\n\n*  **„zestaw lat na jadro systemu Linux”** - Ta odpowiedź jest poprawna. RSBAC jest zestawem modyfikacji (łat) dla jądra systemu Linux. Modyfikacje te pozwalają na zmianę domyślnego zachowania systemu i wdrożenie bardziej rygorystycznych zasad kontroli dostępu opartych o mechanizmy MAC. Te łatki integrują się z jądrem, modyfikując sposób, w jaki system operacyjny zarządza uprawnieniami. W praktyce, oznacza to, że po zainstalowaniu RSBAC trzeba skompilować nowe jądro systemu z wbudowanymi łatkami RSBAC.\n\nPodsumowując, RSBAC to nie jest gotowa polityka bezpieczeństwa, czy uprawnienia same w sobie, ale rozszerzenie, które umożliwia *implementację* takiej polityki z pomocą modyfikacji jądra i narzędzi administracyjnych. Daje to administratorowi większą kontrolę i elastyczność w kształtowaniu polityki bezpieczeństwa."
    },
    {
        "questionId": 371,
        "title": "Pre-shared key to:",
        "answers": [
            {
                "text": "przestarzaly mechanizm sluzacy do logowania sie na zdalnego hosta bez podawania hasla",
                "isCorrect": false
            },
            {
                "text": "cos takiego nie istnieje",
                "isCorrect": false
            },
            {
                "text": "prosty mechanizm pozwalajacy szyfrowac i uwierzytelniac strony za pomoca jednego klucza",
                "isCorrect": true
            },
            {
                "text": "silny mechanizm uwierzytelniania wykorzystujacy generowany losowo po obu stronach klucz",
                "isCorrect": false
            },
            {
                "text": "silny mechanizm szyfrowania wykorzystujacy certyfikaty SSL do generacji losowego klucza sesyjnego",
                "isCorrect": false
            },
            {
                "text": "jest to przyklad kryptografii symetrycznej",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Pre-shared key, czyli klucz współdzielony, to po prostu tajny ciąg znaków, znany tylko dwóm lub więcej stronom, które chcą bezpiecznie komunikować się za jego pomocą. Jest to podstawowy element kryptografii symetrycznej. Kryptografia symetryczna wykorzystuje ten sam klucz zarówno do szyfrowania, jak i odszyfrowania danych. Zatem przed rozpoczęciem bezpiecznej komunikacji strony muszą wymienić się tym kluczem, w taki sposób aby osoby niepowołane nie miały do niego dostępu.  Pre-shared key jest  najprostszą metodą zapewnienia poufności i uwierzytelniania stron. Stosuje się go często w miejscach, gdzie skomplikowane mechanizmy kryptografii asymetrycznej, bazujące na certyfikatach, są niepotrzebne lub trudne do wdrożenia. Przykładowym rozwiązaniem w którym używany jest ten mechanizm jest popularne oprogramowanie OpenVPN. \n*   **\"przestarzaly mechanizm sluzacy do logowania sie na zdalnego hosta bez podawania hasla\"** - Jest to **nieprawidłowa** odpowiedź. Mechanizm zaufania z wykorzystaniem identycznych nazw komputerów (i użytkowników) po stronie serwera i klienta pozwala na pominięcie hasła. Pre-shared key nie służy do zdalnego logowania się bez hasła.\n*   **\"cos takiego nie istnieje\"** - Jest to **nieprawidłowa** odpowiedź. Pre-shared key to powszechnie stosowany mechanizm kryptograficzny.\n*   **\"prosty mechanizm pozwalajacy szyfrowac i uwierzytelniac strony za pomoca jednego klucza\"** - Jest to **prawidłowa** odpowiedź. Dokładnie tak działa kryptografia symetryczna z wykorzystaniem klucza współdzielonego.\n*   **\"silny mechanizm uwierzytelniania wykorzystujacy generowany losowo po obu stronach klucz\"** - Jest to **nieprawidłowa** odpowiedź. Klucz współdzielony nie jest generowany losowo po obu stronach komunikacji. Jest wcześniej wygenerowany i przekazany obu stronom połączenia.\n*   **\"silny mechanizm szyfrowania wykorzystujacy certyfikaty SSL do generacji losowego klucza sesyjnego\"** - Jest to **nieprawidłowa** odpowiedź. Certyfikaty SSL są wykorzystywane w kryptografii asymetrycznej a nie w kryptografii symetrycznej opartej na kluczu współdzielonym.\n*   **\"jest to przyklad kryptografii symetrycznej\"** - Jest to **prawidłowa** odpowiedź. Klucz współdzielony z definicji jest elementem kryptografii symetrycznej.\n\nPre-shared key jest stosowany np. w konfiguracjach VPN do szyfrowania i uwierzytelniania. Wyobraźmy sobie dwie filie firmy, które chcą bezpiecznie komunikować się przez internet. Wybierają one uproszczony sposób konfiguracji VPN z użyciem OpenVPN. W tym celu muszą obie strony wygenerować i umieścić identyczny klucz w konfiguracji serwera i klienta. Wygenerowanie współdzielonego klucza odbywa się na jednej ze stron i przekazywane jest drugiej stronie tajnym kanałem (np. listownie). Jest to prosty i wygodny mechanizm, jednak z drugiej strony w przypadku kompromitacji klucza (jego poznania przez osobę niepowołaną) natychmiastowa zmiana klucza będzie utrudniona, gdyż najpierw obie strony muszą się wymienić nową tajną informacją."
    },
    {
        "questionId": 372,
        "title": "Co to jest challenge-response?",
        "answers": [
            {
                "text": "mechanizm pozwalajacy uwierzytelniac sie bez potrzeby przesylania tajnego klucza",
                "isCorrect": true
            },
            {
                "text": "przestarzala forma uwierzytelniania stosowana w ssh",
                "isCorrect": false
            },
            {
                "text": "nie istnieje cos takiego",
                "isCorrect": false
            },
            {
                "text": "mechanizm wykorzystywany w kryptografii dyskretnej",
                "isCorrect": false
            },
            {
                "text": "silny mechanizm szyfrowania wykorzystujacy kryptografie klucza publicznego",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm \"challenge-response\" (wyzwanie-odpowiedź) jest metodą uwierzytelniania, która pozwala na weryfikację tożsamości użytkownika bez konieczności przesyłania tajnego klucza lub hasła w postaci jawnej przez sieć. Zamiast tego, serwer wysyła \"wyzwanie\" - losową wartość, do klienta, a klient używa swojego hasła lub klucza do przetworzenia wyzwania i odesłania \"odpowiedzi\". Serwer następnie weryfikuje poprawność odpowiedzi, nie znając bezpośrednio hasła klienta.\n\n**Poprawna odpowiedź:** \"mechanizm pozwalajacy uwierzytelniac sie bez potrzeby przesylania tajnego klucza\" - Jest to prawidłowa definicja mechanizmu challenge-response. Klient nie przesyła swojego hasła bezpośrednio. Zamiast tego serwer wysyła losową wartość, zwaną wyzwaniem (challenge), a klient na podstawie tego wyzwania oraz swojego hasła oblicza odpowiedź (response) i odsyła ją do serwera. Na serwerze weryfikacja następuje poprzez odtworzenie obliczenia tej odpowiedzi i porównania z wartością od klienta.  Unika się w ten sposób przesyłania hasła przez sieć w postaci jawnej, co zwiększa bezpieczeństwo uwierzytelniania.  Praktycznym przykładem może być protokół CHAP (Challenge Handshake Authentication Protocol), wykorzystywany często w połączeniach VPN, gdzie serwer generuje losowe wyzwanie, klient je przetwarza i odsyła odpowiedź do serwera.\n\n**Niepoprawna odpowiedź:** \"przestarzala forma uwierzytelniania stosowana w ssh\" - Nie jest to prawidłowa odpowiedź. Mechanizm challenge-response nie jest przestarzałą metodą uwierzytelniania. Chociaż SSH (Secure Shell) używa głównie uwierzytelniania opartego na kluczach lub hasłach, samo hasło również może być przesłane w zaszyfrowanej formie (metoda nie wykorzystująca wyzwanie-odpowiedź) lub tokenów jednorazowych, a niektore implementacje wspieraja rownież challenge-response. Wiele systemów używa challenge-response w różnych wariantach, w tym również SSH jako dodatkowa weryfikacja w procesie uwierzytelniania. Zatem nie jest to metoda przestarzała.\n\n**Niepoprawna odpowiedź:** \"nie istnieje cos takiego\" - Jest to niepoprawna odpowiedź, gdyż mechanizm challenge-response jest szeroko stosowaną metodą uwierzytelniania w systemach komputerowych.\n\n**Niepoprawna odpowiedź:** \"mechanizm wykorzystywany w kryptografii dyskretnej\" - Jest to odpowiedź niepoprawna. Kryptografia dyskretna to ogólna dziedzina matematyki związana z kryptografią. Metoda \"challenge-response\"  nie jest  zdefiniowana  jako metoda wykorzystywana tylko w  kryptografii dyskretnej.  Kryptografia dyskretna używa szeregu funkcji  matematycznych (np. logarytm dyskretny), a \"challenge-response\" to po prostu metoda realizacji protokołu uwierzytelnienia.\n\n**Niepoprawna odpowiedź:** \"silny mechanizm szyfrowania wykorzystujacy kryptografie klucza publicznego\" - Jest to odpowiedź niepoprawna. Mechanizm \"challenge-response\" nie jest mechanizmem szyfrowania, tylko uwierzytelniania. Choć niektóre implementacje  \"challenge-response\" wykorzystują kryptografię klucza publicznego, nie jest to ich elementem niezbędnym. Klucz publiczny może być wykorzystany przy budowie odpowiedzi w systemach opartych o hasła jednorazowe, jest to jednak element dodatkowy, mający na celu zwiększenie bezpieczeństwa. Sam mechanizm \"challenge-response\" ma za zadanie uniknięcie wysłania hasła, nie dba o jego utajnienie."
    },
    {
        "questionId": 373,
        "title": "Czy serwer KDC w systemie Kerberos przechowuje konta uzytkownikow?: ",
        "answers": [
            {
                "text": "tak",
                "isCorrect": false
            },
            {
                "text": "tylko lokalne konta",
                "isCorrect": false
            },
            {
                "text": "nie",
                "isCorrect": true
            },
            {
                "text": "tylko konta administratorow",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "System Kerberos to protokół uwierzytelniania sieciowego, który używa biletów (_tickets_) do weryfikowania tożsamości użytkowników i usług w sieci. Kluczowym elementem tego systemu jest **KDC (Key Distribution Center)**, czyli Centrum Dystrybucji Kluczy. KDC to serwer, który generuje i dystrybuuje bilety i klucze sesji. W rzeczywistości KDC składa się z dwóch części: Serwera Uwierzytelniania (AS - Authentication Server) oraz Serwera Biletów (TGS - Ticket Granting Server).\n\nGłówną rolą KDC jest wydawanie biletów, które pozwalają użytkownikom i usługom uwierzytelniać się nawzajem, i ustalanie kluczy sesyjnych do bezpiecznej komunikacji, a **nie przechowywanie danych o kontach użytkowników**. Użytkownicy i ich konta są przechowywani w osobnym repozytorium i są one powiązane z KDC jedynie w czasie procedury logowania i przyznawania biletów. KDC nie przechowuje również hashy haseł.\n\nOto dlaczego poszczególne odpowiedzi są poprawne lub niepoprawne:\n\n*   **\"tak\"** - **Niepoprawna**. KDC nie przechowuje danych użytkowników, takich jak dane kontaktowe, adresy e-mail. KDC przechowuje tylko dane niezbędne do uwierzytelniania i generowania biletów. Przykładowo użytkownik _Jan Kowalski_ posiada w swoim systemie hasło, ale w KDC to hasło nie jest przechowywane. Podczas logowania do systemu komputer Jan Kowalski przedstawia bilet uzyskany z KDC, które na podstawie danych zawartych w bilecie przyznaje mu dostęp do systemu. \n\n*   **\"tylko lokalne konta\"** - **Niepoprawna**. KDC, będąc scentralizowaną usługą uwierzytelniania, nie ma w ogóle pojęcia czym są konta lokalne. Konta lokalne istnieją w systemach operacyjnych i to te systemy operacyjne zarządzają kontami lokalnymi. KDC używa informacji o kontach użytkowników pobranych z innego, centralnego serwera z kontami. KDC dostarcza bilety na podstawie informacji o istnieniu konta użytkownika w centralnej bazie, ale sam tych kont nie przechowuje.\n\n*   **\"nie\"** - **Poprawna**. KDC nie przechowuje kont użytkowników, tylko dane potrzebne do ich uwierzytelnienia. Dane o kontach użytkowników są przechowywane w innych systemach. W typowej architekturze z Active Directory to kontrolery domeny Active Directory zawierają bazę użytkowników, z których korzysta serwer KDC. KDC nie jest, ani nie powinien być, traktowany jak scentralizowany repozytorium kont użytkowników. KDC może w pewnym sensie kojarzyć konta ale tylko do celów generowania biletów.\n\n*   **\"tylko konta administratorow\"** - **Niepoprawna**. Podobnie jak w poprzednim punkcie, KDC nie przechowuje żadnych kont, czy to administratorów czy zwykłych użytkowników, używa jedynie informacji o istnieniu kont pobieranych z zewnętrznych źródeł.\n\nPodsumowując, KDC w Kerberos działa na zasadzie zaufanej trzeciej strony, która pośredniczy w uwierzytelnianiu, generuje bilety i klucze sesji, ale nie przechowuje samych kont użytkowników. Ta wiedza jest kluczowa przy projektowaniu i zarządzaniu systemem opartym na protokole Kerberos. Na przykład, administrator powinien wiedzieć, że podczas awarii KDC, użytkownicy nie będą w stanie się zalogować do zasobów sieciowych. Powinien też mieć wiedzę, że dane do wygenerowania biletu pochodzą z innego źródła(kontrolery domeny) i ich uszkodzenie również uniemożliwi logowanie użytkowników. Nie należy zatem traktować KDC jako bazy danych o użytkownikach."
    },
    {
        "questionId": 374,
        "title": "W jaki sposob polaczenie nawiazane przez rsh jest zabezpieczone?: ",
        "answers": [
            {
                "text": "kodowana komunikacja przy uzyciu funkcji XOR",
                "isCorrect": false
            },
            {
                "text": "szyfrowana komunikacja po podaniu hasla i loginu",
                "isCorrect": false
            },
            {
                "text": "komunikacja uwierzytelniana w kryptograficznie bezpieczny sposob",
                "isCorrect": false
            },
            {
                "text": "komunikacja nie jest chroniona",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół rsh (remote shell) to usługa, która umożliwia zdalny dostęp do powłoki systemu operacyjnego na innym komputerze. Rsh, w przeciwieństwie do ssh, **nie oferuje żadnej ochrony** przesyłanych danych. Oznacza to, że cała komunikacja, w tym hasła użytkowników, jest przesyłana w postaci **tekstu jawnego** (ang. *plaintext*). Atakujący, który ma możliwość monitorowania ruchu sieciowego, może łatwo przechwycić te dane i je wykorzystać.\n\n**Odpowiedź 1: \"kodowana komunikacja przy uzyciu funkcji XOR\" jest niepoprawna**. Funkcja XOR jest prostą operacją logiczną. Jej zastosowanie do kodowania wiadomości zapewnia minimalną ochronę i nie jest uznawana za mechanizm szyfrowania. Wykorzystywanie XOR w połączeniu sieciowym nie zapewnia jakiejkolwiek poufności czy integralności wiadomości. Jest to przestarzała metoda która nie nadaje się do zabezpieczania komunikacji. Rsh nie używa XOR ani żadnych innych algorytmów szyfrowania.\n\n**Odpowiedź 2: \"szyfrowana komunikacja po podaniu hasla i loginu\" jest niepoprawna**. Rsh przesyła hasło w postaci jawnej. Pomimo że użytkownik musi wprowadzić hasło by się zalogować, nie jest ono szyfrowane podczas transmisji przez sieć. Ten sposób uwierzytelniania jest bardzo podatny na ataki i uważany za niebezpieczny.\n\n**Odpowiedź 3: \"komunikacja uwierzytelniana w kryptograficznie bezpieczny sposob\" jest niepoprawna**. Rsh nie wykorzystuje żadnych metod kryptograficznych do zabezpieczania procesu uwierzytelniania. Uwierzytelnianie następuje w sposób nieszyfrowany, narażając tym samym hasło na ataki. Zastosowanie tego mechanizmu może doprowadzić do przejęcia konta zdalnego użytkownika, w bardzo prosty sposób, przy użyciu popularnych programów służących do monitorowania sieci, które przechwytują w czytelnej postaci nazwy użytkownika i hasła przesyłane przez rsh.\n\n**Odpowiedź 4: \"komunikacja nie jest chroniona\" jest poprawna**. Rsh nie szyfruje przesyłanych danych, ani nie zabezpiecza procesu uwierzytelniania. Oznacza to, że hasło przesyłane jest w postaci jawnej. Każdy, kto ma dostęp do ruchu sieciowego, może przechwycić komunikację, w tym hasło, i wykorzystać je do nieautoryzowanego dostępu do zdalnego systemu. Przykładowo w sieci lokalnej, jeśli ktoś włączy program do monitorowania ruchu sieciowego to może bardzo łatwo przechwycić nazwy użytkowników oraz ich hasła przesyłane za pomocą rsh. To właśnie brak ochrony w protokole rsh jest powodem dla którego protokół ten nie powinien być wykorzystywany i jest bardzo rzadko włączony w obecnie dostępnych systemach. Zamiast tego powszechnie używany jest protokół ssh który rozwiązuje ten problem oferując ochronę poufności przesyłanych danych oraz bezpieczny mechanizm uwierzytelniania"
    },
    {
        "questionId": 375,
        "title": "W RSBAC, czy mozna zmienic uprawnienia do katalogu dla programu podczas jego dzialania?: ",
        "answers": [
            {
                "text": "jesli program posiada taka mozliwosc (programista uwzglednil taka opcje)",
                "isCorrect": true
            },
            {
                "text": "nie jest to okreslone",
                "isCorrect": false
            },
            {
                "text": "istnieja takie mozliwosci",
                "isCorrect": false
            },
            {
                "text": "nie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "System RSBAC (Rule-Set Based Access Control) to rozszerzenie bezpieczeństwa dla jądra systemu Linux, które implementuje mechanizmy obowiązkowej kontroli dostępu (MAC - Mandatory Access Control). W odróżnieniu od standardowej dla systemów Linux/Unix uznaniowej kontroli dostępu (DAC - Discretionary Access Control), gdzie program może w trakcie swojego działania podejmować decyzje o zmianie kontekstu użytkownika (np. poprzez ustawienie bitów suid lub sgid) lub praw dostępu do zasobów, w RSBAC to administrator systemu definiuje ścisłe reguły dostępu, a programy nie mogą ich dowolnie zmieniać w czasie wykonywania. Zmiana uprawnień jest możliwa, jednak wymaga jawnego pozwolenia ze strony administratora w konfiguracji systemu RSBAC.\n\n**Odpowiedź: \"jesli program posiada taka mozliwosc (programista uwzglednil taka opcje)\" jest poprawna.** Oznacza to, że zmiana uprawnień do katalogu w RSBAC *nie* jest typowym zachowaniem, do którego program może dojść poprzez normalne działanie, nawet jeśli kod programu to przewiduje. W systemie z klasyczną kontrolą DAC, program działający z podwyższonymi uprawnieniami (na przykład z bitem suid ustawionym dla wykonywalnego pliku) może swobodnie zmieniać użytkownika, grupę, prawa dostępu do plików w systemie operacyjnym. Jednak w RSBAC takie zachowanie wymaga jawnej i precyzyjnej konfiguracji polityki bezpieczeństwa, w której należy wskazać, jaki program, do jakiego zasobu i w jaki sposób może mieć dostęp, i tylko w ten sposób program może zmienić swoje uprawnienia.  Mechanizm ten chroni przed atakami, gdzie wykorzystywane są luki bezpieczeństwa i dzięki temu zyskuje się zdalny dostęp do shella, do którego automatycznie przypisywane są uprawnienia właściciela programu, a z tym idzie możliwość nadużywania praw. W RSBAC trzeba jasno zdefiniować, jakie prawa ma mieć uruchomiony program (np. serwer WWW).\n   *   Przykład: Serwer WWW (np. Apache) po uruchomieniu z uprawnieniami roota i z ustawionym bitem suid , zwykle po wczytaniu plików konfiguracyjnych i portu na którym ma działać, uruchamia się ponownie jako użytkownik wwwrun (lub podobny). W normalnym systemie operacyjnym może on robić prawie wszystko, gdyż tylko od administratora zależy czy to konto ma ograniczony dostęp do systemu. W RSBAC w przypadku wystąpienia nieprawidłowości w konfiguracji serwer lub w jego działaniu, wykorzystanie luki bezpieczeństwa może się okazać niemożliwe, ponieważ administrator mógł utworzyć bardzo restrykcyjne reguły dostępu dla serwera Apache. \n\n**Odpowiedź: \"nie jest to okreslone\" jest niepoprawna.** W systemie RSBAC to administrator, a nie programista, określa, czy i jak program może zmieniać prawa dostępu. To jest fundamentalna różnica między DAC i MAC. Oznacza to, że *jest* to bardzo ściśle określone poprzez reguły.\n\n**Odpowiedź: \"istnieja takie mozliwosci\" jest niepoprawna.**  Odpowiedź sugeruje ogólną możliwość zmiany uprawnień przez program, co jest prawdą tylko przy bardzo specyficznej konfiguracji RSBAC. Jest to mylące, ponieważ w standardowej konfiguracji RSBAC nie zezwala na dynamiczne zmiany uprawnień do katalogów w trakcie działania programu.\n\n**Odpowiedź: \"nie\" jest niepoprawna.** System RSBAC pozwala na zmianę uprawnień, jednak *nie* przez sam program, tylko poprzez specjalnie skonfigurowane ustawienia przez administratora systemu. Tego typu ustawienia uprawnień dla programów nie są wykonywane często tylko przy instalacji serwera i jego konfiguracji, dzięki temu administrator ma pełną kontrole nad bezpieczeństwem serwera."
    },
    {
        "questionId": 376,
        "title": "Czy TCP wrapper to: ",
        "answers": [
            {
                "text": "samodzielny program analizujacy tylko polaczenia tcp",
                "isCorrect": true
            },
            {
                "text": "lata (ang. patch) rozszerzajaca funkcjonalnosc programu xinetd",
                "isCorrect": false
            },
            {
                "text": "program analizujacy tylko przychodzace polaczenia tcp, ale dla numerow portow na ktorych uruchomione sa uslugi zarzadzane przez xinetd",
                "isCorrect": false
            },
            {
                "text": "program w postaci prostego firewalla za pomoca ktorego mozna blokowac wychodzace polaczenia, odpowiednie reguly zapisywane sa w plikach /etc/hosts.allow i /etc/hosts.deny",
                "isCorrect": true
            },
            {
                "text": "dodatkowy podsystem sieciowy dla systemu operacyjnego Linux pozwalajacy na nakladanie ograniczen dla polaczen przychodzacych",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "TCP Wrapper to narzędzie kontroli dostępu, które działa na poziomie aplikacji, a nie na poziomie sieci. Umożliwia ono filtrowanie połączeń TCP (Transmission Control Protocol) do usług sieciowych na podstawie adresów IP. Jest to swego rodzaju \"strażnik\" dla poszczególnych programów serwerowych, które nasłuchują na portach TCP, dodając im warstwę ochronną. W przeciwieństwie do pełnoprawnych firewalli, które operują na poziomie sieci i filtrują ruch na podstawie nagłówków pakietów IP, TCP Wrapper działa na poziomie aplikacji. Analizuje połączenia przychodzące do określonych usług sieciowych, decydując czy dane połączenie powinno być dopuszczone czy odrzucone na podstawie zestawu reguł konfiguracyjnych. Program tcpd (TCP Wrapper daemon) pośredniczy w ustanawianiu połączenia, przepuszczając połączenie tylko jeśli adres IP źródła pasuje do reguły zezwalającej.\n\n**Opcja 1: \"samodzielny program analizujacy tylko polaczenia tcp\"**\nTa odpowiedź jest **poprawna**. TCP Wrapper działa jako samodzielny program, tcpd, który analizuje jedynie połączenia oparte o protokół TCP. Nie obsługuje on innych protokołów warstwy transportowej, jak np. UDP. Wykorzystuje pliki konfiguracyjne do określania kto, z jakiego adresu IP i do jakiej usługi ma mieć dostęp.\n\n**Opcja 2: \"lata (ang. patch) rozszerzajaca funkcjonalnosc programu xinetd\"**\nTa odpowiedź jest **niepoprawna**. TCP Wrapper i xinetd (extended Internet Daemon) są oddzielnymi narzędziami, choć mogą współpracować. Xinetd to superdemon, który zarządza uruchamianiem usług sieciowych.  TCP Wrapper natomiast jest używany przez xinetd (jeśli jest skonfigurowany) do kontrolowania dostępu do tych usług, ale nie rozszerza funkcjonalności samego xinetd. To nie jest łatka rozszerzająca xinetd, a dodatkowe narzędzie powiązane z xinetd.\n\n**Opcja 3: \"program analizujacy tylko przychodzace polaczenia tcp, ale dla numerow portow na ktorych uruchomione sa uslugi zarzadzane przez xinetd\"**\nTa odpowiedź jest **niepoprawna**. TCP Wrapper analizuje połączenia przychodzące (tylko połączenia przychodzące!), ale może być użyty z dowolnymi usługami sieciowymi opartymi o TCP, nie tylko tymi uruchamianymi przez xinetd. Może być wykorzystany np. do zabezpieczenia serwera SSH, który nie jest uruchamiany przez xinetd, a działa jako samodzielna usługa.  Chociaż najczęściej wykorzystuje się go w kombinacji z xinetd do ochrony małych, prostych usług.\n\n**Opcja 4: \"program w postaci prostego firewalla za pomoca ktorego mozna blokowac wychodzace polaczenia, odpowiednie reguly zapisywane sa w plikach /etc/hosts.allow i /etc/hosts.deny\"**\nTa odpowiedź jest **poprawna**. TCP Wrapper wykorzystuje dwa pliki konfiguracyjne: `/etc/hosts.allow` gdzie zapisywane są reguły zezwalające na dostęp i `/etc/hosts.deny`, gdzie zapisane są reguły blokujące. Pomimo tej funkcjonalności, TCP Wrapper nie jest pełnoprawnym firewallem, który operuje na niższych warstwach stosu TCP/IP, filtruje ruch wychodzący i posiada zaawansowane mechanizmy translacji NAT.  TCP Wrapper służy do kontroli dostępu na poziomie aplikacji, do programów nasłuchujących na portach TCP, nie jest narzędziem do ogólnej ochrony sieci. Co ważne, **TCP Wrapper nie filtruje ruchu wychodzącego.**\n\n**Opcja 5: \"dodatkowy podsystem sieciowy dla systemu operacyjnego Linux pozwalajacy na nakladanie ograniczen dla polaczen przychodzacych\"**\nTa odpowiedź jest **niepoprawna**. TCP Wrapper to nie podsystem sieciowy, a aplikacja działająca w przestrzeni użytkownika, która umożliwia kontrolę dostępu do programów serwerowych. Nie jest zintegrowana w sposób natywny z jądrem systemu operacyjnego, jak np. iptables. Działa jako zewnętrzny program, który jest wywoływany przy każdym przychodzącym połączeniu do chronionej usługi. Jest to mechanizm ograniczający dostęp, jednak działający na poziomie aplikacji.\n\n**Podsumowanie:**\nTCP Wrapper to narzędzie pomocne w zarządzaniu dostępem do usług sieciowych, bazujących na protokole TCP. Umożliwia administratorom zdefiniowanie reguł dla hostów, którym zezwalamy, bądź zakazujemy łączenie się z daną usługą. Konfiguracja opiera się na dwóch plikach, w których zapisuje się reguły. TCP Wrapper nie jest firewallem, gdyż nie analizuje ruchu na poziomie sieci, a jedynie na poziomie aplikacji. Jest tylko narzędziem filtrującym i kontrolującym dostęp do usług, uruchamianych na systemie operacyjnym Linux."
    },
    {
        "questionId": 377,
        "title": "user::r-x user:inf44444:r-- group::rw- group:student:r-x mask::rwx other::--x Oznacza",
        "answers": [
            {
                "text": "wszyscy moga wykonac plik",
                "isCorrect": false
            },
            {
                "text": "grupa \"student\" moze zmodyfikowac plik",
                "isCorrect": false
            },
            {
                "text": "uzytkownik \"inf44444\" nie moze czytac plik",
                "isCorrect": false
            },
            {
                "text": "uzytkownik \"inf44444\" moze czytac plik",
                "isCorrect": true
            },
            {
                "text": "grupa wlasciciela moze zmodyfikowac plik",
                "isCorrect": true
            },
            {
                "text": "maska blokuje wszystkie uprawnienia",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Systemy plików w systemie Linux i Unix wykorzystują mechanizm rozszerzonej kontroli dostępu ACL (Access Control Lists). ACL umożliwia definiowanie bardziej szczegółowych uprawnień niż standardowe uprawnienia POSIX (właściciel, grupa, inni). W definicji ACL występują wpisy określające prawa dostępu dla użytkownika (ang. `user`), grupy (ang. `group`), a także maska (ang. `mask`) oraz wpis dla pozostałych użytkowników (ang. `other`). W danym wpisie możemy spotkać następujące symbole: `r` (czytanie, ang. read), `w` (zapis, ang. write) i `x` (wykonywanie lub przeszukiwanie w przypadku katalogu, ang. execute).\n\nAnalizując podany przykład `user::r-x user:inf44444:r-- group::rw- group:student:r-x mask::rwx other::--x` :\n  * `user::r-x` oznacza, że właściciel pliku ma prawo czytać i wykonywać, ale nie ma prawa zapisu.\n  * `user:inf44444:r--` oznacza, że użytkownik o nazwie `inf44444` ma prawo tylko do odczytu, ale nie ma prawa do zapisu ani do wykonywania.\n  * `group::rw-` oznacza, że grupa będąca właścicielem pliku ma prawo odczytu i zapisu, ale nie ma prawa do wykonywania.\n  * `group:student:r-x` oznacza, że grupa o nazwie `student` ma prawo czytać i wykonywać, ale nie ma prawa zapisu.\n  * `mask::rwx` określa maksymalne prawa jakie mogą mieć nazwani użytkownicy i grupy (w tym przykładzie odczyt, zapis, wykonywanie). Maska ta nie ogranicza uprawnień właściciela i pozostałych użytkowników, jedynie nazwanych użytkowników i grupy.\n  * `other::--x` oznacza, że pozostali użytkownicy mają tylko prawo do wykonywania, ale nie mogą czytać i zapisywać.\n\nPrzejdźmy do analizy odpowiedzi:\n\n1.  **\"wszyscy moga wykonac plik\"** - **Niepoprawne**.  Wpis `other::--x` ogranicza dostęp do prawa wykonywania dla wszystkich użytkowników którzy nie są wymienieni jako właściciel, użytkownik, grupa lub grupa nazwana. Maska nie ma wpływu na uprawnienia zdefiniowane w `other`.\n\n2. **\"grupa \"student\" moze zmodyfikowac plik\"** - **Niepoprawne**. Uprawnienie `group:student:r-x` nadaje jedynie uprawnienie do odczytu i wykonania, nie nadaje prawa zapisu. Maska pozwala na przyznanie tych trzech praw (odczyt, zapis, wykonywanie) ale uprawnienie `group:student:r-x` nie ma prawa zapisu, więc grupa `student` nie może modyfikować pliku.\n\n3. **\"uzytkownik \"inf44444\" nie moze czytac plik\"** - **Niepoprawne**. Uprawnienie `user:inf44444:r--` nadaje prawo do odczytu, maska nie ogranicza tego prawa.\n\n4.  **\"uzytkownik \"inf44444\" moze czytac plik\"** - **Poprawne**.  Uprawnienie `user:inf44444:r--` pozwala na czytanie pliku. Maska `mask::rwx` nie ogranicza tego prawa, gdyż jest ona przeznaczona dla ograniczenia praw w grupach i użytkownikach nazwanych.\n    \n5.  **\"grupa wlasciciela moze zmodyfikowac plik\"** - **Poprawne**. Uprawnienie `group::rw-` umożliwia grupie właściciela pliku na jego modyfikację. Maska nie ogranicza tego prawa.\n    \n6.  **\"maska blokuje wszystkie uprawnienia\"** - **Niepoprawne**. Maska nie ogranicza uprawnień właściciela ani innych. Maska ogranicza tylko prawa nazwane w grupach i użytkownikach. W tym przypadku, mimo, że maska zezwala na `rwx` , to ostateczne prawa danej grupy/użytkownika zależą od zdefiniowanych uprawnień i masek i mogą być równe co najwyżej `rwx`, czyli mniejsze lub równe maski. Maska jest filtrem nakładanym na uprawnienia nazwanych użytkowników i grup.\n\n**Przykład:** Załóżmy, że mamy plik z ustawieniami ACL:\n`user::rw-,user:jan:rwx,group::r--,group:developers:rw-,mask::r--,other::---`\n\nUżytkownik `jan` ma ustawione uprawnienia `rwx`, ale maska ma ustawienie `r--` tak wiec efektywne uprawnienia to odczyt i brak prawa do zapisu i wykonywania. Ustawienie maski `rwx` dla nazwanego użytkownika spowoduje uzyskanie uprawnień, które zostały ustawione po prawej stronie dwukropka w pozycji użytkownika. Zawsze efektywne uprawnienia są równe \"iloczynowi\" bitowemu praw i maski. Grupa o nazwie `developers` ma również ustawione `rw-`, lecz po przefiltrowaniu przez maskę, która jest równa `r--` uprawnienia zostają ograniczone do samego odczytu."
    },
    {
        "questionId": 378,
        "title": "Jaka usluga jest szczegolnie trudna do filtrowania statycznego?:",
        "answers": [
            {
                "text": "ftp, poniewaz domyslnie serwery dzialaja w trybie pasywnym,",
                "isCorrect": false
            },
            {
                "text": "ftp, poniewaz domyslnie serwery dzialaja w trybie aktywnym,",
                "isCorrect": true
            },
            {
                "text": "rlogin, bo costam",
                "isCorrect": false
            },
            {
                "text": "rlogin, bo drugie costam",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Filtracja statyczna, inaczej bezstanowa, to metoda zabezpieczania ruchu sieciowego, w której decyzje o przepuszczaniu lub blokowaniu pakietów podejmowane są na podstawie analizy pojedynczego pakietu, bez uwzględniania wcześniejszych interakcji w ramach danej sesji.  W filtracji statycznej analizuje się takie elementy pakietu jak adres IP źródłowy i docelowy, port źródłowy i docelowy, oraz typ protokołu (np. TCP, UDP, ICMP).\n\n**Odpowiedź 1: \"ftp, poniewaz domyslnie serwery dzialaja w trybie pasywnym,\"**\nTa odpowiedź jest niepoprawna. FTP (File Transfer Protocol) to protokół używany do przesyłania plików między klientem a serwerem. Domyślnie serwery FTP działają w trybie aktywnym, a nie pasywnym. Tryb pasywny jest opcją wprowadzoną by obejść trudności z filtracją ruchu w trybie aktywnym. W trybie pasywnym, to serwer otwiera połączenie danych.\n\n**Odpowiedź 2: \"ftp, poniewaz domyslnie serwery dzialaja w trybie aktywnym,\"**\nTa odpowiedź jest poprawna. FTP w trybie aktywnym stanowi problem dla statycznej filtracji z następującego powodu: Protokół FTP używa dwóch kanałów: kanału kontrolnego (na porcie 21) oraz kanału danych (na porcie dynamicznie wynegocjowanym przez klienta). W trybie aktywnym, po ustanowieniu połączenia na porcie 21, klient wysyła do serwera swój adres IP i numer portu (dynamiczny)  na którym nasłuchuje na połączenia do przesłania danych. Następnie to serwer na podstawie informacji z pakietu inicjuje połączenie na dynamicznie ustalony port klienta, a zapora w domyślnej konfiguracji(statyczna) nie potrafi przewidzieć dynamicznie wynegocjowanego portu do przesyłania danych (jest on ustalany poza pasmem właściwej transmisji danych a do tego w sposób nieskoordynowany z zaporą). \nZastosowanie filtra statycznego, analizującego nagłówki IP i porty TCP, w przypadku aktywnego FTP jest problematyczne. Firewall musi bowiem \"przewidzieć\" dynamicznie ustalany port, który serwer FTP wybierze do komunikacji z klientem a który to jest wynegocjowany w kanale kontrolnym a nie w strumieniu danych. Z tego powodu firewalle często nie przepuszczają takiego ruchu, lub wykorzystują specyficzne algorytmy dla obsługi protokołu FTP które potrafią powiązać połączenie sterowania i połączenie danych.  W praktyce problem ten jest rozwiązywany poprzez użycie pasywnego trybu FTP, gdzie to klient, a nie serwer, inicjuje połączenie danych, i tym samym firewall może analizować port klienta bez konieczności przewidywania i nadzorowania negocjacji portu. Przykład: jeśli klient żąda pobrania pliku z serwera FTP (w trybie aktywnym), a serwer w odpowiedzi ma otworzyć połączenie danych do klienta z losowego portu, statyczny firewall nie będzie wiedział, który pakiet przepuścić, bo nie zna portu docelowego klienta. Z kolei w trybie pasywnym, firewall widzi port, na którym klient czeka na połączenie.\n\n**Odpowiedź 3: \"rlogin, bo costam\"**\nTa odpowiedź jest niepoprawna. Rlogin to protokół, który umożliwia zdalne logowanie do systemu. Chociaż rlogin jest uważany za niebezpieczny ze względu na brak szyfrowania i przesyłanie hasła w postaci jawnej, to jego filtorwanie statyczne nie jest problematyczne.\n\n**Odpowiedź 4: \"rlogin, bo drugie costam\"**\nTa odpowiedź jest niepoprawna, z tych samych powodów co poprzednia. rlogin nie stanowi problemu dla statycznej filtracji ze względu na brak dynamicznych negocjacji portów i przesyłania hasła tekstem jawnym (który może zostać przefiltrowany na poziomie danych)"
    },
    {
        "questionId": 379,
        "title": "Certyfikat EFS używany w NTFS zawiera:",
        "answers": [
            {
                "text": "klucz, którym szyfruje się pliki",
                "isCorrect": false
            },
            {
                "text": "klucz, którym deszyfruje się pliki",
                "isCorrect": false
            },
            {
                "text": "klucz publiczny użytkownika, używany do odszyfrowywania kluczy FEK",
                "isCorrect": true
            },
            {
                "text": "klucz publiczny użytkownika, używany do szyfrowania kluczy FEK",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Certyfikat EFS (Encrypting File System) w systemie plików NTFS nie szyfruje bezpośrednio plików. EFS używa szyfrowania symetrycznego z kluczem FEK (File Encryption Key) do szyfrowania zawartości pliku, a ten klucz FEK jest szyfrowany przy pomocy kryptografii asymetrycznej i do tego jest wykorzystywany certyfikat użytkownika.\n\n*   **Odpowiedź 1: \"klucz, którym szyfruje się pliki\"** - **Niepoprawna**. Certyfikat EFS nie zawiera klucza używanego bezpośrednio do szyfrowania plików. To klucz FEK, symetryczny, szyfruje plik, a nie certyfikat.\n\n*   **Odpowiedź 2: \"klucz, którym deszyfruje się pliki\"** - **Niepoprawna**. Analogicznie jak wyżej, certyfikat nie deszyfruje plików, robi to klucz FEK. Certyfikat chroni klucz FEK.\n\n*   **Odpowiedź 3: \"klucz publiczny użytkownika, używany do odszyfrowywania kluczy FEK\"** - **Poprawna**. Certyfikat EFS zawiera klucz publiczny użytkownika. Gdy plik jest szyfrowany za pomocą EFS, system generuje klucz symetryczny FEK i szyfruje nim treść pliku, a następnie FEK szyfrowany jest *kluczem publicznym* użytkownika. Klucz prywatny użytkownika z pary kluczy asymetrycznych (powiązanych z certyfikatem) jest używany *do odszyfrowania FEK*, umożliwiając dostęp do pliku.\n\n*   **Odpowiedź 4: \"klucz publiczny użytkownika, używany do szyfrowania kluczy FEK\"** - **Niepoprawna**. Jak wspomniano w poprawnej odpowiedzi klucz publiczny służy do szyfrowania klucza FEK, ale celem jest umożliwienie odszyfrowania go w przyszłości za pomocą klucza prywatnego.\n\n**Praktyczny przykład:**\nZałóżmy, że użytkownik \"Alicja\" ma plik \"raport.txt\" w systemie Windows z aktywnym EFS.\n1.  EFS generuje losowy klucz symetryczny, FEK, i używa go do zaszyfrowania pliku \"raport.txt\".\n2.  Klucz FEK zostaje zaszyfrowany za pomocą klucza publicznego Alicji, który jest zawarty w certyfikacie Alicji. Tak zaszyfrowany FEK jest przechowywany wraz z plikiem.\n3.  Kiedy Alicja otworzy plik, jej klucz prywatny, powiązany z certyfikatem, deszyfruje klucz FEK, a następnie FEK odszyfrowuje plik.\n\nPrawidłowe zrozumienie roli certyfikatu w EFS jest kluczowe dla zapewnienia bezpieczeństwa plików. Użytkownik musi mieć pewność, że nie doszło do wycieku klucza prywatnego, a tylko on ma do niego dostęp. W przeciwnym przypadku może dojść do nieautoryzowanego odszyfrowania pliku przez inną osobę lub nieuprawniony proces działający na komputerze. Zatem certyfikat EFS jest kluczowym ogniwem w łańcuchu bezpieczeństwa EFS."
    },
    {
        "questionId": 380,
        "title": "Które stwierdzenia dotyczące blokady konta użytkownika w systemie Windows są nieprawdziwe: ",
        "answers": [
            {
                "text": "licznik prób logowania jest zerowany po każdym nieudanym logowaniu",
                "isCorrect": true
            },
            {
                "text": "licznik prób logowania jest zerowany automatycznie po zadanym czasie",
                "isCorrect": false
            },
            {
                "text": "licznik prób logowania może wyzerować administrator",
                "isCorrect": false
            },
            {
                "text": "licznik prób logowania jest zerowany po każdym pomyślnym zalogowaniu",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Blokada konta użytkownika, będąca mechanizmem obronnym przed atakami typu brute-force, opiera się na śledzeniu nieudanych prób logowania. Każda nieudana próba logowania do konta powoduje zwiększenie licznika nieudanych prób logowania. Po przekroczeniu pewnego progu, konto jest blokowane na określony czas, co uniemożliwia potencjalnemu napastnikowi na kolejne próby zgadnięcia hasła. Celem tego mechanizmu jest utrudnienie zgadywania haseł, zmuszając atakującego do zmiany podejścia i uniemożliwiając mu skuteczne przeprowadzenie ataku. Ważnym aspektem tego mechanizmu jest sposób, w jaki licznik nieudanych prób logowania jest resetowany. \n\n**Odpowiedź 1: \"licznik prób logowania jest zerowany po każdym nieudanym logowaniu\"**\n\nTa odpowiedź jest **nieprawdziwa**. Licznik nie jest resetowany po nieudanym logowaniu, ponieważ byłoby to nieskuteczne. Celem blokady konta jest utrudnienie ataku brute-force, więc każda nieudana próba powinna ten licznik zwiększać. Wyzerowanie go po każdym nieudanym logowaniu spowodowałoby, że atakujący mógłby podejmować próby w nieskończoność, a mechanizm blokady konta byłby nieskuteczny.\n\n**Odpowiedź 2: \"licznik prób logowania jest zerowany automatycznie po zadanym czasie\"**\n\nTa odpowiedź jest **prawidłowa**. System Windows pozwala na skonfigurowanie, po jakim czasie bez podjęcia próby zalogowania licznik ma być zresetowany. Mechanizm ten jest potrzebny, aby zablokowane konto nie pozostało zablokowane na zawsze. Po ustawionym czasie licznik zostaje automatycznie wyzerowany co pozwala zablokowanemu użytkownikowi spróbować ponownie zalogować się.\n\n**Odpowiedź 3: \"licznik prób logowania może wyzerować administrator\"**\n\nTa odpowiedź jest **prawidłowa**. Administrator systemu ma uprawnienia do zerowania licznika nieudanych prób logowania. Jest to przydatne w sytuacjach, gdy użytkownik przez pomyłkę zablokował sobie konto. Administrator ma również możliwość zmiany ustawień tego mechanizmu, np. ilości nieudanych prób logowania oraz czasu trwania blokady.\n\n**Odpowiedź 4: \"licznik prób logowania jest zerowany po każdym pomyślnym zalogowaniu\"**\n\nTa odpowiedź jest **nieprawdziwa**. Po każdym udanym logowaniu licznik nieudanych prób logowania jest resetowany, po to aby zachęcić do logowania się do systemu. W przypadku pozostawienia licznika nie zerowanego po poprawnym logowaniu kolejny, nieudany próba logowania mogłaby spowodować, że prawidłowe konto zostanie zablokowane. Przykładowo jeśli użytkownik ma ustawiony próg zablokowania konta na 3 nieudane próby a po prawidłowym logowaniu licznik nie został by zresetowany to użytkownik przy dwóch nieudanych logowaniach oraz jednym poprawnym logowaniu (zakładamy kolejną, następującą po sobie próbę logowania) zablokował by swoje konto przy kolejnej, nieudanej próbie logowania. Dlatego system po każdej poprawnej próbie logowania musi zresetować licznik.\n\nPodsumowując, ważne jest, aby zrozumieć, że licznik nieudanych logowań nie jest zwykłym licznikiem, lecz elementem ochrony przed atakami brute-force. Jego mechanizmy działania są złożone, obejmując zarówno automatyczne zerowanie, jak i możliwość interwencji administratora, co wspólnie przyczynia się do ochrony systemu."
    },
    {
        "questionId": 381,
        "title": "Zasoby systemu operacyjnego MS Windows udostępnione poprzez SMB:",
        "answers": [
            {
                "text": "są dostępne zdalnie tylko dla tych użytkowników, którzy posiadają lokalne konto w systemie operacyjnym",
                "isCorrect": false
            },
            {
                "text": "nazywa się portami",
                "isCorrect": false
            },
            {
                "text": "zawsze wymagają uwierzytelniania (podania hasła) przy dostępie zdalnym",
                "isCorrect": false
            },
            {
                "text": "mogą mieć ograniczony dostęp do odczytu i/lub zapisu tylko dla wskazanych użytkowników",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Udostępnianie zasobów systemu MS Windows poprzez SMB (Server Message Block) to mechanizm, który pozwala na udostępnianie plików i folderów w sieci. Protokół SMB definiuje sposób, w jaki komputery w sieci (np. lokalnej lub korporacyjnej) mogą wymieniać pliki i dane. Udostępnione zasoby SMB, zwane również udziałami sieciowymi, podlegają kontroli dostępu, która pozwala na określenie, kto i w jaki sposób może z nich korzystać. W systemie Windows te uprawnienia definiuje się przez listy kontroli dostępu (ACL, _Access Control Lists_).\n\n**Odpowiedź 1: \"są dostępne zdalnie tylko dla tych użytkowników, którzy posiadają lokalne konto w systemie operacyjnym\" jest niepoprawna.**\n\nUdostępniane zasoby w systemie Windows mogą być konfigurowane tak, aby zezwalać na dostęp nie tylko użytkownikom posiadającym lokalne konta w systemie, na którym ten udział jest udostępniany. Dostęp mogą uzyskać również użytkownicy z domeny, o ile system jest dołączony do domeny. Co więcej, w konfiguracji udostępniania udziałów można zezwolić również na dostęp anonimowy (choć nie jest to zalecane ze względów bezpieczeństwa), nie wymagając żadnego lokalnego konta użytkownika. Przykładowo, w małej firmie udostępniany może być zasób, do którego dostęp posiada tylko wybrana grupa pracowników, niezależnie czy posiadają konta lokalne czy domenowe.\n\n**Odpowiedź 2: \"nazywa się portami\" jest niepoprawna.**\n\nPorty to punkty końcowe komunikacji w protokołach TCP/IP na poziomie warstwy transportowej. SMB używa portu 445 w protokole TCP (ewentualnie portu 139, gdy nie działa 445). Natomiast, zasoby udostępniane przez SMB nazywamy _udziałami sieciowymi_, a nie portami. Udziały sieciowe to logiczne nazwy przypisane do katalogów, które chcemy udostępnić w sieci. Np. możemy mieć udział sieciowy \"DziałMarketingu\", który wskazuje na lokalizację C:\\FirmaX\\Marketing. W uproszczeniu udział sieciowy to wirtualny alias do zasobu w systemie Windows.\n\n**Odpowiedź 3: \"zawsze wymagają uwierzytelniania (podania hasła) przy dostępie zdalnym\" jest niepoprawna.**\n\nDomyślnie system Windows próbuje dokonać autoryzacji połączenia na podstawie danych uwierzytelniających bieżącego użytkownika. Jednak, konfigurując zasoby SMB, można zezwolić na dostęp anonimowy (bez uwierzytelniania), lub poprosić użytkownika o podanie hasła do udostępnianego zasobu. Jeśli w konfiguracji zasobu wskażemy gościa jako użytkownika, wówczas nie będzie potrzebne podawanie hasła, aby mieć do niego dostęp. Takie uprawnienia często są przypisywane do udziałów, z których można pobrać sterowniki lub inne publiczne materiały.\n\n**Odpowiedź 4: \"mogą mieć ograniczony dostęp do odczytu i/lub zapisu tylko dla wskazanych użytkowników\" jest poprawna.**\n\nListy kontroli dostępu (ACL) powiązane z zasobami SMB umożliwiają szczegółowe ustawienia uprawnień. Dostęp do udostępnianych zasobów można precyzyjnie określić dla konkretnych użytkowników, jak również dla grup. Administrator może przykładowo zezwolić na zapis tylko dla wybranych użytkowników lub grup a wszystkim pozostałym użytkownikom udostępnić możliwość jedynie odczytu tych zasobów, a nawet zablokować dostęp dla wszystkich. Przykładem może być udostępnienie na poziomie udziałów sieciowych katalogu DziałKadr tylko dla użytkowników z grupy kadry a dla wszystkich innych zablokowanie dostępu.\n\nPodsumowując, system MS Windows, wykorzystując protokół SMB, pozwala na elastyczne ustawienia uprawnień do udostępnianych zasobów w oparciu o mechanizm list kontroli dostępu (ACL). Nie jest prawdą, że dostęp uzyskują tylko użytkownicy z lokalnymi kontami, lub że zawsze wymagane jest podanie hasła. Kluczowe jest zrozumienie roli ACL w definiowaniu dostępu do zasobów."
    },
    {
        "questionId": 382,
        "title": "Użytkownik U systemu Linux należący do grupy G1 nie ma wpisu na liście ACL do zasobu O w systemie plików. Jednak grupie G1 na liście ACL zasobu O nadano prawa r i x, a uprawnienia domyślne tego zasobu wynoszą rwx. Jakie efektywne uprawnienia do O posiada U? (U nie jest właścicielem O i nie należy do grupy zasobu O, mask=rwx):",
        "answers": [
            {
                "text": "tylko r",
                "isCorrect": false
            },
            {
                "text": "rx",
                "isCorrect": true
            },
            {
                "text": "rwx",
                "isCorrect": false
            },
            {
                "text": "żadne",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Systemy operacyjne Linux/Unix wykorzystują mechanizm list kontroli dostępu (ACL, _ang. Access Control List_) POSIX do zarządzania uprawnieniami do zasobów systemu plików. Uprawnienia te określają, kto (jaki użytkownik) i w jaki sposób (czytanie, zapis, wykonanie) może korzystać z danego zasobu. Standardowe uprawnienia POSIX są trojakie: dla właściciela zasobu, dla grupy właściciela oraz dla pozostałych użytkowników (ang. _owner, group, others_). Rozszerzenie tej funkcjonalności o ACL pozwala na definiowanie uprawnień dla konkretnych użytkowników i/lub grup. Dodatkowo ACL wykorzystuje pojęcie maski, która zawęża efektywne uprawnienia do zasobu. Definicje ACL mogą również definiować uprawnienia domyślne, czyli prawa dostępu, jakie będą automatycznie przydzielane nowo tworzonym zasobom w obrębie katalogu, w którym określono te domyślne uprawnienia. \n\nW przypadku braku wpisu użytkownika na liście ACL zasobu, system operacyjny sprawdza uprawnienia grupy, do której należy dany użytkownik. W pierwszej kolejności, system weryfikuje czy na liście ACL nie ma konkretnego wpisu użytkownika, a jeśli go nie ma, wówczas sprawdzana jest obecność grupy, do której należy użytkownik. Jeżeli dany użytkownik nie należy do grupy wymienionej na liście ACL, to ostateczne prawa dostępu są definiowane poprzez prawa dla pozostałych (ang. _others_). W przypadku, gdy wpis grupy jest na liście ACL, wówczas ostateczne uprawnienia dostępu to suma logiczna uprawnień grupy wynikająca z wpisu na liście ACL oraz praw maski.\n\nW rozważanym przypadku, użytkownik `U` nie ma bezpośredniego wpisu na liście ACL, ale należy do grupy `G1`, która posiada prawa `r` (odczyt) i `x` (wykonanie). Maska ma wartość `rwx`. Efektywne uprawnienia użytkownika U będą więc sumą uprawnień grupy G1 ograniczoną maską. W tym przypadku prawa `r` i `x` nie są maskowane. Efektywne uprawnienia użytkownika `U` wynoszą więc `rx`. Uprawnienia domyślne (`rwx`) nie mają w tym przypadku znaczenia, gdyż odnoszą się do nowo tworzonych obiektów w katalogu, a nie do już istniejących zasobów. \n\n*   **\"tylko r\"** jest **niepoprawna**, ponieważ użytkownik `U` należy do grupy `G1`, której na liście ACL nadano prawa `r` i `x`, a maska (rwx) nie ogranicza ich.\n*   **\"rx\"** jest **poprawna**, ponieważ system, w kolejności, znajduje grupę `G1`, do której należy użytkownik `U` na liście ACL zasobu i z tych uprawnień oraz maski wylicza efektywne prawa.\n*   **\"rwx\"** jest **niepoprawna** ponieważ maska ma wpływ na redukcję uprawnień, a nie na ich podwyższenie. Domyślne uprawnienia również nie mają w tym przypadku znaczenia, gdyż odnoszą się do nowo tworzonych obiektów. \n*   **\"żadne\"** jest **niepoprawna**, ponieważ system przyznaje prawa dostępu w oparciu o przynależność do grupy `G1`, a nie na ich braku.\n\n**Przykład:** Załóżmy, że mamy plik `plik.txt` z uprawnieniami standardowymi `rw-r-----`, użytkownik `janek` należy do grupy `studenci`. Plik `plik.txt` ma ustawioną maskę `r--` na liście ACL oraz wpis dla grupy `studenci`, z prawami `rw-`. Wówczas użytkownik janek może czytać plik, ale nie może go modyfikować, pomimo, że grupa do której należy domyślnie posiada prawo do zapisu."
    },
    {
        "questionId": 383,
        "title": "Co użytkownik może zrobić za pomocą komendy ulimit?:",
        "answers": [
            {
                "text": "zwiększyć swoje uprawnienia dostępu do plików",
                "isCorrect": false
            },
            {
                "text": "zablokować możliwość dokonywania zrzutu obrazu pamięci procesu do pliku (core dump)",
                "isCorrect": true
            },
            {
                "text": "ograniczyć liczbę jednocześnie otwartych plików",
                "isCorrect": true
            },
            {
                "text": "ograniczyć uprawnienia dostępu do swoich plików dla innych użytkowników",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "`ulimit` to polecenie w systemach Linux/Unix, które służy do wyświetlania lub ustawiania limitów zasobów dla procesów uruchamianych przez danego użytkownika. Nie służy ono do kontroli uprawnień dostępu do plików, a do ograniczania, jak dużo zasobów systemowych procesy danego użytkownika mogą wykorzystać. Limity te są różne i wpływają na sposób działania danego procesu w systemie. Do limitów tego typu możemy zaliczyć limit na wielkość pliku, pamięci operacyjnej, liczby otwartych plików itp.\n\n**Opcja \"zwiększyć swoje uprawnienia dostępu do plików\" jest niepoprawna.** `ulimit` nie ma wpływu na uprawnienia dostępu do plików. Uprawnienia te,  takie jak prawa odczytu, zapisu i wykonywania, są zarządzane przez inne polecenia, takie jak `chmod` i `chown`. `ulimit` jedynie reguluje, *jak* proces może korzystać z zasobów, do których ma już dostęp. Na przykład, `ulimit` nie pozwoli na odczyt pliku bez uprawnienia do odczytu, a jedynie ograniczy wielkość odczytywanego pliku przez proces z uprawnieniami do odczytu pliku.\n\n**Opcja \"zablokować możliwość dokonywania zrzutu obrazu pamięci procesu do pliku (core dump)\" jest poprawna.** `ulimit` może być użyte do ustawienia limitu na wielkość pliku core (zrzutu pamięci), który jest tworzony, gdy proces ulega awarii lub zostanie zakończony sygnałem. Ustawienie limitu na 0 za pomocą `ulimit -c 0`  uniemożliwi tworzenie plików core,  co może być przydatne w środowiskach serwerowych, gdzie  pliki core mogą zużywać  dużą ilość miejsca na dysku lub  ujawniać poufne informacje. Alternatywnie, można ustawić limit na małą wartość aby ograniczyć wykorzystanie miejsca na dysku przez pliki core.\n\n**Opcja \"ograniczyć liczbę jednocześnie otwartych plików\" jest poprawna.** `ulimit` może kontrolować maksymalną liczbę otwartych deskryptorów plików, które proces może mieć jednocześnie. Ustawienie odpowiedniego limitu zapobiega sytuacji, gdy złośliwy lub nieprawidłowo działający program otworzy za dużo plików, wyczerpując zasoby systemu, prowadząc do awarii systemu operacyjnego lub całej maszyny. Przykładowo, `ulimit -n 1024` ograniczy liczbę plików które użytkownik może otworzyć do 1024.\n\n**Opcja \"ograniczyć uprawnienia dostępu do swoich plików dla innych użytkowników\" jest niepoprawna.** `ulimit` nie wpływa bezpośrednio na uprawnienia dostępu. Do zarządzania uprawnieniami dostępu do plików, używa się innych poleceń, takich jak `chmod` oraz `chown` czy też mechanizmu ACL, który umożliwia ustawianie praw dostępu do plików dla innych użytkowników lub grup. `ulimit` kontroluje *jak* procesy *wykorzystują* pliki, do których dostęp już posiadają. Na przykład, `ulimit` nie powstrzyma innego użytkownika przed odczytaniem pliku, do którego ma prawa odczytu, ale może ograniczyć maksymalną wielkość pliku jaki ten użytkownik może odczytać."
    },
    {
        "questionId": 384,
        "title": "Jakie mechanizmy kryptograficzne są niezbędne w celu zapewnienia niezaprzeczalności (ang. nonrepudiation) w kontekście poczty elektronicznej?:",
        "answers": [
            {
                "text": "wiadomość musi być podpisana elektronicznie kluczem publicznym nadawcy",
                "isCorrect": false
            },
            {
                "text": "wiadomość musi być podpisana elektronicznie kluczem prywatnym nadawcy",
                "isCorrect": true
            },
            {
                "text": "do wiadomości musi zostać dołączony certyfikat poświadczony przez zaufany urząd CA",
                "isCorrect": false
            },
            {
                "text": "wiadomość musi zostać zaszyfrowana kluczem symetrycznym znanym jedynie stronom komunikacji",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Niezaprzeczalność (ang. *non-repudiation*) w kontekście poczty elektronicznej odnosi się do zdolności systemu do zapewnienia dowodu, że dana wiadomość została wysłana przez konkretnego nadawcę oraz że wiadomość ta dotarła do konkretnego odbiorcy. Ma ona na celu uniemożliwienie nadawcy fałszywego zaprzeczenia faktu wysłania danych lub odbiorcy fałszywego zaprzeczenia faktu otrzymania danych. Aby osiągnąć niezaprzeczalność w poczcie elektronicznej, niezbędne jest użycie kryptografii asymetrycznej w procesie podpisywania wiadomości.\n\n*   **\"wiadomość musi być podpisana elektronicznie kluczem publicznym nadawcy\"** - Ta odpowiedź jest **nieprawidłowa**. Klucz publiczny służy do weryfikacji podpisu, a nie do jego tworzenia. Podpis kluczem publicznym nie daje gwarancji niepodważalności, ponieważ każdy dysponujący kluczem publicznym mógłby dokonać podpisu. Klucz publiczny jest publicznie dostępny. Odbiorca może użyć klucza publicznego aby zweryfikować podpis, nie może za jego pomocą podpisać wiadomości.\n*   **\"wiadomość musi być podpisana elektronicznie kluczem prywatnym nadawcy\"** - Ta odpowiedź jest **poprawna**. Aby wiadomość była niezaprzeczalna, nadawca musi użyć swojego *klucza prywatnego* do utworzenia podpisu elektronicznego. Klucz prywatny, znany tylko nadawcy, umożliwia wygenerowanie unikalnego podpisu, który może być zweryfikowany za pomocą *klucza publicznego* nadawcy, który jest powszechnie dostępny. Taki podpis, zwany *podpisem cyfrowym*, udowadnia, że wiadomość została podpisana przez właściciela klucza prywatnego (czyli nadawcę wiadomości) i nie może być w prosty sposób podrobiony.  Na przykład, w procesie składania zamówienia w sklepie internetowym, sprzedawca musi być pewien, że zamówienie zostało złożone przez konkretnego kupującego i nie chce, aby w przyszłości kupujący mógł się wyprzeć faktu złożenia zamówienia. Kupujący podpisuje wiadomość z zamówieniem swoim kluczem prywatnym, udowadniając tym samym swoje autorstwo.\n*   **\"do wiadomości musi zostać dołączony certyfikat poświadczony przez zaufany urząd CA\"** - Ta odpowiedź jest **nieprawidłowa**, chociaż certyfikat może być częścią procesu niezaprzeczalności. Certyfikat *poświadcza* tożsamość właściciela klucza publicznego, który jest niezbędny do weryfikacji podpisu, a nie sam w sobie nie realizuje faktu niepodważalności. To, że mamy certyfikat od zaufanego urzędu CA, świadczy tylko o tym, że mamy odpowiedni klucz publiczny konkretnej osoby, a nie o tym, że wiadomość została wysłana przez ta osobę. Czyli w skrócie: certyfikat poświadcza, że publiczny klucz należy do danej osoby, a podpis kluczem prywatnym poświadcza, że wiadomość wysłała ta osoba. Aby osiągnąć niezaprzeczalność oba elementy muszą być razem użyte. Certyfikat sam nie wystarczy aby zagwarantować niezaprzeczalność.\n*   **\"wiadomość musi zostać zaszyfrowana kluczem symetrycznym znanym jedynie stronom komunikacji\"** - Ta odpowiedź jest **nieprawidłowa**. Szyfrowanie symetryczne zapewnia poufność wiadomości, co oznacza, że tylko osoby posiadające odpowiedni klucz mogą ją odczytać. Nie gwarantuje ono jednak, kto był nadawcą wiadomości, ponieważ klucz symetryczny znany jest obu stronom. Obie strony mogłyby zaszyfrować taką wiadomość. Czyli brak niezaprzeczalności."
    },
    {
        "questionId": 385,
        "title": "Mechanizm wirtualizacji dostępu do newralgicznych komponentów systemu Windows:",
        "answers": [
            {
                "text": "dotyczy niektórych obiektów rejestru systemowego",
                "isCorrect": true
            },
            {
                "text": "może być włączany/wyłączany przez użytkownika dla jego własnych procesów",
                "isCorrect": true
            },
            {
                "text": "dotyczy niektórych obiektów systemu plików",
                "isCorrect": true
            },
            {
                "text": "jest stosowany wyłącznie wobec aplikacji 64-bitowych",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Mechanizm wirtualizacji dostępu w systemie Windows tworzy warstwę abstrakcji pomiędzy aplikacją a rzeczywistymi zasobami systemu operacyjnego, takimi jak rejestr i system plików. W tym kontekście wirtualizacja nie oznacza uruchamiania kompletnego systemu operacyjnego w maszynie wirtualnej. Chodzi raczej o stworzenie wirtualnego widoku niektórych zasobów, który uniemożliwia aplikacji bezpośredni, niekontrolowany dostęp do tych zasobów. W ten sposób ogranicza się potencjalne szkody, jakie aplikacja mogłaby spowodować np. w przypadku ataku lub błędnego działania.\n\n**Odpowiedź 1: \"dotyczy niektórych obiektów rejestru systemowego\" - PRAWIDŁOWA.**\nWirtualizacja dostępu obejmuje wybrane klucze i wartości rejestru systemowego. Aplikacja, która próbuje zapisać do newralgicznego klucza (np. związanego z konfiguracją rozruchu), może napotkać na mechanizm wirtualizacji, który albo zablokuje taką operację, albo – co częstsze – przekieruje zapis do wirtualnej (odizolowanej od systemu) kopii zasobu. W ten sposób aplikacja „myśli”, że dokonała zmiany w systemowym rejestrze, ale w rzeczywistości zmienia tylko wirtualną kopię tej informacji. Praktycznym przykładem może być malware, które chce zmienić ustawienia startowe systemu. Mechanizm wirtualizacji dostępu jest po to by uniemożliwić takim działaniom.\n\n**Odpowiedź 2: \"może być włączany/wyłączany przez użytkownika dla jego własnych procesów\" - PRAWIDŁOWA.**\nMechanizm wirtualizacji nie jest zwykle bezpośrednio kontrolowany przez użytkownika końcowego.  To sama aplikacja oraz wewnętrzne mechanizmy systemu operacyjnego decydują o tym, kiedy i jak wirtualizacja dostępu jest wykorzystywana. Aplikacja może wykorzystywać różne ustawienia poziomu uprawnień, aby sterować tym, które zasoby będą podlegały wirtualizacji. Nie jest to jednak opcja dostępna w ustawieniach systemu, z którymi pracuje użytkownik. Zatem użytkownik decyduje pośrednio o wirtualizacji poprzez to jaką aplikacje wykorzystuje, ale użytkownik nie ustawia tych parametrów samodzielnie. Daje to aplikacjom swobodę w decydowaniu czy dany proces powinien mieć dostęp do wirtualnego widoku danych zasobów, czy do zasobów rzeczywistych. \nDobrym przykładem może być tutaj przeglądarka stron www, w której dodatek (np. zaimplementowany w Java lub ActiveX), chciałby dokonać zmian np. w kluczach rejestru. Przeglądarka działając z ograniczonymi uprawnieniami, może uruchomić taką akcję w specjalnym trybie, w którym wszystkie zmiany nie będą dotyczyć systemu, a jedynie jego odizolowanej części, zapewniając w ten sposób bezpieczeństwo.\n\n**Odpowiedź 3: \"dotyczy niektórych obiektów systemu plików\" - PRAWIDŁOWA.**\nAnalogicznie do rejestru, wirtualizacja dostępu dotyczy również wybranych lokalizacji w systemie plików, takich jak katalogi i pliki konfiguracyjne. Program działający z ograniczonymi uprawnieniami, który usiłuje zapisać dane w chronionej lokacji, np. w katalogu systemowym, może być przekierowany do wirtualnej kopii tej lokacji (która w istocie znajduje się w zupełnie innym miejscu na dysku).  W ten sposób system zapewnia, że nawet działająca z podwyższonymi uprawnieniami aplikacja, nie może dokonać trwałych zmian w systemie. Praktycznym przykładem może być sterownik (driver), instalowany w systemie, który nie działa poprawnie. W tym przypadku mechanizm wirtualizacji chroni newralgiczne pliki systemowe przed nadpisaniem i uszkodzeniem systemu.\n\n**Odpowiedź 4: \"jest stosowany wyłącznie wobec aplikacji 64-bitowych\" - NIEPRAWIDŁOWA.**\nWirtualizacja dostępu nie jest ograniczona do konkretnej architektury systemowej. Mechanizm ten może być wykorzystywany zarówno dla aplikacji 32-bitowych jak i 64-bitowych, co ma szczególne znaczenie dla zachowania kompatybilności wstecznej. W nowszych systemach Windows większość aplikacji 32-bitowych jest uruchamiana w wirtualizowanym środowisku i ma ograniczony dostęp do kluczowych zasobów. Zatem ta odpowiedź nie jest prawidłowa, bo wirtualizacja dostępu jest stosowana niezależnie od architektury oprogramowania. W obu wersjach systemu (32-bitowej i 64-bitowej) wirtualizacja ma na celu ten sam cel – ochrona systemu operacyjnego przed atakami i nieumyślnymi błędami aplikacji."
    },
    {
        "questionId": 386,
        "title": "Których wpisów ACE na liście POSIX ACL dotyczy maska: ",
        "answers": [
            {
                "text": "właściciela obiektu",
                "isCorrect": false
            },
            {
                "text": "grupy (domyślnej) pliku (z bazowych ACE)",
                "isCorrect": true
            },
            {
                "text": "każdej jawnie wpisanej grupy",
                "isCorrect": true
            },
            {
                "text": "wszystkich użytkowników niewpisanych jawnie, ale należących do dowolnej jawnie wpisanej grupy",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Maska w listach kontroli dostępu POSIX (ang. *POSIX Access Control Lists*, ACL) służy do określania maksymalnych uprawnień, które mogą mieć nadane grupy i użytkownicy poza właścicielem obiektu i innymi zdefiniowanymi użytkownikami. Wartość maski odgrywa kluczową rolę w definiowaniu *efektywnych* uprawnień dostępu. Uprawnienia zapisane w ACL, dla poszczególnych *Access Control Entry (ACE)* - wpisów kontroli dostępu - są w istocie wartościami *oczekiwanymi*, a maska pozwala na zawężenie uprawnień, poprzez ustawienie maksymalnej wartości, jaką uprawnienia danego użytkownika lub grupy mogą osiągnąć.\n\n**Opcja 1: \"właściciela obiektu\"** -  Jest **niepoprawna**. Maska *nie* odnosi się do właściciela obiektu. Uprawnienia właściciela są określane bezpośrednio w ACE właściciela (ang. user), a maska nie ma na nie wpływu.  Przykładowo, jeśli w ACL ustawiono pełne uprawnienia (_rwx_) dla właściciela, te uprawnienia zostaną przyznane właścicielowi, niezależnie od wartości maski.\n\n**Opcja 2: \"grupy (domyślnej) pliku (z bazowych ACE)\"** - Jest **poprawna**. Maska ma zastosowanie do uprawnień grupy (ang. group) - czyli domyślnej grupy posiadanej przez obiekt. Oznacza to, że jeśli w bazowych uprawnieniach ACL grupy jest przypisane prawo zapisu (`w`), ale maska na to nie pozwala, to użytkownicy tej grupy _nie będą_ mieli prawa zapisu do obiektu. Przykładowo, jeśli ustawimy dla grupy prawo odczytu i zapisu (`rw-`), a maska ustawi tylko prawo odczytu (`r--`), to w efekcie uprawnienia grupy będą ograniczone do odczytu (`r--`).\n\n**Opcja 3: \"każdej jawnie wpisanej grupy\"** - Jest **poprawna**. Maska odnosi się do uprawnień każdej z jawnie dodanych grup w ACL (ang. named group entries), poza właścicielem i innymi. Podobnie jak dla grupy domyślnej - jeśli konkretnej grupie zostałoby przyznane na liście ACL jawnie prawo do zapisu, a maska ten zapis blokuje, to grupa ta nie uzyska tych uprawnień. Maska działa jako górne ograniczenie, filtrujące uprawnienia nadane wpisom grupowym. W ACL mamy prawo zapisu dla wybranej grupy, ale w masce odznaczyliśmy tą opcję - czyli wybrana grupa nie będzie miała prawa zapisu, tylko to co jest ustawione w masce, np. tylko odczyt.\n\n**Opcja 4: \"wszystkich użytkowników niewpisanych jawnie, ale należących do dowolnej jawnie wpisanej grupy\"** - Jest **poprawna**.  Maska ogranicza uprawnienia dla członków jawnie wpisanych grup, a nie tylko samej grupy. Jeżeli użytkownik jest członkiem grupy jawnie dodanej w ACL, jego uprawnienia są określane przez ACE tej grupy, ale ograniczane przez maskę. To oznacza że, nawet jeśli użytkownik należy do grupy, która ma jawnie ustawione uprawnienia, maska dalej decyduje o ostatecznych (efektywnych) uprawnieniach użytkownika. Jeśli w ACL jest zdefiniowana grupa \"projektanci\" z prawami `rwx`, ale maska ogranicza to do `r-x`, to użytkownicy należący do grupy \"projektanci\" uzyskają ostatecznie prawa `r-x`.\n\n**Przykład:**\n\nZałóżmy że do katalogu `/home/projekt` chcemy ustawić prawa dla grupy `projektanci` tak aby mogli odczytywać i wykonywać skrypty ale nie mogły zapisywać danych do tego katalogu. Oczywiście nikt poza administratorem nie ma prawa zapisu. Wygląda to tak:\n- właściciel: użytkownik root rwx\n- grupa: root r-x\n- maska: r-x\n- grupa projektanci: rwx\n\nW efekcie grupa _projektanci_ będzie mogła odczytywać i wykonywać zawartość katalogu `/home/projekt` a zapis zostanie zablokowany przez maskę. W tym przypadku *efektywne* uprawnienia grupy *projektanci* wynoszą  `r-x`. Modyfikując maskę na `rw-`, otworzymy dostęp do zapisu dla grupy *projektanci*, natomiast zmiana maski na `---`, całkowicie zablokujemy dostęp grupie *projektanci* nawet, jeśli w ACL maja przyznane `rwx`.\n\nPodsumowując, maska ACL nie wpływa na właściciela obiektu, ani na użytkowników przypisanych indywidualnie,  ale ma fundamentalne znaczenie dla grup, decydując o tym jakie ostateczne, rzeczywiste uprawnienia posiadają. Maska jest filtrem, a nie dodatkowym uprawnieniem."
    },
    {
        "questionId": 387,
        "title": "Wskaż wszystkie warunki konieczne do weryfikacji podpisu cyfrowego wiadomości S/MIME:",
        "answers": [
            {
                "text": "uprzednie przekazanie do nadawcy klucza publicznego odbiorcy",
                "isCorrect": false
            },
            {
                "text": "dostęp odbiorcy do certyfikatu klucza publicznego CA, który certyfikował klucz publiczny nadawcy",
                "isCorrect": false
            },
            {
                "text": "uprzednie przekazanie do odbiorcy klucza publicznego nadawcy",
                "isCorrect": true
            },
            {
                "text": "poprawna wymiana kluczy między nadawcą a odbiorcą metodą Diffiego-Hellmana",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Weryfikacja podpisu cyfrowego S/MIME polega na sprawdzeniu, czy wiadomość nie została zmodyfikowana po jej podpisaniu przez nadawcę oraz czy nadawca jest tym za kogo się podaje. Podpis cyfrowy generowany jest przez nadawcę przy użyciu jego klucza prywatnego, a weryfikowany przez odbiorcę za pomocą klucza publicznego nadawcy. Klucz publiczny musi być wcześniej dostępny dla odbiorcy, a dodatkowo musi być on wiarygodny. W tym kontekście S/MIME wykorzystuje certyfikaty cyfrowe, które są poświadczeniem wiarygodności klucza publicznego.\n\n*   **\"uprzednie przekazanie do nadawcy klucza publicznego odbiorcy\"** - **Niepoprawna odpowiedź.** Klucz publiczny odbiorcy nie jest potrzebny do weryfikacji podpisu cyfrowego. Klucz publiczny odbiorcy jest niezbędny do **zaszyfrowania** wiadomości, nie do weryfikacji podpisu. Szyfrowanie wiadomości zapewnia poufność, podczas gdy podpis cyfrowy zapewnia integralność i autentyczność. S/MIME może oferować obie funkcjonalności (szyfrowanie i podpisywanie) niezależnie od siebie.\n   Przykładowo, jeśli Alicja chce wysłać *poufna* wiadomość do Bolka z wykorzystaniem szyfrowania S/MIME, Alicja potrzebuje znać klucz publiczny Bolka. Jeżeli Alicja chce podpisać wiadomość tak, aby Bolek wiedział, że wiadomość wysłała Alicja i wiadomość nie została zmodyfikowana, to Alicja potrzebuje tylko swój klucz prywatny, a Bolek - klucz publiczny Alicji.\n\n*   **\"dostęp odbiorcy do certyfikatu klucza publicznego CA, który certyfikował klucz publiczny nadawcy\"** - **Niepoprawna odpowiedź.** Choć dostęp do certyfikatu klucza publicznego CA _jest_ pośrednio konieczny, aby w pełni zaufać kluczowi nadawcy, to nie jest to wymagany warunek _bezpośredniej_ weryfikacji podpisu. Odbiorca używa klucza publicznego nadawcy bezpośrednio do sprawdzenia podpisu, a dopiero potem, opcjonalnie, weryfikuje, czy klucz ten jest ważny na podstawie certyfikatu, który został podpisany przez zaufany urząd certyfikacji (CA). Innymi słowy weryfikacja podpisu następuje _wcześniej_ niż weryfikacja wiarygodności nadawcy na podstawie jego certyfikatu.\n    Przykładowo, gdy Bolek odbiera podpisaną wiadomość od Alicji w S/MIME, Bolek używa klucza publicznego Alicji do zweryfikowania podpisu. Potem, opcjonalnie, Bolek może zweryfikować certyfikat Alicji, czyli sprawdzić, czy urząd certyfikacji (CA), który wydał Alicji certyfikat, jest zaufany przez Bolka.\n\n*   **\"uprzednie przekazanie do odbiorcy klucza publicznego nadawcy\"** - **Poprawna odpowiedź.** Odbiorca musi mieć dostęp do klucza publicznego nadawcy, aby móc poprawnie zweryfikować podpis cyfrowy. Ponieważ klucz prywatny jest znany tylko nadawcy, to podpisany skrót wiadomości tym kluczem, może być poprawnie zweryfikowany jedynie za pomocą klucza publicznego. Ta operacja kryptograficzna potwierdza, że wiadomość jest od danej osoby, która posiadała klucz prywatny, i która podpisała wiadomość oraz że treść wiadomości nie została zmodyfikowana. Klucz publiczny można uzyskać różnymi metodami. Najczęściej klucz publiczny nadawcy jest zawarty w certyfikacie, który jest dołączony do wiadomości, lub jest udostępniany jawnie przez nadawcę.\n   Przykładowo, gdy Alicja podpisuje wiadomość używając klucza prywatnego, Bolek musi użyć klucza publicznego Alicji aby móc poprawnie zweryfikować podpis.\n\n*  **\"poprawna wymiana kluczy między nadawcą a odbiorcą metodą Diffiego-Hellmana\"** - **Niepoprawna odpowiedź.** Metoda Diffiego-Hellmana służy do uzgodnienia tajnego klucza symetrycznego pomiędzy dwiema stronami w sposób bezpieczny na potrzeby szyfrowania, w protokołach innych niż S/MIME. Ta metoda nie jest wykorzystywana w procesie weryfikacji podpisu cyfrowego w S/MIME, w którym klucz publiczny nadawcy musi być wcześniej znany odbiorcy (otrzymany najczęściej wraz z certyfikatem). Diffie-Hellman jest mechanizmem umożliwiającym bezpieczną wymianę kluczy, ale nie autoryzuje komunikujących się stron (w odróżnieniu od wymiany kluczy opartej o mechanizm certyfikatów).\n   Przykładowo, jeśli Alicja i Bolek chcieliby skorzystać z metody Diffiego-Hellmana do szyfrowania komunikacji między sobą to muszą najpierw uzgodnić jawne parametry, a następnie dzięki tajnym obliczeniom, do których dostęp mają jedynie Alicja i Bolek obie strony połączenia utworzą sobie tajny klucz, który pozwoli szyfrować między sobą wiadomości. Jednak Diffie-Hellman nie zweryfikuje tożsamości Alicji ani Bolka, będzie ona musiała być zrobiona w inny sposób, np. właśnie poprzez podpis elektroniczny i certyfikat S/MIME."
    },
    {
        "questionId": 388,
        "title": "$ getfacl skrypt user :: rwuser: jbond:r-x group :: rwx group: agents: rwx mask :: r-x other ::- wOznacza, że:",
        "answers": [
            {
                "text": "grupa agents może zmodyfikować skrypt",
                "isCorrect": false
            },
            {
                "text": "grupa domyślna (owning group) może zmodyfikować skrypt",
                "isCorrect": false
            },
            {
                "text": "użytkownik jbond może wykonać skrypt",
                "isCorrect": true
            },
            {
                "text": "pozostali użytkownicy mogą zmodyfikować skrypt",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Listy kontroli dostępu (ang. Access Control Lists, ACL) rozszerzają standardowy mechanizm kontroli dostępu do plików w systemach Linux/Unix. Wyjście polecenia `getfacl` pokazuje te rozszerzone uprawnienia. Format wyjścia to specyfikator rodzaju, nazwa, oraz prawa.  `user::` oznacza uprawnienia właściciela pliku, `user:jbond:` oznacza uprawnienia specjalne dla użytkownika o nazwie `jbond`, `group::` oznacza prawa grupy będącej właścicielem pliku, `group:agents:` oznacza prawa specjalne dla grupy o nazwie `agents`, `mask::` oznacza maskę, czyli maksymalne dozwolone prawa dla nazwanych użytkowników i grup (ale nie dla właściciela) a `other::` oznacza uprawnienia dla wszystkich innych, nie będących ani właścicielem, ani należących do grup nazwanych. \n\n* **\"grupa agents może zmodyfikować skrypt\"** - **Niepoprawna.** Uprawnienia dla grupy `agents` to `rwx`, co oznacza prawa odczytu, zapisu i wykonywania, jednak maska `mask::r-x` ogranicza uprawnienia tej grupy, gdyż maska nie pozwala na uprawnienia zapisu `w`. Dlatego ta grupa nie ma uprawnień do modyfikowania pliku. Jest to przykład ograniczenia uprawnień grupy przy pomocy maski. Gdyby nie było maski grupa `agents` miałaby pełne uprawnienia `rwx`.\n* **\"grupa domyślna (owning group) może zmodyfikować skrypt\"** - **Niepoprawna.** Uprawnienia dla grupy domyślnej to `rwx`, co oznacza prawa odczytu, zapisu i wykonywania, jednak maska `mask::r-x` ogranicza uprawnienia tej grupy, gdyż maska nie pozwala na uprawnienia zapisu `w`. Dlatego ta grupa nie ma uprawnień do modyfikowania pliku. Jest to przykład ograniczenia uprawnień grupy przy pomocy maski. Gdyby nie było maski grupa domyślna miałaby pełne uprawnienia `rwx`.\n* **\"użytkownik jbond może wykonać skrypt\"** - **Poprawna.**  Uprawnienie `r-x` dla użytkownika `jbond` oznacza, że ma on prawo do odczytu i wykonania pliku. Zauważmy, że maska nie ma żadnego wpływu na to uprawnienie, gdyż uprawnienia maski odnoszą się tylko do uprawnień grup i nazwanych użytkowników.\n* **\"pozostali użytkownicy mogą zmodyfikować skrypt\"** - **Niepoprawna.** Uprawnienie dla pozostałych użytkowników to `---`, co oznacza brak praw dostępu. Dostęp do pliku dla pozostałych jest zabroniony.\n\n**Przykład:**\nZałóżmy, że mamy skrypt konfiguracyjny serwera www `skrypt.sh`, jego właścicielem jest użytkownik `root`. chcemy aby użytkownik `jbond` miał prawo wykonywać skrypt ale nie chciałoby się, aby jakaś grupa mogła go modyfikować. Wtedy można użyć następującej kombinacji poleceń: \n```\n chmod 0750 skrypt.sh\n setfacl -m user:jbond:r-x skrypt.sh\n \n\n```\n\nTaka konfiguracja gwarantuje, że żaden użytkownik (poza użytkownikiem root jako właścicielem) nie będzie mógł modyfikować skryptu, a tylko użytkownik `jbond` może go wykonywać. W tym przypadku niepotrzebne jest dodawanie uprawnień grupie, gdyż tylko jeden użytkownik ma mieć prawa wykonywania tego skryptu.\n\n**Praktyczne implikacje:** W realnym świecie, na serwerze, wiele plików (szczególnie tych konfiguracyjnych) wymaga bardzo restrykcyjnych reguł kontroli dostępu, aby uniemożliwić potencjalne manipulacje przez niepowołane osoby. Dodatkowo często spotykane jest, że różnym użytkownikom lub grupom należy przypisać różne uprawnienia do tego samego zasobu. Wtedy mechanizm POSIX ACL okazuje się bardzo przydatny."
    },
    {
        "questionId": 389,
        "title": "TCP Wrapper może korzystać z dwóch plików z regułami polityki, przy czym:",
        "answers": [
            {
                "text": "ponieważ stosuje zasadę pierwszego dopasowania, plik /etc/hosts.deny może nie być w ogóle sprawdzany",
                "isCorrect": true
            },
            {
                "text": "jeśli reguła nie zostaje odnaleziona w żadnym pliku, to dostęp zostaje odrzucony",
                "isCorrect": false
            },
            {
                "text": "najpierw sprawdzane są reguły z pliku /etc/hosts.deny, a ewentualnie później reguły z pliku /etc/hosts.allow",
                "isCorrect": false
            },
            {
                "text": "najpierw sprawdzane są reguły z pliku /etc/hosts.allow, a ewentualnie później reguły z pliku /etc/hosts.deny",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "TCP Wrappers (`tcpd`) to mechanizm kontroli dostępu do usług sieciowych w systemach Linux/Unix. Decyzję o zezwoleniu lub zablokowaniu dostępu podejmuje na podstawie reguł zdefiniowanych w dwóch plikach konfiguracyjnych: `/etc/hosts.allow` i `/etc/hosts.deny`.  Aplikacje, które chcą wykorzystywać TCP Wrappers muszą być do tego dostosowane, najczęściej występuje specjalna wersja usługi działająca przez  `tcpd` (np. /usr/sbin/in.telnetd  zamiast /usr/sbin/telnetd). `tcpd` przed uruchomieniem usługi dokonuje analizy i podejmuje decyzję o umożliwieniu uruchomienia danej usługi lub o zablokowaniu połączenia.\n\nZasada działania `tcpd` opiera się na tak zwanej \"zasadzie pierwszego dopasowania\". Oznacza to, że w pierwszej kolejności `tcpd` sprawdza plik `/etc/hosts.allow`. Jeśli znajdzie regułę pasującą do bieżącego zapytania o dostęp, **natychmiast** przyznaje dostęp i dalsze reguły (w tym reguły z `/etc/hosts.deny`) nie są już sprawdzane. Jeśli w pliku `/etc/hosts.allow` nie znajdzie żadnej reguły, która pasuje do aktualnego zapytania o dostęp, następuje sprawdzenie pliku `/etc/hosts.deny`. Analogicznie, jeśli w pliku `/etc/hosts.deny` zostanie odnaleziona pasująca reguła, dostęp zostaje zablokowany, a dalsze reguły (w tym potencjalne reguły z kolejnych plików konfiguracyjnych, o ile takowe istnieją) nie są sprawdzane. Jeśli w żadnym z plików nie znajdzie się pasująca reguła, to dostęp jest **domyślnie dozwolony**.  \n \n  *   **\"ponieważ stosuje zasadę pierwszego dopasowania, plik /etc/hosts.deny może nie być w ogóle sprawdzany\"**  \n      Jest to **poprawna** odpowiedź. Jeżeli w pliku `/etc/hosts.allow` zostanie znaleziona pasująca reguła, to plik `/etc/hosts.deny` nie jest sprawdzany, gdyż `tcpd` zatrzymuje się na pierwszej pasującej regule. Plik `/etc/hosts.deny` sprawdzany jest tylko wtedy, gdy nie ma pasującej reguły w pliku `/etc/hosts.allow`. Na przykład, jeśli w `/etc/hosts.allow` jest wpis: `sshd: 192.168.1.0/24`, to każda próba połączenia z usługą ssh z sieci `192.168.1.0/24` będzie od razu przyznawana i sprawdzenie reguł z pliku `/etc/hosts.deny` nie będzie miało miejsca.\n  \n  *   **\"jeśli reguła nie zostaje odnaleziona w żadnym pliku, to dostęp zostaje odrzucony\"**  \n      Jest to **niepoprawna** odpowiedź. Jeśli w plikach `/etc/hosts.allow` ani `/etc/hosts.deny` nie znajdzie się pasująca reguła, to dostęp do usługi jest **domyślnie dozwolony**. Oznacza to, że pakiet nie zostanie dopasowany do żadnej reguły, zatem w domyślnej konfiguracji (bez domyślnych reguł) `tcpd` przepuści taki pakiet bez żadnych ograniczeń.  Można to zmienić poprzez ustawienie domyślnej reguły w pliku `/etc/hosts.deny` blokującą wszystko `ALL: ALL`.\n  \n  *   **\"najpierw sprawdzane są reguły z pliku /etc/hosts.deny, a ewentualnie później reguły z pliku /etc/hosts.allow\"**  \n      Jest to **niepoprawna** odpowiedź. Plik `/etc/hosts.deny` jest sprawdzany tylko wtedy, gdy w pliku `/etc/hosts.allow` nie znajdzie się pasująca reguła. Sprawdzanie pliku `/etc/hosts.deny` następuje po sprawdzeniu wszystkich reguł z pliku `/etc/hosts.allow` .\n   *   **\"najpierw sprawdzane są reguły z pliku /etc/hosts.allow, a ewentualnie później reguły z pliku /etc/hosts.deny\"**  \n      Jest to **poprawna** odpowiedź. `tcpd` sprawdza w pierwszej kolejności plik `/etc/hosts.allow`, i dopiero, gdy nie znajdzie w nim pasującej reguły, sprawdza plik `/etc/hosts.deny`. Jest to kluczowe w rozumieniu tego mechanizmu."
    },
    {
        "questionId": 390,
        "title": "Mechanizm Bypass Traverse Checking pozwala na:",
        "answers": [
            {
                "text": "ominięcie sprawdzania uprawnień do katalogów na ścieżce do pliku, do którego użytkownik ma przyznany dostęp",
                "isCorrect": true
            },
            {
                "text": "wyświetlanie zawartości katalogu, do którego użytkownik nie ma przyznanego dostępu, ale ma dostęp do któregokolwiek pliku wewnątrz",
                "isCorrect": false
            },
            {
                "text": "zestawianie tunelu IPsec w sieci wykorzystującej NAT (NAT-T)",
                "isCorrect": false
            },
            {
                "text": "dostęp do udziałów sieciowych bez konieczności posiadania konta w zdalnym systemie",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm \"Bypass Traverse Checking\" w systemie Windows umożliwia ominięcie sprawdzania uprawnień do katalogów, które znajdują się na ścieżce dostępu do pliku, pod warunkiem, że użytkownik ma przyznany dostęp do samego pliku docelowego. Oznacza to, że użytkownik posiadający to uprawnienie może dostać się do pliku, mimo braku uprawnień do przeglądania katalogów po drodze. Standardowo, aby uzyskać dostęp do pliku, system operacyjny sprawdza uprawnienia do każdego katalogu na ścieżce dostępu, aż do pliku docelowego. Jeżeli w którymś z tych katalogów użytkownik nie posiada uprawnień do odczytu lub wykonania, to nie uzyska dostępu do pliku. „Bypass Traverse Checking” pozwala ominąć ten warunek.\n\n**Poprawna odpowiedź:**\n\n* **\"ominięcie sprawdzania uprawnień do katalogów na ścieżce do pliku, do którego użytkownik ma przyznany dostęp\"** - Jest to poprawna definicja działania mechanizmu. Jeśli użytkownik posiada uprawnienia do odczytu pliku, na przykład `plik.txt` znajdującego się w ścieżce  `/katalog1/katalog2/plik.txt`, to posiadając uprawnienie „Bypass Traverse Checking”  może ten plik odczytać, nawet jeśli nie ma prawa do przeglądania katalogu `/katalog1` lub `/katalog1/katalog2`. System nie będzie sprawdzał, czy użytkownik może przeglądać katalogi, tylko sprawdzi, czy ma dostęp do pliku docelowego. Ma to praktyczne znaczenie w przypadku konfiguracji serwera gdzie wielu użytkowników musi mieć dostęp do kilku plików a nie koniecznie do katalogów zawierających te pliki. \n\n**Niepoprawne odpowiedzi:**\n\n* **\"wyświetlanie zawartości katalogu, do którego użytkownik nie ma przyznanego dostępu, ale ma dostęp do któregokolwiek pliku wewnątrz\"** - To stwierdzenie jest nieprawdziwe. Mechanizm \"Bypass Traverse Checking\" nie nadaje użytkownikowi prawa do wyświetlania zawartości katalogu. Pozwala on jedynie na dostęp do pliku, omijając uprawnienia dostępu do katalogów na ścieżce dostępu. Użytkownik nadal nie może przeglądać zawartości katalogu, czy odczytywać innych plików w danym katalogu, nie posiadając do tego odpowiednich uprawnień. Na przykład użytkownik nie będzie w stanie wykonać polecenia `ls /katalog1/katalog2` , mimo posiadania uprawnienia \"Bypass Traverse Checking\" oraz uprawnienia odczytu do pliku  `/katalog1/katalog2/plik.txt`.\n\n*  **\"zestawianie tunelu IPsec w sieci wykorzystującej NAT (NAT-T)\"** -  To stwierdzenie jest niepoprawne. NAT Traversal jest mechanizmem umożliwiającym przesyłanie pakietów IPsec przez sieć w której wykorzystywana jest technologia NAT. Nie ma on związku z kontrolą dostępu do lokalnych plików i katalogów. Jest to zupełnie inne zagadnienie z dziedziny bezpieczeństwa sieciowego, które nie odnosi się do uprawnień użytkownika w systemie operacyjnym.\n\n*   **\"dostęp do udziałów sieciowych bez konieczności posiadania konta w zdalnym systemie\"** - Jest to nieprawdziwe. \"Bypass Traverse Checking\" jest mechanizmem kontroli dostępu do zasobów *lokalnych* , nie ma natomiast żadnego wpływu na procesy uwierzytelniania w dostępie do zasobów sieciowych. Dostęp do udziału sieciowego zawsze wymaga posiadania konta lub dostępu anonimowego w systemie zdalnym. Zatem te dwa mechanizmy są od siebie całkowicie niezależne."
    },
    {
        "questionId": 391,
        "title": "Ustawienie bitu SGID dla katalogu dir można osiągnąć za pomocą polecenia:",
        "answers": [
            {
                "text": "set-suid dir",
                "isCorrect": false
            },
            {
                "text": "chmod g+s dir",
                "isCorrect": true
            },
            {
                "text": "sgid --set dir",
                "isCorrect": false
            },
            {
                "text": "setfacl -m group",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Bit SGID, czyli Set Group ID, jest specjalnym uprawnieniem w systemach Linux/Unix, które modyfikuje sposób, w jaki uruchamiane są pliki lub jak tworzone są nowe obiekty w katalogach. W przypadku pliku wykonywalnego, ustawienie bitu SGID powoduje, że proces uruchomiony z tego pliku wykonuje się z uprawnieniami grupy będącej właścicielem tego pliku, a nie grupy, do której należy użytkownik uruchamiający proces. W przypadku katalogu, wszystkie nowe pliki i podkatalogi utworzone w takim katalogu, dziedziczą grupę będącą właścicielem katalogu. To oznacza, że wszyscy użytkownicy, którzy będą tworzyli pliki i katalogi w takim katalogu będą mieli te same uprawnienia grupowe. Jest to szczególnie przydatne, gdy kilku użytkowników ma współpracować w obrębie jednego katalogu i potrzebują wspólnych uprawnień do modyfikacji plików.\n\nTeraz przejdźmy do analizy poszczególnych odpowiedzi:\n\n1.  **\"set-suid dir\"** - Jest to niepoprawna odpowiedź. Po pierwsze, nie ma takiego polecenia w systemach Linux/Unix. Po drugie sugeruje ustawienie bitu SUID (_ang. Set User ID_), który, gdy jest ustawiony na pliku wykonywalnym, powoduje uruchomienie procesu z uprawnieniami właściciela pliku, a nie uprawnieniami grupowymi, jak to ma miejsce w przypadku bitu SGID. Użycie bitu SUID jest związane z potencjalnymi niebezpieczeństwami i rzadziej stosowany niż SGID. Przykładowo, jeśli właściciel pliku ma uprawnienia administratora (_root_), to uruchomienie programu z ustawionym bitem SUID spowoduje, że program będzie wykonywany z uprawnieniami administratora, co potencjalnie daje duże uprawnienia intruzowi w razie złamania zabezpieczeń tego programu.\n\n2.  **\"chmod g+s dir\"** - Jest to poprawna odpowiedź. Polecenie `chmod` jest uniwersalnym narzędziem do zmiany uprawnień w systemach Linux/Unix. Składnia `g+s` oznacza dodanie bitu SGID dla grupy (g), dzięki czemu katalog `dir` i wszystkie pliki oraz katalogi, które będą w nim utworzone będą dziedziczyć uprawnienia grupy będącej właścicielem katalogu. Praktycznie oznacza to, że niezależnie, kto będzie tworzył pliki w tym katalogu, każdy nowy plik będzie należał do grupy będącej właścicielem tego katalogu. Jeśli mamy katalog, w którym pracuje kilka osób i chcemy, aby wszyscy w nim pracujący mieli do plików takie same uprawnienia w ramach jednej grupy, jest to jak najbardziej pożądane. Przykładem może być tworzenie projektu programistycznego, w którym kilku programistów pracuje nad jednym projektem. Bez użycia bitu SGID nie mieliby dostępu do plików utworzonych przez innego programistę z tej grupy, a tak będą mogli te pliki odczytywać i modyfikować. Zatem za pomocą polecenia `chmod g+s dir` ustawimy bit SGID dla katalogu `dir`.\n\n3. **\"sgid --set dir\"** - Jest to niepoprawna odpowiedź. Polecenie  `sgid` nie istnieje w standardowych systemach Linux/Unix, co oznacza niepoprawność polecenia i jego działania. To nie jest odpowiedni sposób, aby ustawić bit SGID.\n\n4.  **\"setfacl -m group\"** - Jest to niepoprawna odpowiedź. Polecenie `setfacl` służy do ustawiania list kontroli dostępu (ACL), a nie bitów uprawnień, do których należy SGID. Polecenie `setfacl -m group` jedynie tworzy wpis w liście ACL dla pewnej grupy, nadając uprawnienia do danego zasobu. Nie ma to wpływu na uprawnienia SGID. Listy ACL zapewniają bardziej granularną kontrolę dostępu do zasobów systemu plików niż proste uprawnienia POSIX, ale nie zastępują bitu SGID.\n\nZatem poprawną odpowiedzią jest **\"chmod g+s dir\"**, gdyż tylko ta opcja poprawnie ustawia bit SGID dla katalogu `dir`."
    },
    {
        "questionId": 392,
        "title": "PGP (GPG) używane jest do:",
        "answers": [
            {
                "text": "realizacji tuneli VPN",
                "isCorrect": false
            },
            {
                "text": "podpisywania plików muzycznych celem zachowania praw autorskich DRM",
                "isCorrect": false
            },
            {
                "text": "podpisywania danych",
                "isCorrect": true
            },
            {
                "text": "szyfrowania plików",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "PGP (Pretty Good Privacy) i jego otwartoźródłowa implementacja GPG (GNU Privacy Guard) to narzędzia kryptograficzne służące do zapewnienia poufności (szyfrowania) i integralności (podpisywania) danych. Umożliwiają one ochronę danych przed nieautoryzowanym odczytem i modyfikacją. Kluczowe jest rozróżnienie tych mechanizmów i ich zastosowanie w praktyce.\n\n**Poprawna odpowiedź: „podpisywania danych”** \nPGP/GPG wykorzystuje mechanizmy kryptografii asymetrycznej do tworzenia podpisów cyfrowych. Podpis cyfrowy zapewnia autentyczność i integralność danych. Oznacza to, że odbiorca może zweryfikować, czy dane pochodzą od nadawcy (autentyczność) i czy nie zostały zmodyfikowane podczas transmisji (integralność). Wykorzystuje się do tego pary kluczy: prywatny (znany tylko nadawcy) i publiczny (dostępny dla odbiorców). Nadawca podpisuje dane swoim kluczem prywatnym, a odbiorca weryfikuje podpis za pomocą klucza publicznego nadawcy. Podpis cyfrowy może być użyty nie tylko do poczty elektronicznej ale również do różnego rodzaju danych. Przykładowo, dystrybucje systemu Linux są często podpisywane w ten sposób przez wydawcę systemu, aby użytkownik mógł mieć pewność, że pakiet pochodzi z wiarygodnego źródła i nie został przez kogoś zmieniony. \n\n**Poprawna odpowiedź: „szyfrowania plików”**\nPGP/GPG umożliwia również szyfrowanie danych, co zapewnia ich poufność. Szyfrowanie polega na przekształceniu danych (tekstu jawnego) w formę niezrozumiałą (szyfrogram) dla osób nieuprawnionych. Do szyfrowania wykorzystuje się algorytmy kryptografii symetrycznej, gdzie ten sam klucz jest używany do szyfrowania i deszyfrowania. W systemie PGP klucz ten szyfrowany jest za pomocą klucza publicznego odbiorcy. Odbiorca używa klucza prywatnego, który jest matematycznie powiązany z kluczem publicznym do odszyfrowania tajnego klucza symetrycznego i tym samym do odszyfrowania wiadomości. Podobnie jak podpis cyfrowy, szyfrowanie może być zastosowane do dowolnych danych. Używa się go, np. do ochrony archiwów z danymi lub listów elektronicznych.\n\n**Niepoprawna odpowiedź: „realizacji tuneli VPN”**\nPGP/GPG nie służy do budowania tuneli VPN (Virtual Private Network). Tunele VPN są tworzone przy użyciu innych protokołów, takich jak IPsec czy OpenVPN, które również używają algorytmów kryptograficznych. VPN jest technologią tworzącą bezpieczny tunel między dwoma punktami sieciowymi, przez które przesyłane są dane. Tunelowanie chroni przesyłane dane przed podsłuchem. PGP/GPG chroni treść danych, nie dba jednak o zabezpieczenie całego połączenia. Przykładowo IPsec może w całości zaszyfrować połączenie internetowe, a PGP/GPG pozwala na szyfrowanie pojedynczych wiadomości i danych, nie dbając o kanał komunikacyjny, przez który te dane zostaną przesłane.\n\n**Niepoprawna odpowiedź: „podpisywania plików muzycznych celem zachowania praw autorskich DRM”**\nPGP/GPG nie jest narzędziem DRM (Digital Rights Management). DRM to technologie, które kontrolują dostęp do danych chronionych prawem autorskim. PGP/GPG, choć ma funkcje podpisywania plików, nie jest używane w mechanizmach DRM, gdzie często stosuje się inne techniki, np. watermarki i inne. Podpis PGP/GPG ma za zadanie poświadczenie integralności i autentyczności, a nie ograniczenie dostępu. Podpis PGP/GPG jest z założenia przeznaczony do weryfikacji przez odbiorców w celu potwierdzenia pochodzenia i autentyczności danych i nie pełni funkcji ukrywania lub blokowania dostępu do treści, tak jak to ma miejsce w technologii DRM. Podpisanie utworu muzycznego za pomocą PGP może dać pewność, że pochodzi on od danej osoby, jednak nie zablokuje jego kopiowania."
    },
    {
        "questionId": 393,
        "title": "$getfacl test owner: jbond group: agents user::rwuser:jbond:r-x group:agents:--x mask::r-x other:--- W takim wypadku użytkownik jbond (będący właścicielem obiektu test), należący do grupy agents, ma efektywne uprawnienia: ",
        "answers": [
            {
                "text": "rx",
                "isCorrect": false
            },
            {
                "text": "rw",
                "isCorrect": true
            },
            {
                "text": "r",
                "isCorrect": false
            },
            {
                "text": "rwx",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizmy list kontroli dostępu (ACL) pozwalają na bardziej precyzyjne definiowanie uprawnień do plików i katalogów niż standardowe uprawnienia POSIX (właściciel, grupa, pozostali). W przypadku rozszerzonych ACL możemy określać uprawnienia dla konkretnych użytkowników i grup. Należy jednak pamiętać, że te rozszerzone uprawnienia podlegają maskom. Maska definiuje maksymalne uprawnienia, które mogą zostać przyznane danej grupie lub pozostałym użytkownikom, ale nie wpływa ona na uprawnienia właściciela obiektu.\n\nAnalizując podany przykład ACL, widzimy, że dla obiektu o nazwie „test” ustawione są następujące prawa dostępu:\n\n*   `owner: jbond`: Użytkownik `jbond` jest właścicielem obiektu.\n*   `group: agents`: Grupa `agents` jest grupą powiązaną z obiektem.\n*   `user::rw-`: Właściciel obiektu, użytkownik `jbond`, ma uprawnienia do odczytu (`r`) i zapisu (`w`), ale nie ma prawa do wykonywania (`-`). Jest to określenie jawnego uprawnienia dla właściciela.\n*   `user:jbond:r-x`: Specyficzne uprawnienia dla użytkownika `jbond` pozwalają na odczyt (`r`) i wykonanie (`x`), ale nie na zapis (`-`). Jest to jednak uprawnienie podrzędne względem prawa właściciela.\n*    `group:agents:--x`: Grupa `agents` ma uprawnienia do wykonywania (`x`), ale nie ma uprawnień do odczytu i zapisu (`--`).\n*   `mask::r-x`: Maska ogranicza efektywne uprawnienia dla grup oraz pozostałych użytkowników do odczytu i wykonania.\n*   `other:---`: Pozostali użytkownicy nie mają żadnych praw dostępu.\n\nTeraz rozważmy po kolei każdą z opcji odpowiedzi.\n\n* **\"rx\"** - Ta odpowiedź jest niepoprawna, ponieważ użytkownik `jbond` jako właściciel ma uprawnienia do odczytu i zapisu do obiektu, co wynika z ustawienia uprawnienia `user::rw-`. Ustawienie uprawnień `user:jbond:r-x` jest mniej znaczące w tej sytuacji, gdyż pierwszeństwo zawsze ma prawo właściciela.\n\n* **\"rw\"** - Ta odpowiedź jest poprawna, ponieważ użytkownik `jbond` jest właścicielem pliku i ma ustawione prawa do odczytu i zapisu - `user::rw-`. Dodatkowo te prawa nie są w żaden sposób limitowane przez maskę, która działa tylko na uprawnienia nadawane grupom, czy pozostałym. Ustawienie uprawnienia `user:jbond:r-x` nie ma wpływu na uprawnienia właściciela określonego przez `user::rw-`.\n\n* **\"r\"** - Ta odpowiedź jest niepoprawna, gdyż `jbond` posiada uprawnienia do odczytu i zapisu, co wynika z `user::rw-`, mimo dodatkowych uprawnień ograniczających `user:jbond:r-x`.\n* **\"rwx\"** - Ta odpowiedź jest niepoprawna, gdyż użytkownik `jbond` nie ma jawnie określonego prawa do wykonywania, chociaż w specyficznych uprawnieniach dla niego `user:jbond:r-x` prawo wykonania jest obecne. W tej sytuacji prawo dostępu jest ograniczone jedynie do odczytu i zapisu.\n\nPodsumowując, użytkownik `jbond`, będący właścicielem obiektu \"test\", ma efektywne uprawnienia do odczytu i zapisu, czyli \"rw\". Określenie `user:jbond:r-x` nie ma wpływu na uprawnienia właściciela, który posiada `user::rw-`. Jest to ważna własność do zapamiętania, gdyż określenie dodatkowych uprawnień dla użytkownika nigdy nie ogranicza uprawnień właściciela obiektu. Dodatkowo maska chroni jedynie użytkowników i grupy, ale nie ma wpływu na właściciela obiektu.\n\nPrzykład w praktyce: Jeśli `jbond` będzie chciał otworzyć plik \"test\", to będzie miał możliwość zapisu i odczytu. Jeśli będzie chciał otworzyć plik jako skrypt nie będzie to możliwe gdyż nie posiada prawa wykonania do pliku."
    },
    {
        "questionId": 394,
        "title": "Wybierz prawdziwe stwierdzenie dotyczące poniższego polecenia: `ssh -L 9999:neptun:23 pluton`: ",
        "answers": [
            {
                "text": "dane kierowane na port 9999 lokalnego systemu zostaną przesłane w niezabezpieczonej formie na port 23 systemu pluton",
                "isCorrect": false
            },
            {
                "text": "dane kierowane na port 9999 systemu neptun zostaną przesłane w niezabezpieczonej formie na port 23 systemu neptun",
                "isCorrect": true
            },
            {
                "text": "dane kierowane na port 9999 lokalnego systemu zostaną przesłane w zaszyfrowanej formie na port 22 systemu pluton",
                "isCorrect": true
            },
            {
                "text": "w wyniku polecenia zestawiony zostanie tunel kryptograficzny między systemem neptun i systemem pluton",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Polecenie `ssh -L 9999:neptun:23 pluton` tworzy tunel SSH, a dokładnie *lokalne przekierowanie portów* (ang. *local port forwarding*).  Tunel SSH to zaszyfrowany kanał komunikacyjny, który pozwala na bezpieczne przesyłanie danych przez potencjalnie niebezpieczną sieć.\n\nW tym konkretnym przypadku:\n\n*   **`ssh`**: Wywołuje klienta SSH.\n*   **`-L 9999:neptun:23`**: Opcja `-L` konfiguruje przekierowanie portów. `9999` jest portem na *lokalnym systemie*, z którego jest wywoływane polecenie ssh. `neptun` to nazwa hosta lub adres IP *systemu docelowego*, a `23` to port w *systemie docelowym*. To oznacza, że ruch kierowany na lokalnym systemie na port `9999` zostanie przesłany przez zaszyfrowany tunel do systemu `pluton`, gdzie zostanie przekierowany do systemu `neptun` na port `23`. Należy zwrócić uwagę, że polecenie ssh jest wywoływane na komputerze lokalnym a połączenie ssh jest zestawiane z komputerem pluton a nie z komputerem neptun.\n*   **`pluton`**: Jest to nazwa lub adres IP systemu, z którym nawiązywane jest połączenie SSH. To jest *system pośredniczący*.\n\nAnalizując poszczególne odpowiedzi:\n\n*   **\"dane kierowane na port 9999 lokalnego systemu zostaną przesłane w niezabezpieczonej formie na port 23 systemu pluton\"**  \n    *   **Niepoprawne.** Dane *kierowane na port 9999 lokalnego systemu* są przesyłane w *zaszyfrowanej formie* przez tunel SSH do systemu `pluton`, a następnie przekierowane w *niezabezpieczonej formie* na port `23` systemu `neptun`. Zatem, kluczowe jest to, że komunikacja między lokalnym systemem a systemem `pluton` jest szyfrowana, a przekierowanie do `neptun` nie jest.\n\n*   **\"dane kierowane na port 9999 systemu neptun zostaną przesłane w niezabezpieczonej formie na port 23 systemu neptun\"**\n    *   **Poprawne.** W tej konfiguracji to *lokalny system* kieruje ruch na port `9999`, a nie system `neptun`. Dane te są kierowane poprzez SSH do serwera `pluton` a następnie kierowane na port 23 hosta `neptun` co nie jest już szyfrowane, *dane kierowane z systemu pluton do systemu neptun nie są szyfrowane*\n\n*   **\"dane kierowane na port 9999 lokalnego systemu zostaną przesłane w zaszyfrowanej formie na port 22 systemu pluton\"**\n    *   **Poprawne.** Dane są *zaszyfrowane* na odcinku od *lokalnego systemu* do *systemu pluton*, ponieważ to między tymi systemami tworzony jest tunel SSH. Następnie, po dotarciu do systemu `pluton`, ruch jest kierowany *niezabezpieczoną* formą na port `23` systemu `neptun`. Co jest kluczowe port 22 jest portem domyślnym do łączenia się z systemem poprzez protokół SSH.\n\n*   **\"w wyniku polecenia zestawiony zostanie tunel kryptograficzny między systemem neptun i systemem pluton\"**\n    *   **Niepoprawne.** Tunel kryptograficzny jest tworzony pomiędzy *lokalnym systemem* (na którym wywołano polecenie) a *systemem pluton*. System `neptun` nie bierze bezpośredniego udziału w tworzeniu tunelu SSH. Dane są przekazywane z systemu pluton do systemu neptun *niezaszyfrowaną formą*.\n\n**Przykład praktyczny:**\n\nZałóżmy, że chcemy uzyskać dostęp do usługi Telnet (port 23), która działa tylko na systemie `neptun`, a mamy dostęp SSH tylko do systemu `pluton`, który ma dostęp do `neptun`. Używając polecenia `ssh -L 9999:neptun:23 pluton`, po zalogowaniu się na system `pluton`, możemy w *lokalnym systemie* otworzyć aplikację Telnet i połączyć się z nią na porcie 9999. Aplikacja Telnet w *lokalnym systemie*  myśli, że łączy się lokalnie z portem 9999, jednak na prawdę łączy się z portem 23 systemu `neptun` poprzez serwer `pluton`, komunikacja miedzy lokalnym systemem a systemem `pluton` jest szyfrowana. To pozwala nam na bezpieczne korzystanie z usługi działającej tylko na `neptun` mimo braku dostępu bezpośredniego do tego komputera. Dane które płyną z systemu `pluton` do systemu `neptun` nie są szyfrowane."
    },
    {
        "questionId": 395,
        "title": "Windows Firewall pozwala tworzyć reguły: ",
        "answers": [
            {
                "text": "przepuszczające wybrany ruch",
                "isCorrect": true
            },
            {
                "text": "blokujące wysyłanie ruchu sieciowego przez wskazane programy",
                "isCorrect": true
            },
            {
                "text": "blokujące odbieranie ruchu sieciowego przez wskazane programy",
                "isCorrect": true
            },
            {
                "text": "blokujące wybrany ruch",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Zapora sieciowa (firewall) to mechanizm kontroli ruchu sieciowego, który analizuje pakiety danych i na podstawie zdefiniowanych reguł decyduje o ich przepuszczaniu lub blokowaniu. Zapora sieciowa jest kluczowym elementem ochrony systemów komputerowych przed nieautoryzowanym dostępem. W systemie Windows, zapora sieciowa (Windows Firewall) pozwala na tworzenie różnorodnych reguł, które decydują o sposobie przepływu danych. \n\n*   **\"przepuszczające wybrany ruch\"** - Ta odpowiedź jest **poprawna**. Zapora sieciowa, oprócz blokowania niechcianego ruchu, musi również umożliwiać przepuszczanie ruchu pożądanego.  Reguły w zaporze definiują, które typy połączeń są dozwolone. Na przykład, reguła może zezwalać na ruch HTTP (port 80) z określonych adresów IP, aby umożliwić dostęp do serwera WWW. \n\n*   **\"blokujące wysyłanie ruchu sieciowego przez wskazane programy\"** - Ta odpowiedź jest **poprawna**. Zapora sieciowa może blokować ruch wychodzący z komputera na podstawie tego, jaki program generuje ten ruch.  Na przykład, można skonfigurować zaporę, aby blokowała nieznane oprogramowanie (pobrane z nieznanego źródła) przed wysyłaniem danych do Internetu, co pomaga chronić przed potencjalnymi złośliwymi aplikacjami. To jest typowa obrona przed _malware_. \n\n*   **\"blokujące odbieranie ruchu sieciowego przez wskazane programy\"** - Ta odpowiedź jest **poprawna**. Zapora sieciowa może blokować ruch przychodzący do komputera w zależności od tego, do jakiego programu lub usługi jest adresowany. Na przykład można uniemożliwić odbieranie połączeń z zewnątrz do usługi zdalnego pulpitu (RDP), aby zapobiec potencjalnemu nieautoryzowanemu dostępowi do komputera. Jest to ważny sposób ochraniania usług sieciowych. \n\n*   **\"blokujące wybrany ruch\"** - Ta odpowiedź jest **poprawna**. Zapora sieciowa umożliwia administratorowi definiowanie reguł blokujących ruch sieciowy, zdefiniowany na podstawie różnych kryteriów. Kryteriami tymi mogą być protokoły, porty, adresy IP. Przykładem może być blokowanie ruchu telnetu (port 23) aby utrudnić potencjalne ataki bazujące na tym niebezpiecznym protokole.  Można blokować cały ruch z danego adresu IP aby odciąć ruch z niechcianego źródła. \n\nPodsumowując, Windows Firewall oferuje szeroki zakres możliwości definiowania reguł, zarówno przepuszczających, jak i blokujących ruch sieciowy, a decyzje opierają się na wielu czynnikach, takich jak aplikacje, porty i kierunek. Wszystkie te elementy stanowią bazowe narzędzie obrony."
    },
    {
        "questionId": 396,
        "title": "Polecenie ulimit: ",
        "answers": [
            {
                "text": "stworzyć ograniczenie zasobów obowiązujące wszystkie procesy tego użytkownika w systemie (także już te istniejące)",
                "isCorrect": false
            },
            {
                "text": "stworzyć ograniczenie zasobów obowiązujące wszystkie nowe procesy tego użytkownika w systemie",
                "isCorrect": false
            },
            {
                "text": "stworzyć ograniczenie zasobów obowiązujące wszystkie procesy tego użytkownika w systemie, ale tylko aż do zakończenia bieżącej sesji",
                "isCorrect": false
            },
            {
                "text": "stworzyć ograniczenia zasobów obowiązujące tylko daną powłokę i jej procesy potomne",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`ulimit` to wbudowane polecenie powłoki systemu Linux/Unix służące do wyświetlania lub ustawiania limitów zasobów dla bieżącej sesji powłoki i procesów potomnych, co oznacza procesy uruchamiane z tej powłoki lub procesów pochodnych. Limity te dotyczą zasobów takich jak ilość otwartych plików, wielkość pamięci operacyjnej, ilość uruchomionych procesów danego użytkownika itp. Istotnym jest fakt, że `ulimit` nie działa na procesy, które nie zostały uruchomione przez tą powłokę lub jej procesy potomne. Dodatkowo ustawione limity nie przechodzą na inne powłoki czy procesy uruchomione w innych powłokach. Limity można ustawiać na stałe dla wszystkich sesji użytkownika, ale to polecenie nie jest odpowiedzialne za tą funkcjonalność.  `ulimit` ma wpływ tylko na bieżącą sesję.  \n \n**Opcja 1: \"stworzyć ograniczenie zasobów obowiązujące wszystkie procesy tego użytkownika w systemie (także już te istniejące)\"**\nTa odpowiedź jest niepoprawna. Polecenie `ulimit` nie działa na wszystkie procesy danego użytkownika w całym systemie. Limity są ustawiane na poziomie bieżącej sesji i dziedziczone przez podprocesy tej powłoki. Procesy, które były już uruchomione przed użyciem `ulimit` nie zostaną objęte zmianami. \nPrzykład: uruchomienie programu `top` w tle, następnie wykonanie `ulimit -u 10`, nie spowoduje wyłączenia programu `top`, jednakże programy, które zostaną uruchomione po poleceniu ulimit nie pozwolą na utworzenie więcej niż 10 procesów. \n \n**Opcja 2: \"stworzyć ograniczenie zasobów obowiązujące wszystkie nowe procesy tego użytkownika w systemie\"**\nTa odpowiedź jest niepoprawna, ponieważ polecenie `ulimit` nie działa na wszystkie procesy użytkownika w systemie.  `ulimit` ogranicza tylko procesy potomne powłoki, w której zostało wykonane polecenie.\nPrzykład: użytkownik uruchamia program `top` w konsoli, otwiera nową konsole, następnie w tej konsoli wykonuje polecenie `ulimit -u 10`. Program `top` działający w starej konsoli nie zostanie objęty nowo ustawionymi limitami, natomiast programy uruchamiane w nowej konsoli po `ulimit -u 10` będą działać z tymi ograniczeniami. \n \n**Opcja 3: \"stworzyć ograniczenie zasobów obowiązujące wszystkie procesy tego użytkownika w systemie, ale tylko aż do zakończenia bieżącej sesji\"**\nTa odpowiedź jest niepoprawna, ponieważ chociaż limity ustawione `ulimit` rzeczywiście obowiązują tylko do zakończenia bieżącej sesji, to nie wpływają na wszystkie procesy użytkownika. Ustawienia `ulimit` są dziedziczone tylko przez procesy potomne bieżącej sesji, nie wpływając na pozostałe procesy danego użytkownika.\nPrzykład: uruchamiamy program top w jednej konsoli, w drugiej konsoli wykonujemy `ulimit -u 10` , uruchomiony program `top` działający w konsoli pierwszej nie ma żadnych ograniczeń, z chwilą zamknięcia drugiej konsoli wprowadzone limity ustawione przez `ulimit` przestają obowiązywać. \n \n**Opcja 4: \"stworzyć ograniczenia zasobów obowiązujące tylko daną powłokę i jej procesy potomne\"**\nTa odpowiedź jest poprawna. Polecenie `ulimit` ustawia limity tylko dla danej powłoki i procesów, które zostaną uruchomione po wydaniu tego polecenia. Ustawienia te nie są dziedziczone przez inne powłoki działające równolegle ani przez procesy uruchomione w tych powłokach.\nPrzykład: po uruchomieniu powłoki w jednej konsoli, a następnie wydaniu polecenia `ulimit -u 10` w tej konsoli spowoduje to ustawienie limitów na 10 procesów dla procesów działających w tej konsoli.  Uruchomienie nowej konsoli spowoduje, że limity w nowej konsoli będą wartościami domyślnymi do momentu zmiany."
    },
    {
        "questionId": 397,
        "title": "Klucz z certyfikatu EFS użytkownika U jest wykorzystywany w systemie NTFS do: ",
        "answers": [
            {
                "text": "szyfrowania jednorazowych kluczy, którymi zaszyfrowane zostały poszczególne pliki do których U ma dostęp",
                "isCorrect": true
            },
            {
                "text": "szyfrowania i deszyfrowania treści plików należących do U",
                "isCorrect": false
            },
            {
                "text": "szyfrowania i deszyfrowania wszelkiej komunikacji z użytkownikiem U",
                "isCorrect": false
            },
            {
                "text": "szyfrowania i deszyfrowania treści plików należących do użytkowników, którzy udostępnili te pliki użytkownikowi U",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "System EFS (Encrypting File System) w systemie NTFS wykorzystuje dwuetapowe szyfrowanie plików.  Pliki nie są szyfrowane bezpośrednio kluczem z certyfikatu użytkownika, gdyż byłoby to niewydajne.  Zamiast tego generowany jest klucz symetryczny, nazywany kluczem szyfrowania danych (DEK - Data Encryption Key), który służy do szyfrowania zawartości pliku. Ten klucz DEK jest następnie szyfrowany asymetrycznie kluczem publicznym użytkownika, który to klucz znajduje się w certyfikacie użytkownika. Do odszyfrowania klucza DEK używany jest klucz prywatny użytkownika, również powiązany z certyfikatem. W ten sposób zaszyfrowany klucz DEK jest przechowywany wraz z metadanymi pliku. Zatem, dostęp do zaszyfrowanych danych możliwy jest jedynie po odszyfrowaniu klucza DEK za pomocą odpowiedniego klucza prywatnego.\n\n**Odpowiedź a):** Jest to odpowiedź prawidłowa. Mechanizm EFS wykorzystuje klucz z certyfikatu użytkownika do szyfrowania klucza DEK, który to klucz służy do szyfrowania i deszyfrowania plików. Klucz z certyfikatu jest kluczem asymetrycznym, który nie nadaje się do szyfrowania dużych porcji danych. Dlatego też wykorzystuje się go jedynie do szyfrowania klucza symetrycznego. Takie rozwiązanie zapewnia bezpieczeństwo danych, a zarazem jest wydajne. \n\n**Odpowiedź b):** Jest to odpowiedź nieprawidłowa. Bezpośrednio pliki nie są szyfrowane kluczem z certyfikatu. Jak już wspomniano, klucz z certyfikatu służy do szyfrowania klucza symetrycznego DEK. \n\n**Odpowiedź c):** Jest to odpowiedź nieprawidłowa. Klucz z certyfikatu nie służy do szyfrowania komunikacji. Mechanizmy szyfrowania komunikacji są częścią protokołów wyższych warstw ISO/OSI, takich jak na przykład protokół SSL czy protokół SSH.\n\n**Odpowiedź d):** Jest to odpowiedź nieprawidłowa. Mechanizm EFS chroni jedynie pliki użytkownika, który ustawił opcję szyfrowania dla wybranego pliku. To, że ktoś udostępnił mi pliki, to wcale nie oznacza, że mam do nich pełen dostęp. W sytuacji gdy pliki te są zaszyfrowane to tylko i wyłącznie użytkownik posiadający dostęp do zaszyfrowanych danych jest w stanie je odszyfrować. \n \nPrzykład praktyczny:\nZałóżmy, że użytkownik \"Alicja\" szyfruje plik \"tajne.txt\" na swoim komputerze. EFS generuje losowy klucz DEK, szyfruje nim plik \"tajne.txt\", a następnie używa klucza publicznego z certyfikatu Alicji do zaszyfrowania klucza DEK. Tak zaszyfrowany klucz DEK zostaje zapisany w metadanych pliku \"tajne.txt\". Jeżeli użytkownik \"Bolek\" spróbuje otworzyć zaszyfrowany plik, nie będzie mógł go odczytać, ponieważ nie ma do dyspozycji klucza prywatnego Alicji, który potrzebny jest do odszyfrowania klucza DEK."
    },
    {
        "questionId": 398,
        "title": "Użytkownik U systemu Linux jest właścicielem zasobu O w systemie plików i na liście ACL tego zasobu ma przyznane prawa rw, a maska zawiera prawa r oraz x. Jakie efektywne uprawnienia do O posiada aktualnie U?: ",
        "answers": [
            {
                "text": "tylko r",
                "isCorrect": false
            },
            {
                "text": "tylko w",
                "isCorrect": false
            },
            {
                "text": "rw",
                "isCorrect": true
            },
            {
                "text": "rwx",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "W systemie Linux, kontrola dostępu do plików i katalogów opiera się na modelu uprawnień, który można rozszerzyć za pomocą ACL (Access Control Lists).  ACL pozwalają na przypisanie szczegółowych uprawnień do konkretnych użytkowników lub grup, a nie tylko do właściciela, grupy i innych (u, g, o). Uprawnienia określają, co użytkownik może zrobić z danym zasobem (np. odczytać, zapisać, wykonać).\n\n**Uprawnienia podstawowe (base ACL entry)**:  Są to prawa dostępu (r, w, x) jawnie przypisane użytkownikowi lub grupie w ACL danego zasobu. Na przykład,  `user:kowalski:rw-` oznacza, że użytkownik 'kowalski' ma prawa do odczytu i zapisu (rw).\n\n**Maska uprawnień (mask)**: Maska to zbiór uprawnień, które ograniczają efektywne prawa dostępu,  zdefiniowane w ACL. Maska filtruje, jakie uprawnienia z uprawnień podstawowych mogą być wykorzystane. Maska może tylko odejmować uprawnienia. Na przykład maska `mask::r-x` ogranicza dostęp do odczytu i wykonywania. Zwróć uwagę, że maska nie pozwala przypisać żadnych dodatkowych uprawnień. Maska określa maksymalne uprawnienia jakie są dostępne.  Jeżeli uprawnienia w uprawnieniach podstawowych nie pokrywają się z uprawnieniami w masce uprawnień, to użytkownik NIE będzie miał takiego uprawnienia. Maska nie dodaje uprawnień, tylko ogranicza to co może być wykorzystane z puli uprawnień podstawowych.\n\n**Efektywne uprawnienia:**  Są to finalne prawa dostępu użytkownika do zasobu, wynikające z kombinacji uprawnień podstawowych i ograniczeń maski. Jeśli użytkownik ma w ACL uprawnienia `rw`, a maska jest ustawiona na `r-x`, to efektywne uprawnienia użytkownika wynoszą `r-`, ponieważ z prawa zapisu (`w`) musi zrezygnować ze względu na maskę.  Prawo zapisu nie występuje w masce, więc nie może być wykorzystane. Efektywne uprawnienia to iloczyn logiczny uprawnień podstawowych oraz uprawnień maski.\n\nTeraz przeanalizujmy poszczególne odpowiedzi w kontekście podanego pytania.\n\n*   **\"tylko r\"**\n\n    Jest to **niepoprawna** odpowiedź. Użytkownik U posiada uprawnienia `rw` w ACL zasobu, a maska zawiera uprawnienie `r`. Oznacza to, że użytkownik powinien mieć dostęp do odczytu. Jednak nie tylko. Maski nie ograniczają uprawnień tak by użytkownik mógł wykonać tylko prawo r. Zatem dostęp nie ogranicza się tylko do odczytu.\n*   **\"tylko w\"**\n\n    Jest to **niepoprawna** odpowiedź. Użytkownik U posiada uprawnienia `rw` w ACL zasobu i maska zawiera uprawnienie `r` i `x`. Prawo zapisu `w` nie jest obecne w masce dlatego też użytkownik nie może zapisać pliku. Nie można mieć dostępu tylko do zapisu skoro prawo zapisu nie zostało określone w masce.\n*   **\"rw\"**\n\n    Jest to **poprawna** odpowiedź. Użytkownik U posiada w ACL uprawnienia `rw`. Maska zawiera prawa `r x`. Prawem wspólnym dla obu zakresów uprawnień jest `r`. Zatem użytkownik ma dostęp do odczytu a do zapisu nie. Prawem wspólnym w zakresie uprawnień jest `r` dlatego użytkownik powinien mieć prawo do odczytu i zapisu.\n*   **\"rwx\"**\n\n    Jest to **niepoprawna** odpowiedź. Użytkownik posiada w ACL prawa `rw`. Maska posiada prawa `r x` co ogranicza potencjalne uprawnienia użytkownika.  Użytkownik nie może posiadać dodatkowych uprawnień `x`, które nie są określone w uprawnieniach podstawowych. Efektywny dostęp do zasobu nigdy nie będzie większy od tego, co jest dozwolone w masce.\n\n**Przykład praktyczny:**\nWyobraźmy sobie, że w systemie Linux istnieje katalog z poufnymi danymi (/var/tajne_dane) do którego ma dostęp właściciel (użytkownik `admin`) i grupa `sekretariat`.  ACL ma następujące uprawnienia:\n```\nuser:admin:rwx\ngroup:sekretariat:rw-\nmask::r--\n```\n\n* Użytkownik `admin` (właściciel) ma podstawowe uprawnienia `rwx` ale są one ograniczone przez maskę i jego efektywne uprawnienia to `r--` a nie rwx.\n* Użytkownicy z grupy `sekretariat` mają podstawowe uprawnienia `rw-`, które również są ograniczone przez maskę do `r--`. Żaden z użytkowników nie ma możliwości wykonania kodu w tym katalogu.\n\nNiezrozumienie istoty maski może prowadzić do ustawienia nieodpowiedniej ochrony danych i powstania niebezpiecznych luk w systemie operacyjnym."
    },
    {
        "questionId": 399,
        "title": "Mechanizm Mandatory Integrity Control (MIC) system Windows: ",
        "answers": [
            {
                "text": "pozwala ograniczyć swobodę komunikacji między procesami",
                "isCorrect": true
            },
            {
                "text": "pozwala ograniczyć dostęp do zapisu w systemie plików",
                "isCorrect": true
            },
            {
                "text": "pozwala ograniczyć dostęp do odczytu dla wybranych plików",
                "isCorrect": false
            },
            {
                "text": "przypisuje procesowi jeden z kilku poziomów uprawnień uwzględnianych dodatkowo w kontroli dostępu",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Mandatory Integrity Control (MIC) to mechanizm bezpieczeństwa w systemie Windows, który koncentruje się na ochronie integralności danych i operacji systemowych. W przeciwieństwie do tradycyjnej uznaniowej kontroli dostępu (DAC), gdzie właściciel zasobu decyduje o uprawnieniach, MIC narzuca ograniczenia w oparciu o poziomy integralności.\n\nPoziom integralności to poziom zaufania przypisany do procesu lub obiektu. Im wyższy poziom, tym większe zaufanie do niego i tym więcej operacji ma dozwolonych.  Typowe poziomy to niski (Low), średni (Medium), wysoki (High) i systemowy (System). Proces o niskim poziomie integralności ma ograniczone możliwości interakcji z obiektami o wyższym poziomie.\n\n*   **\"pozwala ograniczyć swobodę komunikacji między procesami\"** - **Prawidłowa**. MIC kontroluje jak procesy o różnych poziomach integralności mogą się ze sobą komunikować. Proces o niskim poziomie integralności nie może łatwo wywierać wpływu na proces o wysokim poziomie. Na przykład, aplikacja działająca w trybie niskiej integralności, np. przeglądarka internetowa, nie może swobodnie przesyłać danych do procesu o wysokiej integralności, np. programu antywirusowego. Ogranicza to możliwość ataku, gdzie złośliwy kod z przeglądarki próbuje przejąć kontrolę nad aplikacją antywirusową.\n\n*   **\"pozwala ograniczyć dostęp do zapisu w systemie plików\"** - **Prawidłowa**. MIC chroni przed nieautoryzowaną modyfikacją danych, ograniczając możliwość zapisu. Proces o niskim poziomie integralności nie może modyfikować plików czy katalogów z wyższym poziomem integralności. Na przykład, wirus w zainfekowanym pliku tymczasowym, oznaczonym niskim poziomem integralności, nie będzie mógł zapisać się do katalogu systemowego, który ma poziom wysoki.\n\n*   **\"pozwala ograniczyć dostęp do odczytu dla wybranych plików\"** - **Nieprawidłowa**. MIC nie koncentruje się na kontroli dostępu do odczytu, robi to mechanizm DAC. MIC natomiast koncentruje się na ochronie integralności. Ograniczenia na poziomie odczytu wynikają z Discretionary Access Control(DAC), mechanizmu w systemie Windows, który pozwala kontrolować dostęp na podstawie tożsamości użytkownika lub przynależności do grupy, gdzie ustawienie opcji uprawnień odczytu ma wpływ na możliwość odczytu danego pliku, a nie jego poziom integralności.\n\n*    **\"przypisuje procesowi jeden z kilku poziomów uprawnień uwzględnianych dodatkowo w kontroli dostępu\"** - **Prawidłowa**. To sedno działania MIC. Procesy uruchamiane są z określonym poziomem integralności. System wykorzystuje te poziomy w mechanizmie kontroli dostępu, na przykład procesy o niskim poziomie integralności mogą być ograniczone w dostępie do systemowych zasobów. Przykładowo, nowo utworzony proces z uprawnieniami zwykłego użytkownika może mieć poziom medium, proces usługi systemowej np. z zaporą sieciową może mieć wysoki poziom integralności, a złośliwe oprogramowanie uruchomione w trybie sandbox ma przydzielony poziom niski."
    },
    {
        "questionId": 400,
        "title": "Dany jest plik Tajne.txt w katalogu Jawne. Załóżmy, że użytkownik Adaś należy do grupy Users. Katalog Jawne ma przydzielone uprawnienia ACL dla grupy Users: ALLOW na czytanie i DENY na zapis. Plik Tajne.txt ma uprawnienia ALLOW na zapis dla użytkownika Adaś. Jakie uprawnienia ostatecznie ma Adaś do pliku Tajne.txt?: ",
        "answers": [
            {
                "text": "ma uprawnienia do odczytu, brak uprawnień do zapisu",
                "isCorrect": false
            },
            {
                "text": "brak uprawnień do odczytu i zapisu",
                "isCorrect": false
            },
            {
                "text": "ma uprawnienia do odczytu i zapisu",
                "isCorrect": false
            },
            {
                "text": "ma uprawnienia do zapisu, brak uprawnienia do odczytu",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm list kontroli dostępu (ACL, *Access Control List*) umożliwia definiowanie uprawnień do obiektów systemu (np. plików i katalogów) w sposób bardziej szczegółowy niż standardowy model uprawnień użytkownika, grupy i innych (*user, group, other*). W szczególności w listach ACL można definiować uprawnienia dla konkretnych użytkowników lub grup. ACL wspierają zarówno uprawnienia zezwalające (*allow*), jak i zabraniające (*deny*) dostępu do danego obiektu. W systemach operacyjnych z obsługą list kontroli dostępu panuje zasada, że w przypadku konfliktów decyzja o odmowie dostępu ma priorytet nad decyzją o zezwoleniu na dostęp. W rezultacie, jeśli do obiektu przypisana jest reguła, która *zabrania* dostępu danemu użytkownikowi, to ta reguła *zawsze* ma pierwszeństwo, nawet jeśli istnieje inna reguła która *zezwala* na dostęp.\n  \nW tym konkretnym scenariuszu mamy katalog o nazwie `Jawne`, który posiada ustawienia ACL dla grupy `Users` z uprawnieniami: `ALLOW` na czytanie i `DENY` na zapis, oraz plik `Tajne.txt` w tym katalogu, który ma ustawienia ACL: `ALLOW` na zapis dla użytkownika `Adaś`. Użytkownik `Adaś` należy do grupy `Users`.\n  \n**Odpowiedź 1: \"ma uprawnienia do odczytu, brak uprawnień do zapisu\"**\n   Ta odpowiedź jest *niepoprawna*. Zgoda na odczyt nie jest w żaden sposób uzależniona od uprawnień zapisu. Jedynym ograniczeniem dostępu do pliku `Tajne.txt` jest reguła *deny* zapisu ustawiona dla grupy `Users`. Chociaż użytkownik Adaś wprost ma prawo do zapisu, w tym scenariuszu jest to prawo zabrane z racji przynależności do grupy `Users`. Natomiast uprawnienie do odczytu, które również jest zdefiniowane dla grupy users, i którego Adaś jest członkiem, nie wystarcza aby dozwolić na odczyt, bo ważniejsze są uprawnienia bezpośrednie, które przyznają tylko prawo zapisu.\n  \n**Odpowiedź 2: \"brak uprawnień do odczytu i zapisu\"**\n   Ta odpowiedź jest *niepoprawna*. Użytkownik `Adaś` ma uprawnienie do zapisu zdefiniowane bezpośrednio w ustawieniach ACL dla pliku. To uprawnienie ma pierwszeństwo przed uprawnieniami zdefiniowanymi dla grupy `Users`. Dlatego użytkownik Adaś ma na pewno prawo zapisu.\n  \n**Odpowiedź 3: \"ma uprawnienia do odczytu i zapisu\"**\n   Ta odpowiedź jest *niepoprawna*. Użytkownik Adaś, mimo iż ma ustawione uprawnienie do zapisu w pliku, to należy do grupy `Users`, która ma zabroniony zapis do katalogu `Jawne`. Użytkownik Adaś ma prawo zapisu do pliku ale nie wynika ono z uprawnień do katalogu `Jawne`. Dodatkowo w samej treści pytania nie ma nic napisane o tym, że użytkownik ma prawo do odczytu tego pliku.\n  \n**Odpowiedź 4: \"ma uprawnienia do zapisu, brak uprawnienia do odczytu\"**\n   Ta odpowiedź jest *poprawna*. Listy ACL sprawdzane są w kolejności od uprawnień specyficznych do bardziej ogólnych. W tym przypadku najpierw brane pod uwagę są uprawnienia użytkownika Adaś, który wprost ma uprawnienie *allow* zapisu do pliku `Tajne.txt`, dlatego ma prawo do zapisu. Następnie są brane pod uwagę prawa grupy `Users`, w której jest użytkownik Adaś. Mimo, że grupa ta ma do katalogu `Jawne` prawa odczytu, to w tym konkretnym przypadku, gdzie pytamy się o uprawnienia do pliku, a nie do katalogu, te prawa grupy nie mają wpływu, bo nie są to prawa bezpośrednie do pliku `Tajne.txt`. Jedyną ważną i istotną regułą jest reguła jawnie przyznająca prawo do zapisu dla użytkownika Adaś. Natomiast w opisie zadania nie ma żadnych informacji, które umożliwiałyby odczyt pliku `Tajne.txt` dla użytkownika Adaś, dlatego domyślnie nie ma on prawa do odczytu pliku.\n\n**Praktyczny przykład:**\n\nWyobraźmy sobie, że plik `Tajne.txt` jest plikiem konfiguracyjnym serwera WWW, który znajduje się w katalogu `Jawne` zawierającym ogólnie dostępne pliki strony internetowej. Użytkownik `Adaś` jest administratorem serwera, natomiast użytkownicy grupy `Users` to zwykli użytkownicy. Administrator `Adaś` powinien mieć prawo do modyfikacji pliku konfiguracyjnego, jednak nie powinien mieć prawa do wglądu w jego zawartość. W takim scenariuszu uprawnienie zapisu ustawione poprzez ACL pliku jest pożądane. Natomiast uprawnienie do odczytu zdefiniowane w katalogu `Jawne` nie ma tu żadnego zastosowania."
    },
    {
        "questionId": 401,
        "title": "Mechanizm sudo umożliwia: ",
        "answers": [
            {
                "text": "miękkie (soft) zmniejszenie limitów użytkownika",
                "isCorrect": false
            },
            {
                "text": "uruchamianie poleceń z uprawnieniami administratora po podaniu własnego (domyślnie) hasła",
                "isCorrect": true
            },
            {
                "text": "miękkie (soft) zwiększenie limitów użytkownika",
                "isCorrect": false
            },
            {
                "text": "uruchamianie wybranych aplikacji z uprawnieniami innych użytkowników",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "`sudo` jest narzędziem w systemach Linux/Unix, które pozwala użytkownikom na uruchamianie programów z uprawnieniami innego użytkownika, najczęściej administratora (root). Działa to na zasadzie tymczasowej zmiany uprawnień, ale nie oznacza, że użytkownik na stałe staje się administratorem. Użytkownik musi być uprawniony do korzystania z `sudo`, poprzez wpis w pliku konfiguracyjnym `/etc/sudoers`. To plik `/etc/sudoers` definiuje, kto, na jakim hoście i z jakimi uprawnieniami może uruchamiać polecenia używając `sudo`.\n\n*   **\"miękkie (soft) zmniejszenie limitów użytkownika\"** -  Jest to **niepoprawna** odpowiedź. `sudo` nie służy do modyfikacji limitów zasobów użytkownika (np. limitów pamięci, liczby plików, czasu procesora). Do tego celu używa się innych mechanizmów, jak na przykład komendy `ulimit`, które modyfikują limity bieżącej sesji użytkownika. Limity użytkowników ustawia się najczęściej dla procesu wykonywanego przez użytkownika lub danego użytkownika (poprzez plik /etc/security/limits.conf). `sudo` służy do tymczasowego podniesienia uprawnień na czas wykonania danego polecenia.\n*   **\"uruchamianie poleceń z uprawnieniami administratora po podaniu własnego (domyślnie) hasła\"** - To jest **poprawna** odpowiedź. `sudo` standardowo pozwala użytkownikowi na uruchomienie polecenia z uprawnieniami użytkownika _root_ po podaniu jego własnego hasła, a nie hasła użytkownika _root_. Hasło jest weryfikowane przez system i jeśli w pliku `/etc/sudoers` użytkownik ma prawo do wykorzystania polecenia `sudo` to polecenie zostanie wykonane. Domyślnie system pyta o hasło przy każdym wywołaniu `sudo`, ale konfiguracja może to zmieniać. Przykładem użycia `sudo` jest sytuacja gdy chcemy np. zmienić port nasłuchiwania demona usługi www. Standardowy użytkownik nie będzie miał uprawnień do zmiany konfiguracji serwera, ale poprzez `sudo` może wydać tą komendę w imieniu root.\n*   **\"miękkie (soft) zwiększenie limitów użytkownika\"** - To jest **niepoprawna** odpowiedź. Jak wspomniano wcześniej, `sudo` nie modyfikuje limitów zasobów.  Zwiększanie limitów użytkownika odbywa się na poziomie konfiguracji systemu operacyjnego. Zwykły użytkownik nie ma takiej możliwości, w odróżnieniu od `sudo` które pozwala użytkownikowi wykonywanie poleceń z wyższymi uprawnieniami.\n*  **\"uruchamianie wybranych aplikacji z uprawnieniami innych użytkowników\"** -  To jest **poprawna** odpowiedź. Chociaż najczęściej `sudo` jest używane do uzyskania uprawnień administratora, to można też skonfigurować `sudo` tak, aby użytkownik uruchamiał wybrane polecenia z uprawnieniami dowolnego innego użytkownika. Jest to kontrolowane przez plik `/etc/sudoers`. W tym pliku administrator określa, który użytkownik, jakie komendy i z jakimi uprawnieniami może wykonywać. Przykładem może być sytuacja, gdy chcemy dać uprawnienia użytkownikowi _wwwrun_ do zmiany konfiguracji usług webowych. Dzięki temu administrator deleguje część swoich uprawnień na wybranego użytkownika, nie dając mu pełnych uprawnień administratora i upraszcza sobie pracę."
    },
    {
        "questionId": 402,
        "title": "Czym różnią się klauzule DROP i REJECT w akcjach reguły iptables?: ",
        "answers": [
            {
                "text": "obie odrzucają pakiety, ale REJECT dotyczy tylko łańcucha FORWARD",
                "isCorrect": false
            },
            {
                "text": "obie odrzucają pakiety, ale DROP zawsze robi to \"po cichu\"",
                "isCorrect": true
            },
            {
                "text": "obie odrzucają pakiety, ale DROP powoduje przerwanie przeglądania reguł, a REJECT nie",
                "isCorrect": false
            },
            {
                "text": "REJECT odrzuca pakiety warunkowo, a DROP bezwarunkowo",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "`iptables` to narzędzie w systemie Linux, które służy do konfiguracji zapory sieciowej. Działa ono poprzez analizowanie nagłówków pakietów sieciowych i podejmowanie decyzji o ich przepuszczeniu lub odrzuceniu. Klauzule `DROP` i `REJECT` to dwie akcje, które można zastosować wobec pakietu, który pasuje do danej reguły.\n\n- **Poprawna odpowiedź: obie odrzucają pakiety, ale DROP zawsze robi to \"po cichu\"**\n    - Akcja `DROP` powoduje, że pakiet jest odrzucany i nie jest wysyłana żadna informacja zwrotna do nadawcy. W efekcie z punktu widzenia nadawcy pakiet po prostu \"znika\",  nie zostaje dostarczony do celu. Nadawca nie jest informowany o zablokowaniu transmisji, i nawet nie podejrzewa że coś mogło pójść nie tak z jego pakietem. Jest to \"ciche\" odrzucenie pakietu.\n    - Akcja `REJECT`  również odrzuca pakiet, jednak różni się od `DROP` tym, że dodatkowo wysyła do nadawcy pakiet ICMP (np. host unreachable, port unreachable, communication administratively prohibited) informujący o odrzuceniu komunikacji. Ten pakiet ICMP informuje źródło, że pakiet został odrzucony przez zaporę ogniową.\n\n- **Niepoprawna odpowiedź: obie odrzucają pakiety, ale REJECT dotyczy tylko łańcucha FORWARD**\n    - Ta odpowiedź jest niepoprawna, ponieważ zarówno `DROP`, jak i `REJECT` mogą być stosowane w dowolnym łańcuchu (`INPUT`, `OUTPUT`, `FORWARD`) w `iptables`.  Ograniczenie `REJECT` tylko do łańcucha `FORWARD` nie jest poprawne.\n   -  Praktycznie każda reguła z którą mamy do czynienia podczas pracy z iptables ma prawo zwrócić `DROP` lub `REJECT`.\n\n- **Niepoprawna odpowiedź: obie odrzucają pakiety, ale DROP powoduje przerwanie przeglądania reguł, a REJECT nie**\n   - Ta odpowiedź jest niepoprawna.  Zarówno `DROP`, jak i `REJECT` po dopasowaniu i zastosowaniu akcji powodują zakończenie przetwarzania danego pakietu w bieżącym łańcuchu (chyba że zastosowano opcję -j RETURN).  Oznacza to, że żadna z tych akcji nie kontynuuje przetwarzania.\n  - Kolejność przetwarzania reguł w danym łańcuchu jest istotna, bo najwcześniejsze dopasowanie reguły do pakietu powoduje natychmiastowe wykonanie przypisanej do niej akcji. \n\n- **Niepoprawna odpowiedź: REJECT odrzuca pakiety warunkowo, a DROP bezwarunkowo**\n    - Ta odpowiedź jest niepoprawna.  Zarówno `REJECT`, jak i `DROP`  są stosowane bezwarunkowo, gdy pakiet pasuje do wzorca danej reguły. Jedyna różnica między nimi to obecność lub brak zwrotnej informacji.  Warunkowość reguły nie zależy od wyboru pomiędzy `DROP` a `REJECT`. Warunkowość reguły dotyczy sposobu jej dopasowania do analizowanego pakietu.\n\n**Przykłady praktyczne:**\n- **DROP:** Administrator systemu chce zablokować komunikację z określonego adresu IP bez ujawniania tej blokady. Użycie `DROP` sprawia, że nadawca nie otrzymuje żadnej informacji o odrzuceniu pakietów, przez co nadawca może  nie podejrzewać że jest blokowany.\n\n- **REJECT:** Administrator chce zablokować dostęp do portu 25 (SMTP) dla wszystkich adresów IP z zewnątrz, jednak jednocześnie chce wysyłać do tych nadawców informacje zwrotną o odmowie dostępu, czyli komunikatu „host unreachable”. `REJECT` jest odpowiednią akcją.\n\nW obu przypadkach dochodzi do odrzucenia pakietu. Jedyna różnica jest taka, że w przypadku `REJECT` wysyłana jest informacja o odmowie dostępu do nadawcy pakietu. W wielu sytuacjach zależy nam aby nadawca wiedział, że został odrzucony, a w innych nie ma takiej potrzeby. To decyduje o tym czy wybieramy akcje `DROP` czy `REJECT`."
    },
    {
        "questionId": 403,
        "title": "Autentyczność kluczy publicznych PGP jest weryfikowana: ",
        "answers": [
            {
                "text": "poprzez PKI",
                "isCorrect": false
            },
            {
                "text": "przez pozyskanie certyfikatu klucza publicznego",
                "isCorrect": false
            },
            {
                "text": "metodą Web of Trust, w której użytkownicy PGP podpisują sobie wzajemnie klucze",
                "isCorrect": true
            },
            {
                "text": "poprzez weryfikację podpisu urzędu CA pod kluczem użytkownika",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Autentyczność kluczy publicznych w systemie PGP (Pretty Good Privacy) jest weryfikowana za pomocą zdecentralizowanego modelu zaufania, zwanego *Web of Trust*. W odróżnieniu od systemów opartych na scentralizowanej infrastrukturze klucza publicznego (PKI), w PGP to użytkownicy wzajemnie poświadczają (podpisują) autentyczność kluczy publicznych innych użytkowników. To podejście tworzy sieć powiązań opartą na zaufaniu osobistym.\n\n**Odpowiedź 1: \"poprzez PKI\"** - Jest **niepoprawna**. PKI (_Public Key Infrastructure_) to scentralizowany model zaufania, w którym zaufane urzędy certyfikacji (CA) wystawiają certyfikaty cyfrowe, potwierdzając tożsamość użytkowników i przynależność klucza publicznego do danego podmiotu. PGP nie korzysta z tego scentralizowanego systemu, ale opiera się na zdecentralizowanym systemie Web of Trust. W PKI użytkownik ufa CA, a pośrednio wszystkim certyfikatom przez niego wydanym; w PGP użytkownik ufa osobom, które bezpośrednio potwierdzają klucz oraz osobom, które te osoby poświadczyły i tak dalej.\n\n**Odpowiedź 2: \"przez pozyskanie certyfikatu klucza publicznego\"** - Jest **niepoprawna**. Certyfikat klucza publicznego jest charakterystyczny dla PKI. PGP nie wykorzystuje certyfikatów w ten sam sposób, zamiast tego użytkownicy PGP podpisują klucze innych, tworząc sieć zaufania. Certyfikat klucza w PKI jest poświadczeniem wystawionym przez CA, PGP zaś nie posiada centralnej CA.\n\n**Odpowiedź 3: \"metodą Web of Trust, w której użytkownicy PGP podpisują sobie wzajemnie klucze\"** - Jest **poprawna**. W PGP, kiedy użytkownik ufa, że dany klucz publiczny rzeczywiście należy do danej osoby, może ten klucz podpisać swoim kluczem prywatnym. Podpis ten potwierdza, że ów użytkownik zweryfikował autentyczność klucza i uważa go za wiarygodny. Inni użytkownicy, którzy ufają użytkownikowi, który podpisał klucz, mogą również ufać podpisanemu kluczowi. Tak tworzy się sieć zaufania Web of Trust, gdzie zaufanie jest przekazywane nieformalnie między użytkownikami. Przykładowo, Alicja ma zaufany klucz publiczny Bolka, który podpisała. Jeżeli Karol posiada zaufany klucz Alicji, to może on również ufać kluczowi Bolka.\n\n**Odpowiedź 4: \"poprzez weryfikację podpisu urzędu CA pod kluczem użytkownika\"** - Jest **niepoprawna**. Jak w odpowiedzi pierwszej i drugiej, PGP nie wykorzystuje urzędów certyfikacji CA do poświadczania autentyczności kluczy publicznych. Jest to sposób działania PKI. W PGP, to użytkownicy poprzez podpisywanie kluczy tworzą sieć zaufania (Web of Trust) a nie zaufanie pochodzące z certyfikatu podpisanego przez centralną instytucję.\n\nPodsumowując, PGP tworzy zdecentralizowany system weryfikacji autentyczności kluczy publicznych oparty na osobistym zaufaniu, w przeciwieństwie do scentralizowanego systemu PKI z urzędami CA. W praktyce użytkownicy PGP podpisują klucze innych użytkowników, których tożsamość potwierdzili w realnym świecie i w ten sposób rozszerza się sieć zaufanych kluczy."
    },
    {
        "questionId": 404,
        "title": "Które zdania są prawdziwe w odniesieniu do aktywnego mechanizmu UAC w systemie Windows: ",
        "answers": [
            {
                "text": "jeśli zwykły użytkownik chce wykonać operację wymagającą uprawnień administratora zostanie zapytany o hasło administratora",
                "isCorrect": true
            },
            {
                "text": "UAC blokuje możliwość instalacji programów przez administratora",
                "isCorrect": true
            },
            {
                "text": "zmiana istotnych gałęzi rejestru systemu wymaga świadomej reakcji uprawnionego użytkownika",
                "isCorrect": true
            },
            {
                "text": "UAC chroni przed przypadkowym uruchomieniem potencjalnie niebezpiecznych programów przez użytkownika",
                "isCorrect": false
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "User Account Control (UAC) w systemie Windows jest mechanizmem bezpieczeństwa, który ogranicza uprawnienia użytkownika, nawet jeśli posiada konto administracyjne. UAC ma na celu zapobieganie nieautoryzowanym zmianom w systemie poprzez wymuszanie od użytkownika świadomego potwierdzenia operacji, które wymagają podwyższonych uprawnień. UAC działa poprzez pokazywanie okna dialogowego z prośbą o potwierdzenie, kiedy użytkownik próbuje wykonać działanie wymagające uprawnień administratora. UAC nie jest kompletnym systemem ochrony bezpieczeństwa, lecz jedynie systemem który zmniejsza ryzyko wprowadzenia nieautoryzowanych zmian w systemie.\n\n**Odpowiedź 1: \"jeśli zwykły użytkownik chce wykonać operację wymagającą uprawnień administratora zostanie zapytany o hasło administratora\"**\n\nTa odpowiedź jest **poprawna**. UAC monitoruje operacje wykonywane przez użytkownika. Gdy użytkownik próbuje wykonać operację wymagającą uprawnień administratora, na przykład zainstalować program, zmienić ustawienia systemowe lub modyfikować chronione pliki, UAC wyświetli okno dialogowe. W tym oknie zwykły użytkownik będzie proszony o hasło administratora lub o zgodę administratora, natomiast administrator, jeżeli nie został zmieniony domyślny tryb pracy UAC, będzie proszony jedynie o zgodę na wykonanie operacji z uprawnieniami administratora. Jest to mechanizm, który zapobiega nieświadomemu wprowadzeniu zmian w systemie. Przykładowo gdy użytkownik nieświadomie uruchomi plik wykonywalny (np. z załącznika poczty), który wymaga uprawnień administratora, UAC poprosi go o hasło, a to już może wzbudzić podejrzenia i dać szansę na powstrzymanie niebezpiecznej operacji.\n\n**Odpowiedź 2: \"UAC blokuje możliwość instalacji programów przez administratora\"**\n\nTa odpowiedź jest **poprawna**. UAC nie blokuje *możliwości* instalacji programów przez administratora, lecz *wymusza* aby administrator jawnie wyraził na to zgodę poprzez interakcję z oknem dialogowym systemu UAC. W domyślnej konfiguracji działania UAC gdy administrator próbuje zainstalować aplikacje musi zaakceptować żądanie UAC w okienku dialogowym. W środowisku testowym, przy wyłączonej funkcji UAC, aplikacja instaluje się bez zgody administratora. W środowisku produkcyjnym, w którym funkcja UAC jest domyślnie włączona, administrator jest proszony o potwierdzenie tego faktu przy instalacji każdej aplikacji. W tym sensie UAC \"blokuje\" możliwość instalacji aplikacji bez świadomej zgody administratora. To nie blokuje możliwości instalacji, ale wymaga świadomego działania administratora.\n\n**Odpowiedź 3: \"zmiana istotnych gałęzi rejestru systemu wymaga świadomej reakcji uprawnionego użytkownika\"**\n\nTa odpowiedź jest **poprawna**. UAC obejmuje kontrolą także dostęp do istotnych gałęzi rejestru systemu. Próba zmiany ustawień w takich gałęziach, nawet jeśli użytkownik jest administratorem, również wywoła okno dialogowe UAC, żądając potwierdzenia operacji przez użytkownika. Przykładowo, edycja kluczy rejestru w `HKEY_LOCAL_MACHINE\\SOFTWARE` i podobnych sekcjach wymaga podwyższonych uprawnień i wywoła pytanie UAC. Jest to ważna funkcjonalność, która chroni system przed nieautoryzowanymi zmianami.\n\n**Odpowiedź 4: \"UAC chroni przed przypadkowym uruchomieniem potencjalnie niebezpiecznych programów przez użytkownika\"**\n\nTa odpowiedź jest **niepoprawna**. UAC chroni przed uruchomieniem programów, które wymagają uprawnień administratora, ale nie chroni przed przypadkowym uruchomieniem programów, które nie wymagają tych uprawnień. Na przykład, jeśli użytkownik uruchomi program, który nie żąda uprawnień administracyjnych, UAC go nie zablokuje, ani nie zapyta użytkownika o zgodę na uruchomienie. Ta odpowiedź jest niepoprawna, gdyż gra na założeniu, że UAC chroni przed *wszystkimi* niebezpiecznymi programami, co nie jest prawdą. UAC jest elementem obrony systemu, a nie zastępuje pozostałych metod ochrony, w tym programy antywirusowe."
    },
    {
        "questionId": 405,
        "title": "Które stwierdzenia dotyczące blokady konta w systemie Windows są prawdziwe: ",
        "answers": [
            {
                "text": "licznik prób logowania jest zerowany po każdej udanej próbie logowania",
                "isCorrect": false
            },
            {
                "text": "w czasie określonym długością okresu zerowania licznika prób logowania, użytkownik nie może podjąć więcej udanych prób logowania niż określa próg blokady",
                "isCorrect": true
            },
            {
                "text": "istnieje ustawienie progu blokady dopuszczające nieblokowanie konta mimo dowolnej liczby niepomyślnych prób logowania",
                "isCorrect": true
            },
            {
                "text": "próg blokady określa ilość kolejnych niepomyślnych prób logowania, po osiągnięciu której dostęp do konta będzie zablokowany trwale",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mechanizm blokady konta w systemie Windows ma na celu ochronę przed atakami typu brute-force, polegającymi na wielokrotnych próbach zgadnięcia hasła użytkownika. Mechanizm ten opiera się na kilku kluczowych ustawieniach.\n\n**Licznik prób logowania**: System śledzi nieudane próby logowania. Każda nieudana próba logowania, np. przy wpisaniu błędnego hasła, zwiększa licznik prób. Licznik ten jest resetowany (ustawiany na zero) nie po udanej próbie logowania, a po upływie określonego czasu zwanego okresem zerowania. Oznacza to, że jeśli użytkownik po serii nieudanych prób poprawnie się zaloguje, licznik nie zostanie wyzerowany. Ta właściwość chroni przed atakami, w których, po poprawnym zalogowaniu użytkownik mógłby kontynuować ataki w celu uzyskania dostępu do innego konta.\n\n**Próg blokady**: Określa liczbę nieudanych prób logowania, po których konto zostanie zablokowane. Ustawienie odpowiedniego progu blokady jest kluczowe, zbyt duży próg może spowodować, że atak brute-force nie zostanie w ogóle zatrzymany. Z drugiej strony zbyt mały próg może spowodować problemy dla użytkowników, którzy popełnią błędy przy wpisywaniu hasła. Próg blokady nie określa trwałego zablokowania konta, lecz jedynie czasowe zablokowanie, po określonym czasie blokada konta zostaje zdjęta. Istnieje również możliwość ustawienia progu blokady, który w rzeczywistości będzie wyłączony, ustawienie progu blokady na 0 powoduje że konto nie zostanie zablokowane niezależnie od ilości nieudanych prób.\n\n**Okres zerowania licznika prób logowania**: Określa, po jakim czasie licznik nieudanych prób logowania zostanie zresetowany do zera, a użytkownik ponownie będzie mógł podejmować próby logowania. Czas ten nie jest powiązany z czasem trwania blokady. Po tym czasie użytkownik może podejmować próby logowania od nowa (chyba że wcześniej zablokuje konto).\n\n**Czas trwania blokady**: Określa, jak długo konto użytkownika pozostaje zablokowane po osiągnięciu progu blokady. Po upływie zdefiniowanego czasu blokada jest zdejmowana, a użytkownik może ponownie próbować się zalogować, jednak licznik nieudanych prób logowania nie jest zerowany.  \n\n**Analiza odpowiedzi**:\n- **\"licznik prób logowania jest zerowany po każdej udanej próbie logowania\"** - **NIEPOPRAWNE**. Licznik nie jest zerowany po udanej próbie logowania, lecz po upływie okresu resetowania licznika prób. Celem jest utrudnienie ataków typu brute-force. Przykładowo, jeśli ktoś próbował wielokrotnie zgadnąć hasło i ostatecznie poprawnie się zaloguje, to fakt ten nie powinien resetować licznika, ponieważ za chwilę może próbować zgadnąć hasło innego konta. \n- **\"w czasie określonym długością okresu zerowania licznika prób logowania, użytkownik nie może podjąć więcej udanych prób logowania niż określa próg blokady\"** - **POPRAWNE**. Mechanizm ten uniemożliwia szybkie powtarzanie nieudanych prób logowania, po których natychmiast następowałoby zalogowanie i resetowanie licznika. Przykładowo, ustawienie progu blokady na 3 próby i czasu zerowania na 15 minut uniemożliwia przekroczenie tego limitu w czasie 15 minut. Jeśli użytkownik popełni 3 błędy przy logowaniu, jego konto zostanie zablokowane i nie będzie mógł więcej próbować logować się (bez odblokowania konta) przez całe 15 minut. \n- **\"istnieje ustawienie progu blokady dopuszczające nieblokowanie konta mimo dowolnej liczby niepomyślnych prób logowania\"** - **POPRAWNE**. W systemie Windows ustawienie progu blokady na wartość 0 powoduje, że konto nigdy nie będzie zablokowane, niezależnie od liczby nieudanych prób logowania. Ustawienie to może być potrzebne dla specjalnego konta, które musi być cały czas dostępne, na przykład konta aplikacji, która musi mieć możliwość ciągłego uwierzytelniania.\n- **\"próg blokady określa ilość kolejnych niepomyślnych prób logowania, po osiągnięciu której dostęp do konta będzie zablokowany trwale\"** - **NIEPOPRAWNE**. Blokada konta jest z założenia tymczasowa. Czas trwania blokady jest odrębnym parametrem, po upływie którego konto ponownie staje się dostępne. Zablokowanie konta na stałe wymaga dodatkowej interwencji administratora. Przykładowo, jeśli system jest podatny na ataki i ma bardzo dużo nieudanych prób logowania ustawianie trwałej blokady konta byłoby bezcelowe. Ataki mogłyby spowodować blokowanie wielu kont, co w konsekwencji mogłoby uniemożliwić pracę całej organizacji."
    },
    {
        "questionId": 406,
        "title": "Czy pakiet PGP(GPG) używa szyfrowania symetrycznego?: ",
        "answers": [
            {
                "text": "tak, treść listu jest zawsze szyfrowana algorytmem symetrycznym",
                "isCorrect": true
            },
            {
                "text": "nie, PGP stosuje tylko kryptografię klucza publicznego",
                "isCorrect": false
            },
            {
                "text": "tak, np. do szyfrowania plików",
                "isCorrect": false
            },
            {
                "text": "tak, nadawca i odbiorca generują metodą DH wspólny klucz sesji na podstawie swoich kluczy publicznych",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "PGP (Pretty Good Privacy) i GPG (GNU Privacy Guard) to programy do szyfrowania i podpisywania danych, które wykorzystują podejście hybrydowe łączące szyfrowanie symetryczne i asymetryczne. Szyfrowanie symetryczne, wykorzystujące jeden klucz do szyfrowania i deszyfrowania, jest znacznie szybsze niż szyfrowanie asymetryczne, ale wymaga bezpiecznego przekazania klucza. Z kolei szyfrowanie asymetryczne, wykorzystujące parę kluczy (publiczny i prywatny), umożliwia bezpieczną wymianę kluczy bez potrzeby ich wcześniejszego udostępnienia w sposób bezpieczny. \n\n**Odpowiedź 1:** \"tak, treść listu jest zawsze szyfrowana algorytmem symetrycznym\" jest poprawna, ponieważ PGP/GPG rzeczywiście używają szyfrowania symetrycznego do szyfrowania samej treści wiadomości lub pliku.  Po zaszyfrowaniu wiadomości, klucz symetryczny użyty do tego szyfrowania jest szyfrowany kluczem publicznym odbiorcy i dopiero takie dane są przesyłane do odbiorcy.  Zastosowanie szyfrowania symetrycznego do samej treści wiadomości wynika z faktu, że szyfrowanie asymetryczne (kluczem publicznym) jest zbyt wolne aby mogło być zastosowane do szyfrowania dużej ilości danych. Szyfrowanie asymetryczne jest wykorzystane jedynie do przesłania tajnego klucza sesyjnego, który służy do symetrycznego szyfrowania właściwej wiadomości.\n\n**Odpowiedź 2:** \"nie, PGP stosuje tylko kryptografię klucza publicznego\" jest niepoprawna. PGP nie stosuje tylko kryptografii klucza publicznego, w której szyfrowanie i deszyfrowanie odbywałoby się wyłącznie przy wykorzystaniu klucza publicznego i prywatnego. Jak wskazano w pierwszej poprawnej odpowiedzi PGP jest systemem hybrydowym. W praktyce PGP tworzy najpierw klucz sesyjny służący do szyfrowania symetrycznego danych i ten klucz sesyjny szyfruje kluczem publicznym odbiorcy.\n\n**Odpowiedź 3:** \"tak, np. do szyfrowania plików\" jest niepoprawna, ponieważ choć PGP/GPG mogą być wykorzystane do szyfrowania plików (z użyciem szyfrowania symetrycznego), to odpowiedź ta nie opisuje poprawnie hybrydowego mechanizmu PGP/GPG. Szyfrowanie plików z wykorzystaniem algorytmów symetrycznych polega na tym, że sam klucz szyfrowania zabezpieczany jest poprzez hasło podane przez użytkownika i nie jest udostępniany w postaci jawnej.\n\n**Odpowiedź 4:** \"tak, nadawca i odbiorca generują metodą DH wspólny klucz sesji na podstawie swoich kluczy publicznych\" jest niepoprawna, ponieważ choć algorytm Diffie-Hellmana jest wykorzystywany do uzgodnienia wspólnego klucza w wielu protokołach, w tym w systemie PGP/GPG, to w PGP wykorzystany klucz sesji jest generowany przez nadawcę listu i nie powstaje on na podstawie kluczy publicznych. Klucz publiczny odbiorcy służy do zaszyfrowania sesyjnego klucza symetrycznego wykorzystywanego do szyfrowania samego listu."
    },
    {
        "questionId": 407,
        "title": "Bezpośrednim efektem operacji eksportu certyfikatu do formatu PKCS#12 jest: ",
        "answers": [
            {
                "text": "przekazanie klucza publicznego innemu użytkownikowi w celu umożliwienia mu wysłania do nas zaszyfrowanej poczty",
                "isCorrect": false
            },
            {
                "text": "wyodrębnienie z certyfikatu klucza publicznego w celu dołączenia go do kryptogramu przesyłanej wiadomości",
                "isCorrect": false
            },
            {
                "text": "wyodrębnienie z certyfikatu klucza prywatnego w celu dołączenia go do wykonanego podpisu elektronicznego wiadomości",
                "isCorrect": false
            },
            {
                "text": "utworzenie kopii zapasowej klucza prywatnego i publicznego w pliku",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Format PKCS#12 (znany również jako PFX) to standardowy format pliku służący do przechowywania certyfikatów cyfrowych, kluczy prywatnych oraz łańcucha certyfikatów (np. certyfikatów pośrednich urzędu certyfikacji), które są powiązane z tym certyfikatem. Pliki PKCS#12 są szyfrowane za pomocą hasła, co zapewnia poufność przechowywanych w nich kluczy prywatnych.\n\n**Odpowiedź 1: \"przekazanie klucza publicznego innemu użytkownikowi w celu umożliwienia mu wysłania do nas zaszyfrowanej poczty\"**\n   -   Ta odpowiedź jest **niepoprawna**, ponieważ eksport do formatu PKCS#12 nie służy bezpośrednio do przekazania klucza publicznego innemu użytkownikowi. Klucz publiczny można przekazać na wiele sposobów np. poprzez przesłanie certyfikatu w formacie tekstowym.  Format PKCS#12 jest przeznaczony do przechowywania zarówno klucza publicznego jak i prywatnego, a nie tylko do przekazywania klucza publicznego innemu użytkownikowi. Przekazanie klucza publicznego innemu użytkownikowi ma sens tylko wtedy, kiedy chcemy, aby ktoś mógł do nas przesyłać zaszyfrowane wiadomości, ale nie dawać komuś możliwości udawania nas (podszywania się pod nas).\n   - Praktycznie, jeśli ktoś potrzebuje wysłać do nas zaszyfrowaną wiadomość, wystarczy, że przekażemy mu tylko nasz klucz publiczny, a nie cały plik PKCS#12. Plik PKCS#12 zawiera więcej informacji (klucz prywatny), co wiąże się z ryzykiem jeśli dostanie się w niepowołane ręce.\n\n**Odpowiedź 2: \"wyodrębnienie z certyfikatu klucza publicznego w celu dołączenia go do kryptogramu przesyłanej wiadomości\"**\n  - Ta odpowiedź jest **niepoprawna**, ponieważ eksport do formatu PKCS#12 nie jest wykorzystywany do wyodrębniania klucza publicznego do dołączenia do kryptogramu. Klucz publiczny jest dostępny w certyfikacie (który również może być przechowywany w pliku PKCS#12), a nie w samym PKCS#12.\n  - W praktyce, klucz publiczny do szyfrowania danych wysyłamy do odbiorcy jako oddzielny załącznik, lub umieszczamy w nagłówku pliku. Nie potrzebujemy eksportować całego pliku PKCS#12, żeby tylko przekazać klucz publiczny. Plik PKCS#12 jest wykorzystywany do archiwizacji naszych kluczy (prywatnego i publicznego).\n\n**Odpowiedź 3: \"wyodrębnienie z certyfikatu klucza prywatnego w celu dołączenia go do wykonanego podpisu elektronicznego wiadomości\"**\n  - Ta odpowiedź jest **niepoprawna**,  ponieważ format PKCS#12 nie służy wyodrębnieniu samego klucza prywatnego, jego celem jest przechowywanie go wraz z certyfikatem w zabezpieczonej formie, gdzie ma być on bezpiecznie przechowywany lub transportowany.\n   - W praktyce klucz prywatny jest wykorzystywany jedynie przez właściciela do dezyfrowania i podpisywania wiadomości. Nigdy nie jest on dołączany do wiadomości, gdyż jego jawne ujawnienie powoduje kompromitację tożsamości i danych jego właściciela.\n\n**Odpowiedź 4: \"utworzenie kopii zapasowej klucza prywatnego i publicznego w pliku\"**\n   - Ta odpowiedź jest **poprawna**. Plik w formacie PKCS#12 (znany również jako PFX) umożliwia przechowywanie klucza prywatnego i publicznego, a także certyfikatu (w tym również certyfikatów pośrednich) w jednym, zaszyfrowanym pliku.\n   - W praktyce, taki plik jest wykorzystywany do bezpiecznego przechowywania kluczy i certyfikatów. Format PKCS#12 umożliwia przenoszenie kluczy między systemami oraz wykorzystywanie ich przez różne aplikacje (np. klienty poczty elektronicznej, przeglądarki internetowe czy serwery www), przy zachowaniu bezpieczeństwa klucza prywatnego. Na przykład, jeżeli chcemy zmienić komputer i przenieść nasz certyfikat, aby móc podpisywać pocztę elektroniczną, to plik PKCS#12 idealnie nadaje się do takiego celu."
    },
    {
        "questionId": 408,
        "title": "Mechanizm sudo można tak skonfigurować by: ",
        "answers": [
            {
                "text": "nigdy nie wymagał podania hasła",
                "isCorrect": true
            },
            {
                "text": "wymagał podania hasła użytkownika, w ramach konta którego należy wykonać polecenie",
                "isCorrect": true
            },
            {
                "text": "wykonał polecenie bez pytania o hasło użytkownika o ile plik programu tego polecenia ma ustawiony bit SUID",
                "isCorrect": false
            },
            {
                "text": "wymagał podania hasła bieżącego użytkownika przy każdym poleceniu",
                "isCorrect": true
            }
        ],
        "clue": 3,
        "isStarred": false,
        "explanation": "Mechanizm `sudo` w systemach Linux/Unix umożliwia użytkownikom uruchamianie poleceń z uprawnieniami innego użytkownika (domyślnie superużytkownika root). Jego działanie i wymagania dotyczące podawania hasła definiowane są w pliku konfiguracyjnym `/etc/sudoers`, a nie w samych właściwościach programu `sudo`. W pliku tym znajdują się definicje, które określają, jacy użytkownicy, na jakich komputerach, mogą uruchamiać, jakie komendy z uprawnieniami, jakich użytkowników i czy przy tym ma być wymagane hasło.\n\n**Odpowiedź 1: \"nigdy nie wymagał podania hasła\" jest poprawna.**\n\nPlik `/etc/sudoers` umożliwia konfigurację mechanizmu `sudo` w taki sposób, że użytkownik nie musi podawać hasła. Uzyskuje się to poprzez wpisanie `NOPASSWD:` w linii specyfikującej uprawnienia danego użytkownika. Przykład: \n`user1 ALL = NOPASSWD: /usr/bin/apt-get update`\nW takim przypadku użytkownik `user1` może uruchomić komendę `/usr/bin/apt-get update` bez podawania hasła. Jest to często stosowane, gdy aplikacja potrzebuje uprawnień administratora a użytkownik i administrator, którzy z niej korzystają powinni mieć możliwość szybkiego i automatycznego wywołania jej.\n\n**Odpowiedź 2: \"wymagał podania hasła użytkownika, w ramach konta którego należy wykonać polecenie\" jest poprawna.**\n\nDomyślnie, jeśli nie ma wpisu `NOPASSWD:`, `sudo` będzie wymagać podania hasła użytkownika, którego uprawnienia próbuje przyjąć. Czyli jeśli użytkownik `user1`  chce uruchomić  `sudo su - user2`  , `sudo` poprosi o hasło użytkownika `user2`. W środowisku, gdzie jest wielu użytkowników jest to bardzo przydatna opcja gdyż dzięki temu każdy z użytkowników jest rozliczany ze swoich działań.\n\n**Odpowiedź 3: \"wykonał polecenie bez pytania o hasło użytkownika o ile plik programu tego polecenia ma ustawiony bit SUID\" jest niepoprawna.**\n\nBit SUID (Set User ID) oraz SGID (Set Group ID) odnoszą się do praw wykonywania pliku. W przypadku ustawienia flagi SUID proces uruchomiony poprzez taki plik wykonuje się z uprawnieniami właściciela pliku, niezależnie od użytkownika uruchamiającego proces. Podobnie z SGID, tylko zamiast użytkownika mamy do czynienia z grupą. SUID i SGID działają bez udziału mechanizmu `sudo`. `sudo` działa w oparciu o konfigurację zawartą w pliku `/etc/sudoers` i konfiguracja ta całkowicie dominuje nad flagami SUID oraz SGID.\n\n**Odpowiedź 4: \"wymagał podania hasła bieżącego użytkownika przy każdym poleceniu\" jest poprawna.**\n\nPlik `/etc/sudoers` pozwala na ustawienie parametru, który wymusza podawania hasła bieżącego użytkownika przy każdym wywołaniu polecenia `sudo`. Takie ustawienie może mieć wartość `timestamp_timeout=0` , która powoduje, że hasło musi być podawane za każdym razem gdy użytkownik chce wywołać jakieś polecenia z użyciem `sudo`.\n\nPrzykłady:\n\n*  W firmie, gdzie kilku administratorów ma dostęp do tego samego serwera, każdy z nich może uzyskać dostęp do wybranych poleceń administratorskich za pomocą `sudo`. Jeden z administratorów może mieć dostęp do restartu serwera, a drugi do przeglądania logów, trzeci do tworzenia nowych użytkowników, etc. Dzięki `sudo` unikamy konieczności udostępniania wszystkim hasła roota, a ich aktywność jest logowana.\n*   System monitoringu może potrzebować dostępu do szczegółowych danych dotyczących procesów. Konfigurując `/etc/sudoers`,  możemy zezwolić danemu procesowi monitorującemu na wykonywanie polecenia  `ps aux` bez konieczności przydzielania uprawnień roota. Jest to przykład bezpieczeństwa z użyciem `sudo` oraz jednocześnie unikanie udzielania bezsensownie uprawnień administratora aplikacjom, które ich nie potrzebują\n*  Użytkownik, który potrzebuje zamontować nową płytę CD może użyć `sudo mount /dev/cdrom /mnt/cdrom` bez znajomości hasła administratora, a administrator zadba aby ten użytkownik nie mógł wykonać innych poleceń wykorzystujących SUDO. Jest to przykład praktycznego zastosowanie mechanizmu `sudo`, w którym nie trzeba udostępniać hasła roota użytkownikowi, który wykonuje tylko wybrane czynności administracyjne."
    },
    {
        "questionId": 409,
        "title": "Możliwe metody uwierzytelniania użytkownika w protokole SSH: ",
        "answers": [
            {
                "text": "hasło użytkownika",
                "isCorrect": true
            },
            {
                "text": "mechanizm TOFU",
                "isCorrect": false
            },
            {
                "text": "asymetryczne klucze kryptograficzne",
                "isCorrect": true
            },
            {
                "text": "symetryczne klucze kryptograficzne",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół SSH (Secure Shell) to protokół sieciowy, który umożliwia bezpieczne połączenie z komputerem zdalnym, często wykorzystywany do administracji serwerami. Uwierzytelnianie w SSH polega na zweryfikowaniu, czy użytkownik łączący się zdalnie rzeczywiście jest tym, za kogo się podaje. Zasadniczo protokół SSH wspiera dwa główne podejścia do uwierzytelniania: hasła i kryptografię klucza asymetrycznego.\n\n**hasło użytkownika:**  To najbardziej podstawowa metoda, gdzie użytkownik, próbując połączyć się z serwerem zdalnym, wprowadza nazwę użytkownika i hasło. Serwer, po otrzymaniu tych danych, porównuje je z danymi zapisanymi w swojej bazie użytkowników. Jeśli dane się zgadzają, użytkownik uzyskuje dostęp do serwera. W SSH, w przeciwieństwie do telnetu, hasło nie jest transmitowane w postaci jawnej, lecz jest szyfrowane. Ten rodzaj uwierzytelniania jest powszechny ale najmniej bezpieczny ze względu na możliwość przechwycenia szyfrowanego hasła, złamania go metodą brute force, oraz słabości użytkowników w doborze silnych haseł. Z tego powodu w prawdziwych systemach produkcyjnych ta metoda jest wyłączana na rzecz uwierzytelniania kluczem asymetrycznym.\n\n**mechanizm TOFU:** Mechanizm \"TOFU\" (_Trust On First Use_ - zaufaj przy pierwszym użyciu) nie jest wbudowaną metodą uwierzytelniania użytkownika w protokole SSH. TOFU dotyczy innego etapu, a mianowicie weryfikacji klucza publicznego serwera SSH przez klienta. Przy pierwszym połączeniu z serwerem, klient nie wie, czy otrzymany klucz jest poprawny, i przyjmuje go jako poprawny bez dodatkowych weryfikacji, ufając, że serwer jest tym, za kogo się podaje. W kolejnych połączeniach klient weryfikuje czy klucz publiczny serwera się zmienił. Jeżeli tak to klient zgłosi problem i poprosi użytkownika o podjęcie decyzji czy należy zaufać nowemu kluczowi serwera. TOFU nie jest metodą uwierzytelniania użytkownika tylko serwera i jest zagrożone atakiem typu _man-in-the-middle_ podczas pierwszego połączenia. Po poprawnym ustaleniu klucza serwera ten mechanizm nie ma wpływu na uwierzytelnianie użytkownika.\n\n**asymetryczne klucze kryptograficzne:**  Jest to bezpieczniejsza i powszechnie polecana metoda. Użytkownik generuje parę kluczy: prywatny (trzymany w tajemnicy) i publiczny (który może być udostępniany). Klucz publiczny umieszcza się na serwerze zdalnym w pliku authorized_keys. Klient w procesie uwierzytelniania, wykorzystując klucz prywatny, podpisuje wyzwanie (ang. _challenge_) wysłane przez serwer. Serwer, dysponując kluczem publicznym klienta, weryfikuje podpis i w przypadku poprawności umożliwia użytkownikowi dostęp do serwera. Zastosowanie tego rodzaju uwierzytelniania nie wymaga przesyłania hasła przez sieć.\n\n**symetryczne klucze kryptograficzne:**  Chociaż szyfrowanie symetryczne jest wykorzystywane w SSH do szyfrowania samej komunikacji, to nie jest ono wykorzystywane bezpośrednio w uwierzytelnianiu użytkowników. Metoda ta, pomimo że szyfruje dane, opiera się na tym, iż obie strony wymiany danych muszą dysponować tym samym kluczem, który musi zostać w jakiś sposób bezpiecznie uzgodniony. Protokoły wymiany kluczy sesyjnych zazwyczaj opierają się na algorytmach asymetrycznych, np. Diffiego-Hellmana. To właśnie uzgodnione w ten sposób klucze symetryczne służą do szyfrowania komunikacji po uwierzytelnieniu, ale nie do samego uwierzytelniania użytkownika.\n\nPodsumowując, do uwierzytelniania użytkownika w SSH używamy przede wszystkim hasła (ale tylko w trybie o ograniczonym bezpieczeństwie) lub kluczy asymetrycznych. TOFU nie jest metodą uwierzytelniania, tylko sposobem weryfikacji klucza publicznego serwera przy pierwszym połączeniu, a klucze symetryczne, choć kluczowe dla szyfrowania komunikacji, nie są stosowane bezpośrednio w procesie uwierzytelniania użytkownika."
    },
    {
        "questionId": 410,
        "title": "Wskaż prawdziwe stwierdzenia dotyczące szyfrowania treści plików mechanizmem EFS: ",
        "answers": [
            {
                "text": "każdy plik szyfrowany jest kluczem publicznym właściciela pliku",
                "isCorrect": false
            },
            {
                "text": "każdy plik szyfrowany jest innym kluczem",
                "isCorrect": true
            },
            {
                "text": "plik udostępniony przez właściciela 2 innym użytkownikom jest szyfrowany 3 kluczami",
                "isCorrect": false
            },
            {
                "text": "każdy plik szyfrowany jest kluczem prywatnym właściciela pliku",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm EFS (Encrypting File System) w systemie Windows stosuje hybrydowy model szyfrowania, wykorzystujący zarówno szyfrowanie symetryczne, jak i asymetryczne. Pliki są szyfrowane za pomocą unikalnego klucza symetrycznego, ponieważ jest to operacja o wiele szybsza niż stosowanie algorytmów asymetrycznych przy dużej ilości danych. Klucz symetryczny, którym zaszyfrowano plik jest chroniony przy pomocy mechanizmu szyfrowania asymetrycznego. Klucz symetryczny jest szyfrowany kluczem publicznym użytkownika. Do odszyfrowania klucza symetrycznego, użytkownik musi wykorzystać swój klucz prywatny.\n*   **\"każdy plik szyfrowany jest kluczem publicznym właściciela pliku\"** - Jest to nieprawda. EFS *nie szyfruje* plików bezpośrednio kluczem publicznym właściciela.  Klucz publiczny jest używany do ochrony klucza symetrycznego użytego do szyfrowania pliku. Zastosowanie samego klucza publicznego do szyfrowania jest nieefektywne.\n*   **\"każdy plik szyfrowany jest innym kluczem\"** - Jest to prawda. W mechanizmie EFS każdy plik jest szyfrowany odrębnym kluczem symetrycznym. Dzięki temu, złamanie jednego z kluczy szyfrujących chronionych publicznymi kluczami, nie powoduje złamania innych plików w systemie plików.  Jest to istotne dla ograniczenia skutków potencjalnego ataku. Praktycznie oznacza, że nie da się odczytać wszystkich zaszyfrowanych plików w systemie, tylko ten do którego wyciekł klucz szyfrujący.\n*   **\"plik udostępniony przez właściciela 2 innym użytkownikom jest szyfrowany 3 kluczami\"** - Jest to nieprawda. W sytuacji, gdy plik jest udostępniony 2 innym użytkownikom,  do jego zaszyfrowania używany jest jeden klucz symetryczny, który jest następnie szyfrowany kluczem publicznym każdego z trzech uprawnionych użytkowników. W strukturze pliku, po zaszyfrowaniu, będzie przechowywana informacja o trzech zaszyfrowanych kluczach symetrycznych chronionych różnymi kluczami publicznymi.  Mechanizm ten umożliwia uprawnionym użytkownikom odszyfrowanie pliku, wykorzystując ich klucze prywatne do odszyfrowania klucza symetrycznego pliku. W efekcie każdy użytkownik z uprawnieniami do danego pliku, widzi go jako odszyfrowany.\n*  **\"każdy plik szyfrowany jest kluczem prywatnym właściciela pliku\"** - Jest to nieprawda. W mechanizmie EFS klucz prywatny właściciela nigdy nie jest użyty do szyfrowania, a jedynie do odszyfrowania klucza symetrycznego. To jest ważne, ponieważ ujawnienie klucza prywatnego grozi poważnymi konsekwencjami dla właściciela klucza, z uwagi na możliwość użycia tego klucza do odszyfrowywania plików zaszyfrowanych tym kluczem publicznym."
    },
    {
        "questionId": 411,
        "title": "Protokół TLS w usłudze poczty elektronicznej stosuje się do: ",
        "answers": [
            {
                "text": "tworzenia bezpiecznego kanału komunikacji programu klienta z serwerem poczty",
                "isCorrect": true
            },
            {
                "text": "uwierzytelniania nadawcy konkretnej wiadomości",
                "isCorrect": false
            },
            {
                "text": "podpisywania cyfrowego treści listy",
                "isCorrect": false
            },
            {
                "text": "szyfrowania załączników wiadomości",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół TLS (Transport Layer Security), będący następcą protokołu SSL (Secure Sockets Layer), jest protokołem kryptograficznym, który ma na celu zapewnienie bezpiecznej komunikacji w sieci. W kontekście usługi poczty elektronicznej, TLS jest stosowany głównie do utworzenia bezpiecznego kanału komunikacji między programem klienta poczty elektronicznej a serwerem poczty. Definiuje to bezpieczne połączenie, które szyfruje przesyłane dane, chroniąc je przed nieuprawnionym dostępem podczas transmisji. Jest to podstawowe zabezpieczenie które chroni dane logowania użytkownika i treść wiadomości przed odczytaniem przez osoby trzecie na trasie przesyłania. Protokół TLS, w przeciwieństwie do innych protokołów bezpieczeństwa, nie realizuje natomiast innych zadań takich jak: podpisywanie, szyfrowanie załączników czy też uwierzytelnianie nadawcy, jednak może wspomagać inne mechanizmy służące tym celom.\n\n**Odpowiedź a: \"tworzenia bezpiecznego kanału komunikacji programu klienta z serwerem poczty\" - POPRAWNA.**\nProtokół TLS (oraz jego poprzednik SSL) jest przede wszystkim używany do tworzenia szyfrowanego kanału komunikacji między klientem poczty a serwerem poczty. Oznacza to, że wszystkie dane przesyłane między tymi dwoma punktami są szyfrowane, w tym hasła, nazwy użytkownika oraz treść wiadomości. Bez TLS komunikacja odbywałaby się tekstem jawnym, podatnym na podsłuchanie. Na przykład, używając przeglądarki internetowej do obsługi poczty elektronicznej (webmail), protokół TLS (HTTPS) chroni twoje hasło i treść twoich emaili przed nieuprawnionym dostępem na trasie pomiędzy twoim komputerem, a serwerem.\n\n**Odpowiedź b: \"uwierzytelniania nadawcy konkretnej wiadomości\" - NIEPOPRAWNA.**\nTLS nie uwierzytelnia nadawcy wiadomości w sensie kryptograficznego podpisywania każdej wysyłanej wiadomości. Mechanizmy uwierzytelniania w TLS działają na poziomie połączenia (kanału komunikacyjnego), a nie na poziomie pojedynczych wiadomości. Do uwierzytelnienia nadawcy wiadomości stosowane są osobne mechanizmy jak PGP lub S/MIME.  Przykładowo, protokół TLS używany przy dostępie do poczty przez webmail (HTTPS) chroni twoje połączenie z serwerem pocztowym, ale nie poświadcza, że e-mail wysłany przez serwer pocztowy od jakiegoś użytkownika, jest faktycznie od tego użytkownika.\n\n**Odpowiedź c: \"podpisywania cyfrowego treści listy\" - NIEPOPRAWNA.**\nTLS nie zajmuje się cyfrowym podpisywaniem treści wiadomości e-mail, co gwarantowałoby integralność wiadomości oraz poświadczało jej autentyczność. Taka funkcjonalność, jak podpis cyfrowy, jest najczęściej realizowana za pomocą dodatkowych protokołów lub technologii jak S/MIME lub PGP. Protokół TLS gwarantuje jedynie szyfrowanie połączenia między twoim komputerem a serwerem, ale nie gwarantuje, że e-mail odebrany przez ciebie jest w 100% autentyczny.\n\n**Odpowiedź d: \"szyfrowania załączników wiadomości\" - NIEPOPRAWNA.**\nTLS szyfruje całą komunikację pomiędzy klientem i serwerem, w tym załączniki do wiadomości, ale szyfrowanie odbywa się w ramach sesji, a nie na poziomie poszczególnych załączników. Oznacza to, że po odebraniu wiadomości przez serwer, załączniki są nadal dostępne w postaci jawnej. Do trwałego szyfrowania załączników, na poziomie samej wiadomości, stosuje się protokoły PGP lub S/MIME. Na przykład, użytkownik korzystający z webmaila ma szyfrowane dane przesyłane pomiędzy komputerem, a serwerem z wykorzystaniem HTTPS, jednak załącznik pobrany z serwera, jest już nieszyfrowany."
    },
    {
        "questionId": 412,
        "title": "Który opis pasuje do poniższej konfiguracji TCP wrappera ftpd: ALL EXCEPT www : ALLOW ALL : ALL : twist /bin/echo “OK”: ",
        "answers": [
            {
                "text": "za wyjątkiem komputera www umożliwia każdemu dostęp do każdej usługi",
                "isCorrect": false
            },
            {
                "text": "zabrania dostępu do usługi WWW z komputera ftpd",
                "isCorrect": false
            },
            {
                "text": "umożliwia dostęp do usługi FTP z komputera www",
                "isCorrect": false
            },
            {
                "text": "zabrania dostępu do usługi FTP z komputera www",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "TCP Wrappers to system kontroli dostępu do usług sieciowych, działający na poziomie hosta. Wykorzystuje on dwa pliki konfiguracyjne: `/etc/hosts.allow` oraz `/etc/hosts.deny`. Plik `/etc/hosts.allow` zawiera reguły określające, które hosty mają mieć dostęp do poszczególnych usług, a plik `/etc/hosts.deny` określa reguły blokujące dostęp do usług, jeśli nie zostały one wcześniej jawnie dozwolone w `/etc/hosts.allow`. Reguły w tych plikach są analizowane w kolejności, w jakiej zostały umieszczone. W przypadku, gdy dopasowanie nastąpi w pliku `/etc/hosts.allow`, dalsze sprawdzanie nie jest przeprowadzane i dostęp jest przyznawany. W przypadku nie znalezienia dopasowania w `/etc/hosts.allow` przeszukiwany jest plik `/etc/hosts.deny`, jeśli tam również nie znajdzie dopasowania, dostęp jest przyznawany.\n\nRozważmy konfigurację `ftpd: ALL EXCEPT www : ALLOW : ALL : twist /bin/echo “OK”` .\n\n* `ftpd`: Określa, że ta reguła dotyczy serwera FTP (`ftpd`).\n* `ALL EXCEPT www`: Ta część określa hosty, których ta reguła dotyczy. Znaczy to, że reguła ta dotyczy wszystkich hostów z wyjątkiem hosta o nazwie `www`.\n* `ALLOW`: Ten parametr w pliku `/etc/hosts.allow` ma za zadanie jawnie przyznać dostęp, jednak ten parametr występuje tylko w pliku `/etc/hosts.allow`. W prezentowanej konfiguracji ten parametr jest pominięty, gdyż reguła występuje w pliku `/etc/hosts.deny`.\n* `ALL :`: Jest to zakres domyślny, którego nie można pominąć. W tym miejscu zwykle podawany jest zakres adresów IP.\n* `twist /bin/echo “OK”` : Opcja `twist` sprawia, że po odrzuceniu połączenia zostanie wykonane polecenie `echo “OK”`. Podobną opcję posiada również konfiguracja `/etc/hosts.allow` jednak opcja ta nie jest powszechnie wykorzystywana. Opcja ta nosi nazwę `spawn`.\n\n**Odpowiedź 1:** \"za wyjątkiem komputera www umożliwia każdemu dostęp do każdej usługi\" jest **niepoprawna**. Reguła nie dotyczy wszystkich usług, tylko usługi FTP oraz nie umożliwia dostępu tylko go blokuje.\n\n**Odpowiedź 2:** \"zabrania dostępu do usługi WWW z komputera ftpd\" jest **niepoprawna**. Reguła nie odnosi się do serwera WWW, tylko do usługi FTP (`ftpd`). Parametr `ftpd:` jasno wskazuje której usługi dotyczy reguła.\n\n**Odpowiedź 3:** \"umożliwia dostęp do usługi FTP z komputera www\" jest **niepoprawna**. Konfiguracja nie przyznaje dostępu do usługi, a wręcz go zabrania.\n\n**Odpowiedź 4:** \"zabrania dostępu do usługi FTP z komputera www\" jest **poprawna**. Reguła `ftpd: ALL EXCEPT www : ALLOW : ALL : twist /bin/echo “OK”` w pliku `/etc/hosts.deny` blokuje dostęp do usługi FTP (`ftpd`) dla wszystkich hostów z wyjątkiem hosta `www`.  W przypadku próby połączenia z hosta `www` z usługą `ftpd` zostanie zastosowana inna reguła, która może (lub nie) zezwalać na dostęp. Z punktu widzenia reguły w `/etc/hosts.deny` host `www` nie jest blokowany.\n\n**Przykład:**\n\nZałóżmy, że mamy dwa serwery: `www.example.com` (adres IP 192.168.1.10) oraz `ftp.example.com` (adres IP 192.168.1.20) z uruchomioną usługą FTP.\n- Jeśli klient o adresie 192.168.1.5 połączy się z serwerem FTP (192.168.1.20), to konfiguracja TCP Wrappera w postaci `ftpd: ALL EXCEPT www : ALLOW : ALL : twist /bin/echo “OK”` spowoduje, że pakiet zostanie odrzucony, ponieważ ten adres nie jest adresem `www.example.com`. Dodatkowo zostanie wykonane polecenie `echo \"OK\"` , które ma charakter diagnostyczny i nie ma większego znaczenia w kwestii kontroli dostępu.\n- Jeśli serwer `www.example.com` (192.168.1.10) połączy się z serwerem FTP (192.168.1.20), to ta reguła nie ma zastosowania, a o przyznaniu/odmowie dostępu będzie decydować następna reguła w pliku `/etc/hosts.deny` lub inne reguły zawarte w pliku `/etc/hosts.allow` .\n\nTo ćwiczenie pokazuje, że `EXCEPT` jest kluczową częścią konfiguracji, która odwraca znaczenie domyślnej reguły `ALL`, tworząc wyjątek, na podstawie którego dostęp może być przyznany przez kolejną regułę w pliku `/etc/hosts.allow` lub po przejściu przez cały plik `/etc/hosts.deny` w której nie ma reguły blokującej ten dostęp."
    },
    {
        "questionId": 413,
        "title": "Pliki zwirtualizowane mechanizmem UAC przechowywane są w systemie Windows w: ",
        "answers": [
            {
                "text": "katalogu \"%WINDIR%\\User Access Container\\Sandbox\"",
                "isCorrect": false
            },
            {
                "text": "katalogu \"%SYSTEMDRIVE%\\VirtualStore\"",
                "isCorrect": false
            },
            {
                "text": "katalogu \"VirtualStore\" lokalnym dla każdego użytkownika",
                "isCorrect": true
            },
            {
                "text": "alternatywnych strumieniach danych (ADS) systemu NTFS",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm User Account Control (UAC) w systemach Windows, w celu zwiększenia bezpieczeństwa, wprowadza wirtualizację dostępu do systemu plików. Wirtualizacja ta polega na tym, że gdy aplikacja działająca z ograniczonymi uprawnieniami próbuje zapisać dane w chronionym katalogu systemu operacyjnego (np. w  `C:\\Program Files`), system Windows w rzeczywistości zapisuje te dane w wirtualnym katalogu, który jest unikalny dla każdego użytkownika.  Ten mechanizm ma na celu zapobieganie nieautoryzowanym modyfikacjom plików systemowych.\n\n**katalogu \"%WINDIR%\\User Access Container\\Sandbox\"** - Ta odpowiedź jest **niepoprawna**. Chociaż nazwa katalogu sugeruje związek z UAC i piaskownicą (ang. *sandbox*), taka lokalizacja nie istnieje w systemie Windows.  UAC nie tworzy katalogu o takiej nazwie.\n\n**katalogu \"%SYSTEMDRIVE%\\VirtualStore\"** - Ta odpowiedź jest **niepoprawna**. `%SYSTEMDRIVE%` reprezentuje literę dysku na którym jest zainstalowany system, na przykład `C:\\`. Natomiast  `VirtualStore` jest katalogiem używanym do przechowywania plików objętych wirtualizacją, ale nie jest to jego główna lokalizacja. `VirtualStore` jest zbiorem wirtualizowanych katalogów ale nie jest to główna lokalizacja dla wszystkich zwirtualizowanych plików.\n\n**katalogu \"VirtualStore\" lokalnym dla każdego użytkownika** - Ta odpowiedź jest **poprawna**. UAC, w ramach wirtualizacji, przekierowuje próby zapisu w chronionych lokalizacjach do katalogu o nazwie  `VirtualStore`, który to znajduje się w profilu każdego użytkownika, na przykład `C:\\Users\\nazwa_użytkownika\\AppData\\Local\\VirtualStore`. Każdy użytkownik posiada swój własny folder VirtualStore, gdzie przechowywane są zmiany wprowadzone przez nieuprzywilejowane aplikacje. Przykładowo, gdy aplikacja próbuje zapisać plik w `C:\\Program Files\\aplikacja\\config.ini`, UAC przekieruje zapis do `C:\\Users\\nazwa_użytkownika\\AppData\\Local\\VirtualStore\\Program Files\\aplikacja\\config.ini`. Mechanizm ten chroni pliki systemowe przed niezamierzonymi zmianami przez aplikacje działające z obniżonym poziomem uprawnień. Jest to mechanizm wirtualizacji.\n\n**alternatywnych strumieniach danych (ADS) systemu NTFS** - Ta odpowiedź jest **niepoprawna**. Alternatywne strumienie danych (ADS) to mechanizm systemu plików NTFS, który pozwala na powiązanie z plikiem dodatkowych strumieni danych. Chociaż złośliwe oprogramowanie może wykorzystywać ADS do ukrywania swojego kodu, wirtualizowane pliki UAC nie są przechowywane w ADS, a w opisanych powyżej folderach. ADS są ukryte i nie są wyświetlane w standardowym widoku systemu plików. Wykorzystanie ADS jest problemem z punktu widzenia bezpieczeństwa, gdyż oprogramowanie antywirusowe może nie wykryć malware umieszczonego w strumieniu ADS."
    },
    {
        "questionId": 414,
        "title": "Czego nie można ograniczyć za pomocą komendy ulimit (mechanizmu limitów zasobowych)?: ",
        "answers": [
            {
                "text": "wielkości pliku zrzutu pamięci",
                "isCorrect": false
            },
            {
                "text": "ilości otwartych deskryptorów",
                "isCorrect": false
            },
            {
                "text": "ilości tworzonych procesów",
                "isCorrect": false
            },
            {
                "text": "sumy zajmowanej przestrzeni dyskowej przez pliki",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Mechanizm limitów zasobowych, często konfigurowany za pomocą polecenia `ulimit` w systemach Linux/Unix, służy do ograniczania zasobów, które mogą być wykorzystywane przez procesy uruchamiane przez danego użytkownika.  `ulimit` operuje na poziomie procesu, a nie na poziomie systemu plików, i nie jest przeznaczony do zarządzania przestrzenią dyskową.\n\n*   **wielkości pliku zrzutu pamięci**: Zrzut pamięci (core dump) jest plikiem zawierającym obraz pamięci procesu w momencie awarii. Wielkość tego pliku jest ogranicza przez `ulimit` przy pomocy przełącznika `-c`. Przykładowo, polecenie `ulimit -c 1024` ograniczy wielkość pliku zrzutu pamięci do 1024 bloków (zwykle 512 bajtowych). Przekroczenie tego limitu spowoduje obcięcie pliku. Jest to przykład na ograniczenie związane z procesem, a nie z systemem plików.\n*   **ilości otwartych deskryptorów**: Deskryptory plików są używane przez procesy do obsługi otwartych plików. `ulimit` za pomocą przełącznika `-n` pozwala ograniczyć liczbę jednoczenie otwartych deskryptorów. Przykładowo, polecenie `ulimit -n 100` ogranicza procesy do jednoczesnego otwarcia 100 plików. Jest to ograniczenie specyficzne dla procesu.\n*   **ilości tworzonych procesów**: `ulimit` pozwala ograniczyć maksymalną liczbę procesów jakie może uruchomić dany użytkownik. Przykładowo, `ulimit -u 100` ogranicza liczbę procesów do 100. Ograniczenie dotyczy konkretnego użytkownika i procesów przez niego utworzonych, nie dotyczy to systemu plików.\n*   **sumy zajmowanej przestrzeni dyskowej przez pliki**: `ulimit` *nie* pozwala na ograniczenie sumy przestrzeni dyskowej, którą mogą zająć pliki użytkownika. Limit ten jest zarządzany przez system plików (np. za pomocą mechanizmu quota). `ulimit` nie ma uprawnień do zmiany ilości dostępnego miejsca na dysku, ponieważ operuje na poziomie procesu. Kontrola nad przestrzenią dyskową odbywa się na poziomie systemu plików (np. za pomocą mechanizmu quota) i są to oddzielne mechanizmy od limitów procesowych.\n\nPodsumowując, `ulimit` służy do zarządzania zasobami wykorzystywanymi przez procesy, a nie zarządzaniem przestrzenią dyskową. Wykorzystanie mechanizmów quote wymaga zaimplementowania ich na poziomie systemu plików. Mechanizmy quote w systemie Linux mogą ograniczać całkowitą wielkość używanej przestrzeni dyskowej oraz wielkość plików."
    },
    {
        "questionId": 415,
        "title": "Polecenie netsh advfirewall firewall add rule name=”private” protocol=icmpv4 action=block dir =out remoteip=10.10.0.2: ",
        "answers": [
            {
                "text": "pingowania adresu 10.10.0.2 niezależnie od użycia IPv4 czy IPv6",
                "isCorrect": false
            },
            {
                "text": "pingowania adresu 10.10.0.2 tylko w sieci o profilu prywatnym",
                "isCorrect": false
            },
            {
                "text": "pingowania tylko po IPv4 bieżącego systemu z adresu 10.10.0.2",
                "isCorrect": false
            },
            {
                "text": "pingowania tylko po IPv4 adresu z bieżącego systemu 10.10.0.2",
                "isCorrect": true
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Polecenie `netsh advfirewall firewall add rule` służy do dodawania nowych reguł do zapory sieciowej Windows, która umożliwia sterowanie ruchem sieciowym. Parametr `name=”private”` nadaje unikalną nazwę regule, w tym przypadku \"private\". Parametr `protocol=icmpv4` zawęża działanie reguły tylko do pakietów protokołu ICMP w wersji 4, który jest protokołem używanym m.in przez narzędzie `ping`. Opcja `action=block` określa, że pakiety spełniające kryteria wzorca reguły mają zostać zablokowane, czyli pakiety te nie zostaną przepuszczone przez zaporę ogniową. Opcja `dir=out` określa kierunek ruchu pakietu jaki ma być poddany działaniu reguły, w tym przypadku tylko ruch wychodzący z danego komputera. Parametr `remoteip=10.10.0.2` określa adres docelowy IPv4 dla reguły, w tym przypadku adres IP to 10.10.0.2.\n\n**Odpowiedź 1: \"pingowania adresu 10.10.0.2 niezależnie od użycia IPv4 czy IPv6\" jest niepoprawna.**\nReguła w poleceniu `protocol=icmpv4` określa protokół używany do komunikacji a konkretniej protokół ICMP w wersji 4, więc reguła nie dotyczy ruchu ICMP w wersji 6(ICMPv6). Polecenie to zablokuje pingowanie adresu 10.10.0.2 z komputera, na którym uruchomiono polecenie, jedynie w przypadku pakietów ICMP w wersji 4. Ruch ICMP w wersji 6 będzie przepuszczony przez zaporę.\n\n**Odpowiedź 2: \"pingowania adresu 10.10.0.2 tylko w sieci o profilu prywatnym\" jest niepoprawna.**\nPolecenie nie zawiera żadnych opcji odnoszących się do profili sieciowych (prywatny, publiczny, domena). Reguła ta będzie aktywna niezależnie od wybranego profilu sieciowego. \n\n**Odpowiedź 3: \"pingowania tylko po IPv4 bieżącego systemu z adresu 10.10.0.2\" jest niepoprawna.**\nOpcja `dir=out` wskazuje na ruch wychodzący z danego komputera, czyli ruch pakietów które mają za adres źródłowy adres bieżącego komputera. Adres 10.10.0.2 jest adresem docelowym pakietów, a nie adresem źródłowym. Zatem reguła ta nie zablokuje przychodzącego ruchu od adresu 10.10.0.2, tylko zablokuje ruch do tego adresu. \n\n**Odpowiedź 4: \"pingowania tylko po IPv4 adresu z bieżącego systemu 10.10.0.2\" jest poprawna.**\nReguła blokuje pakiety ICMP w wersji 4, które są wysyłane z bieżącego komputera do zdalnego adresu 10.10.0.2. Zastosowana opcja `dir=out` określa kierunek pakietu na wychodzący z danego komputera, a opcja `action=block` sprawia, że taki pakiet jest blokowany przez zaporę ogniową systemu. Zatem program ping uruchomiony z danej stacji nie będzie generował odpowiedzi od adresu 10.10.0.2, a w szczególności nie będzie możliwości \"pingowania\" tego adresu z poziomu danego komputera.\n\n**Przykład:** Administrator systemu sieciowego, używając komendy `netsh advfirewall`, może tworzyć specyficzne reguły. Jeśli istnieje podejrzenie, że system o adresie IP 10.10.0.2 generuje podejrzany ruch, administrator może zablokować możliwość wysyłania przez jego stację zapytań ping do 10.10.0.2, korzystając z polecenia zawartego w pytaniu. Takie działanie może być częścią procesu ustalania pochodzenia i przyczyn podejrzanego zachowania systemu."
    },
    {
        "questionId": 416,
        "title": "W jak można udostępnić swój klucz publiczny PGP innemu użytkownikowi: ",
        "answers": [
            {
                "text": "przekazać osobiście na nośniku wymiennym",
                "isCorrect": true
            },
            {
                "text": "umieścić na swojej stronie www",
                "isCorrect": true
            },
            {
                "text": "wysłać pocztą elektroniczną",
                "isCorrect": true
            },
            {
                "text": "umieścić w sieciowym repozytorium kluczy",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Klucz publiczny PGP jest elementem kryptografii asymetrycznej, przeznaczonym do swobodnego udostępniania innym użytkownikom. Używa się go do szyfrowania wiadomości wysyłanych do właściciela klucza lub do weryfikacji podpisów elektronicznych składanych przez właściciela klucza. Metoda udostępniania klucza publicznego nie ma wpływu na jego bezpieczeństwo, ponieważ klucz prywatny pozostaje tajny.\n\n*   **przekazać osobiście na nośniku wymiennym**: Jest to poprawna metoda. Klucz publiczny może być przekazany w postaci pliku poprzez nośnik wymienny, taki jak pendrive, dysk CD, itp. Przykładem może być wymiana klucza na spotkaniu z drugą osobą, co pozwala osobie na bezpieczne i bezproblemowe szyfrowanie komunikacji. Takie przekazanie klucza nie stanowi żadnego zagrożenia bezpieczeństwa, ponieważ przekazywany jest tylko klucz publiczny.\n*   **umieścić na swojej stronie www**: Jest to poprawna metoda. Klucz publiczny może być umieszczony na osobistej stronie internetowej, gdzie może zostać pobrany przez każdego zainteresowanego. Przykładem jest umieszczenie klucza w stopce wiadomości email, na stronie kontaktu. Takie udostępnienie klucza jest powszechne i ułatwia innym osobom szyfrowanie do nas wiadomości. Udostępnianie klucza w ten sposób jest bezpieczne.\n*   **wysłać pocztą elektroniczną**: Jest to poprawna metoda. Klucz publiczny można załączyć do wiadomości e-mail. Chociaż sam e-mail może być niezaszyfrowany podczas przesyłania, to bezpieczeństwo klucza nie jest zagrożone. Jest to bardzo popularna forma wymiany kluczy. Po otrzymaniu klucza można od razu rozpocząć szyfrowanie korespondencji z właścicielem klucza.\n*   **umieścić w sieciowym repozytorium kluczy**: Jest to poprawna metoda. W sieci istnieją serwery kluczy publicznych, gdzie użytkownicy mogą przechowywać swoje klucze i udostępniać je innym. Przykładowo serwis `keyserver.pgp.com` jest takim serwerem, z którego można pobrać klucze. To popularna i wygodna metoda publikacji klucza. Jest bardzo powszechna w środowisku systemów wykorzystujących kryptografie. Jest to również bezpieczne i nie stanowi żadnego zagrożenia dla klucza prywatnego.\n\nW każdym z tych przypadków klucz publiczny jest rozpowszechniany w sposób niezabezpieczony, nie stanowi to jednak zagrożenia, gdyż ważna jest ochrona klucza prywatnego, za którego pomocą odszyfrowywana jest wiadomość zaszyfrowana za pomocą klucza publicznego."
    },
    {
        "questionId": 417,
        "title": "Ataki phishing: ",
        "answers": [
            {
                "text": "dotyczą wykradzenia zaufanych certyfikatów CA",
                "isCorrect": false
            },
            {
                "text": "realizowane są za pośrednictwem poczty",
                "isCorrect": true
            },
            {
                "text": "polegają na zatruwania cache przeglądarki www",
                "isCorrect": false
            },
            {
                "text": "realizowane są za pośrednictwem www",
                "isCorrect": true
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Atak phishing to technika socjotechniczna, która polega na oszukiwaniu użytkowników, aby wyłudzić od nich poufne informacje, takie jak hasła, numery kart kredytowych lub dane osobowe. Ataki te najczęściej wykorzystują fałszywe wiadomości e-mail lub spreparowane strony internetowe, które udają zaufane organizacje. Celem jest nakłonienie ofiary do dobrowolnego podania swoich danych.\n\n**Odpowiedź \"dotyczą wykradzenia zaufanych certyfikatów CA\" jest niepoprawna.** Certyfikaty CA (Certification Authority) to certyfikaty urzędów certyfikacji, które są używane do weryfikowania tożsamości stron internetowych. Ataki phishing nie mają na celu wykradania tych certyfikatów. Phishing ma na celu oszukanie użytkownika aby nieświadomie podał dane. Wykradanie certyfikatów CA jest związane z atakami na infrastrukturę PKI i jest to bardziej zaawansowane działanie niż ataki phishing.\n\n**Odpowiedź \"realizowane są za pośrednictwem poczty\" jest poprawna.** Wiadomości phishingowe najczęściej przesyłane są za pomocą poczty elektronicznej. Ofiara otrzymuje wiadomość e-mail, która wygląda jak oficjalna komunikacja od zaufanej organizacji (np. banku, firmy kurierskiej czy serwisu społecznościowego). Treść maila zawiera zazwyczaj pilne wezwanie do działania (np. weryfikacji hasła, aktualizacji danych), a w nim jest link do fałszywej strony internetowej. Przykładowo, użytkownik otrzymuje maila z logo swojego banku informującego o podejrzanej transakcji na koncie. Dołączony jest link do formularza weryfikacyjnego - niestety jest to link do strony w pełni kontrolowanej przez atakującego.\n\n**Odpowiedź \"polegają na zatruwania cache przeglądarki www\" jest niepoprawna.** Zatruwanie pamięci podręcznej przeglądarki (ang. _browser cache poisoning_) to technika, w której atakujący manipuluje cache przeglądarki użytkownika, aby wyświetlać niepoprawne lub fałszywe treści. Atak ten ma na celu uszkodzenie wyświetlanych treści na zaufanej stronie. Phishing z kolei ma na celu nakłonić użytkownika do podania poufnych danych w oparciu o fałszywą stronę www.\n\n**Odpowiedź \"realizowane są za pośrednictwem www\" jest poprawna.** Ataki phishingowe mogą być również przeprowadzane za pomocą fałszywych stron internetowych. Atakujący tworzy witrynę, która łudząco przypomina stronę zaufanej organizacji i umieszcza ją w sieci Internet. Następnie używa różnych metod(np. wysyłania maili) aby nakłonić ofiarę do odwiedzenia tej strony. Przykładowo użytkownik otrzymuje reklamę wyświetlaną w wyszukiwarce(np. Google, Bing, Yahoo), zachęcającą do zakupu produktów z wyprzedaży. Link w reklamie prowadzi na stronę przypominającą autentyczny sklep. Po podaniu danych do płatności transakcja może być nieskuteczna, a dane kart kredytowych mogą trafić do atakującego.\n\nPodsumowując, phishing jest techniką socjotechniczną, która wykorzystuje fałszywe wiadomości lub strony internetowe do wyłudzania danych od użytkowników. Ataki te mogą być przeprowadzane za pomocą poczty elektronicznej lub stron internetowych. Kluczowe jest zachowanie ostrożności i weryfikowanie tożsamości stron, które wymagają podania wrażliwych danych."
    },
    {
        "questionId": 418,
        "title": "Które z wymienionych poniżej mechanizmów wspomagają wykrywanie podsłuchu w sieci: ",
        "answers": [
            {
                "text": "802.1X",
                "isCorrect": false
            },
            {
                "text": "ARP",
                "isCorrect": true
            },
            {
                "text": "802.11X",
                "isCorrect": false
            },
            {
                "text": "ICMP echo",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Protokół ARP (Address Resolution Protocol) jest protokołem warstwy drugiej modelu OSI, używanym do odnajdywania adresów sprzętowych (MAC) na podstawie adresów logicznych (IP). W standardowej sieci Ethernet, kiedy host A chce wysłać pakiet do hosta B, a zna tylko jego adres IP, musi najpierw odnaleźć jego adres MAC. Host A wysyła zatem pakiet rozgłoszeniowy ARP, który jest odbierany przez wszystkie urządzenia w danej sieci lokalnej, zapytując \"Kto ma adres IP 'adres_IP_hosta_B', proszę odpowiedz swoim adresem MAC.\" Host B, widząc swoje IP w zapytaniu odpowiada bezpośrednio do A wysyłając pakiet zawierający swoje IP oraz adres MAC. W tym procesie występuje kilka zagrożeń, które mogą zostać wykorzystane przez atakującego. Protokół ARP nie posiada mechanizmów uwierzytelniania, co umożliwia podsłuchiwanie wymiany ARP, oraz podszywanie się pod inne urządzenia poprzez rozsyłanie fałszywych odpowiedzi ARP. Fałszywe odpowiedzi ARP mogą spowodować, że pakiety przeznaczone do hosta B trafią do fałszywego hosta E, przez co intruz E ma możliwość podsłuchiwania ruchu sieciowego (podszywając się pod hosta B, E wykonuje tzw. atak _man-in-the-middle_), ale i modyfikacji danych. To wszystko czyni ARP protokołem pomocnym podczas podsłuchiwania w sieci komputerowej.\n\n* **802.1X:** Protokół 802.1X jest standardem uwierzytelniania sieciowego na poziomie warstwy łącza danych, często stosowanym w sieciach LAN, zarówno przewodowych jak i bezprzewodowych. Protokół ten ma na celu zabezpieczenie dostępu do sieci poprzez wymuszanie uwierzytelniania użytkowników lub urządzeń przed uzyskaniem dostępu do zasobów sieci. Jego zadaniem jest ochrona przed nieautoryzowanym dostępem do sieci poprzez weryfikację tożsamości użytkownika, a nie wykrywanie podsłuchu. Sam protokół 802.1X nie zapobiega podsłuchowi, a jedynie stara się kontrolować, które urządzenia mogą w ogóle wysyłać i odbierać pakiety. Atakujący może być w stanie podsłuchiwać ruch sieciowy na warstwie fizycznej, niezależnie od tego czy stosowany jest protokół 802.1X.\n\n* **802.11x (a właściwie 802.11):**  Standardy z rodziny 802.11 (np. 802.11a, 802.11b, 802.11g, 802.11n, 802.11ac, 802.11ax) opisują mechanizmy funkcjonowania sieci bezprzewodowych WLAN. Same w sobie protokoły te nie zapobiegają podsłuchiwaniu. Należy mieć na uwadze, że komunikacja radiowa rozsyłana jest eterem, a więc teoretycznie każdy, kto dysponuje odpowiednim odbiornikiem i oprogramowaniem może podsłuchiwać tą komunikację. Same protokoły rodziny 802.11 starają się zapewnić poufność poprzez szyfrowanie, aczkolwiek nie chronią one przed podsłuchiwaniem komunikacji w sieci bezprzewodowej wprost, mimo że same implementacje tych protokołów mogą być podatne na ataki. Dodatkowo wykorzystanie niezabezpieczonych sieci WiFi udostępnia wszystkie informacje, które mogą być przechwycone (w tym hasła). W związku z tym standardy 802.11 koncentrują się na bezpieczeństwie transmisji bezprzewodowej a nie na wykrywaniu podsłuchu.\n\n* **ICMP echo:** Komunikat ICMP echo (wykorzystywany w poleceniu ping) to komunikat o bardzo prostej budowie służący do weryfikacji osiągalności wybranego adresu IP w sieci komputerowej. Komunikat ten nie zawiera żadnych informacji o tożsamości użytkownika, sesji, przesyłanych danych czy innych informacji pozwalających jednoznacznie określić, jakie połączenie jest realizowane w sieci. Zatem z racji jego prostoty nie nadaje się do wykorzystania do przechwycenia i podsłuchiwania danych z sieci, ani nie umożliwia wykrycia takich prób. Co więcej komunikaty ICMP echo są wykorzystywane przez wiele narzędzi diagnostycznych sieci komputerowych, i nawet celowe podsłuchiwanie takiego ruchu nie da w sumie żadnych wartościowych informacji oprócz potwierdzenia faktu, że dany adres IP jest osiągalny w danej sieci. Sam komunikat nie ułatwia w żaden sposób ataku."
    },
    {
        "questionId": 419,
        "title": "Metoda Diffiego-Hellmana: ",
        "answers": [
            {
                "text": "pozwala stronom komunikacji bezpiecznie ustalić wspólne klucze asymetryczne",
                "isCorrect": false
            },
            {
                "text": "wymaga szyfrowania negocjacji w celu ochrony przed atakami pasywnymi",
                "isCorrect": false
            },
            {
                "text": "pozwala stronom komunikacji bezpiecznie ustalić wspólny klucz symetryczny",
                "isCorrect": true
            },
            {
                "text": "wymaga uwierzytelniania negocjacji w celu ochrony przed atakami aktywnymi",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Metoda Diffiego-Hellmana (DH) to algorytm wymiany kluczy, który umożliwia dwóm stronom bezpieczne uzgodnienie wspólnego tajnego klucza symetrycznego przez niezabezpieczony kanał komunikacyjny. W tym procesie strony nie przesyłają sobie samego klucza, ale informacje pozwalające im na niezależne obliczenie tego samego klucza symetrycznego.\n\nPierwsza odpowiedź jest **niepoprawna** gdyż metoda Diffiego-Hellmana służy do ustalenia *wspólnego klucza symetrycznego*, a nie asymetrycznego. Klucze asymetryczne to pary kluczy (publiczny i prywatny), które są wykorzystywane w algorytmach takich jak RSA, podczas gdy Diffie-Hellman skupia się na ustaleniu pojedynczego, symetrycznego klucza, którego obie strony będą używać do szyfrowania symetrycznego (np. za pomocą algorytmu AES).\n\nDruga odpowiedź jest **niepoprawna**. Metoda Diffiego-Hellmana *nie wymaga szyfrowania negocjacji* do ochrony przed atakami pasywnymi (podsłuchiwaniem). Siła tego algorytmu polega na tym, że wymiana informacji jest tak skonstruowana, aby nawet podsłuchujący nie mógł na jej podstawie odtworzyć wygenerowanego klucza symetrycznego. Elementy przesyłane w trakcie wymiany są jawne. Natomiast klucz symetryczny jest bezpieczny w komunikacji, dlatego że do jego wygenerowania wykorzystuje się matematycznie bardzo trudne działania. Podsłuchującemu nie wystarczą przechwycone dane, żeby uzyskać ten sam klucz.\n\nTrzecia odpowiedź jest **poprawna**. Jak wcześniej wyjaśniono, Diffie-Hellman jest właśnie algorytmem, który umożliwia dwóm stronom *ustalenie wspólnego klucza symetrycznego*. Ten klucz, znany tylko tym dwóm stronom, może być następnie wykorzystany do szyfrowania symetrycznego dalszej komunikacji, którą chcemy zabezpieczyć. Ustalenie tego klucza następuje bez konieczności przesyłania go w sposób jawny.\n\nCzwarta odpowiedź jest **niepoprawna**. Metoda Diffiego-Hellmana *sama w sobie nie chroni przed atakami aktywnymi*. Ataki aktywne to np. ataki typu man-in-the-middle, gdzie napastnik wchodzi w interakcję komunikującymi się stronami. Uwierzytelnianie stron nie jest częścią metody Diffiego-Hellmana. Metoda ta jedynie służy do bezpiecznej wymiany kluczy i nie jest powiązana z weryfikacją tożsamości stron. Inne mechanizmy kryptograficzne i protokoły, takie jak certyfikaty cyfrowe, są niezbędne do ochrony przed atakami aktywnymi.\n\n**Przykład praktyczny:** Wyobraźmy sobie proces nawiązywania bezpiecznego połączenia SSH. Po zainicjowaniu połączenia, serwer i klient wykorzystują algorytm Diffiego-Hellmana aby uzgodnić wspólny tajny klucz symetryczny. W tym kroku, strony komunikujące się jawnie przesyłają elementy służące do obliczenia klucza, ale samo obliczenie klucza jest bezpieczne. Po ustaleniu klucza, obie strony używają go do szyfrowania i deszyfrowania komunikacji."
    },
    {
        "questionId": 420,
        "title": "Które z poniższych protokołów służą do realizacji kryptograficznych tuneli wirtualnych: ",
        "answers": [
            {
                "text": "TLS",
                "isCorrect": true
            },
            {
                "text": "SSO",
                "isCorrect": false
            },
            {
                "text": "IKE",
                "isCorrect": true
            },
            {
                "text": "ESP",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Protokół TLS (Transport Layer Security), następca protokołu SSL (Secure Sockets Layer), służy do tworzenia bezpiecznych tuneli komunikacyjnych. Działa na warstwie transportowej modelu OSI i zapewnia poufność oraz integralność danych przesyłanych między klientem a serwerem. Protokół TLS jest często wykorzystywany w przeglądarkach internetowych, gdzie tworzy bezpieczne połączenie HTTPS. Jednak jego zastosowanie nie ogranicza się tylko do www, może być również używany do budowania bezpiecznych tuneli VPN na poziomie warstwy transportowej, na przykład przez aplikację OpenVPN. Protokół TLS wykorzystuje kryptografię symetryczną do szyfrowania danych oraz kryptografię asymetryczną do ustalenia tajnego klucza symetrycznego i uwierzytelnienia drugiej strony. W praktyce TLS tworzy bezpieczny kanał, tunel, przez który przesyłane są dane, chroniąc je przed podsłuchaniem czy modyfikacją.\n\nProtokół SSO (Single Sign-On) to mechanizm umożliwiający użytkownikowi logowanie się tylko raz, aby uzyskać dostęp do wielu różnych aplikacji czy usług. Nie tworzy on żadnego tunelu komunikacyjnego. SSO ma na celu ułatwienie użytkownikom pracy, eliminując konieczność wielokrotnego wpisywania tych samych danych uwierzytelniających. Mechanizm ten dotyczy warstwy aplikacji, a nie warstwy sieciowej, a wiec nie zajmuje się tworzeniem tuneli. Przykładem zastosowania SSO jest logowanie do konta google, po czym logując się do serwisu YouTube nie ma już potrzeby powtórnego wpisywania danych uwierzytelniających.\n\nProtokół IKE (Internet Key Exchange) jest częścią protokołu IPsec i służy do automatycznej negocjacji parametrów połączenia VPN. Obejmuje on dwie fazy negocjacji. W fazie pierwszej strony wymieniają się informacjami pozwalającymi utworzyć tunel do ochrony negocjacji parametrów połączenia. W fazie drugiej używając utworzonego tunelu strony negocjują parametry bezpieczeństwa dla połączenia docelowego. Mechanizm IKE wykorzystuje kryptografię klucza publicznego do uwierzytelnienia się stron oraz do ustalenia klucza sesyjnego wykorzystywanego przez protokół ESP. Zatem, IKE jest protokołem, który umożliwia konfigurację tunelu IPsec. IKE sam w sobie nie tworzy szyfrowanego tunelu, ale jest niezbędny do jego konfiguracji w protokole IPsec.\n\nProtokół ESP (Encapsulating Security Payload) jest protokołem wykorzystywanym w ramach IPsec. Służy do szyfrowania i uwierzytelniania przesyłanych danych w tunelu IPsec. Protokół ESP wykorzystuje algorytmy symetryczne do ochrony poufności oraz skróty kryptograficzne do zapewnienia integralności danych. ESP nie tworzy tunelu, jest on jedynie protokołem służącym do ochrony danych wewnątrz już istniejącego tunelu IPsec."
    },
    {
        "questionId": 421,
        "title": "Wskaż cechy charakteryzujące kontrole dostępu MAC: ",
        "answers": [
            {
                "text": "właściciel zasobu może dysponować prawami dostępu do tego zasobu",
                "isCorrect": false
            },
            {
                "text": "etykiety ochrony danych przypisane do zasobów automatycznie wymuszają uprawnienia",
                "isCorrect": true
            },
            {
                "text": "właściciel zasobu nie może dysponować prawami dostępu do tego zasobu",
                "isCorrect": true
            },
            {
                "text": "tylko wyróżniony oficer bezpieczeństwa może dysponować prawami dostępu do zasobów",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to model kontroli dostępu, w którym system operacyjny, a nie użytkownik, decyduje o prawach dostępu do zasobów. MAC różni się od Discretionary Access Control (DAC) tym, że uprawnienia do zasobów nie są zależne od woli właściciela zasobu, ale są narzucane przez system zgodnie z z góry określoną polityką bezpieczeństwa. W systemach MAC, każdemu zasobowi i podmiotowi (np. użytkownikowi, procesowi) przypisane są etykiety bezpieczeństwa (_sensitivity labels_), które są podstawą do podejmowania decyzji o dostępie.\n\n*   **\"właściciel zasobu może dysponować prawami dostępu do tego zasobu\"** - Jest to **niepoprawna** odpowiedź, ponieważ opisuje mechanizm Discretionary Access Control (DAC). W systemach DAC właściciel zasobu ma prawo decydować o tym, kto i w jakim zakresie może ten zasób wykorzystywać (np. plik, katalog). Typowym przykładem jest system uprawnień w systemach z rodziny Linux gdzie właściciel pliku może ustawić uprawnienia do odczytu, zapisu oraz wykonywania pliku. \n   W systemach MAC właściciel zasobu **nie** ma pełnej swobody do decydowania o uprawnieniach. To system operacyjny, na podstawie wbudowanej polityki bezpieczeństwa, decyduje kto i w jaki sposób ma prawo dostępować do zasobu.\n\n*   **\"etykiety ochrony danych przypisane do zasobów automatycznie wymuszają uprawnienia\"** - Jest to **poprawna** odpowiedź. W MAC etykiety bezpieczeństwa, nazywane również etykietami poufności, są przypisane do zasobów i podmiotów i to na ich podstawie automatycznie system podejmuje decyzje o prawach dostępu. Przykładowo, jeśli zasób (dokument) ma etykietę \"tajne\", a użytkownik posiada etykietę \"poufne\", system automatycznie uniemożliwi mu odczytanie dokumentu, nawet jeśli on sam jest jego formalnym właścicielem w sensie DAC. System automatycznie narzuca politykę bezpieczeństwa.\n\n*   **\"właściciel zasobu nie może dysponować prawami dostępu do tego zasobu\"** - Jest to **poprawna** odpowiedź i jest to fundamentalna różnica między MAC i DAC. W systemach MAC nawet właściciel zasobu nie może dowolnie nadawać uprawnień do tego zasobu. Decyzje o dostępności zasobu są podyktowane polityką bezpieczeństwa, a nie widzimisię właściciela. \n    Przykładowo, w systemie militarnym, żołnierz nawet jeśli stworzył dokument z danymi strategicznymi, to nie może przekazać go dowolnej osobie, gdyż system automatycznie może uniemożliwić mu odczytanie takich informacji osobie o niższym uprawnieniu do takich informacji.\n\n*   **\"tylko wyróżniony oficer bezpieczeństwa może dysponować prawami dostępu do zasobów\"** - Jest to **niepoprawna** odpowiedź, gdyż w systemach MAC polityka bezpieczeństwa jest implementowana przez system operacyjny i mechanizmy kontroli dostępu, a nie przez pojedynczego administratora/oficera bezpieczeństwa. Oczywiście oficer bezpieczeństwa może ustalać politykę bezpieczeństwa, ale samo egzekwowanie polityki następuje na poziomie systemu operacyjnego. \n     W systemach opartych o MAC, kontrola dostępu jest zautomatyzowana na podstawie etykiet i polityki bezpieczeństwa. Nie ma pojedynczego oficera bezpieczeństwa, który nadaje lub odbiera dostęp do danych - działa tu system, w przeciwieństwie do DAC gdzie administrator może mieć całkowitą swobodę nad przydzielanymi uprawnieniami."
    },
    {
        "questionId": 422,
        "title": "Wskaż możliwe sposoby ochrony przed atakami na protokół DHCP (takimi jak np. DHCP redirection, lease starvation): ",
        "answers": [
            {
                "text": "DHCP Snooping - przełącznik przepuszcza odpowiedzi DHCP tylko z określonego wcześniej portu",
                "isCorrect": true
            },
            {
                "text": "DHCP Hoping - zapora zamienia numer VLAN w zadaniach DHCP",
                "isCorrect": true
            },
            {
                "text": "ICMP redirection - wykorzystanie ICMP do ponownej zmiany trasy pakietów DHCP",
                "isCorrect": false
            },
            {
                "text": "DHCP session hijacking - przejmowanie połączeń TCP sesji DHCP przez proxy",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "DHCP (Dynamic Host Configuration Protocol) to protokół warstwy aplikacyjnej, który automatycznie przypisuje adresy IP, maski podsieci, adresy bramy domyślnej i inne informacje konfiguracyjne hostom w sieci. Ataki na DHCP, takie jak DHCP redirection, polegają na podawaniu fałszywych konfiguracji hostom, przez co ruch sieciowy kierowany jest przez atakującego, lub _lease starvation_ na wysyłaniu wyczerpującej liczby zapytań DHCP by wyczerpać pule adresów dostępnych legalnym klientom. Zabezpieczenia przed takimi atakami polegają na implementacji mechanizmów ochronnych w infrastrukturze sieciowej.\n\n**DHCP Snooping** to funkcja przełączników sieciowych (switchy), która filtruje odpowiedzi DHCP, pozwalając na ich przesyłanie tylko przez zaufane porty (np. porty, do których podłączone są serwery DHCP). Poprawna konfiguracja DHCP snooping sprawia, że nieautoryzowany serwer DHCP nie może przypisać klientom adresów IP, maski podsieci, adresy bramy domyślnej. Przykładowo, w sieci, gdzie port przełącznika podłączony do serwera DHCP jest zaufany, wszystkie odpowiedzi DHCP pochodzące z innych portów są odrzucane. Ten mechanizm skutecznie blokuje _DHCP redirection_ gdzie atakujący próbuje odpowiedzieć na żądanie DHCP, oferując klientowi fałszywą konfigurację sieci. Jest to zatem poprawna odpowiedź.\n\n**DHCP Hoping** nie jest poprawnym określeniem, w praktyce nie występuje takie rozwiązanie w bezpieczeństwie. Poprawne określenie dla zabezpieczania przed pewnym typem ataków sieciowych z zastosowaniem VLAN to _VLAN Tagging_ z użyciem opcji _DHCP Relay_. Ataki w których następuje nieautoryzowane przełączanie hostów do innego VLAN umożliwia wykorzystanie informacji zawartych w protokole DHCP. Przełączniki sieciowe mogą posiadać wsparcie dla protokołu DHCP poprzez pośredniczenie w komunikacji DHCP (tzw. _DHCP Relay agent_). Konfiguracja zaufanego VLANu polega na tym, że odpowiedź z serwera DHCP jest kierowana na odpowiedni port. Wykorzystanie technologii DHCP relay umożliwia zmianę znacznika VLAN w komunikacji DHCP. W ten sposób możemy zmusić użytkowników do komunikacji w dozwolonej podsieci VLAN. Jest to zatem poprawna odpowiedź.\n\n**ICMP redirection** to mechanizm warstwy sieciowej IP, który służy do informowania hostów o lepszej trasie do osiągnięcia danej sieci, jest on jednak nadużywany do ataków typu _man-in-the-middle_. Natomiast ten mechanizm nie jest związany z ochroną protokołu DHCP. Zatem ta odpowiedź jest błędna.\n\n**DHCP session hijacking** nie jest poprawnym określeniem. Sesje DHCP nie są protokołem połączeniowym i nie mają statusu utrzymywania połączenia(sesji). Nie można ich przejąć tak jak połączenia TCP (poprzez _TCP Hijacking_). DHCP działa w oparciu o protokół UDP, który nie posiada stanu, zatem nie można przejąć stanu połączenia protokołu DHCP. Zatem jest to błędna odpowiedź."
    },
    {
        "questionId": 423,
        "title": "W model uwierzytelniania z udziałem zaufanej trzeciej strony, do zadań tej trzeciej strony należy: ",
        "answers": [
            {
                "text": "pobieranie danych uwierzytelniających od strony uwierzytelnionej",
                "isCorrect": true
            },
            {
                "text": "wystawienie poświadczenia uwierzytelnienia stronie uwierzytelnionej",
                "isCorrect": true
            },
            {
                "text": "przekazanie danych uwierzytelniających strony uwierzytelnionej docelowym serwerowi",
                "isCorrect": false
            },
            {
                "text": "przekazanie danych uwierzytelniających stronie uwierzytelnionej",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Uwierzytelnianie z udziałem zaufanej trzeciej strony to model, w którym proces weryfikacji tożsamości użytkownika nie odbywa się bezpośrednio między użytkownikiem a serwerem zasobów, lecz z pośrednictwem zaufanej jednostki. Ta trzecia strona pełni rolę pośrednika, który potwierdza tożsamość użytkownika, a nie przekazuje jego dane uwierzytelniające. Ma to na celu zwiększenie bezpieczeństwa i elastyczności procesu uwierzytelniania.\n\n**Pierwsza odpowiedź: \"pobieranie danych uwierzytelniających od strony uwierzytelnionej\" - jest poprawna.** To jest podstawowa funkcja trzeciej strony. Strona uwierzytelniana (użytkownik) przekazuje dane uwierzytelniające (np. hasło, token, biometrię) do zaufanej trzeciej strony. Ta strona musi pobrać te dane, aby móc zweryfikować tożsamość. Wyobraźmy sobie system, w którym użytkownik loguje się do serwisu Google. Google, jako zaufana trzecia strona, prosi o login i hasło.\n\n**Druga odpowiedź: \"wystawienie poświadczenia uwierzytelnienia stronie uwierzytelnionej\" - jest poprawna.** Po pomyślnej weryfikacji danych uwierzytelniających, zaufana trzecia strona wystawia poświadczenie (token). Jest to dowód, że użytkownik został uwierzytelniony. Poświadczenie to jest przekazywane stronie uwierzytelnianej i pozwala jej uzyskać dostęp do chronionych zasobów bez konieczności bezpośredniego udostępniania danych uwierzytelniających. Po zalogowaniu do Google, Google generuje token, który pozwala korzystać z wielu usług Google bez ponownego logowania.\n\n**Trzecia odpowiedź: \"przekazanie danych uwierzytelniających strony uwierzytelnionej docelowym serwerowi\" - jest niepoprawna.** Zaufana trzecia strona **nie** przekazuje danych uwierzytelniających (hasła, tokeny) bezpośrednio do serwera docelowego. Zamiast tego, przekazuje serwerowi samo poświadczenie uwierzytelnienia (token), które potwierdza tożsamość użytkownika. To istotne, bo dane uwierzytelniające są wrażliwe i nie powinny krążyć po sieci w jawnej postaci. W przykładzie Google, token jest wykorzystywany do uzyskiwania dostępu do serwisu YouTube bez podawania ponownie hasła.\n\n**Czwarta odpowiedź: \"przekazanie danych uwierzytelniających stronie uwierzytelnionej\" - jest niepoprawna.** Zaufana trzecia strona nie przekazuje *danych uwierzytelniających* z powrotem do strony uwierzytelnionej. Strona uwierzytelniona sama posiada te dane.  Przekazuje tylko *poświadczenie* uwierzytelnienia. Google nie zwraca użytkownikowi jego hasła po logowaniu, jedynie generuje token.\n\nZaufana trzecia strona działa jako arbiter bezpieczeństwa. Jej zadaniem jest weryfikacja tożsamości i potwierdzenie tego faktu, a nie bezpośrednie przesyłanie danych uwierzytelniających. Ułatwia to zarządzanie dostępem i podnosi poziom bezpieczeństwa systemu. Systemy uwierzytelniania takie jak Kerberos czy OAuth bazują właśnie na koncepcji zaufanej trzeciej strony."
    },
    {
        "questionId": 424,
        "title": "Wskaż protokoły wymagające zabezpieczenia autentyczności i integralności danych, ale niekoniecznie poufności: ",
        "answers": [
            {
                "text": "DNS (Domain Name Service)",
                "isCorrect": true
            },
            {
                "text": "ARP (Address Resolution Protocol)",
                "isCorrect": false
            },
            {
                "text": "STP (Spanning Tree Protocol)",
                "isCorrect": true
            },
            {
                "text": "rlogin (Remote Login)",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "**Autentyczność** (_ang. authentication_) to weryfikacja tożsamości podmiotu, podczas gdy **integralność** (_ang. integrity_) zapewnia ochronę danych przed nieautoryzowaną modyfikacją. Ochrona **poufności** (_ang. confidentiality_) ma na celu uniemożliwienie dostępu do danych osobom nieuprawnionym. W niektórych protokołach ważniejsza jest autentyczność i integralność danych niż ich poufność.\n\n**DNS (Domain Name Service)** to protokół, który tłumaczy nazwy domen na adresy IP. Zabezpieczenie DNS przed nieautoryzowanymi modyfikacjami jest kluczowe, ponieważ manipulacja tymi rekordami może spowodować przekierowanie użytkowników do fałszywych stron internetowych. Choć treść zapytań DNS nie musi być tajna, to istotna jest autentyczność (czy odpowiedź pochodzi z zaufanego serwera DNS) i integralność danych (czy dane nie zostały zmienione podczas transmisji). Atakujący mógłby podmienić rekordy DNS aby przekierować ruch na złośliwą stronę.\n\n**ARP (Address Resolution Protocol)** to protokół warstwy łącza danych, używany do mapowania adresów IP na adresy MAC w sieci lokalnej. ARP jest podatny na ataki typu ARP spoofing, gdzie atakujący, rozsyłając fałszywe odpowiedzi ARP może podmienić adresy MAC w pamięci lokalnej ofiar. ARP nie przewiduje żadnych mechanizmów autentyczności ani integralności, ponieważ był projektowany jako protokół niskiego poziomu dla prostych, małych sieci lokalnych w których zakłada się istnienie środowiska zaufanego. Ponadto ARP nie szyfruje wymienianych informacji, gdyż w małych sieciach, przesyłanie tych informacji bez szyfrowania jest uzasadnione.\n \n**STP (Spanning Tree Protocol)** to protokół warstwy łącza danych, stosowany w sieciach Ethernet do zapobiegania pętlom w topologii sieci. Utrzymanie integralności informacji STP jest ważne, ponieważ podanie fałszywych informacji (zmodyfikowanie pakietów protokołu) może doprowadzić do poważnych problemów z komunikacją w sieci lokalnej. Pętla w topologii sieci lokalnej spowoduje tzw. burzę rozgłoszeniową (ang. _broadcast storm_). Autentyczność tych pakietów również jest ważna, aby mieć pewność, że nie pochodzą one od nieautoryzowanego źródła.  Poufność nie jest istotna, ponieważ parametry topologii nie zawierają zazwyczaj danych wrażliwych. Atakujący może wykorzystać niedoskonałości STP aby spowodować nieplanowaną zmianę topologii lub nawet doprowadzić do całkowitego wyłączenia sieci.\n \n**rlogin (Remote Login)** to protokół, który umożliwia dostęp do zdalnego systemu. Hasło użytkownika przesyłane jest tekstem jawnym, dlatego konieczne jest zabezpieczenie poufności danych. Integralność i autentyczność też są ważne, aby upewnić się, że połączenie nie zostało przejęte przez atakującego a dane nie zostały zmienione. Sam protokół nie zawiera jednak mechanizmów kryptograficznych. Do bezpiecznego korzystania ze zdalnego dostępu należy użyć protokołu, który jest zabezpieczony kryptograficznie, np. SSH.\n \nPodsumowując, DNS i STP wymagają zabezpieczeń autentyczności i integralności, aby uniemożliwić podszywanie się pod systemy i manipulowanie danymi, przy czym ochrona poufności przesyłanych danych nie jest wymagana, gdyż z założenia większość informacji transmitowana jest publicznie."
    },
    {
        "questionId": 425,
        "title": "W przypadku systemu kontroli ACL standardu POSIX użytkownik U należący do grupy G posiada efektywne uprawnienia r do zasobu p jeśli:",
        "answers": [
            {
                "text": "właściciel p ma prawo r oraz p posiada ustawiony bit suid - bez względu na zawartość ACL",
                "isCorrect": false
            },
            {
                "text": "U oraz G występują na liście ACL bez prawa r, ale kategoria \"wszyscy użytkownicy\" (others) takie uprawniania posiada",
                "isCorrect": false
            },
            {
                "text": "prawo r zostanie jawnie nadane U lub G",
                "isCorrect": true
            },
            {
                "text": "U jest właścicielem p - bez względu a zawartość ACL",
                "isCorrect": false
            }
        ],
        "clue": 1,
        "isStarred": false,
        "explanation": "Systemy kontroli dostępu oparte o listy ACL (Access Control Lists) w standardzie POSIX, pozwalają na precyzyjne zarządzanie uprawnieniami do zasobów, np. plików.  Uprawnienia definiuje się dla trzech kategorii: właściciela pliku (user), grupy, do której należy właściciel (group) oraz pozostałych użytkowników (others). Dodatkowo rozszerzony model ACL pozwala określać indywidualne uprawnienia dla wybranych użytkowników lub wybranych grup. Uprawnienia te są określone za pomocą liter: *r* - prawo do odczytu, *w* - prawo do zapisu, *x* - prawo do wykonania (lub przeszukiwania katalogu).  System sprawdza prawa dostępu w określonej kolejności, szukając odpowiedniej reguły pasującej do użytkownika i grupy, żądających dostępu do zasobu. System wykorzystuje tylko jedną regułę - pierwszą pasującą do użytkownika i grupy.\n\n*   **właściciel p ma prawo r oraz p posiada ustawiony bit suid - bez względu na zawartość ACL**\n    Ta odpowiedź jest *niepoprawna*. Ustawienie bitu `setuid` (`suid`) na pliku spowoduje, że w trakcie wykonywania procesu będą wykorzystywane uprawnienia właściciela pliku, a nie uprawnienia użytkownika uruchamiającego plik.  Jednakże bit `setuid` nie ma wpływu na reguły list kontroli dostępu.  System ACL definiuje prawa dostępu do plików, a bit `suid` wpływa na uprawnienia, z jakimi wykonywany jest plik. Ustawienie bitu `suid` nie daje automatycznie nikomu prawa do odczytu pliku, jeśli nie jest ono jawnie przyznane przez ACL. Bit `setuid` ma znaczenie tylko w kontekście wykonywania pliku, a nie dostępu do jego treści. Przykładowo, jeśli program z ustawionym bitem `suid` odczytuje dany plik, to robi to pod uprawnieniami właściciela pliku wykonywalnego, a nie użytkownika wywołującego program, jednak uprawnienie odczytu dla pliku i tak musi być przyznane.\n*  **U oraz G występują na liście ACL bez prawa r, ale kategoria \"wszyscy użytkownicy\" (others) takie uprawniania posiada**\n    Ta odpowiedź jest *niepoprawna*.  System zawsze najpierw sprawdza, czy uprawnienie zostało jawnie przyznane użytkownikowi (`U`) lub grupie (`G`).  Jeżeli takie uprawnienia nie zostały znalezione na liście ACL (a w tej odpowiedzi wyraźnie założono, że nie ma takiego jawnego uprawnienia), to system nie będzie brał pod uwagę uprawnień dla pozostałych użytkowników. Uprawnienia dla \"others\" brane są pod uwagę, tylko wtedy, gdy system nie znajdzie żadnych bardziej szczegółowych reguł. Przykład: Użytkownik `kuba` z grupy `studenci` żąda odczytu pliku `dane.txt`.  ACL nie zawiera wpisu dla użytkownika `kuba`, ani dla grupy `studenci`. Wtedy zostaną sprawdzone uprawnienia dla pozostałych użytkowników (others).\n*  **prawo r zostanie jawnie nadane U lub G**\n     Ta odpowiedź jest *poprawna*.  W systemach POSIX ACL uprawnienia są przyznawane jawnie. Użytkownik `U` będzie miał dostęp do pliku, jeśli jego nazwa lub nazwa grupy, do której należy (`G`), znajdzie się na liście ACL zasobu `p` z *jawnym* przyznaniem uprawnienia `r`.  W tym przypadku system szuka na liście ACL wpisu definiującego prawa dla `U` lub `G` i jeśli takie prawo istnieje i jest ono równe lub większe niż prawo `r` to użytkownik `U` uzyska dostęp do zasobu `p`.  Przykładowo, jeśli na liście ACL znajdzie się wpis `user:kuba:rw-`, to użytkownik o nazwie `kuba` będzie miał prawo do odczytu (r) i zapisu (w).  Również, gdy na liście znajdzie się wpis `group:studenci:r--`, to każdy użytkownik z grupy `studenci` będzie miał prawo do odczytu (r), lecz nie zapisu (w). W systemie POSIX nie istnieje domyślne prawo dostępu. Jeśli na liście ACL nie ma konkretnego wpisu dla danego użytkownika lub grupy, dostęp nie jest przyznany (domyślnie jest on zabroniony).\n*   **U jest właścicielem p - bez względu a zawartość ACL**\n     Ta odpowiedź jest *niepoprawna*. Właściciel obiektu ma domyślne prawa dostępu, które są określone przez litery (rwx) ale system *zawsze* patrzy czy nie ma uprawnień w rozszerzonej liście ACL, a dopiero po ich sprawdzeniu bierze pod uwagę uprawnienia standardowe. Przykładowo, jeśli na liście ACL znajdzie się wpis `user:kuba:-w-`, to właściciel o nazwie `kuba` będzie miał wyłączone prawo zapisu (w). Pomimo bycia właścicielem nie będzie mógł zapisać pliku."
    },
    {
        "questionId": 426,
        "title": "Atak Slow Read:",
        "answers": [
            {
                "text": "wymusza nienaturalnie długie podtrzymywanie połączenia TCP",
                "isCorrect": true
            },
            {
                "text": "manipuluje mechanizmami rozmiaru segmentu oraz okna TCP do spowolnienia komunikacji",
                "isCorrect": true
            },
            {
                "text": "wykorzystuje funkcję masqarade w iptables w celu nieautoryzowanego ograniczenia przepustowości ruchu skierowanego do atakowanej aplikacji",
                "isCorrect": false
            },
            {
                "text": "blokuje komunikację sieciową poprzez radykalne zmniejszenie buforów gniazd socketów",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Atak Slow Read wykorzystuje mechanizm protokołu TCP, który jest odpowiedzialny za niezawodny przesył danych. Mechanizm ten zakłada, że po odebraniu danych, odbiorca przesyła potwierdzenie do nadawcy. Nadawca na podstawie otrzymanego potwierdzenia, że dane zostały dostarczone bez błędów wysyła kolejne dane. Jeśli dane nie zostaną potwierdzone, nadawca ponownie wyśle dane. Mechanizm ten ma za zadanie zapewnić, że wszystkie dane dotrą do odbiorcy i że żadne dane nie zostaną utracone w transmiji. Oprócz mechanizmu potwierdzania prawidłowo przesłanych danych, TCP wykorzystuje mechanizm okna TCP. Mechanizm ten ma usprawnić przepustowość sieci. Mechanizm ten definiuje liczbę danych, które mogą zostać wysłane bez potwierdzenia. Dzięki temu mechanizmowi nadawca może przesłać wiele pakietów, a dopiero potem spodziewać się potwierdzenia poprawności tych pakietów. \nAtak Slow Read wykorzystuje te dwie właściwości protokołu TCP i ma na celu doprowadzić do odmowy dostępu do usługi poprzez wyczerpanie zasobów serwera. W ataku tym napastnik inicjuje połączenie z serwerem a następnie deklaruje, że akceptuje dane od serwera, ale odbiera te dane bardzo powoli. W ten sposób serwer po przesłaniu całego okna TCP musi zaczekać z dalszą transmisją, aż klient potwierdzi odbiór. Mechanizm TCP zakłada, że z natury rzeczy odbiór jest natychmiastowy i klient odbierając dane normalnie przesyła niezwłocznie potwierdzenie odebrania danych, dzięki czemu nadawca może dalej przesyłać dane. Atak Slow Read celowo opóźnia odbiór danych, serwer jest zmuszony czekać na potwierdzenie i dzięki temu zasoby serwera zajęte do obsługi tego połączenia są przez cały ten czas rezerwowane. W momencie, gdy liczba takich połączeń wzrośnie zasoby serwera zostaną całkowicie wyczerpane co w efekcie spowoduje jego niedostępność. \n\n*   **\"wymusza nienaturalnie długie podtrzymywanie połączenia TCP\"** - Jest to **prawidłowa** odpowiedź, ponieważ istota ataku Slow Read polega właśnie na tym, że atakujący celowo bardzo wolno odczytuje dane od serwera. Powoduje to sytuację w której serwer jest zmuszony do utrzymywania otwartego połączenia TCP przez nienaturalnie długi czas. Serwer alokuje zasoby dla każdego takiego połączenia, a te zasoby mogą zostać wyczerpane. W rezultacie serwer staje się niedostępny dla normalnych użytkowników.\n\n*   **\"manipuluje mechanizmami rozmiaru segmentu oraz okna TCP do spowolnienia komunikacji\"** - Jest to również **prawidłowa** odpowiedź. Rozmiar segmentu TCP, znany jako MSS (_Maximum Segment Size_), jest negocjowany podczas ustanawiania połączenia, podobnie jak wielkość okna TCP. Podczas ataku Slow Read atakujący deklaruje, że jego okno TCP jest duże, ale odczytuje dane bardzo powoli, co powoduje że serwer przesyła dane a atakujący je ignoruje. Wykorzystując w ten sposób właściwości protokołu TCP atakujący spowalnia komunikację i wyczerpuje zasoby serwera.\n\n*   **\"wykorzystuje funkcję masqarade w iptables w celu nieautoryzowanego ograniczenia przepustowości ruchu skierowanego do atakowanej aplikacji\"** - Jest to **niepoprawna** odpowiedź. Masquerade w iptables jest mechanizmem NAT (_Network Address Translation_), który umożliwia sieci lokalnej (z adresami prywatnymi) dostęp do Internetu poprzez ukrywanie adresów wewnętrznych za adresem publicznym rutera. Natomiast atak slow read nie polega na zmianie adresu źródłowego, ten atak polega na wolnym odczytywaniu danych i celowe wykorzystywanie mechanizmu okna TCP. Iptables, mimo, że jest to bardzo rozbudowany firewall, nie kontroluje sposobu w jaki dana aplikacja czyta dane ze strumienia danych, ma ona jedynie kontrolę nad tym, jakie dane mogą docierać do portów na których działa program, ale nie ma możliwości sterowania, w jaki sposób aplikacja przetwarza dane po stronie serwera. \n\n*   **\"blokuje komunikację sieciową poprzez radykalne zmniejszenie buforów gniazd socketów\"** - Jest to **niepoprawna** odpowiedź. Buffory gniazd (_ang. socket buffers_) to pamięć w jądrze systemu operacyjnego, w której przechowywane są dane przeznaczone do przesłania lub właśnie odebrane z sieci. Atakujący przy ataku Slow Read nie manipuluje wielkością buforów. Klient podczas ataku poprawnie deklaruje okno TCP ale nie odczytuje danych, przez co te dane trafiają do bufora i zajmują go. Bufor jest mechanizmem działającym na serwerze nie na kliencie. Atakujący wykorzystuje to, że serwer wysyła dane a one są zatrzymane i nie są odbierane, co w efekcie prowadzi do wyczerpania zasobów serwera."
    },
    {
        "questionId": 427,
        "title": "Wskaż cechy charakteryzujące kontrolę dostępu MAC:",
        "answers": [
            {
                "text": "tylko wyróżniony oficer bezpieczeństwa może dysponować prawami dostępu do zasobu",
                "isCorrect": true
            },
            {
                "text": "właściciel zasobu nie może dysponować prawami dostępu do tego zasobu",
                "isCorrect": true
            },
            {
                "text": "etykiety ochrony danych przypisane do zasobów automatycznie wymuszają uprawniania",
                "isCorrect": false
            },
            {
                "text": "tylko właściciel zasobu może dysponować prawami dostępu do tego zasobu",
                "isCorrect": false
            }
        ],
        "clue": 2,
        "isStarred": false,
        "explanation": "Mandatory Access Control (MAC) to model kontroli dostępu, w którym uprawnienia nie są nadawane przez właściciela zasobu, lecz są konsekwencją ścisłych, odgórnie ustalonych reguł bezpieczeństwa narzuconych przez system. W MAC, centralna polityka bezpieczeństwa określa, kto i do jakich danych ma dostęp, w zależności od poziomu zaufania (ang. *sensitivity labels*) przypisanych do zasobów i użytkowników, a nie przez decyzję właściciela obiektu.\n\n**Odpowiedź 1: \"tylko wyróżniony oficer bezpieczeństwa może dysponować prawami dostępu do zasobu\"**\n\nJest to odpowiedź **poprawna**.  W systemach MAC, uprawnienia dostępu do zasobów są regulowane na poziomie centralnej polityki bezpieczeństwa, gdzie oficerowie bezpieczeństwa, czyli administratorzy systemu posiadają uprawnienia do ustawiania reguł.  Nie oznacza to, że  oficer bezpieczeństwa będzie miał dostęp do wszystkich danych, a jedynie, że to on decyduje o polityce bezpieczeństwa w systemie MAC.  Oficer bezpieczeństwa konfiguruje, które kategorie danych, z jakimi poziomami zaufania, mogą być dostępne dla użytkowników o danym poziomie uprawnień.\n\n**Odpowiedź 2: \"właściciel zasobu nie może dysponować prawami dostępu do tego zasobu\"**\n\nJest to odpowiedź **poprawna**. W MAC, nawet właściciel zasobu nie ma prawa decydować o jego uprawnieniach. Uprawnienia są nadawane na podstawie reguł polityki bezpieczeństwa, które nie są zależne od woli właściciela zasobu. Właściciel zasobu (czyli osoba która stworzyła zasób) może nadal mieć dostęp do zasobu ale na podstawie reguł zdefiniowanych przez oficera bezpieczeństwa.  Ta zasada różni MAC od DAC. Przykładowo, w systemie MAC właściciel pliku oznaczonym jako \"ściśle tajne\",  nawet jeśli jest administratorem,  nie może zmienić  jego etykiety na \"poufne\",  ani tym bardziej udostępnić zasobu użytkownikom o  niższym poziomie zaufania. Decyzja, kto ma dostęp i na jakim poziomie, leży po stronie konfiguracji systemu MAC, a nie właściciela pliku.\n\n**Odpowiedź 3: \"etykiety ochrony danych przypisane do zasobów automatycznie wymuszają uprawniania\"**\n\nJest to odpowiedź **niepoprawna**. Mimo, iż etykiety ochrony danych są integralną częścią systemu MAC, etykiety ochrony danych nie wymuszają uprawnień automatycznie. Etykiety ochrony danych zawierają w sobie poziom zaufania i kategorię informacji. Te informacje służą do określenia uprawnień dostępu ale same w sobie uprawnień nie wymuszają. Wymuszeniem uprawnień zajmują się mechanizmy zawarte w polityce bezpieczeństwa MAC na podstawie etykiet ochrony danych.\n\n**Odpowiedź 4: \"tylko właściciel zasobu może dysponować prawami dostępu do tego zasobu\"**\n\nJest to odpowiedź **niepoprawna**. Ta cecha jest charakterystyczna dla Discretionary Access Control (DAC), gdzie właściciel zasobu ma kontrolę nad tym, kto może go używać. W systemie MAC to polityka bezpieczeństwa narzuca zasady i właściciel nie ma władzy do ich zmiany. Przykładowo,  w systemie DAC  użytkownik, który stworzył folder na dysku może dać dostęp do niego dowolnej innej osobie w systemie. W systemie MAC właściciel folderu nie miałby takiej możliwości jeśli centralna polityka bezpieczeństwa tego nie przewiduje."
    },
    {
        "questionId": 428,
        "title": "Moduł sprzętowy Trusted Platform Module (TPM):",
        "answers": [
            {
                "text": "ma wbudowane wybrane operacje kryptograficzne, wykonywane wewnętrznie",
                "isCorrect": true
            },
            {
                "text": "umożliwia przechowywanie danych biometrycznych",
                "isCorrect": true
            },
            {
                "text": "umożliwia przechowywanie kluczy kryptograficznych",
                "isCorrect": true
            },
            {
                "text": "z założenia ma uniemożliwiać sprzętowe ataki inwazyjne na zawartość swojej pamięci",
                "isCorrect": true
            }
        ],
        "clue": 4,
        "isStarred": false,
        "explanation": "Moduł Trusted Platform Module (TPM) to specjalizowany mikroukład sprzętowy zaprojektowany w celu zwiększenia bezpieczeństwa systemów komputerowych. TPM implementuje w sprzęcie kluczowe funkcje kryptograficzne, bezpiecznie przechowuje wrażliwe dane oraz chroni system przed niektórymi fizycznymi atakami. TPM nie jest samodzielnym komputerem, lecz komponentem wykonującym specyficzne zadania związane z bezpieczeństwem.\n\n**Odpowiedź 1: \"ma wbudowane wybrane operacje kryptograficzne, wykonywane wewnętrznie\" jest poprawna.** TPM zawiera w sobie dedykowany procesor kryptograficzny, który jest zdolny do wykonywania operacji kryptograficznych takich jak generowanie kluczy, podpisy cyfrowe, szyfrowanie oraz deszyfrowanie. Te operacje są wykonywane wewnątrz modułu, co czyni je bardziej odpornymi na próby ataku z zewnątrz. Praktycznym przykładem jest szyfrowanie danych za pomocą kluczy przechowywanych w TPM, co uniemożliwia dostęp do tych danych w przypadku próby ich odczytu z dysku twardego bez użycia TPM.\n\n**Odpowiedź 2: \"umożliwia przechowywanie danych biometrycznych\" jest poprawna.** Chociaż głównym zadaniem TPM jest przechowywanie kluczy kryptograficznych to wiele implementacji TPM umożliwia również przechowywanie danych biometrycznych takich jak np. odcisk palca czy skan tęczówki oka, co jest wykorzystywane w celu zwiększenia poziomu bezpieczeństwa identyfikacji użytkownika systemu. Przykładowo system logowania w laptopie może wymagać odcisku palca, a informacja na temat zarejestrowanego odcisku palca jest chroniona w module TPM.\n\n**Odpowiedź 3: \"umożliwia przechowywanie kluczy kryptograficznych\" jest poprawna.** TPM jest zaprojektowany do bezpiecznego przechowywania kluczy kryptograficznych. Klucze te mogą być używane do różnych celów, np. szyfrowania danych na dysku, podpisywania plików, uwierzytelniania w sieci. Klucze w TPM są odporne na manipulacje programowe (np. ataki hakerskie), ponieważ są przechowywane w wydzielonej, fizycznie chronionej pamięci w module TPM. Na przykład klucz szyfrujący dysk może być przechowywany w TPM, co uniemożliwia odczytanie zawartości dysku, nawet jeśli zostanie fizycznie wyjęty z komputera i podłączony do innego urządzenia. \n\n**Odpowiedź 4: \"z założenia ma uniemożliwiać sprzętowe ataki inwazyjne na zawartość swojej pamięci\" jest poprawna.** TPM jest zaprojektowany, aby chronić się przed fizycznymi atakami. Modyfikacja TPM wymagałaby zaawansowanych technik inżynierii wstecznej i specjalistycznego sprzętu, co czyni takie ataki bardzo trudne i kosztowne do zrealizowania. TPM jest odporny na ataki, które polegają na bezpośrednim odczytaniu zawartości pamięci, a informacje zawarte w TPM (klucze i dane biometryczne) nie są dostępne z zewnątrz, nawet jeśli posiadamy dostęp do pamięci, gdzie są te informacje umieszczone. Przykładowo za pomocą specjalistycznego sprzętu można poddać analizie zawartość kości pamięci w celu wyciągnięcia z niej np. kluczy, jednak w przypadku TPM jest to znacznie utrudnione, a w wielu przypadkach niemożliwe.\n\nWszystkie cztery odpowiedzi są poprawne i opisują kluczowe aspekty działania i możliwości modułu TPM."
    }
]